[2022-06-07 00:23:38,953] {processor.py:153} INFO - Started process (PID=15565) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 00:23:38,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 00:23:38,959] {logging_mixin.py:115} INFO - [2022-06-07 00:23:38,959] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 00:23:39,181] {logging_mixin.py:115} INFO - [2022-06-07 00:23:39,171] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 00:23:39,183] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 00:23:39,557] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.624 seconds
[2022-06-07 02:00:07,939] {processor.py:153} INFO - Started process (PID=15632) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 02:00:07,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 02:00:07,943] {logging_mixin.py:115} INFO - [2022-06-07 02:00:07,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 02:00:08,187] {logging_mixin.py:115} INFO - [2022-06-07 02:00:08,175] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 02:00:08,189] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 02:00:08,589] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.657 seconds
[2022-06-07 03:21:44,403] {processor.py:153} INFO - Started process (PID=15691) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 03:21:44,405] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 03:21:44,407] {logging_mixin.py:115} INFO - [2022-06-07 03:21:44,407] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 03:21:44,548] {logging_mixin.py:115} INFO - [2022-06-07 03:21:44,541] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 03:21:44,550] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 03:21:44,739] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.339 seconds
[2022-06-07 04:11:05,896] {processor.py:153} INFO - Started process (PID=15758) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:11:05,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:11:05,912] {logging_mixin.py:115} INFO - [2022-06-07 04:11:05,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:11:06,335] {logging_mixin.py:115} INFO - [2022-06-07 04:11:06,312] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:11:06,348] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:11:06,680] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.800 seconds
[2022-06-07 04:11:37,516] {processor.py:153} INFO - Started process (PID=15816) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:11:37,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:11:37,519] {logging_mixin.py:115} INFO - [2022-06-07 04:11:37,519] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:11:37,580] {logging_mixin.py:115} INFO - [2022-06-07 04:11:37,578] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:11:37,582] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:11:37,682] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 04:12:08,670] {processor.py:153} INFO - Started process (PID=15882) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:12:08,674] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:12:08,675] {logging_mixin.py:115} INFO - [2022-06-07 04:12:08,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:12:08,736] {logging_mixin.py:115} INFO - [2022-06-07 04:12:08,734] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:12:08,738] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:12:08,832] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 04:12:39,571] {processor.py:153} INFO - Started process (PID=15950) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:12:39,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:12:39,575] {logging_mixin.py:115} INFO - [2022-06-07 04:12:39,575] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:12:39,632] {logging_mixin.py:115} INFO - [2022-06-07 04:12:39,630] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:12:39,633] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:12:39,729] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 04:13:09,762] {processor.py:153} INFO - Started process (PID=16020) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:13:09,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:13:09,766] {logging_mixin.py:115} INFO - [2022-06-07 04:13:09,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:13:09,822] {logging_mixin.py:115} INFO - [2022-06-07 04:13:09,818] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:13:09,824] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:13:09,936] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 04:13:40,039] {processor.py:153} INFO - Started process (PID=16087) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:13:40,044] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:13:40,045] {logging_mixin.py:115} INFO - [2022-06-07 04:13:40,045] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:13:40,104] {logging_mixin.py:115} INFO - [2022-06-07 04:13:40,101] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:13:40,105] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:13:40,198] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-07 04:14:10,405] {processor.py:153} INFO - Started process (PID=16152) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:14:10,407] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:14:10,407] {logging_mixin.py:115} INFO - [2022-06-07 04:14:10,407] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:14:10,454] {logging_mixin.py:115} INFO - [2022-06-07 04:14:10,452] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:14:10,456] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:14:10,559] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-07 04:14:40,723] {processor.py:153} INFO - Started process (PID=16209) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:14:40,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:14:40,729] {logging_mixin.py:115} INFO - [2022-06-07 04:14:40,728] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:14:40,793] {logging_mixin.py:115} INFO - [2022-06-07 04:14:40,790] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:14:40,794] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:14:40,887] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 04:15:11,544] {processor.py:153} INFO - Started process (PID=16275) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:15:11,545] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:15:11,546] {logging_mixin.py:115} INFO - [2022-06-07 04:15:11,546] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:15:11,609] {logging_mixin.py:115} INFO - [2022-06-07 04:15:11,607] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:15:11,610] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:15:11,702] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 04:15:42,441] {processor.py:153} INFO - Started process (PID=16344) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:15:42,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:15:42,444] {logging_mixin.py:115} INFO - [2022-06-07 04:15:42,443] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:15:42,495] {logging_mixin.py:115} INFO - [2022-06-07 04:15:42,492] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:15:42,496] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:15:42,605] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-07 04:16:13,394] {processor.py:153} INFO - Started process (PID=16413) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:16:13,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:16:13,400] {logging_mixin.py:115} INFO - [2022-06-07 04:16:13,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:16:13,459] {logging_mixin.py:115} INFO - [2022-06-07 04:16:13,457] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:16:13,461] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:16:13,560] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 04:16:44,199] {processor.py:153} INFO - Started process (PID=16484) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:16:44,202] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:16:44,204] {logging_mixin.py:115} INFO - [2022-06-07 04:16:44,204] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:16:44,269] {logging_mixin.py:115} INFO - [2022-06-07 04:16:44,266] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:16:44,270] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:16:44,367] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 04:17:15,242] {processor.py:153} INFO - Started process (PID=16549) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:17:15,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:17:15,249] {logging_mixin.py:115} INFO - [2022-06-07 04:17:15,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:17:15,308] {logging_mixin.py:115} INFO - [2022-06-07 04:17:15,306] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:17:15,309] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:17:15,403] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 04:17:45,482] {processor.py:153} INFO - Started process (PID=16606) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:17:45,484] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:17:45,487] {logging_mixin.py:115} INFO - [2022-06-07 04:17:45,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:17:45,549] {logging_mixin.py:115} INFO - [2022-06-07 04:17:45,546] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:17:45,551] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:17:45,643] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 04:18:15,741] {processor.py:153} INFO - Started process (PID=16677) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:18:15,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:18:15,746] {logging_mixin.py:115} INFO - [2022-06-07 04:18:15,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:18:15,806] {logging_mixin.py:115} INFO - [2022-06-07 04:18:15,804] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:18:15,807] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:18:15,904] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 04:18:46,051] {processor.py:153} INFO - Started process (PID=16748) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:18:46,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:18:46,058] {logging_mixin.py:115} INFO - [2022-06-07 04:18:46,058] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:18:46,130] {logging_mixin.py:115} INFO - [2022-06-07 04:18:46,126] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:18:46,132] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:18:46,238] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-07 04:19:16,455] {processor.py:153} INFO - Started process (PID=16814) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:19:16,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:19:16,461] {logging_mixin.py:115} INFO - [2022-06-07 04:19:16,461] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:19:16,524] {logging_mixin.py:115} INFO - [2022-06-07 04:19:16,522] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:19:16,525] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:19:16,618] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 04:19:46,916] {processor.py:153} INFO - Started process (PID=16881) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:19:46,918] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:19:46,924] {logging_mixin.py:115} INFO - [2022-06-07 04:19:46,924] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:19:47,010] {logging_mixin.py:115} INFO - [2022-06-07 04:19:47,007] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:19:47,012] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:19:47,114] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-07 04:20:17,403] {processor.py:153} INFO - Started process (PID=16937) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:20:17,404] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:20:17,406] {logging_mixin.py:115} INFO - [2022-06-07 04:20:17,406] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:20:17,517] {logging_mixin.py:115} INFO - [2022-06-07 04:20:17,512] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:20:17,519] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:20:17,652] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-07 04:20:48,670] {processor.py:153} INFO - Started process (PID=17005) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:20:48,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:20:48,677] {logging_mixin.py:115} INFO - [2022-06-07 04:20:48,677] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:20:48,820] {logging_mixin.py:115} INFO - [2022-06-07 04:20:48,813] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:20:48,825] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:20:48,978] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.313 seconds
[2022-06-07 04:21:19,313] {processor.py:153} INFO - Started process (PID=17075) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:21:19,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:21:19,319] {logging_mixin.py:115} INFO - [2022-06-07 04:21:19,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:21:19,443] {logging_mixin.py:115} INFO - [2022-06-07 04:21:19,440] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:21:19,445] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:21:19,594] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.290 seconds
[2022-06-07 04:21:50,133] {processor.py:153} INFO - Started process (PID=17143) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:21:50,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:21:50,136] {logging_mixin.py:115} INFO - [2022-06-07 04:21:50,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:21:50,234] {logging_mixin.py:115} INFO - [2022-06-07 04:21:50,231] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:21:50,236] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:21:50,426] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.301 seconds
[2022-06-07 04:22:20,716] {processor.py:153} INFO - Started process (PID=17209) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:22:20,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:22:20,720] {logging_mixin.py:115} INFO - [2022-06-07 04:22:20,720] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:22:20,826] {logging_mixin.py:115} INFO - [2022-06-07 04:22:20,820] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:22:20,827] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:22:20,943] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.242 seconds
[2022-06-07 04:22:51,216] {processor.py:153} INFO - Started process (PID=17267) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:22:51,218] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:22:51,220] {logging_mixin.py:115} INFO - [2022-06-07 04:22:51,220] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:22:51,316] {logging_mixin.py:115} INFO - [2022-06-07 04:22:51,313] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:22:51,318] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:22:51,428] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-07 04:23:22,400] {processor.py:153} INFO - Started process (PID=17334) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:23:22,402] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:23:22,404] {logging_mixin.py:115} INFO - [2022-06-07 04:23:22,404] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:23:22,487] {logging_mixin.py:115} INFO - [2022-06-07 04:23:22,484] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:23:22,488] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:23:22,618] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-07 04:23:52,982] {processor.py:153} INFO - Started process (PID=17403) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:23:52,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:23:52,985] {logging_mixin.py:115} INFO - [2022-06-07 04:23:52,985] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:23:53,085] {logging_mixin.py:115} INFO - [2022-06-07 04:23:53,083] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:23:53,086] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:23:53,223] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-07 04:24:23,462] {processor.py:153} INFO - Started process (PID=17474) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:24:23,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:24:23,466] {logging_mixin.py:115} INFO - [2022-06-07 04:24:23,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:24:23,587] {logging_mixin.py:115} INFO - [2022-06-07 04:24:23,583] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:24:23,597] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:24:23,778] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.322 seconds
[2022-06-07 04:24:54,198] {processor.py:153} INFO - Started process (PID=17533) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:24:54,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:24:54,202] {logging_mixin.py:115} INFO - [2022-06-07 04:24:54,202] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:24:54,285] {logging_mixin.py:115} INFO - [2022-06-07 04:24:54,281] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:24:54,287] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:24:54,429] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-07 04:25:25,254] {processor.py:153} INFO - Started process (PID=17602) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:25:25,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:25:25,263] {logging_mixin.py:115} INFO - [2022-06-07 04:25:25,263] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:25:25,516] {logging_mixin.py:115} INFO - [2022-06-07 04:25:25,511] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:25:25,525] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:25:25,801] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.559 seconds
[2022-06-07 04:25:56,442] {processor.py:153} INFO - Started process (PID=17671) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:25:56,445] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:25:56,446] {logging_mixin.py:115} INFO - [2022-06-07 04:25:56,446] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:25:56,565] {logging_mixin.py:115} INFO - [2022-06-07 04:25:56,563] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:25:56,566] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:25:56,697] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.260 seconds
[2022-06-07 04:26:26,838] {processor.py:153} INFO - Started process (PID=17729) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:26:26,840] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:26:26,841] {logging_mixin.py:115} INFO - [2022-06-07 04:26:26,841] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:26:26,923] {logging_mixin.py:115} INFO - [2022-06-07 04:26:26,921] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:26:26,925] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:26:27,044] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-07 04:26:58,012] {processor.py:153} INFO - Started process (PID=17797) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:26:58,015] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:26:58,017] {logging_mixin.py:115} INFO - [2022-06-07 04:26:58,017] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:26:58,090] {logging_mixin.py:115} INFO - [2022-06-07 04:26:58,087] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:26:58,091] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:26:58,191] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-07 04:27:28,547] {processor.py:153} INFO - Started process (PID=17864) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:27:28,550] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:27:28,552] {logging_mixin.py:115} INFO - [2022-06-07 04:27:28,552] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:27:28,647] {logging_mixin.py:115} INFO - [2022-06-07 04:27:28,643] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:27:28,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:27:28,762] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-07 04:27:59,673] {processor.py:153} INFO - Started process (PID=17930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:27:59,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:27:59,678] {logging_mixin.py:115} INFO - [2022-06-07 04:27:59,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:27:59,812] {logging_mixin.py:115} INFO - [2022-06-07 04:27:59,807] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:27:59,816] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:27:59,964] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.301 seconds
[2022-06-07 04:28:30,748] {processor.py:153} INFO - Started process (PID=18000) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:28:30,757] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:28:30,759] {logging_mixin.py:115} INFO - [2022-06-07 04:28:30,759] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:28:30,900] {logging_mixin.py:115} INFO - [2022-06-07 04:28:30,896] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:28:30,902] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:28:31,096] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.364 seconds
[2022-06-07 04:29:01,922] {processor.py:153} INFO - Started process (PID=18057) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:29:01,924] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:29:01,925] {logging_mixin.py:115} INFO - [2022-06-07 04:29:01,925] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:29:02,011] {logging_mixin.py:115} INFO - [2022-06-07 04:29:02,008] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:29:02,012] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:29:02,123] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.205 seconds
[2022-06-07 04:29:32,599] {processor.py:153} INFO - Started process (PID=18124) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:29:32,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:29:32,604] {logging_mixin.py:115} INFO - [2022-06-07 04:29:32,604] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:29:32,692] {logging_mixin.py:115} INFO - [2022-06-07 04:29:32,690] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:29:32,693] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:29:32,814] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-07 04:30:03,578] {processor.py:153} INFO - Started process (PID=18191) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:30:03,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:30:03,585] {logging_mixin.py:115} INFO - [2022-06-07 04:30:03,585] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:30:03,692] {logging_mixin.py:115} INFO - [2022-06-07 04:30:03,687] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:30:03,696] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:30:03,829] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.258 seconds
[2022-06-07 04:30:34,532] {processor.py:153} INFO - Started process (PID=18257) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:30:34,539] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:30:34,540] {logging_mixin.py:115} INFO - [2022-06-07 04:30:34,540] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:30:34,628] {logging_mixin.py:115} INFO - [2022-06-07 04:30:34,625] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:30:34,629] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:30:34,744] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-07 04:31:05,538] {processor.py:153} INFO - Started process (PID=18323) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:31:05,542] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:31:05,548] {logging_mixin.py:115} INFO - [2022-06-07 04:31:05,547] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:31:05,728] {logging_mixin.py:115} INFO - [2022-06-07 04:31:05,718] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:31:05,732] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:31:05,958] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.433 seconds
[2022-06-07 04:31:36,436] {processor.py:153} INFO - Started process (PID=18382) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:31:36,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:31:36,444] {logging_mixin.py:115} INFO - [2022-06-07 04:31:36,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:31:36,575] {logging_mixin.py:115} INFO - [2022-06-07 04:31:36,564] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:31:36,577] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:31:36,737] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.309 seconds
[2022-06-07 04:32:07,408] {processor.py:153} INFO - Started process (PID=18448) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:32:07,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:32:07,415] {logging_mixin.py:115} INFO - [2022-06-07 04:32:07,415] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:32:07,525] {logging_mixin.py:115} INFO - [2022-06-07 04:32:07,522] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:32:07,527] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:32:07,658] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-07 04:32:38,180] {processor.py:153} INFO - Started process (PID=18514) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:32:38,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:32:38,183] {logging_mixin.py:115} INFO - [2022-06-07 04:32:38,183] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:32:38,277] {logging_mixin.py:115} INFO - [2022-06-07 04:32:38,275] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:32:38,279] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:32:38,396] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-07 04:33:08,891] {processor.py:153} INFO - Started process (PID=18579) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:33:08,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:33:08,895] {logging_mixin.py:115} INFO - [2022-06-07 04:33:08,895] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:33:08,996] {logging_mixin.py:115} INFO - [2022-06-07 04:33:08,993] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:33:08,998] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:33:09,121] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-07 04:33:39,341] {processor.py:153} INFO - Started process (PID=18640) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:33:39,344] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:33:39,347] {logging_mixin.py:115} INFO - [2022-06-07 04:33:39,346] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:33:39,428] {logging_mixin.py:115} INFO - [2022-06-07 04:33:39,425] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:33:39,431] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:33:39,545] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-07 04:34:10,227] {processor.py:153} INFO - Started process (PID=18706) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:34:10,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:34:10,230] {logging_mixin.py:115} INFO - [2022-06-07 04:34:10,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:34:10,338] {logging_mixin.py:115} INFO - [2022-06-07 04:34:10,335] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:34:10,340] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:34:10,453] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-07 04:34:40,515] {processor.py:153} INFO - Started process (PID=18775) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:34:40,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:34:40,522] {logging_mixin.py:115} INFO - [2022-06-07 04:34:40,521] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:34:40,629] {logging_mixin.py:115} INFO - [2022-06-07 04:34:40,625] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:34:40,631] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:34:40,762] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-07 04:35:11,170] {processor.py:153} INFO - Started process (PID=18843) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:35:11,173] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:35:11,175] {logging_mixin.py:115} INFO - [2022-06-07 04:35:11,175] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:35:11,288] {logging_mixin.py:115} INFO - [2022-06-07 04:35:11,285] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:35:11,291] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:35:11,443] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.280 seconds
[2022-06-07 04:35:42,303] {processor.py:153} INFO - Started process (PID=18901) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:35:42,312] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:35:42,314] {logging_mixin.py:115} INFO - [2022-06-07 04:35:42,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:35:42,417] {logging_mixin.py:115} INFO - [2022-06-07 04:35:42,412] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:35:42,419] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:35:42,565] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.269 seconds
[2022-06-07 04:36:12,843] {processor.py:153} INFO - Started process (PID=18973) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:36:12,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:36:12,847] {logging_mixin.py:115} INFO - [2022-06-07 04:36:12,846] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:36:13,013] {logging_mixin.py:115} INFO - [2022-06-07 04:36:12,998] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:36:13,020] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:36:13,262] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.422 seconds
[2022-06-07 04:36:43,488] {processor.py:153} INFO - Started process (PID=19042) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:36:43,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:36:43,499] {logging_mixin.py:115} INFO - [2022-06-07 04:36:43,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:36:43,594] {logging_mixin.py:115} INFO - [2022-06-07 04:36:43,591] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:36:43,596] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:36:43,709] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-07 04:37:14,406] {processor.py:153} INFO - Started process (PID=19108) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:37:14,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:37:14,411] {logging_mixin.py:115} INFO - [2022-06-07 04:37:14,410] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:37:14,489] {logging_mixin.py:115} INFO - [2022-06-07 04:37:14,485] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:37:14,493] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:37:14,658] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-07 04:37:44,952] {processor.py:153} INFO - Started process (PID=19169) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:37:44,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:37:44,957] {logging_mixin.py:115} INFO - [2022-06-07 04:37:44,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:37:45,047] {logging_mixin.py:115} INFO - [2022-06-07 04:37:45,044] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:37:45,049] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:37:45,173] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-07 04:38:15,653] {processor.py:153} INFO - Started process (PID=19234) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:38:15,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:38:15,657] {logging_mixin.py:115} INFO - [2022-06-07 04:38:15,657] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:38:15,750] {logging_mixin.py:115} INFO - [2022-06-07 04:38:15,747] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:38:15,751] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:38:15,859] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-07 04:38:46,123] {processor.py:153} INFO - Started process (PID=19301) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:38:46,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:38:46,128] {logging_mixin.py:115} INFO - [2022-06-07 04:38:46,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:38:46,226] {logging_mixin.py:115} INFO - [2022-06-07 04:38:46,223] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:38:46,228] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:38:46,343] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-07 04:39:17,291] {processor.py:153} INFO - Started process (PID=19368) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:39:17,295] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:39:17,303] {logging_mixin.py:115} INFO - [2022-06-07 04:39:17,300] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:39:17,406] {logging_mixin.py:115} INFO - [2022-06-07 04:39:17,400] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:39:17,407] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:39:17,521] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.248 seconds
[2022-06-07 04:39:48,013] {processor.py:153} INFO - Started process (PID=19434) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:39:48,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:39:48,017] {logging_mixin.py:115} INFO - [2022-06-07 04:39:48,017] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:39:48,133] {logging_mixin.py:115} INFO - [2022-06-07 04:39:48,129] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:39:48,135] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:39:48,298] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.289 seconds
[2022-06-07 04:40:18,476] {processor.py:153} INFO - Started process (PID=19492) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:40:18,479] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:40:18,484] {logging_mixin.py:115} INFO - [2022-06-07 04:40:18,483] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:40:18,588] {logging_mixin.py:115} INFO - [2022-06-07 04:40:18,584] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:40:18,591] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:40:18,750] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.283 seconds
[2022-06-07 04:40:48,941] {processor.py:153} INFO - Started process (PID=19561) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:40:48,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:40:48,944] {logging_mixin.py:115} INFO - [2022-06-07 04:40:48,944] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:40:49,039] {logging_mixin.py:115} INFO - [2022-06-07 04:40:49,036] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:40:49,041] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:40:49,183] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-07 04:41:20,114] {processor.py:153} INFO - Started process (PID=19630) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:41:20,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:41:20,118] {logging_mixin.py:115} INFO - [2022-06-07 04:41:20,118] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:41:20,194] {logging_mixin.py:115} INFO - [2022-06-07 04:41:20,191] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:41:20,195] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:41:20,293] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 04:41:50,376] {processor.py:153} INFO - Started process (PID=19700) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:41:50,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:41:50,378] {logging_mixin.py:115} INFO - [2022-06-07 04:41:50,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:41:50,449] {logging_mixin.py:115} INFO - [2022-06-07 04:41:50,446] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:41:50,451] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:41:50,544] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 04:42:20,689] {processor.py:153} INFO - Started process (PID=19767) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:42:20,692] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:42:20,693] {logging_mixin.py:115} INFO - [2022-06-07 04:42:20,693] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:42:20,808] {logging_mixin.py:115} INFO - [2022-06-07 04:42:20,805] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:42:20,810] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:42:20,940] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-07 04:42:51,173] {processor.py:153} INFO - Started process (PID=19826) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:42:51,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:42:51,179] {logging_mixin.py:115} INFO - [2022-06-07 04:42:51,179] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:42:51,324] {logging_mixin.py:115} INFO - [2022-06-07 04:42:51,313] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:42:51,325] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:42:51,482] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.322 seconds
[2022-06-07 04:43:21,841] {processor.py:153} INFO - Started process (PID=19894) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:43:21,843] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:43:21,845] {logging_mixin.py:115} INFO - [2022-06-07 04:43:21,845] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:43:21,978] {logging_mixin.py:115} INFO - [2022-06-07 04:43:21,973] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:43:21,979] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:43:22,105] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.270 seconds
[2022-06-07 04:43:52,263] {processor.py:153} INFO - Started process (PID=19960) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:43:52,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:43:52,266] {logging_mixin.py:115} INFO - [2022-06-07 04:43:52,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:43:52,324] {logging_mixin.py:115} INFO - [2022-06-07 04:43:52,322] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:43:52,325] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:43:52,423] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 04:44:22,776] {processor.py:153} INFO - Started process (PID=20026) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:44:22,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:44:22,781] {logging_mixin.py:115} INFO - [2022-06-07 04:44:22,781] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:44:22,886] {logging_mixin.py:115} INFO - [2022-06-07 04:44:22,883] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:44:22,888] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:44:23,035] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.265 seconds
[2022-06-07 04:44:53,102] {processor.py:153} INFO - Started process (PID=20086) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:44:53,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:44:53,106] {logging_mixin.py:115} INFO - [2022-06-07 04:44:53,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:44:53,235] {logging_mixin.py:115} INFO - [2022-06-07 04:44:53,232] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:44:53,236] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:44:53,436] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.346 seconds
[2022-06-07 04:45:23,569] {processor.py:153} INFO - Started process (PID=20153) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:45:23,585] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:45:23,587] {logging_mixin.py:115} INFO - [2022-06-07 04:45:23,587] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:45:23,680] {logging_mixin.py:115} INFO - [2022-06-07 04:45:23,675] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:45:23,685] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:45:23,801] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-07 04:45:53,881] {processor.py:153} INFO - Started process (PID=20220) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:45:53,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:45:53,886] {logging_mixin.py:115} INFO - [2022-06-07 04:45:53,886] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:45:53,984] {logging_mixin.py:115} INFO - [2022-06-07 04:45:53,981] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:45:53,985] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:45:54,090] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-07 04:46:24,318] {processor.py:153} INFO - Started process (PID=20290) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:46:24,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:46:24,321] {logging_mixin.py:115} INFO - [2022-06-07 04:46:24,321] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:46:24,395] {logging_mixin.py:115} INFO - [2022-06-07 04:46:24,392] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:46:24,397] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:46:24,500] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-07 04:46:55,286] {processor.py:153} INFO - Started process (PID=20358) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:46:55,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:46:55,289] {logging_mixin.py:115} INFO - [2022-06-07 04:46:55,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:46:55,373] {logging_mixin.py:115} INFO - [2022-06-07 04:46:55,367] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:46:55,374] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:46:55,490] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-07 04:47:26,414] {processor.py:153} INFO - Started process (PID=20422) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:47:26,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:47:26,416] {logging_mixin.py:115} INFO - [2022-06-07 04:47:26,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:47:26,494] {logging_mixin.py:115} INFO - [2022-06-07 04:47:26,492] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:47:26,496] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:47:26,597] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 04:47:56,693] {processor.py:153} INFO - Started process (PID=20490) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:47:56,696] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:47:56,697] {logging_mixin.py:115} INFO - [2022-06-07 04:47:56,697] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:47:56,761] {logging_mixin.py:115} INFO - [2022-06-07 04:47:56,758] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:47:56,762] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:47:56,865] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-07 04:48:27,626] {processor.py:153} INFO - Started process (PID=20556) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:48:27,628] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:48:27,630] {logging_mixin.py:115} INFO - [2022-06-07 04:48:27,630] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:48:27,685] {logging_mixin.py:115} INFO - [2022-06-07 04:48:27,683] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:48:27,687] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:48:27,781] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 04:48:57,897] {processor.py:153} INFO - Started process (PID=20626) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:48:57,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:48:57,901] {logging_mixin.py:115} INFO - [2022-06-07 04:48:57,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:48:58,028] {logging_mixin.py:115} INFO - [2022-06-07 04:48:58,025] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:48:58,038] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:48:58,187] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.295 seconds
[2022-06-07 04:49:28,534] {processor.py:153} INFO - Started process (PID=20682) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:49:28,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:49:28,539] {logging_mixin.py:115} INFO - [2022-06-07 04:49:28,539] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:49:28,602] {logging_mixin.py:115} INFO - [2022-06-07 04:49:28,599] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:49:28,604] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:49:28,696] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 04:49:59,707] {processor.py:153} INFO - Started process (PID=20751) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:49:59,710] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:49:59,711] {logging_mixin.py:115} INFO - [2022-06-07 04:49:59,711] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:49:59,776] {logging_mixin.py:115} INFO - [2022-06-07 04:49:59,774] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:49:59,777] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:49:59,876] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-07 04:50:30,215] {processor.py:153} INFO - Started process (PID=20817) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:50:30,218] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:50:30,221] {logging_mixin.py:115} INFO - [2022-06-07 04:50:30,221] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:50:30,272] {logging_mixin.py:115} INFO - [2022-06-07 04:50:30,270] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:50:30,274] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:50:30,371] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-07 04:51:00,975] {processor.py:153} INFO - Started process (PID=20887) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:51:00,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:51:00,978] {logging_mixin.py:115} INFO - [2022-06-07 04:51:00,978] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:51:01,034] {logging_mixin.py:115} INFO - [2022-06-07 04:51:01,032] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:51:01,035] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:51:01,133] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 04:51:32,104] {processor.py:153} INFO - Started process (PID=20944) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:51:32,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:51:32,111] {logging_mixin.py:115} INFO - [2022-06-07 04:51:32,110] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:51:32,187] {logging_mixin.py:115} INFO - [2022-06-07 04:51:32,185] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:51:32,188] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:51:32,307] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.208 seconds
[2022-06-07 04:52:02,606] {processor.py:153} INFO - Started process (PID=21014) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:52:02,609] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:52:02,610] {logging_mixin.py:115} INFO - [2022-06-07 04:52:02,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:52:02,681] {logging_mixin.py:115} INFO - [2022-06-07 04:52:02,679] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:52:02,683] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:52:02,781] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 04:52:33,831] {processor.py:153} INFO - Started process (PID=21082) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:52:33,834] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:52:33,835] {logging_mixin.py:115} INFO - [2022-06-07 04:52:33,835] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:52:33,903] {logging_mixin.py:115} INFO - [2022-06-07 04:52:33,901] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:52:33,904] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:52:34,008] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 04:53:04,227] {processor.py:153} INFO - Started process (PID=21149) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:53:04,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:53:04,230] {logging_mixin.py:115} INFO - [2022-06-07 04:53:04,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:53:04,310] {logging_mixin.py:115} INFO - [2022-06-07 04:53:04,308] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:53:04,312] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:53:04,416] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 04:53:35,208] {processor.py:153} INFO - Started process (PID=21215) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:53:35,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:53:35,212] {logging_mixin.py:115} INFO - [2022-06-07 04:53:35,212] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:53:35,264] {logging_mixin.py:115} INFO - [2022-06-07 04:53:35,262] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:53:35,265] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:53:35,359] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-07 04:54:06,286] {processor.py:153} INFO - Started process (PID=21272) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:54:06,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:54:06,289] {logging_mixin.py:115} INFO - [2022-06-07 04:54:06,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:54:06,365] {logging_mixin.py:115} INFO - [2022-06-07 04:54:06,363] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:54:06,367] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:54:06,494] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-07 04:54:36,664] {processor.py:153} INFO - Started process (PID=21344) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:54:36,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:54:36,667] {logging_mixin.py:115} INFO - [2022-06-07 04:54:36,667] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:54:36,722] {logging_mixin.py:115} INFO - [2022-06-07 04:54:36,720] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:54:36,723] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:54:36,820] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 04:55:07,277] {processor.py:153} INFO - Started process (PID=21411) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:55:07,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:55:07,281] {logging_mixin.py:115} INFO - [2022-06-07 04:55:07,281] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:55:07,401] {logging_mixin.py:115} INFO - [2022-06-07 04:55:07,396] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:55:07,404] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:55:07,551] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.283 seconds
[2022-06-07 04:55:38,462] {processor.py:153} INFO - Started process (PID=21477) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:55:38,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:55:38,466] {logging_mixin.py:115} INFO - [2022-06-07 04:55:38,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:55:38,530] {logging_mixin.py:115} INFO - [2022-06-07 04:55:38,528] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:55:38,531] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:55:38,626] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 04:56:09,513] {processor.py:153} INFO - Started process (PID=21545) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:56:09,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:56:09,516] {logging_mixin.py:115} INFO - [2022-06-07 04:56:09,516] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:56:09,562] {logging_mixin.py:115} INFO - [2022-06-07 04:56:09,560] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:56:09,565] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:56:09,660] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-07 04:56:40,585] {processor.py:153} INFO - Started process (PID=21605) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:56:40,587] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:56:40,589] {logging_mixin.py:115} INFO - [2022-06-07 04:56:40,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:56:40,681] {logging_mixin.py:115} INFO - [2022-06-07 04:56:40,679] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:56:40,683] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:56:40,795] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-07 04:57:11,244] {processor.py:153} INFO - Started process (PID=21676) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:57:11,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:57:11,247] {logging_mixin.py:115} INFO - [2022-06-07 04:57:11,247] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:57:11,309] {logging_mixin.py:115} INFO - [2022-06-07 04:57:11,307] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:57:11,310] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:57:11,412] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 04:57:41,542] {processor.py:153} INFO - Started process (PID=21744) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:57:41,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:57:41,546] {logging_mixin.py:115} INFO - [2022-06-07 04:57:41,546] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:57:41,604] {logging_mixin.py:115} INFO - [2022-06-07 04:57:41,602] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:57:41,605] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:57:41,700] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 04:58:12,205] {processor.py:153} INFO - Started process (PID=21819) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:58:12,207] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:58:12,208] {logging_mixin.py:115} INFO - [2022-06-07 04:58:12,208] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:58:12,276] {logging_mixin.py:115} INFO - [2022-06-07 04:58:12,272] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:58:12,277] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:58:12,370] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 04:58:42,611] {processor.py:153} INFO - Started process (PID=21887) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:58:42,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:58:42,613] {logging_mixin.py:115} INFO - [2022-06-07 04:58:42,613] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:58:42,661] {logging_mixin.py:115} INFO - [2022-06-07 04:58:42,659] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:58:42,664] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:58:42,767] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 04:59:12,938] {processor.py:153} INFO - Started process (PID=21942) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:59:12,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:59:12,942] {logging_mixin.py:115} INFO - [2022-06-07 04:59:12,942] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:59:13,045] {logging_mixin.py:115} INFO - [2022-06-07 04:59:13,042] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:59:13,046] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:59:13,169] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-07 04:59:43,300] {processor.py:153} INFO - Started process (PID=22009) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:59:43,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 04:59:43,304] {logging_mixin.py:115} INFO - [2022-06-07 04:59:43,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:59:43,434] {logging_mixin.py:115} INFO - [2022-06-07 04:59:43,430] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 04:59:43,436] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 04:59:43,578] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.289 seconds
[2022-06-07 05:00:14,112] {processor.py:153} INFO - Started process (PID=22074) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:00:14,113] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:00:14,114] {logging_mixin.py:115} INFO - [2022-06-07 05:00:14,114] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:00:14,203] {logging_mixin.py:115} INFO - [2022-06-07 05:00:14,200] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:00:14,205] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:00:14,308] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-07 05:00:45,244] {processor.py:153} INFO - Started process (PID=22131) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:00:45,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:00:45,258] {logging_mixin.py:115} INFO - [2022-06-07 05:00:45,258] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:00:45,401] {logging_mixin.py:115} INFO - [2022-06-07 05:00:45,398] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:00:45,405] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:00:45,606] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.369 seconds
[2022-06-07 05:01:16,117] {processor.py:153} INFO - Started process (PID=22201) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:01:16,120] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:01:16,122] {logging_mixin.py:115} INFO - [2022-06-07 05:01:16,122] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:01:16,202] {logging_mixin.py:115} INFO - [2022-06-07 05:01:16,199] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:01:16,204] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:01:16,310] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 05:01:46,388] {processor.py:153} INFO - Started process (PID=22272) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:01:46,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:01:46,392] {logging_mixin.py:115} INFO - [2022-06-07 05:01:46,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:01:46,481] {logging_mixin.py:115} INFO - [2022-06-07 05:01:46,478] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:01:46,484] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:01:46,595] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-07 05:02:16,645] {processor.py:153} INFO - Started process (PID=22340) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:02:16,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:02:16,655] {logging_mixin.py:115} INFO - [2022-06-07 05:02:16,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:02:16,744] {logging_mixin.py:115} INFO - [2022-06-07 05:02:16,741] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:02:16,745] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:02:16,864] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.224 seconds
[2022-06-07 05:02:47,448] {processor.py:153} INFO - Started process (PID=22397) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:02:47,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:02:47,456] {logging_mixin.py:115} INFO - [2022-06-07 05:02:47,456] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:02:47,582] {logging_mixin.py:115} INFO - [2022-06-07 05:02:47,579] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:02:47,587] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:02:47,740] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.308 seconds
[2022-06-07 05:03:18,646] {processor.py:153} INFO - Started process (PID=22467) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:03:18,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:03:18,652] {logging_mixin.py:115} INFO - [2022-06-07 05:03:18,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:03:18,778] {logging_mixin.py:115} INFO - [2022-06-07 05:03:18,775] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:03:18,779] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:03:18,915] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.284 seconds
[2022-06-07 05:03:49,931] {processor.py:153} INFO - Started process (PID=22536) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:03:49,933] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:03:49,935] {logging_mixin.py:115} INFO - [2022-06-07 05:03:49,935] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:03:50,028] {logging_mixin.py:115} INFO - [2022-06-07 05:03:50,023] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:03:50,029] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:03:50,154] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-07 05:04:20,375] {processor.py:153} INFO - Started process (PID=22600) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:04:20,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:04:20,379] {logging_mixin.py:115} INFO - [2022-06-07 05:04:20,379] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:04:20,488] {logging_mixin.py:115} INFO - [2022-06-07 05:04:20,483] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:04:20,490] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:04:20,599] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-07 05:04:50,804] {processor.py:153} INFO - Started process (PID=22668) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:04:50,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:04:50,810] {logging_mixin.py:115} INFO - [2022-06-07 05:04:50,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:04:50,867] {logging_mixin.py:115} INFO - [2022-06-07 05:04:50,864] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:04:50,869] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:04:51,017] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-07 05:05:21,125] {processor.py:153} INFO - Started process (PID=22727) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:05:21,127] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:05:21,129] {logging_mixin.py:115} INFO - [2022-06-07 05:05:21,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:05:21,211] {logging_mixin.py:115} INFO - [2022-06-07 05:05:21,209] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:05:21,212] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:05:21,321] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 05:05:51,686] {processor.py:153} INFO - Started process (PID=22794) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:05:51,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:05:51,691] {logging_mixin.py:115} INFO - [2022-06-07 05:05:51,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:05:51,863] {logging_mixin.py:115} INFO - [2022-06-07 05:05:51,856] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:05:51,864] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:05:52,044] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.364 seconds
[2022-06-07 05:06:22,240] {processor.py:153} INFO - Started process (PID=22861) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:06:22,243] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:06:22,245] {logging_mixin.py:115} INFO - [2022-06-07 05:06:22,245] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:06:22,344] {logging_mixin.py:115} INFO - [2022-06-07 05:06:22,341] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:06:22,347] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:06:22,449] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-07 05:06:52,743] {processor.py:153} INFO - Started process (PID=22930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:06:52,745] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:06:52,746] {logging_mixin.py:115} INFO - [2022-06-07 05:06:52,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:06:52,838] {logging_mixin.py:115} INFO - [2022-06-07 05:06:52,835] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:06:52,839] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:06:52,963] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-07 05:07:23,078] {processor.py:153} INFO - Started process (PID=22998) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:07:23,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:07:23,082] {logging_mixin.py:115} INFO - [2022-06-07 05:07:23,082] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:07:23,133] {logging_mixin.py:115} INFO - [2022-06-07 05:07:23,131] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:07:23,135] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:07:23,232] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 05:07:53,499] {processor.py:153} INFO - Started process (PID=23056) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:07:53,501] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:07:53,504] {logging_mixin.py:115} INFO - [2022-06-07 05:07:53,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:07:53,586] {logging_mixin.py:115} INFO - [2022-06-07 05:07:53,581] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:07:53,587] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:07:53,688] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-07 05:08:24,763] {processor.py:153} INFO - Started process (PID=23125) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:08:24,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:08:24,767] {logging_mixin.py:115} INFO - [2022-06-07 05:08:24,767] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:08:24,865] {logging_mixin.py:115} INFO - [2022-06-07 05:08:24,862] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:08:24,867] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:08:24,971] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-07 05:08:55,306] {processor.py:153} INFO - Started process (PID=23193) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:08:55,308] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:08:55,309] {logging_mixin.py:115} INFO - [2022-06-07 05:08:55,309] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:08:55,386] {logging_mixin.py:115} INFO - [2022-06-07 05:08:55,383] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:08:55,387] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:08:55,492] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-07 05:09:25,952] {processor.py:153} INFO - Started process (PID=23259) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:09:25,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:09:25,956] {logging_mixin.py:115} INFO - [2022-06-07 05:09:25,956] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:09:26,067] {logging_mixin.py:115} INFO - [2022-06-07 05:09:26,062] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:09:26,070] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:09:26,187] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-07 05:09:56,548] {processor.py:153} INFO - Started process (PID=23320) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:09:56,551] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:09:56,554] {logging_mixin.py:115} INFO - [2022-06-07 05:09:56,554] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:09:56,697] {logging_mixin.py:115} INFO - [2022-06-07 05:09:56,692] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:09:56,699] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:09:56,876] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.339 seconds
[2022-06-07 05:10:27,401] {processor.py:153} INFO - Started process (PID=23386) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:10:27,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:10:27,405] {logging_mixin.py:115} INFO - [2022-06-07 05:10:27,405] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:10:27,496] {logging_mixin.py:115} INFO - [2022-06-07 05:10:27,493] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:10:27,498] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:10:27,605] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-07 05:10:58,028] {processor.py:153} INFO - Started process (PID=23452) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:10:58,030] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:10:58,032] {logging_mixin.py:115} INFO - [2022-06-07 05:10:58,032] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:10:58,113] {logging_mixin.py:115} INFO - [2022-06-07 05:10:58,110] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:10:58,114] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:10:58,219] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 05:11:28,410] {processor.py:153} INFO - Started process (PID=23520) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:11:28,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:11:28,422] {logging_mixin.py:115} INFO - [2022-06-07 05:11:28,421] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:11:28,636] {logging_mixin.py:115} INFO - [2022-06-07 05:11:28,628] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:11:28,637] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:11:28,828] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.426 seconds
[2022-06-07 05:11:59,648] {processor.py:153} INFO - Started process (PID=23576) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:11:59,651] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:11:59,655] {logging_mixin.py:115} INFO - [2022-06-07 05:11:59,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:11:59,814] {logging_mixin.py:115} INFO - [2022-06-07 05:11:59,808] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:11:59,815] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:11:59,979] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.344 seconds
[2022-06-07 05:12:31,006] {processor.py:153} INFO - Started process (PID=23642) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:12:31,009] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:12:31,011] {logging_mixin.py:115} INFO - [2022-06-07 05:12:31,011] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:12:31,125] {logging_mixin.py:115} INFO - [2022-06-07 05:12:31,122] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:12:31,126] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:12:31,258] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-07 05:13:01,624] {processor.py:153} INFO - Started process (PID=23710) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:13:01,626] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:13:01,628] {logging_mixin.py:115} INFO - [2022-06-07 05:13:01,628] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:13:01,725] {logging_mixin.py:115} INFO - [2022-06-07 05:13:01,721] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:13:01,728] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:13:01,842] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-07 05:13:32,873] {processor.py:153} INFO - Started process (PID=23774) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:13:32,881] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:13:32,884] {logging_mixin.py:115} INFO - [2022-06-07 05:13:32,884] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:13:33,018] {logging_mixin.py:115} INFO - [2022-06-07 05:13:33,013] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:13:33,020] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:13:33,267] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.401 seconds
[2022-06-07 05:14:03,369] {processor.py:153} INFO - Started process (PID=23830) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:14:03,371] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:14:03,374] {logging_mixin.py:115} INFO - [2022-06-07 05:14:03,374] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:14:03,461] {logging_mixin.py:115} INFO - [2022-06-07 05:14:03,458] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:14:03,464] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:14:03,566] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 05:14:33,766] {processor.py:153} INFO - Started process (PID=23900) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:14:33,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:14:33,771] {logging_mixin.py:115} INFO - [2022-06-07 05:14:33,770] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:14:33,870] {logging_mixin.py:115} INFO - [2022-06-07 05:14:33,867] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:14:33,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:14:33,981] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-07 05:15:04,414] {processor.py:153} INFO - Started process (PID=23967) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:15:04,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:15:04,417] {logging_mixin.py:115} INFO - [2022-06-07 05:15:04,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:15:04,504] {logging_mixin.py:115} INFO - [2022-06-07 05:15:04,502] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:15:04,507] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:15:04,621] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-07 05:15:35,167] {processor.py:153} INFO - Started process (PID=24024) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:15:35,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:15:35,172] {logging_mixin.py:115} INFO - [2022-06-07 05:15:35,172] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:15:35,265] {logging_mixin.py:115} INFO - [2022-06-07 05:15:35,261] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:15:35,266] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:15:35,372] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-07 05:16:05,522] {processor.py:153} INFO - Started process (PID=24094) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:16:05,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:16:05,526] {logging_mixin.py:115} INFO - [2022-06-07 05:16:05,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:16:05,610] {logging_mixin.py:115} INFO - [2022-06-07 05:16:05,608] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:16:05,612] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:16:05,717] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-07 05:16:36,500] {processor.py:153} INFO - Started process (PID=24161) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:16:36,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:16:36,503] {logging_mixin.py:115} INFO - [2022-06-07 05:16:36,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:16:36,595] {logging_mixin.py:115} INFO - [2022-06-07 05:16:36,592] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:16:36,596] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:16:36,705] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.208 seconds
[2022-06-07 05:17:07,435] {processor.py:153} INFO - Started process (PID=24228) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:17:07,437] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:17:07,440] {logging_mixin.py:115} INFO - [2022-06-07 05:17:07,440] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:17:07,578] {logging_mixin.py:115} INFO - [2022-06-07 05:17:07,572] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:17:07,583] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:17:07,758] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.333 seconds
[2022-06-07 05:17:38,082] {processor.py:153} INFO - Started process (PID=24292) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:17:38,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:17:38,089] {logging_mixin.py:115} INFO - [2022-06-07 05:17:38,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:17:38,183] {logging_mixin.py:115} INFO - [2022-06-07 05:17:38,180] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:17:38,185] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:17:38,332] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-07 05:18:08,826] {processor.py:153} INFO - Started process (PID=24349) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:18:08,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:18:08,830] {logging_mixin.py:115} INFO - [2022-06-07 05:18:08,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:18:08,931] {logging_mixin.py:115} INFO - [2022-06-07 05:18:08,927] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:18:08,932] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:18:09,043] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-07 05:18:39,296] {processor.py:153} INFO - Started process (PID=24417) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:18:39,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:18:39,302] {logging_mixin.py:115} INFO - [2022-06-07 05:18:39,302] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:18:39,453] {logging_mixin.py:115} INFO - [2022-06-07 05:18:39,443] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:18:39,455] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:18:39,597] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.314 seconds
[2022-06-07 05:19:10,312] {processor.py:153} INFO - Started process (PID=24482) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:19:10,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:19:10,317] {logging_mixin.py:115} INFO - [2022-06-07 05:19:10,316] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:19:10,430] {logging_mixin.py:115} INFO - [2022-06-07 05:19:10,426] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:19:10,431] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:19:10,547] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-07 05:19:40,813] {processor.py:153} INFO - Started process (PID=24552) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:19:40,815] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:19:40,818] {logging_mixin.py:115} INFO - [2022-06-07 05:19:40,817] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:19:40,888] {logging_mixin.py:115} INFO - [2022-06-07 05:19:40,886] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:19:40,890] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:19:40,992] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-07 05:20:11,830] {processor.py:153} INFO - Started process (PID=24611) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:20:11,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:20:11,836] {logging_mixin.py:115} INFO - [2022-06-07 05:20:11,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:20:11,969] {logging_mixin.py:115} INFO - [2022-06-07 05:20:11,956] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:20:11,970] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:20:12,107] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.289 seconds
[2022-06-07 05:20:42,414] {processor.py:153} INFO - Started process (PID=24677) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:20:42,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:20:42,419] {logging_mixin.py:115} INFO - [2022-06-07 05:20:42,419] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:20:42,505] {logging_mixin.py:115} INFO - [2022-06-07 05:20:42,502] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:20:42,507] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:20:42,628] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-07 05:21:13,521] {processor.py:153} INFO - Started process (PID=24743) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:21:13,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:21:13,525] {logging_mixin.py:115} INFO - [2022-06-07 05:21:13,525] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:21:13,610] {logging_mixin.py:115} INFO - [2022-06-07 05:21:13,607] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:21:13,611] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:21:13,726] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-07 05:21:44,444] {processor.py:153} INFO - Started process (PID=24815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:21:44,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:21:44,449] {logging_mixin.py:115} INFO - [2022-06-07 05:21:44,449] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:21:44,547] {logging_mixin.py:115} INFO - [2022-06-07 05:21:44,544] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:21:44,549] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:21:44,668] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-07 05:22:14,786] {processor.py:153} INFO - Started process (PID=24872) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:22:14,788] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:22:14,790] {logging_mixin.py:115} INFO - [2022-06-07 05:22:14,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:22:14,904] {logging_mixin.py:115} INFO - [2022-06-07 05:22:14,900] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:22:14,906] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:22:15,032] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-07 05:22:45,373] {processor.py:153} INFO - Started process (PID=24939) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:22:45,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:22:45,377] {logging_mixin.py:115} INFO - [2022-06-07 05:22:45,377] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:22:45,484] {logging_mixin.py:115} INFO - [2022-06-07 05:22:45,481] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:22:45,486] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:22:45,599] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-07 05:23:15,679] {processor.py:153} INFO - Started process (PID=25009) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:23:15,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:23:15,683] {logging_mixin.py:115} INFO - [2022-06-07 05:23:15,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:23:15,791] {logging_mixin.py:115} INFO - [2022-06-07 05:23:15,788] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:23:15,792] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:23:15,904] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-07 05:23:46,815] {processor.py:153} INFO - Started process (PID=25070) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:23:46,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:23:46,818] {logging_mixin.py:115} INFO - [2022-06-07 05:23:46,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:23:46,925] {logging_mixin.py:115} INFO - [2022-06-07 05:23:46,919] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:23:46,926] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:23:47,044] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-07 05:24:17,868] {processor.py:153} INFO - Started process (PID=25141) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:24:17,870] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:24:17,871] {logging_mixin.py:115} INFO - [2022-06-07 05:24:17,871] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:24:17,980] {logging_mixin.py:115} INFO - [2022-06-07 05:24:17,977] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:24:17,982] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:24:18,092] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-07 05:24:48,344] {processor.py:153} INFO - Started process (PID=25211) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:24:48,347] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:24:48,349] {logging_mixin.py:115} INFO - [2022-06-07 05:24:48,349] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:24:48,445] {logging_mixin.py:115} INFO - [2022-06-07 05:24:48,442] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:24:48,447] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:24:48,566] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-07 05:25:19,015] {processor.py:153} INFO - Started process (PID=25268) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:25:19,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:25:19,019] {logging_mixin.py:115} INFO - [2022-06-07 05:25:19,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:25:19,133] {logging_mixin.py:115} INFO - [2022-06-07 05:25:19,130] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:25:19,135] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:25:19,277] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.268 seconds
[2022-06-07 05:25:49,438] {processor.py:153} INFO - Started process (PID=25336) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:25:49,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:25:49,443] {logging_mixin.py:115} INFO - [2022-06-07 05:25:49,443] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:25:49,516] {logging_mixin.py:115} INFO - [2022-06-07 05:25:49,514] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:25:49,517] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:25:49,648] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-07 05:26:19,909] {processor.py:153} INFO - Started process (PID=25406) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:26:19,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:26:19,913] {logging_mixin.py:115} INFO - [2022-06-07 05:26:19,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:26:20,002] {logging_mixin.py:115} INFO - [2022-06-07 05:26:19,999] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:26:20,004] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:26:20,104] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 05:26:50,469] {processor.py:153} INFO - Started process (PID=25465) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:26:50,471] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:26:50,472] {logging_mixin.py:115} INFO - [2022-06-07 05:26:50,472] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:26:50,590] {logging_mixin.py:115} INFO - [2022-06-07 05:26:50,586] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:26:50,591] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:26:50,737] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.272 seconds
[2022-06-07 05:27:21,722] {processor.py:153} INFO - Started process (PID=25533) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:27:21,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:27:21,726] {logging_mixin.py:115} INFO - [2022-06-07 05:27:21,726] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:27:21,839] {logging_mixin.py:115} INFO - [2022-06-07 05:27:21,835] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:27:21,841] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:27:21,972] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-07 05:27:52,365] {processor.py:153} INFO - Started process (PID=25602) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:27:52,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:27:52,370] {logging_mixin.py:115} INFO - [2022-06-07 05:27:52,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:27:52,503] {logging_mixin.py:115} INFO - [2022-06-07 05:27:52,500] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:27:52,505] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:27:52,645] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.288 seconds
[2022-06-07 05:28:23,186] {processor.py:153} INFO - Started process (PID=25668) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:28:23,189] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:28:23,190] {logging_mixin.py:115} INFO - [2022-06-07 05:28:23,190] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:28:23,442] {logging_mixin.py:115} INFO - [2022-06-07 05:28:23,439] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:28:23,485] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:28:23,671] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.502 seconds
[2022-06-07 05:28:54,373] {processor.py:153} INFO - Started process (PID=25730) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:28:54,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:28:54,376] {logging_mixin.py:115} INFO - [2022-06-07 05:28:54,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:28:54,478] {logging_mixin.py:115} INFO - [2022-06-07 05:28:54,472] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:28:54,481] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:28:54,612] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-07 05:29:25,670] {processor.py:153} INFO - Started process (PID=25795) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:29:25,673] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:29:25,675] {logging_mixin.py:115} INFO - [2022-06-07 05:29:25,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:29:25,773] {logging_mixin.py:115} INFO - [2022-06-07 05:29:25,770] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:29:25,775] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:29:25,890] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-07 05:29:56,597] {processor.py:153} INFO - Started process (PID=25866) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:29:56,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:29:56,601] {logging_mixin.py:115} INFO - [2022-06-07 05:29:56,601] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:29:56,713] {logging_mixin.py:115} INFO - [2022-06-07 05:29:56,709] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:29:56,715] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:29:56,837] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-07 05:30:27,378] {processor.py:153} INFO - Started process (PID=25928) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:30:27,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:30:27,386] {logging_mixin.py:115} INFO - [2022-06-07 05:30:27,386] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:30:27,519] {logging_mixin.py:115} INFO - [2022-06-07 05:30:27,516] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:30:27,526] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:30:27,657] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.296 seconds
[2022-06-07 05:30:58,369] {processor.py:153} INFO - Started process (PID=25993) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:30:58,372] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:30:58,374] {logging_mixin.py:115} INFO - [2022-06-07 05:30:58,374] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:30:58,480] {logging_mixin.py:115} INFO - [2022-06-07 05:30:58,475] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:30:58,482] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:30:58,603] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-07 05:31:29,091] {processor.py:153} INFO - Started process (PID=26063) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:31:29,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:31:29,097] {logging_mixin.py:115} INFO - [2022-06-07 05:31:29,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:31:29,238] {logging_mixin.py:115} INFO - [2022-06-07 05:31:29,231] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:31:29,240] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:31:29,396] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.313 seconds
[2022-06-07 05:31:59,733] {processor.py:153} INFO - Started process (PID=26130) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:31:59,736] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:31:59,737] {logging_mixin.py:115} INFO - [2022-06-07 05:31:59,737] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:31:59,846] {logging_mixin.py:115} INFO - [2022-06-07 05:31:59,843] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:31:59,848] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:31:59,961] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-07 05:32:30,029] {processor.py:153} INFO - Started process (PID=26190) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:32:30,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:32:30,034] {logging_mixin.py:115} INFO - [2022-06-07 05:32:30,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:32:30,086] {logging_mixin.py:115} INFO - [2022-06-07 05:32:30,084] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:32:30,087] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:32:30,192] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 05:33:00,744] {processor.py:153} INFO - Started process (PID=26259) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:33:00,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:33:00,749] {logging_mixin.py:115} INFO - [2022-06-07 05:33:00,748] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:33:00,826] {logging_mixin.py:115} INFO - [2022-06-07 05:33:00,823] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:33:00,827] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:33:00,934] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 05:33:31,176] {processor.py:153} INFO - Started process (PID=26326) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:33:31,178] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:33:31,179] {logging_mixin.py:115} INFO - [2022-06-07 05:33:31,179] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:33:31,226] {logging_mixin.py:115} INFO - [2022-06-07 05:33:31,223] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:33:31,227] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:33:31,326] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-07 05:34:01,681] {processor.py:153} INFO - Started process (PID=26398) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:34:01,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:34:01,686] {logging_mixin.py:115} INFO - [2022-06-07 05:34:01,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:34:01,769] {logging_mixin.py:115} INFO - [2022-06-07 05:34:01,767] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:34:01,771] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:34:01,873] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-07 05:34:32,208] {processor.py:153} INFO - Started process (PID=26465) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:34:32,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:34:32,212] {logging_mixin.py:115} INFO - [2022-06-07 05:34:32,212] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:34:32,294] {logging_mixin.py:115} INFO - [2022-06-07 05:34:32,289] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:34:32,295] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:34:32,454] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.251 seconds
[2022-06-07 05:35:02,910] {processor.py:153} INFO - Started process (PID=26524) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:35:02,914] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:35:02,916] {logging_mixin.py:115} INFO - [2022-06-07 05:35:02,916] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:35:02,992] {logging_mixin.py:115} INFO - [2022-06-07 05:35:02,989] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:35:02,994] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:35:03,102] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 05:35:33,322] {processor.py:153} INFO - Started process (PID=26598) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:35:33,325] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:35:33,328] {logging_mixin.py:115} INFO - [2022-06-07 05:35:33,328] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:35:33,391] {logging_mixin.py:115} INFO - [2022-06-07 05:35:33,389] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:35:33,393] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:35:33,500] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 05:36:03,832] {processor.py:153} INFO - Started process (PID=26665) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:36:03,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:36:03,837] {logging_mixin.py:115} INFO - [2022-06-07 05:36:03,837] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:36:03,907] {logging_mixin.py:115} INFO - [2022-06-07 05:36:03,904] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:36:03,908] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:36:04,008] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 05:36:34,164] {processor.py:153} INFO - Started process (PID=26735) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:36:34,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:36:34,168] {logging_mixin.py:115} INFO - [2022-06-07 05:36:34,168] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:36:34,222] {logging_mixin.py:115} INFO - [2022-06-07 05:36:34,220] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:36:34,223] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:36:34,321] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 05:37:04,567] {processor.py:153} INFO - Started process (PID=26801) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:37:04,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:37:04,571] {logging_mixin.py:115} INFO - [2022-06-07 05:37:04,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:37:04,653] {logging_mixin.py:115} INFO - [2022-06-07 05:37:04,650] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:37:04,655] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:37:04,926] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.366 seconds
[2022-06-07 05:37:34,998] {processor.py:153} INFO - Started process (PID=26862) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:37:35,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:37:35,002] {logging_mixin.py:115} INFO - [2022-06-07 05:37:35,002] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:37:35,072] {logging_mixin.py:115} INFO - [2022-06-07 05:37:35,069] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:37:35,073] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:37:35,181] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-07 05:38:05,882] {processor.py:153} INFO - Started process (PID=26929) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:38:05,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:38:05,886] {logging_mixin.py:115} INFO - [2022-06-07 05:38:05,886] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:38:05,942] {logging_mixin.py:115} INFO - [2022-06-07 05:38:05,940] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:38:05,944] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:38:06,038] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 05:38:36,872] {processor.py:153} INFO - Started process (PID=26997) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:38:36,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:38:36,877] {logging_mixin.py:115} INFO - [2022-06-07 05:38:36,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:38:36,939] {logging_mixin.py:115} INFO - [2022-06-07 05:38:36,936] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:38:36,940] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:38:37,034] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-07 05:39:07,975] {processor.py:153} INFO - Started process (PID=27063) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:39:07,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:39:07,977] {logging_mixin.py:115} INFO - [2022-06-07 05:39:07,977] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:39:08,024] {logging_mixin.py:115} INFO - [2022-06-07 05:39:08,023] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:39:08,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:39:08,121] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-07 05:39:38,370] {processor.py:153} INFO - Started process (PID=27132) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:39:38,372] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:39:38,373] {logging_mixin.py:115} INFO - [2022-06-07 05:39:38,373] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:39:38,435] {logging_mixin.py:115} INFO - [2022-06-07 05:39:38,432] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:39:38,436] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:39:38,544] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 05:40:08,675] {processor.py:153} INFO - Started process (PID=27190) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:40:08,677] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:40:08,679] {logging_mixin.py:115} INFO - [2022-06-07 05:40:08,679] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:40:08,741] {logging_mixin.py:115} INFO - [2022-06-07 05:40:08,738] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:40:08,742] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:40:08,835] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 05:40:39,280] {processor.py:153} INFO - Started process (PID=27258) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:40:39,282] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:40:39,285] {logging_mixin.py:115} INFO - [2022-06-07 05:40:39,285] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:40:39,347] {logging_mixin.py:115} INFO - [2022-06-07 05:40:39,345] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:40:39,352] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:40:39,449] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 05:41:09,506] {processor.py:153} INFO - Started process (PID=27326) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:41:09,510] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:41:09,513] {logging_mixin.py:115} INFO - [2022-06-07 05:41:09,512] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:41:09,587] {logging_mixin.py:115} INFO - [2022-06-07 05:41:09,585] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:41:09,588] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:41:09,682] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 05:41:39,953] {processor.py:153} INFO - Started process (PID=27395) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:41:39,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:41:39,957] {logging_mixin.py:115} INFO - [2022-06-07 05:41:39,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:41:40,006] {logging_mixin.py:115} INFO - [2022-06-07 05:41:40,004] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:41:40,008] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:41:40,104] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-07 05:42:10,163] {processor.py:153} INFO - Started process (PID=27459) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:42:10,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:42:10,168] {logging_mixin.py:115} INFO - [2022-06-07 05:42:10,168] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:42:10,237] {logging_mixin.py:115} INFO - [2022-06-07 05:42:10,234] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:42:10,238] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:42:10,355] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 05:42:40,743] {processor.py:153} INFO - Started process (PID=27518) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:42:40,745] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:42:40,746] {logging_mixin.py:115} INFO - [2022-06-07 05:42:40,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:42:40,799] {logging_mixin.py:115} INFO - [2022-06-07 05:42:40,797] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:42:40,801] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:42:40,902] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 05:43:11,292] {processor.py:153} INFO - Started process (PID=27583) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:43:11,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:43:11,295] {logging_mixin.py:115} INFO - [2022-06-07 05:43:11,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:43:11,367] {logging_mixin.py:115} INFO - [2022-06-07 05:43:11,365] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:43:11,368] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:43:11,464] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 05:43:42,271] {processor.py:153} INFO - Started process (PID=27648) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:43:42,274] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:43:42,276] {logging_mixin.py:115} INFO - [2022-06-07 05:43:42,276] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:43:42,339] {logging_mixin.py:115} INFO - [2022-06-07 05:43:42,337] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:43:42,341] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:43:42,437] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 05:44:12,505] {processor.py:153} INFO - Started process (PID=27719) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:44:12,506] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:44:12,507] {logging_mixin.py:115} INFO - [2022-06-07 05:44:12,507] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:44:12,565] {logging_mixin.py:115} INFO - [2022-06-07 05:44:12,562] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:44:12,566] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:44:12,659] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 05:44:42,785] {processor.py:153} INFO - Started process (PID=27779) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:44:42,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:44:42,788] {logging_mixin.py:115} INFO - [2022-06-07 05:44:42,788] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:44:42,834] {logging_mixin.py:115} INFO - [2022-06-07 05:44:42,832] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:44:42,837] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:44:42,933] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-07 05:45:13,522] {processor.py:153} INFO - Started process (PID=27851) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:45:13,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:45:13,526] {logging_mixin.py:115} INFO - [2022-06-07 05:45:13,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:45:13,588] {logging_mixin.py:115} INFO - [2022-06-07 05:45:13,586] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:45:13,589] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:45:13,688] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 05:45:44,243] {processor.py:153} INFO - Started process (PID=27921) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:45:44,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:45:44,247] {logging_mixin.py:115} INFO - [2022-06-07 05:45:44,247] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:45:44,306] {logging_mixin.py:115} INFO - [2022-06-07 05:45:44,304] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:45:44,307] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:45:44,404] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-07 05:46:14,874] {processor.py:153} INFO - Started process (PID=27989) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:46:14,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:46:14,877] {logging_mixin.py:115} INFO - [2022-06-07 05:46:14,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:46:14,935] {logging_mixin.py:115} INFO - [2022-06-07 05:46:14,933] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:46:14,936] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:46:15,029] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 05:46:45,227] {processor.py:153} INFO - Started process (PID=28056) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:46:45,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:46:45,230] {logging_mixin.py:115} INFO - [2022-06-07 05:46:45,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:46:45,291] {logging_mixin.py:115} INFO - [2022-06-07 05:46:45,288] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:46:45,293] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:46:45,547] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.323 seconds
[2022-06-07 05:47:16,441] {processor.py:153} INFO - Started process (PID=28114) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:47:16,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:47:16,445] {logging_mixin.py:115} INFO - [2022-06-07 05:47:16,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:47:16,517] {logging_mixin.py:115} INFO - [2022-06-07 05:47:16,515] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:47:16,519] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:47:16,617] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 05:47:46,993] {processor.py:153} INFO - Started process (PID=28179) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:47:46,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:47:46,998] {logging_mixin.py:115} INFO - [2022-06-07 05:47:46,998] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:47:47,058] {logging_mixin.py:115} INFO - [2022-06-07 05:47:47,055] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:47:47,059] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:47:47,153] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 05:48:17,255] {processor.py:153} INFO - Started process (PID=28245) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:48:17,258] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:48:17,260] {logging_mixin.py:115} INFO - [2022-06-07 05:48:17,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:48:17,338] {logging_mixin.py:115} INFO - [2022-06-07 05:48:17,336] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:48:17,340] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:48:17,435] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-07 05:48:47,719] {processor.py:153} INFO - Started process (PID=28309) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:48:47,722] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:48:47,723] {logging_mixin.py:115} INFO - [2022-06-07 05:48:47,723] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:48:47,784] {logging_mixin.py:115} INFO - [2022-06-07 05:48:47,780] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:48:47,785] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:48:47,879] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 05:49:17,989] {processor.py:153} INFO - Started process (PID=28365) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:49:17,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:49:17,993] {logging_mixin.py:115} INFO - [2022-06-07 05:49:17,993] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:49:18,060] {logging_mixin.py:115} INFO - [2022-06-07 05:49:18,058] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:49:18,062] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:49:18,159] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 05:49:48,739] {processor.py:153} INFO - Started process (PID=28434) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:49:48,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:49:48,744] {logging_mixin.py:115} INFO - [2022-06-07 05:49:48,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:49:48,796] {logging_mixin.py:115} INFO - [2022-06-07 05:49:48,795] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:49:48,797] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:49:48,892] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 05:50:19,092] {processor.py:153} INFO - Started process (PID=28500) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:50:19,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:50:19,096] {logging_mixin.py:115} INFO - [2022-06-07 05:50:19,096] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:50:19,172] {logging_mixin.py:115} INFO - [2022-06-07 05:50:19,169] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:50:19,174] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:50:19,271] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 05:50:49,638] {processor.py:153} INFO - Started process (PID=28569) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:50:49,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:50:49,641] {logging_mixin.py:115} INFO - [2022-06-07 05:50:49,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:50:49,707] {logging_mixin.py:115} INFO - [2022-06-07 05:50:49,701] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:50:49,708] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:50:49,816] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 05:51:20,752] {processor.py:153} INFO - Started process (PID=28637) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:51:20,757] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:51:20,758] {logging_mixin.py:115} INFO - [2022-06-07 05:51:20,758] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:51:20,841] {logging_mixin.py:115} INFO - [2022-06-07 05:51:20,832] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:51:20,844] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:51:21,002] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-07 05:51:51,309] {processor.py:153} INFO - Started process (PID=28697) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:51:51,312] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:51:51,314] {logging_mixin.py:115} INFO - [2022-06-07 05:51:51,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:51:51,379] {logging_mixin.py:115} INFO - [2022-06-07 05:51:51,377] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:51:51,383] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:51:51,479] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 05:52:21,896] {processor.py:153} INFO - Started process (PID=28763) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:52:21,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:52:21,902] {logging_mixin.py:115} INFO - [2022-06-07 05:52:21,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:52:21,982] {logging_mixin.py:115} INFO - [2022-06-07 05:52:21,980] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:52:21,983] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:52:22,082] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-07 05:52:52,403] {processor.py:153} INFO - Started process (PID=28832) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:52:52,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:52:52,408] {logging_mixin.py:115} INFO - [2022-06-07 05:52:52,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:52:52,476] {logging_mixin.py:115} INFO - [2022-06-07 05:52:52,473] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:52:52,477] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:52:52,575] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 05:53:23,390] {processor.py:153} INFO - Started process (PID=28899) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:53:23,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:53:23,397] {logging_mixin.py:115} INFO - [2022-06-07 05:53:23,397] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:53:23,477] {logging_mixin.py:115} INFO - [2022-06-07 05:53:23,474] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:53:23,478] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:53:23,588] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-07 05:53:54,464] {processor.py:153} INFO - Started process (PID=28969) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:53:54,468] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:53:54,469] {logging_mixin.py:115} INFO - [2022-06-07 05:53:54,469] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:53:54,569] {logging_mixin.py:115} INFO - [2022-06-07 05:53:54,566] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:53:54,570] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:53:54,689] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-07 05:54:24,799] {processor.py:153} INFO - Started process (PID=29026) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:54:24,802] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:54:24,803] {logging_mixin.py:115} INFO - [2022-06-07 05:54:24,803] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:54:24,944] {logging_mixin.py:115} INFO - [2022-06-07 05:54:24,941] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:54:24,945] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:54:25,099] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.314 seconds
[2022-06-07 05:54:55,579] {processor.py:153} INFO - Started process (PID=29094) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:54:55,581] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:54:55,582] {logging_mixin.py:115} INFO - [2022-06-07 05:54:55,582] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:54:55,687] {logging_mixin.py:115} INFO - [2022-06-07 05:54:55,685] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:54:55,689] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:54:55,800] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-07 05:55:26,338] {processor.py:153} INFO - Started process (PID=29160) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:55:26,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:55:26,342] {logging_mixin.py:115} INFO - [2022-06-07 05:55:26,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:55:26,477] {logging_mixin.py:115} INFO - [2022-06-07 05:55:26,474] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:55:26,479] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:55:26,645] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.319 seconds
[2022-06-07 05:55:56,884] {processor.py:153} INFO - Started process (PID=29227) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:55:56,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:55:56,889] {logging_mixin.py:115} INFO - [2022-06-07 05:55:56,889] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:55:57,177] {logging_mixin.py:115} INFO - [2022-06-07 05:55:57,172] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:55:57,189] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:55:57,368] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.490 seconds
[2022-06-07 05:56:27,808] {processor.py:153} INFO - Started process (PID=29284) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:56:27,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:56:27,812] {logging_mixin.py:115} INFO - [2022-06-07 05:56:27,812] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:56:27,942] {logging_mixin.py:115} INFO - [2022-06-07 05:56:27,937] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:56:27,944] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:56:28,093] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.299 seconds
[2022-06-07 05:56:58,795] {processor.py:153} INFO - Started process (PID=29351) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:56:58,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:56:58,802] {logging_mixin.py:115} INFO - [2022-06-07 05:56:58,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:56:58,878] {logging_mixin.py:115} INFO - [2022-06-07 05:56:58,876] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:56:58,884] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:56:58,990] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 05:57:29,434] {processor.py:153} INFO - Started process (PID=29418) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:57:29,437] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:57:29,438] {logging_mixin.py:115} INFO - [2022-06-07 05:57:29,438] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:57:29,530] {logging_mixin.py:115} INFO - [2022-06-07 05:57:29,527] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:57:29,531] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:57:29,640] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-07 05:57:59,852] {processor.py:153} INFO - Started process (PID=29475) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:57:59,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:57:59,855] {logging_mixin.py:115} INFO - [2022-06-07 05:57:59,854] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:57:59,944] {logging_mixin.py:115} INFO - [2022-06-07 05:57:59,942] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:57:59,946] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:58:00,062] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-07 05:58:30,733] {processor.py:153} INFO - Started process (PID=29545) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:58:30,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:58:30,739] {logging_mixin.py:115} INFO - [2022-06-07 05:58:30,739] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:58:30,832] {logging_mixin.py:115} INFO - [2022-06-07 05:58:30,830] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:58:30,834] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:58:30,953] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-07 05:59:01,214] {processor.py:153} INFO - Started process (PID=29610) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:59:01,217] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:59:01,218] {logging_mixin.py:115} INFO - [2022-06-07 05:59:01,218] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:59:01,297] {logging_mixin.py:115} INFO - [2022-06-07 05:59:01,294] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:59:01,300] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:59:01,411] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 05:59:31,970] {processor.py:153} INFO - Started process (PID=29680) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:59:31,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 05:59:31,974] {logging_mixin.py:115} INFO - [2022-06-07 05:59:31,974] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:59:32,076] {logging_mixin.py:115} INFO - [2022-06-07 05:59:32,072] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 05:59:32,077] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 05:59:32,227] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-07 06:00:02,902] {processor.py:153} INFO - Started process (PID=29738) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:00:02,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:00:02,906] {logging_mixin.py:115} INFO - [2022-06-07 06:00:02,906] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:00:02,986] {logging_mixin.py:115} INFO - [2022-06-07 06:00:02,984] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:00:02,987] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:00:03,089] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-07 06:00:33,736] {processor.py:153} INFO - Started process (PID=29808) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:00:33,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:00:33,745] {logging_mixin.py:115} INFO - [2022-06-07 06:00:33,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:00:33,923] {logging_mixin.py:115} INFO - [2022-06-07 06:00:33,917] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:00:33,926] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:00:34,332] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.613 seconds
[2022-06-07 06:01:04,652] {processor.py:153} INFO - Started process (PID=29877) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:01:04,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:01:04,656] {logging_mixin.py:115} INFO - [2022-06-07 06:01:04,656] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:01:04,780] {logging_mixin.py:115} INFO - [2022-06-07 06:01:04,776] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:01:04,784] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:01:05,019] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.374 seconds
[2022-06-07 06:01:35,241] {processor.py:153} INFO - Started process (PID=29946) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:01:35,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:01:35,248] {logging_mixin.py:115} INFO - [2022-06-07 06:01:35,248] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:01:35,333] {logging_mixin.py:115} INFO - [2022-06-07 06:01:35,331] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:01:35,335] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:01:35,444] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.208 seconds
[2022-06-07 06:02:06,356] {processor.py:153} INFO - Started process (PID=30007) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:02:06,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:02:06,361] {logging_mixin.py:115} INFO - [2022-06-07 06:02:06,361] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:02:06,451] {logging_mixin.py:115} INFO - [2022-06-07 06:02:06,449] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:02:06,453] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:02:06,551] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-07 06:02:36,746] {processor.py:153} INFO - Started process (PID=30073) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:02:36,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:02:36,748] {logging_mixin.py:115} INFO - [2022-06-07 06:02:36,748] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:02:36,813] {logging_mixin.py:115} INFO - [2022-06-07 06:02:36,810] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:02:36,815] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:02:36,910] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 06:03:07,127] {processor.py:153} INFO - Started process (PID=30144) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:03:07,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:03:07,130] {logging_mixin.py:115} INFO - [2022-06-07 06:03:07,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:03:07,201] {logging_mixin.py:115} INFO - [2022-06-07 06:03:07,199] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:03:07,202] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:03:07,312] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-07 06:03:37,765] {processor.py:153} INFO - Started process (PID=30210) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:03:37,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:03:37,768] {logging_mixin.py:115} INFO - [2022-06-07 06:03:37,768] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:03:37,914] {logging_mixin.py:115} INFO - [2022-06-07 06:03:37,911] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:03:37,916] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:03:38,062] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.302 seconds
[2022-06-07 06:04:08,290] {processor.py:153} INFO - Started process (PID=30280) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:04:08,292] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:04:08,293] {logging_mixin.py:115} INFO - [2022-06-07 06:04:08,293] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:04:08,410] {logging_mixin.py:115} INFO - [2022-06-07 06:04:08,406] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:04:08,412] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:04:08,612] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.327 seconds
[2022-06-07 06:04:38,909] {processor.py:153} INFO - Started process (PID=30339) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:04:38,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:04:38,913] {logging_mixin.py:115} INFO - [2022-06-07 06:04:38,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:04:39,036] {logging_mixin.py:115} INFO - [2022-06-07 06:04:39,032] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:04:39,068] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:04:39,283] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.380 seconds
[2022-06-07 06:05:10,198] {processor.py:153} INFO - Started process (PID=30409) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:05:10,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:05:10,202] {logging_mixin.py:115} INFO - [2022-06-07 06:05:10,202] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:05:10,310] {logging_mixin.py:115} INFO - [2022-06-07 06:05:10,306] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:05:10,311] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:05:10,462] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.269 seconds
[2022-06-07 06:05:40,951] {processor.py:153} INFO - Started process (PID=30477) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:05:40,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:05:40,955] {logging_mixin.py:115} INFO - [2022-06-07 06:05:40,955] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:05:41,076] {logging_mixin.py:115} INFO - [2022-06-07 06:05:41,073] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:05:41,079] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:05:41,293] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.350 seconds
[2022-06-07 06:06:11,667] {processor.py:153} INFO - Started process (PID=30545) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:06:11,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:06:11,672] {logging_mixin.py:115} INFO - [2022-06-07 06:06:11,672] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:06:11,763] {logging_mixin.py:115} INFO - [2022-06-07 06:06:11,760] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:06:11,764] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:06:11,870] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-07 06:06:42,037] {processor.py:153} INFO - Started process (PID=30604) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:06:42,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:06:42,042] {logging_mixin.py:115} INFO - [2022-06-07 06:06:42,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:06:42,128] {logging_mixin.py:115} INFO - [2022-06-07 06:06:42,125] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:06:42,129] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:06:42,233] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-07 06:07:13,282] {processor.py:153} INFO - Started process (PID=30670) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:07:13,285] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:07:13,287] {logging_mixin.py:115} INFO - [2022-06-07 06:07:13,287] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:07:13,422] {logging_mixin.py:115} INFO - [2022-06-07 06:07:13,418] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:07:13,424] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:07:13,556] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.285 seconds
[2022-06-07 06:07:43,809] {processor.py:153} INFO - Started process (PID=30740) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:07:43,814] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:07:43,817] {logging_mixin.py:115} INFO - [2022-06-07 06:07:43,817] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:07:43,912] {logging_mixin.py:115} INFO - [2022-06-07 06:07:43,909] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:07:43,914] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:07:44,022] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-07 06:08:14,403] {processor.py:153} INFO - Started process (PID=30805) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:08:14,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:08:14,408] {logging_mixin.py:115} INFO - [2022-06-07 06:08:14,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:08:14,488] {logging_mixin.py:115} INFO - [2022-06-07 06:08:14,486] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:08:14,491] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:08:14,605] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-07 06:08:45,202] {processor.py:153} INFO - Started process (PID=30874) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:08:45,204] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:08:45,205] {logging_mixin.py:115} INFO - [2022-06-07 06:08:45,205] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:08:45,270] {logging_mixin.py:115} INFO - [2022-06-07 06:08:45,268] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:08:45,273] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:08:45,398] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 06:09:15,469] {processor.py:153} INFO - Started process (PID=30931) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:09:15,472] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:09:15,474] {logging_mixin.py:115} INFO - [2022-06-07 06:09:15,474] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:09:15,552] {logging_mixin.py:115} INFO - [2022-06-07 06:09:15,549] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:09:15,554] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:09:15,660] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-07 06:09:45,721] {processor.py:153} INFO - Started process (PID=31000) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:09:45,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:09:45,728] {logging_mixin.py:115} INFO - [2022-06-07 06:09:45,728] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:09:45,805] {logging_mixin.py:115} INFO - [2022-06-07 06:09:45,802] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:09:45,806] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:09:45,905] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 06:10:16,927] {processor.py:153} INFO - Started process (PID=31068) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:10:16,930] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:10:16,932] {logging_mixin.py:115} INFO - [2022-06-07 06:10:16,932] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:10:17,012] {logging_mixin.py:115} INFO - [2022-06-07 06:10:17,010] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:10:17,015] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:10:17,119] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-07 06:10:47,856] {processor.py:153} INFO - Started process (PID=31136) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:10:47,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:10:47,861] {logging_mixin.py:115} INFO - [2022-06-07 06:10:47,861] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:10:47,973] {logging_mixin.py:115} INFO - [2022-06-07 06:10:47,970] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:10:47,975] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:10:48,092] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-07 06:11:18,502] {processor.py:153} INFO - Started process (PID=31204) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:11:18,506] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:11:18,508] {logging_mixin.py:115} INFO - [2022-06-07 06:11:18,507] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:11:18,583] {logging_mixin.py:115} INFO - [2022-06-07 06:11:18,581] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:11:18,586] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:11:18,686] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-07 06:11:48,770] {processor.py:153} INFO - Started process (PID=31262) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:11:48,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:11:48,775] {logging_mixin.py:115} INFO - [2022-06-07 06:11:48,775] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:11:48,858] {logging_mixin.py:115} INFO - [2022-06-07 06:11:48,856] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:11:48,859] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:11:48,962] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-07 06:12:19,213] {processor.py:153} INFO - Started process (PID=31332) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:12:19,216] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:12:19,218] {logging_mixin.py:115} INFO - [2022-06-07 06:12:19,218] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:12:19,318] {logging_mixin.py:115} INFO - [2022-06-07 06:12:19,311] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:12:19,320] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:12:19,435] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-07 06:12:49,828] {processor.py:153} INFO - Started process (PID=31404) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:12:49,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:12:49,840] {logging_mixin.py:115} INFO - [2022-06-07 06:12:49,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:12:50,048] {logging_mixin.py:115} INFO - [2022-06-07 06:12:50,040] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:12:50,053] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:12:50,358] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.546 seconds
[2022-06-07 06:13:20,905] {processor.py:153} INFO - Started process (PID=31473) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:13:20,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:13:20,913] {logging_mixin.py:115} INFO - [2022-06-07 06:13:20,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:13:21,060] {logging_mixin.py:115} INFO - [2022-06-07 06:13:21,057] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:13:21,062] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:13:21,254] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.360 seconds
[2022-06-07 06:13:52,129] {processor.py:153} INFO - Started process (PID=31540) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:13:52,132] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:13:52,136] {logging_mixin.py:115} INFO - [2022-06-07 06:13:52,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:13:52,263] {logging_mixin.py:115} INFO - [2022-06-07 06:13:52,259] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:13:52,268] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:13:52,430] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.310 seconds
[2022-06-07 06:14:22,493] {processor.py:153} INFO - Started process (PID=31597) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:14:22,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:14:22,499] {logging_mixin.py:115} INFO - [2022-06-07 06:14:22,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:14:22,574] {logging_mixin.py:115} INFO - [2022-06-07 06:14:22,572] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:14:22,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:14:22,684] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 06:14:52,940] {processor.py:153} INFO - Started process (PID=31663) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:14:52,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:14:52,944] {logging_mixin.py:115} INFO - [2022-06-07 06:14:52,944] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:14:53,036] {logging_mixin.py:115} INFO - [2022-06-07 06:14:53,028] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:14:53,038] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:14:53,140] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-07 06:15:23,363] {processor.py:153} INFO - Started process (PID=31730) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:15:23,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:15:23,367] {logging_mixin.py:115} INFO - [2022-06-07 06:15:23,367] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:15:23,426] {logging_mixin.py:115} INFO - [2022-06-07 06:15:23,424] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:15:23,428] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:15:23,557] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 06:15:53,653] {processor.py:153} INFO - Started process (PID=31797) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:15:53,656] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:15:53,658] {logging_mixin.py:115} INFO - [2022-06-07 06:15:53,658] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:15:53,756] {logging_mixin.py:115} INFO - [2022-06-07 06:15:53,754] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:15:53,760] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:15:53,888] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-07 06:16:24,101] {processor.py:153} INFO - Started process (PID=31853) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:16:24,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:16:24,105] {logging_mixin.py:115} INFO - [2022-06-07 06:16:24,105] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:16:24,187] {logging_mixin.py:115} INFO - [2022-06-07 06:16:24,184] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:16:24,188] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:16:24,330] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-07 06:16:54,826] {processor.py:153} INFO - Started process (PID=31919) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:16:54,829] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:16:54,831] {logging_mixin.py:115} INFO - [2022-06-07 06:16:54,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:16:54,914] {logging_mixin.py:115} INFO - [2022-06-07 06:16:54,911] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:16:54,916] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:16:55,025] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-07 06:17:25,815] {processor.py:153} INFO - Started process (PID=31985) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:17:25,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:17:25,819] {logging_mixin.py:115} INFO - [2022-06-07 06:17:25,819] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:17:25,901] {logging_mixin.py:115} INFO - [2022-06-07 06:17:25,899] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:17:25,903] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:17:26,018] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-07 06:17:56,518] {processor.py:153} INFO - Started process (PID=32051) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:17:56,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:17:56,521] {logging_mixin.py:115} INFO - [2022-06-07 06:17:56,521] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:17:56,585] {logging_mixin.py:115} INFO - [2022-06-07 06:17:56,583] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:17:56,587] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:17:56,686] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 06:18:26,739] {processor.py:153} INFO - Started process (PID=32119) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:18:26,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:18:26,742] {logging_mixin.py:115} INFO - [2022-06-07 06:18:26,742] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:18:26,811] {logging_mixin.py:115} INFO - [2022-06-07 06:18:26,808] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:18:26,812] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:18:26,929] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-07 06:18:57,247] {processor.py:153} INFO - Started process (PID=32178) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:18:57,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:18:57,251] {logging_mixin.py:115} INFO - [2022-06-07 06:18:57,251] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:18:57,319] {logging_mixin.py:115} INFO - [2022-06-07 06:18:57,317] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:18:57,321] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:18:57,423] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 06:19:27,875] {processor.py:153} INFO - Started process (PID=32246) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:19:27,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:19:27,898] {logging_mixin.py:115} INFO - [2022-06-07 06:19:27,897] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:19:28,118] {logging_mixin.py:115} INFO - [2022-06-07 06:19:28,115] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:19:28,121] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:19:28,357] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.490 seconds
[2022-06-07 06:19:58,741] {processor.py:153} INFO - Started process (PID=32315) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:19:58,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:19:58,745] {logging_mixin.py:115} INFO - [2022-06-07 06:19:58,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:19:58,842] {logging_mixin.py:115} INFO - [2022-06-07 06:19:58,839] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:19:58,844] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:19:58,963] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-07 06:20:29,741] {processor.py:153} INFO - Started process (PID=32384) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:20:29,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:20:29,744] {logging_mixin.py:115} INFO - [2022-06-07 06:20:29,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:20:29,852] {logging_mixin.py:115} INFO - [2022-06-07 06:20:29,849] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:20:29,853] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:20:30,006] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.286 seconds
[2022-06-07 06:21:00,942] {processor.py:153} INFO - Started process (PID=32454) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:21:00,952] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:21:00,953] {logging_mixin.py:115} INFO - [2022-06-07 06:21:00,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:21:01,108] {logging_mixin.py:115} INFO - [2022-06-07 06:21:01,100] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:21:01,111] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:21:01,254] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.321 seconds
[2022-06-07 06:21:31,761] {processor.py:153} INFO - Started process (PID=32512) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:21:31,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:21:31,769] {logging_mixin.py:115} INFO - [2022-06-07 06:21:31,769] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:21:31,872] {logging_mixin.py:115} INFO - [2022-06-07 06:21:31,868] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:21:31,874] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:21:31,986] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-07 06:22:02,651] {processor.py:153} INFO - Started process (PID=32580) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:22:02,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:22:02,655] {logging_mixin.py:115} INFO - [2022-06-07 06:22:02,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:22:02,751] {logging_mixin.py:115} INFO - [2022-06-07 06:22:02,749] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:22:02,752] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:22:02,858] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-07 06:22:33,285] {processor.py:153} INFO - Started process (PID=32647) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:22:33,292] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:22:33,312] {logging_mixin.py:115} INFO - [2022-06-07 06:22:33,312] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:22:33,526] {logging_mixin.py:115} INFO - [2022-06-07 06:22:33,519] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:22:33,531] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:22:33,716] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.451 seconds
[2022-06-07 06:23:04,488] {processor.py:153} INFO - Started process (PID=32714) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:23:04,490] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:23:04,492] {logging_mixin.py:115} INFO - [2022-06-07 06:23:04,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:23:04,581] {logging_mixin.py:115} INFO - [2022-06-07 06:23:04,578] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:23:04,582] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:23:04,683] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 06:23:34,866] {processor.py:153} INFO - Started process (PID=32771) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:23:34,869] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:23:34,871] {logging_mixin.py:115} INFO - [2022-06-07 06:23:34,871] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:23:34,935] {logging_mixin.py:115} INFO - [2022-06-07 06:23:34,933] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:23:34,937] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:23:35,044] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-07 06:24:05,092] {processor.py:153} INFO - Started process (PID=32841) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:24:05,093] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:24:05,095] {logging_mixin.py:115} INFO - [2022-06-07 06:24:05,094] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:24:05,186] {logging_mixin.py:115} INFO - [2022-06-07 06:24:05,183] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:24:05,191] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:24:05,307] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-07 06:24:36,164] {processor.py:153} INFO - Started process (PID=32910) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:24:36,167] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:24:36,173] {logging_mixin.py:115} INFO - [2022-06-07 06:24:36,173] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:24:36,363] {logging_mixin.py:115} INFO - [2022-06-07 06:24:36,359] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:24:36,375] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:24:36,545] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.392 seconds
[2022-06-07 06:25:06,644] {processor.py:153} INFO - Started process (PID=32977) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:25:06,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:25:06,649] {logging_mixin.py:115} INFO - [2022-06-07 06:25:06,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:25:06,739] {logging_mixin.py:115} INFO - [2022-06-07 06:25:06,736] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:25:06,740] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:25:06,842] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-07 06:25:37,679] {processor.py:153} INFO - Started process (PID=33045) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:25:37,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:25:37,683] {logging_mixin.py:115} INFO - [2022-06-07 06:25:37,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:25:37,728] {logging_mixin.py:115} INFO - [2022-06-07 06:25:37,725] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:25:37,730] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:25:37,824] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-07 06:26:08,029] {processor.py:153} INFO - Started process (PID=33102) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:26:08,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:26:08,032] {logging_mixin.py:115} INFO - [2022-06-07 06:26:08,032] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:26:08,117] {logging_mixin.py:115} INFO - [2022-06-07 06:26:08,114] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:26:08,118] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:26:08,227] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 06:26:38,447] {processor.py:153} INFO - Started process (PID=33171) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:26:38,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:26:38,451] {logging_mixin.py:115} INFO - [2022-06-07 06:26:38,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:26:38,506] {logging_mixin.py:115} INFO - [2022-06-07 06:26:38,504] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:26:38,508] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:26:38,619] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 06:27:08,884] {processor.py:153} INFO - Started process (PID=33238) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:27:08,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:27:08,887] {logging_mixin.py:115} INFO - [2022-06-07 06:27:08,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:27:08,953] {logging_mixin.py:115} INFO - [2022-06-07 06:27:08,951] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:27:08,954] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:27:09,049] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 06:27:39,718] {processor.py:153} INFO - Started process (PID=33303) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:27:39,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:27:39,723] {logging_mixin.py:115} INFO - [2022-06-07 06:27:39,723] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:27:39,805] {logging_mixin.py:115} INFO - [2022-06-07 06:27:39,801] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:27:39,806] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:27:39,904] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-07 06:28:09,991] {processor.py:153} INFO - Started process (PID=33370) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:28:09,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:28:09,997] {logging_mixin.py:115} INFO - [2022-06-07 06:28:09,997] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:28:10,076] {logging_mixin.py:115} INFO - [2022-06-07 06:28:10,073] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:28:10,077] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:28:10,174] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-07 06:28:40,362] {processor.py:153} INFO - Started process (PID=33428) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:28:40,363] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:28:40,364] {logging_mixin.py:115} INFO - [2022-06-07 06:28:40,364] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:28:40,414] {logging_mixin.py:115} INFO - [2022-06-07 06:28:40,413] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:28:40,416] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:28:40,515] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-07 06:29:10,874] {processor.py:153} INFO - Started process (PID=33498) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:29:10,877] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:29:10,878] {logging_mixin.py:115} INFO - [2022-06-07 06:29:10,878] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:29:10,956] {logging_mixin.py:115} INFO - [2022-06-07 06:29:10,954] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:29:10,958] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:29:11,057] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-07 06:29:41,266] {processor.py:153} INFO - Started process (PID=33565) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:29:41,268] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:29:41,270] {logging_mixin.py:115} INFO - [2022-06-07 06:29:41,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:29:41,333] {logging_mixin.py:115} INFO - [2022-06-07 06:29:41,330] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:29:41,334] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:29:41,441] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 06:30:11,643] {processor.py:153} INFO - Started process (PID=33634) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:30:11,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:30:11,647] {logging_mixin.py:115} INFO - [2022-06-07 06:30:11,647] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:30:11,730] {logging_mixin.py:115} INFO - [2022-06-07 06:30:11,728] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:30:11,732] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:30:11,832] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-07 06:30:42,121] {processor.py:153} INFO - Started process (PID=33699) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:30:42,123] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:30:42,125] {logging_mixin.py:115} INFO - [2022-06-07 06:30:42,125] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:30:42,196] {logging_mixin.py:115} INFO - [2022-06-07 06:30:42,193] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:30:42,197] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:30:42,293] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 06:31:12,987] {processor.py:153} INFO - Started process (PID=33758) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:31:12,988] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:31:12,991] {logging_mixin.py:115} INFO - [2022-06-07 06:31:12,991] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:31:13,060] {logging_mixin.py:115} INFO - [2022-06-07 06:31:13,057] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:31:13,062] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:31:13,170] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 06:31:43,926] {processor.py:153} INFO - Started process (PID=33826) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:31:43,930] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:31:43,932] {logging_mixin.py:115} INFO - [2022-06-07 06:31:43,931] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:31:44,004] {logging_mixin.py:115} INFO - [2022-06-07 06:31:44,001] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:31:44,005] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:31:44,100] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 06:32:14,259] {processor.py:153} INFO - Started process (PID=33896) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:32:14,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:32:14,264] {logging_mixin.py:115} INFO - [2022-06-07 06:32:14,264] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:32:14,334] {logging_mixin.py:115} INFO - [2022-06-07 06:32:14,332] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:32:14,336] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:32:14,431] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 06:32:44,593] {processor.py:153} INFO - Started process (PID=33962) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:32:44,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:32:44,597] {logging_mixin.py:115} INFO - [2022-06-07 06:32:44,597] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:32:44,655] {logging_mixin.py:115} INFO - [2022-06-07 06:32:44,652] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:32:44,656] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:32:44,753] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-07 06:33:14,848] {processor.py:153} INFO - Started process (PID=34033) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:33:14,852] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:33:14,862] {logging_mixin.py:115} INFO - [2022-06-07 06:33:14,862] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:33:14,936] {logging_mixin.py:115} INFO - [2022-06-07 06:33:14,934] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:33:14,938] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:33:15,038] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-07 06:33:45,357] {processor.py:153} INFO - Started process (PID=34089) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:33:45,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:33:45,360] {logging_mixin.py:115} INFO - [2022-06-07 06:33:45,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:33:45,409] {logging_mixin.py:115} INFO - [2022-06-07 06:33:45,407] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:33:45,411] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:33:45,507] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-07 06:34:15,825] {processor.py:153} INFO - Started process (PID=34158) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:34:15,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:34:15,828] {logging_mixin.py:115} INFO - [2022-06-07 06:34:15,828] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:34:15,919] {logging_mixin.py:115} INFO - [2022-06-07 06:34:15,914] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:34:15,920] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:34:16,045] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-07 06:34:46,218] {processor.py:153} INFO - Started process (PID=34226) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:34:46,221] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:34:46,223] {logging_mixin.py:115} INFO - [2022-06-07 06:34:46,222] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:34:46,319] {logging_mixin.py:115} INFO - [2022-06-07 06:34:46,316] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:34:46,324] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:34:46,425] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-07 06:35:17,096] {processor.py:153} INFO - Started process (PID=34295) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:35:17,100] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:35:17,104] {logging_mixin.py:115} INFO - [2022-06-07 06:35:17,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:35:17,195] {logging_mixin.py:115} INFO - [2022-06-07 06:35:17,192] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:35:17,196] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:35:17,299] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-07 06:35:47,387] {processor.py:153} INFO - Started process (PID=34351) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:35:47,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:35:47,391] {logging_mixin.py:115} INFO - [2022-06-07 06:35:47,391] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:35:47,486] {logging_mixin.py:115} INFO - [2022-06-07 06:35:47,480] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:35:47,489] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:35:47,595] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-07 06:36:17,984] {processor.py:153} INFO - Started process (PID=34419) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:36:17,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:36:17,989] {logging_mixin.py:115} INFO - [2022-06-07 06:36:17,989] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:36:18,090] {logging_mixin.py:115} INFO - [2022-06-07 06:36:18,086] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:36:18,092] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:36:18,210] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-07 06:36:48,799] {processor.py:153} INFO - Started process (PID=34485) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:36:48,802] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:36:48,805] {logging_mixin.py:115} INFO - [2022-06-07 06:36:48,805] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:36:48,902] {logging_mixin.py:115} INFO - [2022-06-07 06:36:48,899] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:36:48,904] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:36:49,018] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-07 06:37:19,570] {processor.py:153} INFO - Started process (PID=34553) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:37:19,572] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:37:19,574] {logging_mixin.py:115} INFO - [2022-06-07 06:37:19,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:37:19,650] {logging_mixin.py:115} INFO - [2022-06-07 06:37:19,647] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:37:19,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:37:19,749] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-07 06:37:50,144] {processor.py:153} INFO - Started process (PID=34624) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:37:50,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:37:50,148] {logging_mixin.py:115} INFO - [2022-06-07 06:37:50,147] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:37:50,244] {logging_mixin.py:115} INFO - [2022-06-07 06:37:50,238] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:37:50,246] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:37:50,394] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-07 06:38:20,584] {processor.py:153} INFO - Started process (PID=34681) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:38:20,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:38:20,588] {logging_mixin.py:115} INFO - [2022-06-07 06:38:20,588] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:38:20,671] {logging_mixin.py:115} INFO - [2022-06-07 06:38:20,668] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:38:20,672] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:38:20,780] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 06:38:51,187] {processor.py:153} INFO - Started process (PID=34750) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:38:51,190] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:38:51,191] {logging_mixin.py:115} INFO - [2022-06-07 06:38:51,191] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:38:51,310] {logging_mixin.py:115} INFO - [2022-06-07 06:38:51,302] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:38:51,314] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:38:51,470] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.290 seconds
[2022-06-07 06:39:22,004] {processor.py:153} INFO - Started process (PID=34819) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:39:22,006] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:39:22,008] {logging_mixin.py:115} INFO - [2022-06-07 06:39:22,008] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:39:22,101] {logging_mixin.py:115} INFO - [2022-06-07 06:39:22,098] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:39:22,102] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:39:22,210] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.210 seconds
[2022-06-07 06:39:52,758] {processor.py:153} INFO - Started process (PID=34885) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:39:52,761] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:39:52,763] {logging_mixin.py:115} INFO - [2022-06-07 06:39:52,763] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:39:52,877] {logging_mixin.py:115} INFO - [2022-06-07 06:39:52,861] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:39:52,880] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:39:53,011] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.266 seconds
[2022-06-07 06:40:23,374] {processor.py:153} INFO - Started process (PID=34955) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:40:23,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:40:23,381] {logging_mixin.py:115} INFO - [2022-06-07 06:40:23,381] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:40:23,471] {logging_mixin.py:115} INFO - [2022-06-07 06:40:23,467] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:40:23,472] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:40:23,574] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-07 06:40:53,781] {processor.py:153} INFO - Started process (PID=35014) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:40:53,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:40:53,785] {logging_mixin.py:115} INFO - [2022-06-07 06:40:53,785] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:40:53,860] {logging_mixin.py:115} INFO - [2022-06-07 06:40:53,857] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:40:53,861] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:40:53,960] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-07 06:41:24,461] {processor.py:153} INFO - Started process (PID=35083) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:41:24,463] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:41:24,464] {logging_mixin.py:115} INFO - [2022-06-07 06:41:24,464] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:41:24,521] {logging_mixin.py:115} INFO - [2022-06-07 06:41:24,518] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:41:24,522] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:41:24,650] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 06:41:54,699] {processor.py:153} INFO - Started process (PID=35151) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:41:54,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:41:54,720] {logging_mixin.py:115} INFO - [2022-06-07 06:41:54,720] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:41:54,788] {logging_mixin.py:115} INFO - [2022-06-07 06:41:54,786] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:41:54,789] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:41:54,885] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-07 06:42:25,139] {processor.py:153} INFO - Started process (PID=35221) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:42:25,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:42:25,142] {logging_mixin.py:115} INFO - [2022-06-07 06:42:25,142] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:42:25,199] {logging_mixin.py:115} INFO - [2022-06-07 06:42:25,196] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:42:25,200] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:42:25,298] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 06:42:55,494] {processor.py:153} INFO - Started process (PID=35290) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:42:55,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:42:55,497] {logging_mixin.py:115} INFO - [2022-06-07 06:42:55,497] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:42:55,560] {logging_mixin.py:115} INFO - [2022-06-07 06:42:55,558] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:42:55,561] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:42:55,655] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 06:43:25,890] {processor.py:153} INFO - Started process (PID=35347) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:43:25,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:43:25,893] {logging_mixin.py:115} INFO - [2022-06-07 06:43:25,893] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:43:25,945] {logging_mixin.py:115} INFO - [2022-06-07 06:43:25,943] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:43:25,947] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:43:26,046] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 06:43:56,332] {processor.py:153} INFO - Started process (PID=35417) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:43:56,334] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:43:56,336] {logging_mixin.py:115} INFO - [2022-06-07 06:43:56,336] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:43:56,419] {logging_mixin.py:115} INFO - [2022-06-07 06:43:56,415] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:43:56,421] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:43:56,558] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-07 06:44:27,145] {processor.py:153} INFO - Started process (PID=35483) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:44:27,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:44:27,150] {logging_mixin.py:115} INFO - [2022-06-07 06:44:27,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:44:27,239] {logging_mixin.py:115} INFO - [2022-06-07 06:44:27,236] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:44:27,241] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:44:27,350] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-07 06:44:57,499] {processor.py:153} INFO - Started process (PID=35550) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:44:57,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:44:57,503] {logging_mixin.py:115} INFO - [2022-06-07 06:44:57,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:44:57,575] {logging_mixin.py:115} INFO - [2022-06-07 06:44:57,572] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:44:57,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:44:57,672] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 06:45:27,862] {processor.py:153} INFO - Started process (PID=35616) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:45:27,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:45:27,867] {logging_mixin.py:115} INFO - [2022-06-07 06:45:27,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:45:27,920] {logging_mixin.py:115} INFO - [2022-06-07 06:45:27,918] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:45:27,922] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:45:28,016] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 06:45:58,923] {processor.py:153} INFO - Started process (PID=35682) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:45:58,925] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:45:58,926] {logging_mixin.py:115} INFO - [2022-06-07 06:45:58,926] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:45:58,996] {logging_mixin.py:115} INFO - [2022-06-07 06:45:58,993] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:45:58,997] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:45:59,124] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.205 seconds
[2022-06-07 06:46:29,460] {processor.py:153} INFO - Started process (PID=35740) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:46:29,461] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:46:29,462] {logging_mixin.py:115} INFO - [2022-06-07 06:46:29,462] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:46:29,531] {logging_mixin.py:115} INFO - [2022-06-07 06:46:29,528] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:46:29,536] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:46:29,636] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 06:46:59,916] {processor.py:153} INFO - Started process (PID=35807) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:46:59,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:46:59,923] {logging_mixin.py:115} INFO - [2022-06-07 06:46:59,922] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:46:59,994] {logging_mixin.py:115} INFO - [2022-06-07 06:46:59,991] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:46:59,995] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:47:00,097] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 06:47:30,178] {processor.py:153} INFO - Started process (PID=35873) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:47:30,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:47:30,183] {logging_mixin.py:115} INFO - [2022-06-07 06:47:30,183] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:47:30,262] {logging_mixin.py:115} INFO - [2022-06-07 06:47:30,260] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:47:30,264] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:47:30,364] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-07 06:48:00,590] {processor.py:153} INFO - Started process (PID=35942) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:48:00,592] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:48:00,593] {logging_mixin.py:115} INFO - [2022-06-07 06:48:00,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:48:00,657] {logging_mixin.py:115} INFO - [2022-06-07 06:48:00,655] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:48:00,659] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:48:00,753] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 06:48:30,937] {processor.py:153} INFO - Started process (PID=36000) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:48:30,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:48:30,943] {logging_mixin.py:115} INFO - [2022-06-07 06:48:30,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:48:31,014] {logging_mixin.py:115} INFO - [2022-06-07 06:48:31,012] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:48:31,016] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:48:31,123] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-07 06:49:01,322] {processor.py:153} INFO - Started process (PID=36069) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:49:01,325] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:49:01,326] {logging_mixin.py:115} INFO - [2022-06-07 06:49:01,326] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:49:01,413] {logging_mixin.py:115} INFO - [2022-06-07 06:49:01,411] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:49:01,414] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:49:01,516] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 06:49:31,832] {processor.py:153} INFO - Started process (PID=36141) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:49:31,834] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:49:31,835] {logging_mixin.py:115} INFO - [2022-06-07 06:49:31,835] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:49:31,883] {logging_mixin.py:115} INFO - [2022-06-07 06:49:31,881] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:49:31,885] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:49:31,997] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 06:50:02,275] {processor.py:153} INFO - Started process (PID=36211) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:50:02,278] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:50:02,280] {logging_mixin.py:115} INFO - [2022-06-07 06:50:02,280] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:50:02,362] {logging_mixin.py:115} INFO - [2022-06-07 06:50:02,359] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:50:02,364] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:50:02,470] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-07 06:50:32,644] {processor.py:153} INFO - Started process (PID=36279) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:50:32,647] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:50:32,648] {logging_mixin.py:115} INFO - [2022-06-07 06:50:32,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:50:32,704] {logging_mixin.py:115} INFO - [2022-06-07 06:50:32,701] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:50:32,705] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:50:32,800] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 06:51:02,996] {processor.py:153} INFO - Started process (PID=36336) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:51:02,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:51:03,000] {logging_mixin.py:115} INFO - [2022-06-07 06:51:03,000] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:51:03,097] {logging_mixin.py:115} INFO - [2022-06-07 06:51:03,094] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:51:03,101] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:51:03,220] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-07 06:51:33,678] {processor.py:153} INFO - Started process (PID=36406) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:51:33,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:51:33,682] {logging_mixin.py:115} INFO - [2022-06-07 06:51:33,682] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:51:33,734] {logging_mixin.py:115} INFO - [2022-06-07 06:51:33,732] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:51:33,735] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:51:33,841] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 06:52:04,312] {processor.py:153} INFO - Started process (PID=36473) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:52:04,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:52:04,314] {logging_mixin.py:115} INFO - [2022-06-07 06:52:04,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:52:04,388] {logging_mixin.py:115} INFO - [2022-06-07 06:52:04,385] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:52:04,390] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:52:04,485] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 06:52:34,701] {processor.py:153} INFO - Started process (PID=36542) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:52:34,705] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:52:34,708] {logging_mixin.py:115} INFO - [2022-06-07 06:52:34,708] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:52:34,791] {logging_mixin.py:115} INFO - [2022-06-07 06:52:34,788] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:52:34,792] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:52:34,893] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 06:53:05,228] {processor.py:153} INFO - Started process (PID=36609) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:53:05,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:53:05,231] {logging_mixin.py:115} INFO - [2022-06-07 06:53:05,231] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:53:05,283] {logging_mixin.py:115} INFO - [2022-06-07 06:53:05,280] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:53:05,284] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:53:05,384] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-07 06:53:35,644] {processor.py:153} INFO - Started process (PID=36675) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:53:35,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:53:35,647] {logging_mixin.py:115} INFO - [2022-06-07 06:53:35,647] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:53:35,713] {logging_mixin.py:115} INFO - [2022-06-07 06:53:35,710] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:53:35,714] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:53:35,821] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 06:54:05,935] {processor.py:153} INFO - Started process (PID=36733) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:54:05,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:54:05,938] {logging_mixin.py:115} INFO - [2022-06-07 06:54:05,938] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:54:06,008] {logging_mixin.py:115} INFO - [2022-06-07 06:54:06,006] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:54:06,009] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:54:06,136] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.204 seconds
[2022-06-07 06:54:36,249] {processor.py:153} INFO - Started process (PID=36800) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:54:36,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:54:36,254] {logging_mixin.py:115} INFO - [2022-06-07 06:54:36,254] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:54:36,359] {logging_mixin.py:115} INFO - [2022-06-07 06:54:36,357] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:54:36,361] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:54:36,498] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.261 seconds
[2022-06-07 06:55:06,625] {processor.py:153} INFO - Started process (PID=36866) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:55:06,628] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:55:06,634] {logging_mixin.py:115} INFO - [2022-06-07 06:55:06,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:55:06,719] {logging_mixin.py:115} INFO - [2022-06-07 06:55:06,715] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:55:06,727] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:55:06,841] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-07 06:55:37,057] {processor.py:153} INFO - Started process (PID=36932) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:55:37,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:55:37,060] {logging_mixin.py:115} INFO - [2022-06-07 06:55:37,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:55:37,108] {logging_mixin.py:115} INFO - [2022-06-07 06:55:37,106] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:55:37,109] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:55:37,220] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-07 06:56:07,251] {processor.py:153} INFO - Started process (PID=36992) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:56:07,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:56:07,254] {logging_mixin.py:115} INFO - [2022-06-07 06:56:07,254] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:56:07,346] {logging_mixin.py:115} INFO - [2022-06-07 06:56:07,333] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:56:07,347] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:56:07,499] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.251 seconds
[2022-06-07 06:56:37,639] {processor.py:153} INFO - Started process (PID=37059) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:56:37,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:56:37,643] {logging_mixin.py:115} INFO - [2022-06-07 06:56:37,643] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:56:37,704] {logging_mixin.py:115} INFO - [2022-06-07 06:56:37,702] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:56:37,706] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:56:37,804] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 06:57:07,990] {processor.py:153} INFO - Started process (PID=37128) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:57:07,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:57:07,995] {logging_mixin.py:115} INFO - [2022-06-07 06:57:07,995] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:57:08,076] {logging_mixin.py:115} INFO - [2022-06-07 06:57:08,074] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:57:08,078] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:57:08,177] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-07 06:57:38,313] {processor.py:153} INFO - Started process (PID=37196) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:57:38,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:57:38,315] {logging_mixin.py:115} INFO - [2022-06-07 06:57:38,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:57:38,369] {logging_mixin.py:115} INFO - [2022-06-07 06:57:38,366] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:57:38,371] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:57:38,467] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-07 06:58:08,564] {processor.py:153} INFO - Started process (PID=37263) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:58:08,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:58:08,568] {logging_mixin.py:115} INFO - [2022-06-07 06:58:08,568] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:58:08,634] {logging_mixin.py:115} INFO - [2022-06-07 06:58:08,632] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:58:08,635] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:58:08,755] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-07 06:58:38,847] {processor.py:153} INFO - Started process (PID=37323) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:58:38,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:58:38,850] {logging_mixin.py:115} INFO - [2022-06-07 06:58:38,850] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:58:38,900] {logging_mixin.py:115} INFO - [2022-06-07 06:58:38,898] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:58:38,902] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:58:39,008] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 06:59:09,862] {processor.py:153} INFO - Started process (PID=37395) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:59:09,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:59:09,867] {logging_mixin.py:115} INFO - [2022-06-07 06:59:09,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:59:09,959] {logging_mixin.py:115} INFO - [2022-06-07 06:59:09,956] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:59:09,961] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:59:10,062] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-07 06:59:41,069] {processor.py:153} INFO - Started process (PID=37462) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:59:41,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 06:59:41,074] {logging_mixin.py:115} INFO - [2022-06-07 06:59:41,074] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:59:41,126] {logging_mixin.py:115} INFO - [2022-06-07 06:59:41,123] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 06:59:41,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 06:59:41,229] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 07:00:11,635] {processor.py:153} INFO - Started process (PID=37529) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:00:11,637] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:00:11,639] {logging_mixin.py:115} INFO - [2022-06-07 07:00:11,639] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:00:11,723] {logging_mixin.py:115} INFO - [2022-06-07 07:00:11,721] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:00:11,725] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:00:11,828] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 07:00:42,752] {processor.py:153} INFO - Started process (PID=37597) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:00:42,755] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:00:42,756] {logging_mixin.py:115} INFO - [2022-06-07 07:00:42,756] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:00:42,809] {logging_mixin.py:115} INFO - [2022-06-07 07:00:42,807] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:00:42,811] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:00:42,926] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 07:01:13,095] {processor.py:153} INFO - Started process (PID=37655) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:01:13,098] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:01:13,101] {logging_mixin.py:115} INFO - [2022-06-07 07:01:13,101] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:01:13,186] {logging_mixin.py:115} INFO - [2022-06-07 07:01:13,184] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:01:13,187] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:01:13,286] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 07:01:43,468] {processor.py:153} INFO - Started process (PID=37726) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:01:43,471] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:01:43,472] {logging_mixin.py:115} INFO - [2022-06-07 07:01:43,471] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:01:43,523] {logging_mixin.py:115} INFO - [2022-06-07 07:01:43,522] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:01:43,524] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:01:43,658] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 07:02:13,873] {processor.py:153} INFO - Started process (PID=37795) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:02:13,877] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:02:13,878] {logging_mixin.py:115} INFO - [2022-06-07 07:02:13,878] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:02:13,961] {logging_mixin.py:115} INFO - [2022-06-07 07:02:13,958] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:02:13,962] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:02:14,083] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-07 07:02:44,840] {processor.py:153} INFO - Started process (PID=37863) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:02:44,844] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:02:44,846] {logging_mixin.py:115} INFO - [2022-06-07 07:02:44,846] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:02:44,942] {logging_mixin.py:115} INFO - [2022-06-07 07:02:44,940] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:02:44,943] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:02:45,049] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-07 07:03:15,357] {processor.py:153} INFO - Started process (PID=37932) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:03:15,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:03:15,368] {logging_mixin.py:115} INFO - [2022-06-07 07:03:15,367] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:03:15,563] {logging_mixin.py:115} INFO - [2022-06-07 07:03:15,558] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:03:15,566] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:03:15,746] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.394 seconds
[2022-06-07 07:03:46,168] {processor.py:153} INFO - Started process (PID=37992) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:03:46,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:03:46,173] {logging_mixin.py:115} INFO - [2022-06-07 07:03:46,173] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:03:46,269] {logging_mixin.py:115} INFO - [2022-06-07 07:03:46,266] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:03:46,270] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:03:46,393] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-07 07:04:17,014] {processor.py:153} INFO - Started process (PID=38060) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:04:17,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:04:17,019] {logging_mixin.py:115} INFO - [2022-06-07 07:04:17,019] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:04:17,133] {logging_mixin.py:115} INFO - [2022-06-07 07:04:17,128] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:04:17,136] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:04:17,283] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.280 seconds
[2022-06-07 07:04:47,688] {processor.py:153} INFO - Started process (PID=38133) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:04:47,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:04:47,692] {logging_mixin.py:115} INFO - [2022-06-07 07:04:47,692] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:04:47,814] {logging_mixin.py:115} INFO - [2022-06-07 07:04:47,806] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:04:47,816] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:04:47,967] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.285 seconds
[2022-06-07 07:05:18,502] {processor.py:153} INFO - Started process (PID=38198) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:05:18,506] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:05:18,508] {logging_mixin.py:115} INFO - [2022-06-07 07:05:18,508] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:05:18,656] {logging_mixin.py:115} INFO - [2022-06-07 07:05:18,653] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:05:18,658] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:05:18,869] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.376 seconds
[2022-06-07 07:05:49,896] {processor.py:153} INFO - Started process (PID=38258) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:05:49,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:05:49,900] {logging_mixin.py:115} INFO - [2022-06-07 07:05:49,900] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:05:50,007] {logging_mixin.py:115} INFO - [2022-06-07 07:05:50,004] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:05:50,008] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:05:50,140] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.250 seconds
[2022-06-07 07:06:20,268] {processor.py:153} INFO - Started process (PID=38329) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:06:20,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:06:20,271] {logging_mixin.py:115} INFO - [2022-06-07 07:06:20,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:06:20,355] {logging_mixin.py:115} INFO - [2022-06-07 07:06:20,352] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:06:20,358] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:06:20,461] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-07 07:06:50,575] {processor.py:153} INFO - Started process (PID=38398) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:06:50,578] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:06:50,580] {logging_mixin.py:115} INFO - [2022-06-07 07:06:50,580] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:06:50,688] {logging_mixin.py:115} INFO - [2022-06-07 07:06:50,686] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:06:50,689] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:06:50,794] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-07 07:07:21,314] {processor.py:153} INFO - Started process (PID=38461) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:07:21,316] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:07:21,319] {logging_mixin.py:115} INFO - [2022-06-07 07:07:21,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:07:21,465] {logging_mixin.py:115} INFO - [2022-06-07 07:07:21,456] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:07:21,469] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:07:21,623] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.328 seconds
[2022-06-07 07:07:51,784] {processor.py:153} INFO - Started process (PID=38520) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:07:51,788] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:07:51,790] {logging_mixin.py:115} INFO - [2022-06-07 07:07:51,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:07:51,893] {logging_mixin.py:115} INFO - [2022-06-07 07:07:51,889] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:07:51,894] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:07:52,005] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-07 07:08:22,204] {processor.py:153} INFO - Started process (PID=38588) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:08:22,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:08:22,209] {logging_mixin.py:115} INFO - [2022-06-07 07:08:22,209] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:08:22,365] {logging_mixin.py:115} INFO - [2022-06-07 07:08:22,362] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:08:22,367] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:08:22,538] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.347 seconds
[2022-06-07 07:08:52,850] {processor.py:153} INFO - Started process (PID=38653) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:08:52,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:08:52,852] {logging_mixin.py:115} INFO - [2022-06-07 07:08:52,852] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:08:52,947] {logging_mixin.py:115} INFO - [2022-06-07 07:08:52,943] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:08:52,948] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:08:53,061] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-07 07:09:23,827] {processor.py:153} INFO - Started process (PID=38709) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:09:23,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:09:23,836] {logging_mixin.py:115} INFO - [2022-06-07 07:09:23,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:09:23,930] {logging_mixin.py:115} INFO - [2022-06-07 07:09:23,927] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:09:23,934] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:09:24,036] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-07 07:09:54,693] {processor.py:153} INFO - Started process (PID=38779) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:09:54,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:09:54,710] {logging_mixin.py:115} INFO - [2022-06-07 07:09:54,709] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:09:54,955] {logging_mixin.py:115} INFO - [2022-06-07 07:09:54,950] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:09:54,957] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:09:55,166] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.492 seconds
[2022-06-07 07:10:25,748] {processor.py:153} INFO - Started process (PID=38846) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:10:25,749] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:10:25,751] {logging_mixin.py:115} INFO - [2022-06-07 07:10:25,750] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:10:25,826] {logging_mixin.py:115} INFO - [2022-06-07 07:10:25,822] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:10:25,827] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:10:25,936] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-07 07:10:56,191] {processor.py:153} INFO - Started process (PID=38915) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:10:56,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:10:56,194] {logging_mixin.py:115} INFO - [2022-06-07 07:10:56,194] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:10:56,303] {logging_mixin.py:115} INFO - [2022-06-07 07:10:56,300] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:10:56,305] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:10:56,410] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-07 07:11:26,800] {processor.py:153} INFO - Started process (PID=38970) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:11:26,804] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:11:26,806] {logging_mixin.py:115} INFO - [2022-06-07 07:11:26,805] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:11:26,913] {logging_mixin.py:115} INFO - [2022-06-07 07:11:26,907] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:11:26,914] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:11:27,032] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-07 07:11:57,396] {processor.py:153} INFO - Started process (PID=39038) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:11:57,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:11:57,399] {logging_mixin.py:115} INFO - [2022-06-07 07:11:57,399] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:11:57,512] {logging_mixin.py:115} INFO - [2022-06-07 07:11:57,506] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:11:57,514] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:11:57,626] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-07 07:12:28,428] {processor.py:153} INFO - Started process (PID=39107) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:12:28,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:12:28,435] {logging_mixin.py:115} INFO - [2022-06-07 07:12:28,435] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:12:28,637] {logging_mixin.py:115} INFO - [2022-06-07 07:12:28,631] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:12:28,638] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:12:28,917] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.494 seconds
[2022-06-07 07:12:59,018] {processor.py:153} INFO - Started process (PID=39175) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:12:59,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:12:59,022] {logging_mixin.py:115} INFO - [2022-06-07 07:12:59,022] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:12:59,119] {logging_mixin.py:115} INFO - [2022-06-07 07:12:59,115] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:12:59,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:12:59,231] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-07 07:13:29,341] {processor.py:153} INFO - Started process (PID=39245) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:13:29,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:13:29,344] {logging_mixin.py:115} INFO - [2022-06-07 07:13:29,344] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:13:29,485] {logging_mixin.py:115} INFO - [2022-06-07 07:13:29,481] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:13:29,494] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:13:29,646] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.309 seconds
[2022-06-07 07:14:00,412] {processor.py:153} INFO - Started process (PID=39303) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:14:00,414] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:14:00,416] {logging_mixin.py:115} INFO - [2022-06-07 07:14:00,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:14:00,517] {logging_mixin.py:115} INFO - [2022-06-07 07:14:00,511] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:14:00,519] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:14:00,658] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-07 07:14:30,772] {processor.py:153} INFO - Started process (PID=39370) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:14:30,775] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:14:30,777] {logging_mixin.py:115} INFO - [2022-06-07 07:14:30,777] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:14:30,872] {logging_mixin.py:115} INFO - [2022-06-07 07:14:30,869] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:14:30,874] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:14:30,981] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-07 07:15:01,965] {processor.py:153} INFO - Started process (PID=39436) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:15:01,968] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:15:01,971] {logging_mixin.py:115} INFO - [2022-06-07 07:15:01,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:15:02,061] {logging_mixin.py:115} INFO - [2022-06-07 07:15:02,058] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:15:02,064] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:15:02,172] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-07 07:15:32,748] {processor.py:153} INFO - Started process (PID=39503) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:15:32,753] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:15:32,755] {logging_mixin.py:115} INFO - [2022-06-07 07:15:32,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:15:32,858] {logging_mixin.py:115} INFO - [2022-06-07 07:15:32,855] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:15:32,861] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:15:32,980] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-07 07:16:03,231] {processor.py:153} INFO - Started process (PID=39571) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:16:03,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:16:03,237] {logging_mixin.py:115} INFO - [2022-06-07 07:16:03,237] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:16:03,345] {logging_mixin.py:115} INFO - [2022-06-07 07:16:03,342] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:16:03,348] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:16:03,504] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.278 seconds
[2022-06-07 07:16:34,205] {processor.py:153} INFO - Started process (PID=39632) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:16:34,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:16:34,208] {logging_mixin.py:115} INFO - [2022-06-07 07:16:34,208] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:16:34,314] {logging_mixin.py:115} INFO - [2022-06-07 07:16:34,311] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:16:34,320] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:16:34,425] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-07 07:17:04,610] {processor.py:153} INFO - Started process (PID=39702) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:17:04,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:17:04,614] {logging_mixin.py:115} INFO - [2022-06-07 07:17:04,614] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:17:04,707] {logging_mixin.py:115} INFO - [2022-06-07 07:17:04,704] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:17:04,708] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:17:04,821] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-07 07:17:35,398] {processor.py:153} INFO - Started process (PID=39769) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:17:35,404] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:17:35,407] {logging_mixin.py:115} INFO - [2022-06-07 07:17:35,407] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:17:35,523] {logging_mixin.py:115} INFO - [2022-06-07 07:17:35,520] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:17:35,526] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:17:35,678] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.289 seconds
[2022-06-07 07:18:06,108] {processor.py:153} INFO - Started process (PID=39828) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:18:06,110] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:18:06,113] {logging_mixin.py:115} INFO - [2022-06-07 07:18:06,112] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:18:06,209] {logging_mixin.py:115} INFO - [2022-06-07 07:18:06,205] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:18:06,211] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:18:06,353] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-07 07:18:37,063] {processor.py:153} INFO - Started process (PID=39905) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:18:37,069] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:18:37,080] {logging_mixin.py:115} INFO - [2022-06-07 07:18:37,079] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:18:37,459] {logging_mixin.py:115} INFO - [2022-06-07 07:18:37,450] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:18:37,463] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:18:37,730] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.684 seconds
[2022-06-07 07:19:08,467] {processor.py:153} INFO - Started process (PID=39972) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:19:08,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:19:08,470] {logging_mixin.py:115} INFO - [2022-06-07 07:19:08,470] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:19:08,545] {logging_mixin.py:115} INFO - [2022-06-07 07:19:08,542] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:19:08,546] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:19:08,680] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-07 07:19:38,805] {processor.py:153} INFO - Started process (PID=40038) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:19:38,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:19:38,810] {logging_mixin.py:115} INFO - [2022-06-07 07:19:38,809] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:19:38,897] {logging_mixin.py:115} INFO - [2022-06-07 07:19:38,894] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:19:38,899] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:19:39,013] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-07 07:20:09,102] {processor.py:153} INFO - Started process (PID=40095) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:20:09,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:20:09,104] {logging_mixin.py:115} INFO - [2022-06-07 07:20:09,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:20:09,200] {logging_mixin.py:115} INFO - [2022-06-07 07:20:09,197] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:20:09,201] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:20:09,316] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-07 07:20:39,571] {processor.py:153} INFO - Started process (PID=40166) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:20:39,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:20:39,574] {logging_mixin.py:115} INFO - [2022-06-07 07:20:39,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:20:39,618] {logging_mixin.py:115} INFO - [2022-06-07 07:20:39,616] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:20:39,620] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:20:39,715] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-07 07:21:10,140] {processor.py:153} INFO - Started process (PID=40233) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:21:10,144] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:21:10,147] {logging_mixin.py:115} INFO - [2022-06-07 07:21:10,147] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:21:10,228] {logging_mixin.py:115} INFO - [2022-06-07 07:21:10,225] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:21:10,229] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:21:10,339] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.205 seconds
[2022-06-07 07:21:40,743] {processor.py:153} INFO - Started process (PID=40299) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:21:40,745] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:21:40,746] {logging_mixin.py:115} INFO - [2022-06-07 07:21:40,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:21:40,820] {logging_mixin.py:115} INFO - [2022-06-07 07:21:40,818] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:21:40,822] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:21:40,920] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 07:22:11,794] {processor.py:153} INFO - Started process (PID=40368) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:22:11,796] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:22:11,798] {logging_mixin.py:115} INFO - [2022-06-07 07:22:11,798] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:22:11,903] {logging_mixin.py:115} INFO - [2022-06-07 07:22:11,901] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:22:11,904] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:22:12,015] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-07 07:22:42,685] {processor.py:153} INFO - Started process (PID=40426) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:22:42,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:22:42,690] {logging_mixin.py:115} INFO - [2022-06-07 07:22:42,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:22:42,797] {logging_mixin.py:115} INFO - [2022-06-07 07:22:42,793] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:22:42,798] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:22:42,915] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-07 07:23:13,367] {processor.py:153} INFO - Started process (PID=40494) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:23:13,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:23:13,369] {logging_mixin.py:115} INFO - [2022-06-07 07:23:13,369] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:23:13,473] {logging_mixin.py:115} INFO - [2022-06-07 07:23:13,470] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:23:13,474] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:23:13,599] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-07 07:23:43,853] {processor.py:153} INFO - Started process (PID=40559) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:23:43,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:23:43,856] {logging_mixin.py:115} INFO - [2022-06-07 07:23:43,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:23:43,940] {logging_mixin.py:115} INFO - [2022-06-07 07:23:43,938] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:23:43,946] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:23:44,079] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-07 07:24:14,441] {processor.py:153} INFO - Started process (PID=40626) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:24:14,444] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:24:14,445] {logging_mixin.py:115} INFO - [2022-06-07 07:24:14,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:24:14,515] {logging_mixin.py:115} INFO - [2022-06-07 07:24:14,513] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:24:14,518] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:24:14,618] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 07:24:45,075] {processor.py:153} INFO - Started process (PID=40683) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:24:45,077] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:24:45,078] {logging_mixin.py:115} INFO - [2022-06-07 07:24:45,078] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:24:45,198] {logging_mixin.py:115} INFO - [2022-06-07 07:24:45,195] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:24:45,200] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:24:45,338] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.269 seconds
[2022-06-07 07:25:16,238] {processor.py:153} INFO - Started process (PID=40751) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:25:16,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:25:16,241] {logging_mixin.py:115} INFO - [2022-06-07 07:25:16,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:25:16,317] {logging_mixin.py:115} INFO - [2022-06-07 07:25:16,315] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:25:16,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:25:16,416] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 07:25:46,601] {processor.py:153} INFO - Started process (PID=40819) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:25:46,609] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:25:46,614] {logging_mixin.py:115} INFO - [2022-06-07 07:25:46,614] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:25:46,683] {logging_mixin.py:115} INFO - [2022-06-07 07:25:46,681] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:25:46,684] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:25:46,786] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 07:26:17,264] {processor.py:153} INFO - Started process (PID=40887) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:26:17,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:26:17,267] {logging_mixin.py:115} INFO - [2022-06-07 07:26:17,267] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:26:17,333] {logging_mixin.py:115} INFO - [2022-06-07 07:26:17,330] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:26:17,335] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:26:17,470] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-07 07:26:47,971] {processor.py:153} INFO - Started process (PID=40954) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:26:47,974] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:26:47,977] {logging_mixin.py:115} INFO - [2022-06-07 07:26:47,977] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:26:48,043] {logging_mixin.py:115} INFO - [2022-06-07 07:26:48,040] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:26:48,044] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:26:48,152] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 07:27:18,674] {processor.py:153} INFO - Started process (PID=41021) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:27:18,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:27:18,677] {logging_mixin.py:115} INFO - [2022-06-07 07:27:18,677] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:27:18,747] {logging_mixin.py:115} INFO - [2022-06-07 07:27:18,744] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:27:18,749] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:27:18,861] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-07 07:27:49,091] {processor.py:153} INFO - Started process (PID=41079) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:27:49,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:27:49,098] {logging_mixin.py:115} INFO - [2022-06-07 07:27:49,098] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:27:49,184] {logging_mixin.py:115} INFO - [2022-06-07 07:27:49,180] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:27:49,185] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:27:49,294] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-07 07:28:19,451] {processor.py:153} INFO - Started process (PID=41149) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:28:19,454] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:28:19,457] {logging_mixin.py:115} INFO - [2022-06-07 07:28:19,457] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:28:19,527] {logging_mixin.py:115} INFO - [2022-06-07 07:28:19,523] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:28:19,531] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:28:19,640] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-07 07:28:49,746] {processor.py:153} INFO - Started process (PID=41220) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:28:49,748] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:28:49,750] {logging_mixin.py:115} INFO - [2022-06-07 07:28:49,750] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:28:49,828] {logging_mixin.py:115} INFO - [2022-06-07 07:28:49,825] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:28:49,830] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:28:49,932] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 07:29:20,396] {processor.py:153} INFO - Started process (PID=41291) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:29:20,399] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:29:20,401] {logging_mixin.py:115} INFO - [2022-06-07 07:29:20,401] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:29:20,475] {logging_mixin.py:115} INFO - [2022-06-07 07:29:20,473] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:29:20,477] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:29:20,577] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-07 07:29:50,687] {processor.py:153} INFO - Started process (PID=41348) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:29:50,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:29:50,693] {logging_mixin.py:115} INFO - [2022-06-07 07:29:50,692] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:29:50,750] {logging_mixin.py:115} INFO - [2022-06-07 07:29:50,749] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:29:50,752] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:29:50,849] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 07:30:21,740] {processor.py:153} INFO - Started process (PID=41415) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:30:21,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:30:21,744] {logging_mixin.py:115} INFO - [2022-06-07 07:30:21,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:30:21,789] {logging_mixin.py:115} INFO - [2022-06-07 07:30:21,787] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:30:21,791] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:30:21,890] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-07 07:30:52,715] {processor.py:153} INFO - Started process (PID=41483) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:30:52,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:30:52,718] {logging_mixin.py:115} INFO - [2022-06-07 07:30:52,718] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:30:52,777] {logging_mixin.py:115} INFO - [2022-06-07 07:30:52,774] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:30:52,781] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:30:52,898] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 07:31:23,212] {processor.py:153} INFO - Started process (PID=41550) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:31:23,215] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:31:23,216] {logging_mixin.py:115} INFO - [2022-06-07 07:31:23,216] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:31:23,270] {logging_mixin.py:115} INFO - [2022-06-07 07:31:23,268] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:31:23,271] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:31:23,366] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 07:31:53,467] {processor.py:153} INFO - Started process (PID=41619) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:31:53,470] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:31:53,472] {logging_mixin.py:115} INFO - [2022-06-07 07:31:53,472] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:31:53,533] {logging_mixin.py:115} INFO - [2022-06-07 07:31:53,530] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:31:53,536] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:31:53,627] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 07:32:23,756] {processor.py:153} INFO - Started process (PID=41688) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:32:23,758] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:32:23,759] {logging_mixin.py:115} INFO - [2022-06-07 07:32:23,759] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:32:23,820] {logging_mixin.py:115} INFO - [2022-06-07 07:32:23,817] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:32:23,821] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:32:23,920] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 07:32:54,650] {processor.py:153} INFO - Started process (PID=41748) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:32:54,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:32:54,655] {logging_mixin.py:115} INFO - [2022-06-07 07:32:54,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:32:54,711] {logging_mixin.py:115} INFO - [2022-06-07 07:32:54,709] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:32:54,713] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:32:54,807] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 07:33:24,856] {processor.py:153} INFO - Started process (PID=41815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:33:24,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:33:24,860] {logging_mixin.py:115} INFO - [2022-06-07 07:33:24,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:33:24,916] {logging_mixin.py:115} INFO - [2022-06-07 07:33:24,913] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:33:24,917] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:33:25,025] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 07:33:55,128] {processor.py:153} INFO - Started process (PID=41884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:33:55,130] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:33:55,132] {logging_mixin.py:115} INFO - [2022-06-07 07:33:55,131] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:33:55,177] {logging_mixin.py:115} INFO - [2022-06-07 07:33:55,175] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:33:55,179] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:33:55,283] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 07:34:25,671] {processor.py:153} INFO - Started process (PID=41951) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:34:25,674] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:34:25,676] {logging_mixin.py:115} INFO - [2022-06-07 07:34:25,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:34:25,742] {logging_mixin.py:115} INFO - [2022-06-07 07:34:25,740] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:34:25,744] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:34:25,857] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 07:34:56,598] {processor.py:153} INFO - Started process (PID=42019) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:34:56,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:34:56,601] {logging_mixin.py:115} INFO - [2022-06-07 07:34:56,601] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:34:56,647] {logging_mixin.py:115} INFO - [2022-06-07 07:34:56,644] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:34:56,648] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:34:56,745] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-07 07:35:26,846] {processor.py:153} INFO - Started process (PID=42077) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:35:26,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:35:26,850] {logging_mixin.py:115} INFO - [2022-06-07 07:35:26,850] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:35:26,914] {logging_mixin.py:115} INFO - [2022-06-07 07:35:26,912] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:35:26,915] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:35:27,011] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 07:35:57,856] {processor.py:153} INFO - Started process (PID=42145) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:35:57,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:35:57,859] {logging_mixin.py:115} INFO - [2022-06-07 07:35:57,859] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:35:57,906] {logging_mixin.py:115} INFO - [2022-06-07 07:35:57,903] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:35:57,908] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:35:58,025] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 07:36:28,266] {processor.py:153} INFO - Started process (PID=42217) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:36:28,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:36:28,271] {logging_mixin.py:115} INFO - [2022-06-07 07:36:28,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:36:28,331] {logging_mixin.py:115} INFO - [2022-06-07 07:36:28,329] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:36:28,332] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:36:28,429] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 07:36:58,851] {processor.py:153} INFO - Started process (PID=42284) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:36:58,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:36:58,857] {logging_mixin.py:115} INFO - [2022-06-07 07:36:58,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:36:58,934] {logging_mixin.py:115} INFO - [2022-06-07 07:36:58,930] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:36:58,935] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:36:59,035] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-07 07:37:29,964] {processor.py:153} INFO - Started process (PID=42357) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:37:29,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:37:29,967] {logging_mixin.py:115} INFO - [2022-06-07 07:37:29,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:37:30,024] {logging_mixin.py:115} INFO - [2022-06-07 07:37:30,022] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:37:30,025] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:37:30,124] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-07 07:38:00,221] {processor.py:153} INFO - Started process (PID=42413) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:38:00,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:38:00,223] {logging_mixin.py:115} INFO - [2022-06-07 07:38:00,223] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:38:00,285] {logging_mixin.py:115} INFO - [2022-06-07 07:38:00,282] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:38:00,287] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:38:00,429] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-07 07:38:31,211] {processor.py:153} INFO - Started process (PID=42480) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:38:31,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:38:31,216] {logging_mixin.py:115} INFO - [2022-06-07 07:38:31,216] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:38:31,314] {logging_mixin.py:115} INFO - [2022-06-07 07:38:31,307] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:38:31,316] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:38:31,455] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-07 07:39:02,208] {processor.py:153} INFO - Started process (PID=42548) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:39:02,211] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:39:02,213] {logging_mixin.py:115} INFO - [2022-06-07 07:39:02,213] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:39:02,283] {logging_mixin.py:115} INFO - [2022-06-07 07:39:02,281] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:39:02,285] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:39:02,384] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 07:39:33,363] {processor.py:153} INFO - Started process (PID=42616) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:39:33,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:39:33,367] {logging_mixin.py:115} INFO - [2022-06-07 07:39:33,367] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:39:33,446] {logging_mixin.py:115} INFO - [2022-06-07 07:39:33,444] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:39:33,448] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:39:33,557] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 07:40:04,010] {processor.py:153} INFO - Started process (PID=42684) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:40:04,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:40:04,015] {logging_mixin.py:115} INFO - [2022-06-07 07:40:04,015] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:40:04,126] {logging_mixin.py:115} INFO - [2022-06-07 07:40:04,122] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:40:04,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:40:04,258] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.258 seconds
[2022-06-07 07:40:34,617] {processor.py:153} INFO - Started process (PID=42751) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:40:34,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:40:34,640] {logging_mixin.py:115} INFO - [2022-06-07 07:40:34,639] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:40:34,780] {logging_mixin.py:115} INFO - [2022-06-07 07:40:34,777] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:40:34,783] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:40:34,939] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.334 seconds
[2022-06-07 07:41:05,221] {processor.py:153} INFO - Started process (PID=42808) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:41:05,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:41:05,225] {logging_mixin.py:115} INFO - [2022-06-07 07:41:05,224] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:41:05,321] {logging_mixin.py:115} INFO - [2022-06-07 07:41:05,318] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:41:05,322] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:41:05,443] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-07 07:41:36,291] {processor.py:153} INFO - Started process (PID=42873) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:41:36,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:41:36,296] {logging_mixin.py:115} INFO - [2022-06-07 07:41:36,296] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:41:36,425] {logging_mixin.py:115} INFO - [2022-06-07 07:41:36,421] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:41:36,427] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:41:36,558] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.277 seconds
[2022-06-07 07:42:06,707] {processor.py:153} INFO - Started process (PID=42940) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:42:06,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:42:06,715] {logging_mixin.py:115} INFO - [2022-06-07 07:42:06,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:42:06,794] {logging_mixin.py:115} INFO - [2022-06-07 07:42:06,791] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:42:06,795] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:42:06,992] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.289 seconds
[2022-06-07 07:42:37,577] {processor.py:153} INFO - Started process (PID=43006) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:42:37,581] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:42:37,582] {logging_mixin.py:115} INFO - [2022-06-07 07:42:37,582] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:42:37,689] {logging_mixin.py:115} INFO - [2022-06-07 07:42:37,685] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:42:37,695] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:42:37,883] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.313 seconds
[2022-06-07 07:43:08,658] {processor.py:153} INFO - Started process (PID=43063) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:43:08,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:43:08,662] {logging_mixin.py:115} INFO - [2022-06-07 07:43:08,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:43:08,796] {logging_mixin.py:115} INFO - [2022-06-07 07:43:08,792] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:43:08,797] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:43:08,934] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.287 seconds
[2022-06-07 07:43:39,200] {processor.py:153} INFO - Started process (PID=43130) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:43:39,204] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:43:39,207] {logging_mixin.py:115} INFO - [2022-06-07 07:43:39,207] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:43:39,317] {logging_mixin.py:115} INFO - [2022-06-07 07:43:39,314] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:43:39,320] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:43:39,462] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.268 seconds
[2022-06-07 07:44:10,106] {processor.py:153} INFO - Started process (PID=43197) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:44:10,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:44:10,113] {logging_mixin.py:115} INFO - [2022-06-07 07:44:10,113] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:44:10,211] {logging_mixin.py:115} INFO - [2022-06-07 07:44:10,208] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:44:10,214] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:44:10,333] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-07 07:44:40,427] {processor.py:153} INFO - Started process (PID=43266) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:44:40,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:44:40,431] {logging_mixin.py:115} INFO - [2022-06-07 07:44:40,431] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:44:40,520] {logging_mixin.py:115} INFO - [2022-06-07 07:44:40,517] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:44:40,521] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:44:40,634] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-07 07:45:11,441] {processor.py:153} INFO - Started process (PID=43323) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:45:11,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:45:11,445] {logging_mixin.py:115} INFO - [2022-06-07 07:45:11,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:45:11,552] {logging_mixin.py:115} INFO - [2022-06-07 07:45:11,549] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:45:11,554] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:45:11,681] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-07 07:45:42,262] {processor.py:153} INFO - Started process (PID=43393) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:45:42,264] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:45:42,265] {logging_mixin.py:115} INFO - [2022-06-07 07:45:42,265] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:45:42,356] {logging_mixin.py:115} INFO - [2022-06-07 07:45:42,354] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:45:42,358] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:45:42,474] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-07 07:46:12,846] {processor.py:153} INFO - Started process (PID=43459) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:46:12,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:46:12,850] {logging_mixin.py:115} INFO - [2022-06-07 07:46:12,850] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:46:12,935] {logging_mixin.py:115} INFO - [2022-06-07 07:46:12,930] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:46:12,938] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:46:13,044] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-07 07:46:43,313] {processor.py:153} INFO - Started process (PID=43526) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:46:43,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:46:43,321] {logging_mixin.py:115} INFO - [2022-06-07 07:46:43,321] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:46:43,543] {logging_mixin.py:115} INFO - [2022-06-07 07:46:43,538] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:46:43,548] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:46:43,851] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.547 seconds
[2022-06-07 07:47:14,803] {processor.py:153} INFO - Started process (PID=43592) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:47:14,806] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:47:14,808] {logging_mixin.py:115} INFO - [2022-06-07 07:47:14,808] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:47:14,881] {logging_mixin.py:115} INFO - [2022-06-07 07:47:14,878] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:47:14,883] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:47:15,003] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.208 seconds
[2022-06-07 07:47:45,994] {processor.py:153} INFO - Started process (PID=43648) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:47:45,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:47:46,001] {logging_mixin.py:115} INFO - [2022-06-07 07:47:46,001] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:47:46,111] {logging_mixin.py:115} INFO - [2022-06-07 07:47:46,108] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:47:46,113] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:47:46,254] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.268 seconds
[2022-06-07 07:48:16,348] {processor.py:153} INFO - Started process (PID=43713) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:48:16,349] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:48:16,360] {logging_mixin.py:115} INFO - [2022-06-07 07:48:16,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:48:16,461] {logging_mixin.py:115} INFO - [2022-06-07 07:48:16,458] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:48:16,463] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:48:16,645] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.302 seconds
[2022-06-07 07:48:47,413] {processor.py:153} INFO - Started process (PID=43786) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:48:47,416] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:48:47,417] {logging_mixin.py:115} INFO - [2022-06-07 07:48:47,417] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:48:47,531] {logging_mixin.py:115} INFO - [2022-06-07 07:48:47,528] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:48:47,533] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:48:47,689] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.282 seconds
[2022-06-07 07:49:18,122] {processor.py:153} INFO - Started process (PID=43858) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:49:18,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:49:18,127] {logging_mixin.py:115} INFO - [2022-06-07 07:49:18,126] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:49:18,231] {logging_mixin.py:115} INFO - [2022-06-07 07:49:18,226] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:49:18,233] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:49:18,361] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-07 07:49:48,532] {processor.py:153} INFO - Started process (PID=43926) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:49:48,534] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:49:48,536] {logging_mixin.py:115} INFO - [2022-06-07 07:49:48,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:49:48,653] {logging_mixin.py:115} INFO - [2022-06-07 07:49:48,649] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:49:48,656] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:49:48,775] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.248 seconds
[2022-06-07 07:50:19,263] {processor.py:153} INFO - Started process (PID=43984) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:50:19,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:50:19,279] {logging_mixin.py:115} INFO - [2022-06-07 07:50:19,279] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:50:19,521] {logging_mixin.py:115} INFO - [2022-06-07 07:50:19,517] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:50:19,524] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:50:19,711] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.470 seconds
[2022-06-07 07:50:50,126] {processor.py:153} INFO - Started process (PID=44050) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:50:50,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:50:50,130] {logging_mixin.py:115} INFO - [2022-06-07 07:50:50,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:50:50,223] {logging_mixin.py:115} INFO - [2022-06-07 07:50:50,220] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:50:50,224] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:50:50,333] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-07 07:51:20,941] {processor.py:153} INFO - Started process (PID=44118) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:51:20,948] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:51:20,952] {logging_mixin.py:115} INFO - [2022-06-07 07:51:20,952] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:51:21,073] {logging_mixin.py:115} INFO - [2022-06-07 07:51:21,071] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:51:21,074] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:51:21,195] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.268 seconds
[2022-06-07 07:51:51,993] {processor.py:153} INFO - Started process (PID=44184) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:51:51,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:51:51,999] {logging_mixin.py:115} INFO - [2022-06-07 07:51:51,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:51:52,090] {logging_mixin.py:115} INFO - [2022-06-07 07:51:52,087] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:51:52,092] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:51:52,197] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-07 07:52:22,969] {processor.py:153} INFO - Started process (PID=44245) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:52:22,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:52:22,981] {logging_mixin.py:115} INFO - [2022-06-07 07:52:22,981] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:52:23,173] {logging_mixin.py:115} INFO - [2022-06-07 07:52:23,167] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:52:23,175] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:52:23,421] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.469 seconds
[2022-06-07 07:52:53,741] {processor.py:153} INFO - Started process (PID=44310) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:52:53,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:52:53,746] {logging_mixin.py:115} INFO - [2022-06-07 07:52:53,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:52:53,889] {logging_mixin.py:115} INFO - [2022-06-07 07:52:53,885] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:52:53,892] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:52:54,031] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.297 seconds
[2022-06-07 07:53:24,861] {processor.py:153} INFO - Started process (PID=44377) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:53:24,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:53:24,866] {logging_mixin.py:115} INFO - [2022-06-07 07:53:24,866] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:53:24,957] {logging_mixin.py:115} INFO - [2022-06-07 07:53:24,954] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:53:24,958] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:53:25,070] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-07 07:53:55,324] {processor.py:153} INFO - Started process (PID=44444) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:53:55,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:53:55,329] {logging_mixin.py:115} INFO - [2022-06-07 07:53:55,329] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:53:55,434] {logging_mixin.py:115} INFO - [2022-06-07 07:53:55,431] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:53:55,438] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:53:55,541] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-07 07:54:25,723] {processor.py:153} INFO - Started process (PID=44501) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:54:25,725] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:54:25,726] {logging_mixin.py:115} INFO - [2022-06-07 07:54:25,726] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:54:25,817] {logging_mixin.py:115} INFO - [2022-06-07 07:54:25,815] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:54:25,819] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:54:25,934] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-07 07:54:56,008] {processor.py:153} INFO - Started process (PID=44567) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:54:56,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:54:56,012] {logging_mixin.py:115} INFO - [2022-06-07 07:54:56,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:54:56,081] {logging_mixin.py:115} INFO - [2022-06-07 07:54:56,078] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:54:56,083] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:54:56,183] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 07:55:26,569] {processor.py:153} INFO - Started process (PID=44636) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:55:26,576] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:55:26,579] {logging_mixin.py:115} INFO - [2022-06-07 07:55:26,579] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:55:26,634] {logging_mixin.py:115} INFO - [2022-06-07 07:55:26,633] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:55:26,636] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:55:26,730] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-07 07:55:57,633] {processor.py:153} INFO - Started process (PID=44704) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:55:57,636] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:55:57,637] {logging_mixin.py:115} INFO - [2022-06-07 07:55:57,637] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:55:57,705] {logging_mixin.py:115} INFO - [2022-06-07 07:55:57,703] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:55:57,708] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:55:57,820] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 07:56:27,909] {processor.py:153} INFO - Started process (PID=44774) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:56:27,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:56:27,912] {logging_mixin.py:115} INFO - [2022-06-07 07:56:27,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:56:27,967] {logging_mixin.py:115} INFO - [2022-06-07 07:56:27,964] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:56:27,968] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:56:28,082] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 07:56:58,338] {processor.py:153} INFO - Started process (PID=44830) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:56:58,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:56:58,341] {logging_mixin.py:115} INFO - [2022-06-07 07:56:58,341] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:56:58,397] {logging_mixin.py:115} INFO - [2022-06-07 07:56:58,395] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:56:58,398] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:56:58,494] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 07:57:28,756] {processor.py:153} INFO - Started process (PID=44896) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:57:28,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:57:28,761] {logging_mixin.py:115} INFO - [2022-06-07 07:57:28,761] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:57:28,815] {logging_mixin.py:115} INFO - [2022-06-07 07:57:28,812] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:57:28,816] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:57:28,910] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 07:57:59,359] {processor.py:153} INFO - Started process (PID=44963) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:57:59,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:57:59,366] {logging_mixin.py:115} INFO - [2022-06-07 07:57:59,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:57:59,438] {logging_mixin.py:115} INFO - [2022-06-07 07:57:59,435] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:57:59,438] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:57:59,534] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 07:58:30,269] {processor.py:153} INFO - Started process (PID=45032) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:58:30,273] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:58:30,275] {logging_mixin.py:115} INFO - [2022-06-07 07:58:30,275] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:58:30,334] {logging_mixin.py:115} INFO - [2022-06-07 07:58:30,332] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:58:30,335] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:58:30,436] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 07:59:01,261] {processor.py:153} INFO - Started process (PID=45100) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:59:01,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:59:01,263] {logging_mixin.py:115} INFO - [2022-06-07 07:59:01,263] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:59:01,327] {logging_mixin.py:115} INFO - [2022-06-07 07:59:01,324] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:59:01,329] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:59:01,433] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 07:59:31,597] {processor.py:153} INFO - Started process (PID=45157) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:59:31,599] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 07:59:31,600] {logging_mixin.py:115} INFO - [2022-06-07 07:59:31,600] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:59:31,651] {logging_mixin.py:115} INFO - [2022-06-07 07:59:31,648] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 07:59:31,653] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 07:59:31,747] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-07 08:00:02,048] {processor.py:153} INFO - Started process (PID=45226) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:00:02,050] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:00:02,051] {logging_mixin.py:115} INFO - [2022-06-07 08:00:02,051] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:00:02,120] {logging_mixin.py:115} INFO - [2022-06-07 08:00:02,118] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:00:02,122] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:00:02,234] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-07 08:00:32,343] {processor.py:153} INFO - Started process (PID=45296) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:00:32,346] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:00:32,349] {logging_mixin.py:115} INFO - [2022-06-07 08:00:32,349] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:00:32,406] {logging_mixin.py:115} INFO - [2022-06-07 08:00:32,404] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:00:32,408] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:00:32,501] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 08:01:02,737] {processor.py:153} INFO - Started process (PID=45366) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:01:02,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:01:02,742] {logging_mixin.py:115} INFO - [2022-06-07 08:01:02,742] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:01:02,811] {logging_mixin.py:115} INFO - [2022-06-07 08:01:02,809] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:01:02,812] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:01:02,911] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 08:01:33,068] {processor.py:153} INFO - Started process (PID=45433) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:01:33,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:01:33,074] {logging_mixin.py:115} INFO - [2022-06-07 08:01:33,074] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:01:33,137] {logging_mixin.py:115} INFO - [2022-06-07 08:01:33,134] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:01:33,139] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:01:33,255] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 08:02:03,521] {processor.py:153} INFO - Started process (PID=45488) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:02:03,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:02:03,525] {logging_mixin.py:115} INFO - [2022-06-07 08:02:03,525] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:02:03,580] {logging_mixin.py:115} INFO - [2022-06-07 08:02:03,577] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:02:03,581] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:02:03,684] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-07 08:02:33,803] {processor.py:153} INFO - Started process (PID=45554) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:02:33,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:02:33,808] {logging_mixin.py:115} INFO - [2022-06-07 08:02:33,808] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:02:33,878] {logging_mixin.py:115} INFO - [2022-06-07 08:02:33,875] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:02:33,880] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:02:33,987] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-07 08:03:04,085] {processor.py:153} INFO - Started process (PID=45623) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:03:04,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:03:04,090] {logging_mixin.py:115} INFO - [2022-06-07 08:03:04,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:03:04,140] {logging_mixin.py:115} INFO - [2022-06-07 08:03:04,138] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:03:04,142] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:03:04,236] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-07 08:03:34,456] {processor.py:153} INFO - Started process (PID=45692) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:03:34,458] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:03:34,460] {logging_mixin.py:115} INFO - [2022-06-07 08:03:34,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:03:34,518] {logging_mixin.py:115} INFO - [2022-06-07 08:03:34,515] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:03:34,520] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:03:34,623] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 08:04:04,883] {processor.py:153} INFO - Started process (PID=45758) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:04:04,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:04:04,889] {logging_mixin.py:115} INFO - [2022-06-07 08:04:04,888] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:04:04,952] {logging_mixin.py:115} INFO - [2022-06-07 08:04:04,949] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:04:04,953] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:04:05,055] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 08:04:35,840] {processor.py:153} INFO - Started process (PID=45815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:04:35,847] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:04:35,849] {logging_mixin.py:115} INFO - [2022-06-07 08:04:35,849] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:04:35,983] {logging_mixin.py:115} INFO - [2022-06-07 08:04:35,975] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:04:35,985] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:04:36,122] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.298 seconds
[2022-06-07 08:05:06,677] {processor.py:153} INFO - Started process (PID=45881) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:05:06,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:05:06,682] {logging_mixin.py:115} INFO - [2022-06-07 08:05:06,682] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:05:06,776] {logging_mixin.py:115} INFO - [2022-06-07 08:05:06,773] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:05:06,777] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:05:06,888] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-07 08:05:37,179] {processor.py:153} INFO - Started process (PID=45949) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:05:37,181] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:05:37,183] {logging_mixin.py:115} INFO - [2022-06-07 08:05:37,183] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:05:37,279] {logging_mixin.py:115} INFO - [2022-06-07 08:05:37,277] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:05:37,283] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:05:37,428] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.257 seconds
[2022-06-07 08:06:07,548] {processor.py:153} INFO - Started process (PID=46015) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:06:07,551] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:06:07,554] {logging_mixin.py:115} INFO - [2022-06-07 08:06:07,554] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:06:07,761] {logging_mixin.py:115} INFO - [2022-06-07 08:06:07,753] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:06:07,773] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:06:07,998] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.475 seconds
[2022-06-07 08:06:38,123] {processor.py:153} INFO - Started process (PID=46074) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:06:38,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:06:38,126] {logging_mixin.py:115} INFO - [2022-06-07 08:06:38,126] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:06:38,244] {logging_mixin.py:115} INFO - [2022-06-07 08:06:38,240] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:06:38,245] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:06:38,390] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.272 seconds
[2022-06-07 08:07:08,863] {processor.py:153} INFO - Started process (PID=46141) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:07:08,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:07:08,867] {logging_mixin.py:115} INFO - [2022-06-07 08:07:08,866] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:07:08,998] {logging_mixin.py:115} INFO - [2022-06-07 08:07:08,994] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:07:09,001] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:07:09,171] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.316 seconds
[2022-06-07 08:07:39,898] {processor.py:153} INFO - Started process (PID=46208) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:07:39,901] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:07:39,903] {logging_mixin.py:115} INFO - [2022-06-07 08:07:39,903] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:07:40,048] {logging_mixin.py:115} INFO - [2022-06-07 08:07:40,043] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:07:40,051] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:07:40,201] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.317 seconds
[2022-06-07 08:08:10,800] {processor.py:153} INFO - Started process (PID=46276) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:08:10,803] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:08:10,805] {logging_mixin.py:115} INFO - [2022-06-07 08:08:10,805] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:08:10,898] {logging_mixin.py:115} INFO - [2022-06-07 08:08:10,896] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:08:10,900] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:08:11,008] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-07 08:08:41,270] {processor.py:153} INFO - Started process (PID=46334) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:08:41,279] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:08:41,287] {logging_mixin.py:115} INFO - [2022-06-07 08:08:41,286] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:08:41,358] {logging_mixin.py:115} INFO - [2022-06-07 08:08:41,356] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:08:41,359] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:08:41,465] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 08:09:11,673] {processor.py:153} INFO - Started process (PID=46404) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:09:11,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:09:11,676] {logging_mixin.py:115} INFO - [2022-06-07 08:09:11,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:09:11,731] {logging_mixin.py:115} INFO - [2022-06-07 08:09:11,729] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:09:11,732] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:09:11,828] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 08:09:42,380] {processor.py:153} INFO - Started process (PID=46473) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:09:42,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:09:42,384] {logging_mixin.py:115} INFO - [2022-06-07 08:09:42,384] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:09:42,495] {logging_mixin.py:115} INFO - [2022-06-07 08:09:42,490] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:09:42,497] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:09:42,632] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.257 seconds
[2022-06-07 08:10:13,638] {processor.py:153} INFO - Started process (PID=46540) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:10:13,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:10:13,643] {logging_mixin.py:115} INFO - [2022-06-07 08:10:13,643] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:10:13,740] {logging_mixin.py:115} INFO - [2022-06-07 08:10:13,737] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:10:13,742] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:10:13,851] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-07 08:10:44,110] {processor.py:153} INFO - Started process (PID=46610) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:10:44,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:10:44,116] {logging_mixin.py:115} INFO - [2022-06-07 08:10:44,116] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:10:44,297] {logging_mixin.py:115} INFO - [2022-06-07 08:10:44,293] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:10:44,299] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:10:44,474] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.377 seconds
[2022-06-07 08:11:14,955] {processor.py:153} INFO - Started process (PID=46667) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:11:14,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:11:14,965] {logging_mixin.py:115} INFO - [2022-06-07 08:11:14,965] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:11:15,061] {logging_mixin.py:115} INFO - [2022-06-07 08:11:15,057] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:11:15,063] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:11:15,194] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-07 08:11:45,385] {processor.py:153} INFO - Started process (PID=46733) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:11:45,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:11:45,388] {logging_mixin.py:115} INFO - [2022-06-07 08:11:45,388] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:11:45,508] {logging_mixin.py:115} INFO - [2022-06-07 08:11:45,504] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:11:45,509] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:11:45,647] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.268 seconds
[2022-06-07 08:12:15,941] {processor.py:153} INFO - Started process (PID=46801) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:12:15,944] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:12:15,947] {logging_mixin.py:115} INFO - [2022-06-07 08:12:15,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:12:16,028] {logging_mixin.py:115} INFO - [2022-06-07 08:12:16,025] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:12:16,029] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:12:16,135] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 08:12:46,714] {processor.py:153} INFO - Started process (PID=46867) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:12:46,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:12:46,718] {logging_mixin.py:115} INFO - [2022-06-07 08:12:46,718] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:12:46,900] {logging_mixin.py:115} INFO - [2022-06-07 08:12:46,896] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:12:46,905] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:12:47,033] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.335 seconds
[2022-06-07 08:13:17,073] {processor.py:153} INFO - Started process (PID=46926) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:13:17,076] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:13:17,077] {logging_mixin.py:115} INFO - [2022-06-07 08:13:17,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:13:17,147] {logging_mixin.py:115} INFO - [2022-06-07 08:13:17,144] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:13:17,148] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:13:17,250] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 08:13:47,402] {processor.py:153} INFO - Started process (PID=46990) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:13:47,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:13:47,404] {logging_mixin.py:115} INFO - [2022-06-07 08:13:47,404] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:13:47,449] {logging_mixin.py:115} INFO - [2022-06-07 08:13:47,446] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:13:47,452] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:13:47,544] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-07 08:14:18,040] {processor.py:153} INFO - Started process (PID=47056) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:14:18,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:14:18,045] {logging_mixin.py:115} INFO - [2022-06-07 08:14:18,045] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:14:18,127] {logging_mixin.py:115} INFO - [2022-06-07 08:14:18,124] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:14:18,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:14:18,265] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-07 08:14:48,736] {processor.py:153} INFO - Started process (PID=47122) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:14:48,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:14:48,739] {logging_mixin.py:115} INFO - [2022-06-07 08:14:48,739] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:14:48,824] {logging_mixin.py:115} INFO - [2022-06-07 08:14:48,821] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:14:48,827] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:14:48,974] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-07 08:15:19,612] {processor.py:153} INFO - Started process (PID=47180) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:15:19,615] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:15:19,620] {logging_mixin.py:115} INFO - [2022-06-07 08:15:19,619] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:15:19,865] {logging_mixin.py:115} INFO - [2022-06-07 08:15:19,855] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:15:19,867] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:15:20,070] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.469 seconds
[2022-06-07 08:15:50,948] {processor.py:153} INFO - Started process (PID=47252) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:15:50,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:15:50,954] {logging_mixin.py:115} INFO - [2022-06-07 08:15:50,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:15:51,054] {logging_mixin.py:115} INFO - [2022-06-07 08:15:51,051] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:15:51,056] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:15:51,166] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-07 08:16:21,385] {processor.py:153} INFO - Started process (PID=47319) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:16:21,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:16:21,389] {logging_mixin.py:115} INFO - [2022-06-07 08:16:21,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:16:21,504] {logging_mixin.py:115} INFO - [2022-06-07 08:16:21,501] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:16:21,506] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:16:21,637] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.261 seconds
[2022-06-07 08:16:52,244] {processor.py:153} INFO - Started process (PID=47375) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:16:52,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:16:52,249] {logging_mixin.py:115} INFO - [2022-06-07 08:16:52,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:16:52,355] {logging_mixin.py:115} INFO - [2022-06-07 08:16:52,351] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:16:52,357] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:16:52,512] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.271 seconds
[2022-06-07 08:17:22,820] {processor.py:153} INFO - Started process (PID=47443) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:17:22,823] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:17:22,824] {logging_mixin.py:115} INFO - [2022-06-07 08:17:22,824] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:17:22,905] {logging_mixin.py:115} INFO - [2022-06-07 08:17:22,902] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:17:22,906] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:17:23,021] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-07 08:17:53,281] {processor.py:153} INFO - Started process (PID=47511) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:17:53,283] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:17:53,285] {logging_mixin.py:115} INFO - [2022-06-07 08:17:53,285] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:17:53,379] {logging_mixin.py:115} INFO - [2022-06-07 08:17:53,376] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:17:53,380] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:17:53,514] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-07 08:18:24,107] {processor.py:153} INFO - Started process (PID=47576) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:18:24,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:18:24,112] {logging_mixin.py:115} INFO - [2022-06-07 08:18:24,112] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:18:24,230] {logging_mixin.py:115} INFO - [2022-06-07 08:18:24,225] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:18:24,233] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:18:24,380] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.282 seconds
[2022-06-07 08:18:54,719] {processor.py:153} INFO - Started process (PID=47634) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:18:54,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:18:54,722] {logging_mixin.py:115} INFO - [2022-06-07 08:18:54,722] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:18:54,790] {logging_mixin.py:115} INFO - [2022-06-07 08:18:54,788] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:18:54,792] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:18:54,895] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 08:19:25,658] {processor.py:153} INFO - Started process (PID=47702) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:19:25,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:19:25,668] {logging_mixin.py:115} INFO - [2022-06-07 08:19:25,668] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:19:25,772] {logging_mixin.py:115} INFO - [2022-06-07 08:19:25,769] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:19:25,775] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:19:25,885] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-07 08:19:56,322] {processor.py:153} INFO - Started process (PID=47769) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:19:56,325] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:19:56,326] {logging_mixin.py:115} INFO - [2022-06-07 08:19:56,326] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:19:56,426] {logging_mixin.py:115} INFO - [2022-06-07 08:19:56,422] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:19:56,428] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:19:56,543] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-07 08:20:27,270] {processor.py:153} INFO - Started process (PID=47836) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:20:27,272] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:20:27,274] {logging_mixin.py:115} INFO - [2022-06-07 08:20:27,274] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:20:27,394] {logging_mixin.py:115} INFO - [2022-06-07 08:20:27,390] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:20:27,400] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:20:27,580] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.318 seconds
[2022-06-07 08:20:57,701] {processor.py:153} INFO - Started process (PID=47895) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:20:57,702] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:20:57,703] {logging_mixin.py:115} INFO - [2022-06-07 08:20:57,703] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:20:57,788] {logging_mixin.py:115} INFO - [2022-06-07 08:20:57,784] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:20:57,789] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:20:57,912] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-07 08:21:28,280] {processor.py:153} INFO - Started process (PID=47964) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:21:28,282] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:21:28,284] {logging_mixin.py:115} INFO - [2022-06-07 08:21:28,284] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:21:28,360] {logging_mixin.py:115} INFO - [2022-06-07 08:21:28,357] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:21:28,362] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:21:28,482] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-07 08:21:58,624] {processor.py:153} INFO - Started process (PID=48031) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:21:58,626] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:21:58,627] {logging_mixin.py:115} INFO - [2022-06-07 08:21:58,627] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:21:58,677] {logging_mixin.py:115} INFO - [2022-06-07 08:21:58,675] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:21:58,679] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:21:58,777] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-07 08:22:28,995] {processor.py:153} INFO - Started process (PID=48101) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:22:28,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:22:28,999] {logging_mixin.py:115} INFO - [2022-06-07 08:22:28,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:22:29,082] {logging_mixin.py:115} INFO - [2022-06-07 08:22:29,078] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:22:29,084] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:22:29,179] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-07 08:22:59,240] {processor.py:153} INFO - Started process (PID=48161) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:22:59,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:22:59,243] {logging_mixin.py:115} INFO - [2022-06-07 08:22:59,243] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:22:59,299] {logging_mixin.py:115} INFO - [2022-06-07 08:22:59,296] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:22:59,300] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:22:59,403] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-07 08:23:29,783] {processor.py:153} INFO - Started process (PID=48231) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:23:29,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:23:29,787] {logging_mixin.py:115} INFO - [2022-06-07 08:23:29,787] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:23:29,866] {logging_mixin.py:115} INFO - [2022-06-07 08:23:29,863] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:23:29,868] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:23:29,974] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 08:24:00,119] {processor.py:153} INFO - Started process (PID=48301) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:24:00,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:24:00,125] {logging_mixin.py:115} INFO - [2022-06-07 08:24:00,125] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:24:00,184] {logging_mixin.py:115} INFO - [2022-06-07 08:24:00,181] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:24:00,185] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:24:00,279] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 08:24:31,018] {processor.py:153} INFO - Started process (PID=48368) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:24:31,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:24:31,021] {logging_mixin.py:115} INFO - [2022-06-07 08:24:31,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:24:31,083] {logging_mixin.py:115} INFO - [2022-06-07 08:24:31,080] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:24:31,084] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:24:31,182] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 08:25:01,976] {processor.py:153} INFO - Started process (PID=48435) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:25:01,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:25:01,980] {logging_mixin.py:115} INFO - [2022-06-07 08:25:01,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:25:02,047] {logging_mixin.py:115} INFO - [2022-06-07 08:25:02,043] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:25:02,048] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:25:02,195] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-07 08:25:33,135] {processor.py:153} INFO - Started process (PID=48495) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:25:33,139] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:25:33,140] {logging_mixin.py:115} INFO - [2022-06-07 08:25:33,140] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:25:33,200] {logging_mixin.py:115} INFO - [2022-06-07 08:25:33,198] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:25:33,201] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:25:33,298] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-07 08:26:03,501] {processor.py:153} INFO - Started process (PID=48561) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:26:03,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:26:03,504] {logging_mixin.py:115} INFO - [2022-06-07 08:26:03,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:26:03,556] {logging_mixin.py:115} INFO - [2022-06-07 08:26:03,553] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:26:03,557] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:26:03,657] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-07 08:26:33,955] {processor.py:153} INFO - Started process (PID=48628) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:26:33,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:26:33,960] {logging_mixin.py:115} INFO - [2022-06-07 08:26:33,960] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:26:34,029] {logging_mixin.py:115} INFO - [2022-06-07 08:26:34,025] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:26:34,031] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:26:34,129] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 08:27:04,186] {processor.py:153} INFO - Started process (PID=48699) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:27:04,188] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:27:04,191] {logging_mixin.py:115} INFO - [2022-06-07 08:27:04,191] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:27:04,245] {logging_mixin.py:115} INFO - [2022-06-07 08:27:04,242] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:27:04,247] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:27:04,342] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 08:27:34,510] {processor.py:153} INFO - Started process (PID=48757) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:27:34,513] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:27:34,515] {logging_mixin.py:115} INFO - [2022-06-07 08:27:34,515] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:27:34,620] {logging_mixin.py:115} INFO - [2022-06-07 08:27:34,618] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:27:34,622] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:27:34,766] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-07 08:28:04,896] {processor.py:153} INFO - Started process (PID=48823) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:28:04,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:28:04,899] {logging_mixin.py:115} INFO - [2022-06-07 08:28:04,899] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:28:04,953] {logging_mixin.py:115} INFO - [2022-06-07 08:28:04,951] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:28:04,955] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:28:05,052] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 08:28:35,400] {processor.py:153} INFO - Started process (PID=48891) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:28:35,402] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:28:35,404] {logging_mixin.py:115} INFO - [2022-06-07 08:28:35,404] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:28:35,495] {logging_mixin.py:115} INFO - [2022-06-07 08:28:35,493] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:28:35,497] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:28:35,603] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-07 08:29:06,139] {processor.py:153} INFO - Started process (PID=48958) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:29:06,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:29:06,143] {logging_mixin.py:115} INFO - [2022-06-07 08:29:06,143] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:29:06,223] {logging_mixin.py:115} INFO - [2022-06-07 08:29:06,221] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:29:06,225] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:29:06,325] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-07 08:29:36,911] {processor.py:153} INFO - Started process (PID=49016) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:29:36,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:29:36,914] {logging_mixin.py:115} INFO - [2022-06-07 08:29:36,914] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:29:37,049] {logging_mixin.py:115} INFO - [2022-06-07 08:29:37,039] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:29:37,053] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:29:37,201] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.299 seconds
[2022-06-07 08:30:07,585] {processor.py:153} INFO - Started process (PID=49086) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:30:07,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:30:07,587] {logging_mixin.py:115} INFO - [2022-06-07 08:30:07,587] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:30:07,674] {logging_mixin.py:115} INFO - [2022-06-07 08:30:07,671] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:30:07,676] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:30:07,777] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-07 08:30:37,948] {processor.py:153} INFO - Started process (PID=49155) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:30:37,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:30:37,953] {logging_mixin.py:115} INFO - [2022-06-07 08:30:37,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:30:38,014] {logging_mixin.py:115} INFO - [2022-06-07 08:30:38,011] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:30:38,015] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:30:38,114] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 08:31:08,869] {processor.py:153} INFO - Started process (PID=49223) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:31:08,871] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:31:08,873] {logging_mixin.py:115} INFO - [2022-06-07 08:31:08,873] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:31:08,951] {logging_mixin.py:115} INFO - [2022-06-07 08:31:08,948] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:31:08,953] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:31:09,045] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 08:31:39,953] {processor.py:153} INFO - Started process (PID=49288) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:31:39,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:31:39,958] {logging_mixin.py:115} INFO - [2022-06-07 08:31:39,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:31:40,128] {logging_mixin.py:115} INFO - [2022-06-07 08:31:40,125] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:31:40,132] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:31:40,349] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.415 seconds
[2022-06-07 08:32:11,162] {processor.py:153} INFO - Started process (PID=49346) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:32:11,164] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:32:11,167] {logging_mixin.py:115} INFO - [2022-06-07 08:32:11,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:32:11,249] {logging_mixin.py:115} INFO - [2022-06-07 08:32:11,246] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:32:11,250] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:32:11,483] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.325 seconds
[2022-06-07 08:32:41,892] {processor.py:153} INFO - Started process (PID=49415) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:32:41,894] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:32:41,895] {logging_mixin.py:115} INFO - [2022-06-07 08:32:41,895] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:32:41,973] {logging_mixin.py:115} INFO - [2022-06-07 08:32:41,969] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:32:41,975] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:32:42,090] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.204 seconds
[2022-06-07 08:33:12,232] {processor.py:153} INFO - Started process (PID=49485) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:33:12,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:33:12,235] {logging_mixin.py:115} INFO - [2022-06-07 08:33:12,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:33:12,326] {logging_mixin.py:115} INFO - [2022-06-07 08:33:12,324] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:33:12,327] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:33:12,428] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 08:33:43,007] {processor.py:153} INFO - Started process (PID=49551) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:33:43,009] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:33:43,010] {logging_mixin.py:115} INFO - [2022-06-07 08:33:43,010] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:33:43,102] {logging_mixin.py:115} INFO - [2022-06-07 08:33:43,099] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:33:43,104] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:33:43,209] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-07 08:34:14,163] {processor.py:153} INFO - Started process (PID=49607) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:34:14,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:34:14,168] {logging_mixin.py:115} INFO - [2022-06-07 08:34:14,168] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:34:14,235] {logging_mixin.py:115} INFO - [2022-06-07 08:34:14,233] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:34:14,236] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:34:14,339] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 08:34:44,540] {processor.py:153} INFO - Started process (PID=49679) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:34:44,543] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:34:44,545] {logging_mixin.py:115} INFO - [2022-06-07 08:34:44,545] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:34:44,603] {logging_mixin.py:115} INFO - [2022-06-07 08:34:44,601] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:34:44,605] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:34:44,705] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 08:35:14,896] {processor.py:153} INFO - Started process (PID=49746) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:35:14,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:35:14,901] {logging_mixin.py:115} INFO - [2022-06-07 08:35:14,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:35:14,977] {logging_mixin.py:115} INFO - [2022-06-07 08:35:14,975] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:35:14,978] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:35:15,090] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 08:35:45,370] {processor.py:153} INFO - Started process (PID=49812) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:35:45,373] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:35:45,376] {logging_mixin.py:115} INFO - [2022-06-07 08:35:45,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:35:45,431] {logging_mixin.py:115} INFO - [2022-06-07 08:35:45,428] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:35:45,432] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:35:45,524] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 08:36:16,485] {processor.py:153} INFO - Started process (PID=49880) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:36:16,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:36:16,488] {logging_mixin.py:115} INFO - [2022-06-07 08:36:16,488] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:36:16,556] {logging_mixin.py:115} INFO - [2022-06-07 08:36:16,553] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:36:16,557] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:36:16,653] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 08:36:46,925] {processor.py:153} INFO - Started process (PID=49936) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:36:46,927] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:36:46,928] {logging_mixin.py:115} INFO - [2022-06-07 08:36:46,928] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:36:47,006] {logging_mixin.py:115} INFO - [2022-06-07 08:36:47,004] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:36:47,008] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:36:47,121] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 08:37:17,681] {processor.py:153} INFO - Started process (PID=50010) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:37:17,683] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:37:17,685] {logging_mixin.py:115} INFO - [2022-06-07 08:37:17,685] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:37:17,728] {logging_mixin.py:115} INFO - [2022-06-07 08:37:17,726] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:37:17,729] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:37:17,825] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-07 08:37:47,888] {processor.py:153} INFO - Started process (PID=50079) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:37:47,889] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:37:47,890] {logging_mixin.py:115} INFO - [2022-06-07 08:37:47,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:37:47,963] {logging_mixin.py:115} INFO - [2022-06-07 08:37:47,961] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:37:47,965] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:37:48,068] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 08:38:18,485] {processor.py:153} INFO - Started process (PID=50144) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:38:18,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:38:18,490] {logging_mixin.py:115} INFO - [2022-06-07 08:38:18,489] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:38:18,558] {logging_mixin.py:115} INFO - [2022-06-07 08:38:18,556] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:38:18,559] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:38:18,660] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 08:38:48,947] {processor.py:153} INFO - Started process (PID=50210) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:38:48,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:38:48,951] {logging_mixin.py:115} INFO - [2022-06-07 08:38:48,951] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:38:49,030] {logging_mixin.py:115} INFO - [2022-06-07 08:38:49,026] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:38:49,032] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:38:49,252] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.308 seconds
[2022-06-07 08:39:19,388] {processor.py:153} INFO - Started process (PID=50269) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:39:19,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:39:19,393] {logging_mixin.py:115} INFO - [2022-06-07 08:39:19,393] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:39:19,459] {logging_mixin.py:115} INFO - [2022-06-07 08:39:19,456] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:39:19,461] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:39:19,564] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 08:39:50,070] {processor.py:153} INFO - Started process (PID=50337) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:39:50,073] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:39:50,075] {logging_mixin.py:115} INFO - [2022-06-07 08:39:50,075] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:39:50,159] {logging_mixin.py:115} INFO - [2022-06-07 08:39:50,156] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:39:50,160] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:39:50,263] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 08:40:20,483] {processor.py:153} INFO - Started process (PID=50409) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:40:20,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:40:20,486] {logging_mixin.py:115} INFO - [2022-06-07 08:40:20,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:40:20,549] {logging_mixin.py:115} INFO - [2022-06-07 08:40:20,547] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:40:20,551] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:40:20,667] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-07 08:40:51,078] {processor.py:153} INFO - Started process (PID=50478) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:40:51,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:40:51,084] {logging_mixin.py:115} INFO - [2022-06-07 08:40:51,084] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:40:51,162] {logging_mixin.py:115} INFO - [2022-06-07 08:40:51,157] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:40:51,164] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:40:51,263] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-07 08:41:21,413] {processor.py:153} INFO - Started process (PID=50535) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:41:21,416] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:41:21,419] {logging_mixin.py:115} INFO - [2022-06-07 08:41:21,418] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:41:21,485] {logging_mixin.py:115} INFO - [2022-06-07 08:41:21,483] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:41:21,487] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:41:21,585] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 08:41:52,018] {processor.py:153} INFO - Started process (PID=50608) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:41:52,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:41:52,020] {logging_mixin.py:115} INFO - [2022-06-07 08:41:52,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:41:52,082] {logging_mixin.py:115} INFO - [2022-06-07 08:41:52,079] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:41:52,083] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:41:52,178] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 08:42:22,330] {processor.py:153} INFO - Started process (PID=50677) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:42:22,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:42:22,335] {logging_mixin.py:115} INFO - [2022-06-07 08:42:22,335] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:42:22,391] {logging_mixin.py:115} INFO - [2022-06-07 08:42:22,389] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:42:22,393] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:42:22,486] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 08:42:52,800] {processor.py:153} INFO - Started process (PID=50748) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:42:52,804] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:42:52,807] {logging_mixin.py:115} INFO - [2022-06-07 08:42:52,807] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:42:52,885] {logging_mixin.py:115} INFO - [2022-06-07 08:42:52,883] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:42:52,887] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:42:52,990] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 08:43:23,190] {processor.py:153} INFO - Started process (PID=50815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:43:23,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:43:23,193] {logging_mixin.py:115} INFO - [2022-06-07 08:43:23,193] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:43:23,273] {logging_mixin.py:115} INFO - [2022-06-07 08:43:23,270] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:43:23,274] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:43:23,402] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-07 08:43:53,543] {processor.py:153} INFO - Started process (PID=50873) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:43:53,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:43:53,548] {logging_mixin.py:115} INFO - [2022-06-07 08:43:53,548] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:43:53,625] {logging_mixin.py:115} INFO - [2022-06-07 08:43:53,622] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:43:53,627] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:43:53,727] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 08:44:23,909] {processor.py:153} INFO - Started process (PID=50941) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:44:23,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:44:23,914] {logging_mixin.py:115} INFO - [2022-06-07 08:44:23,914] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:44:23,975] {logging_mixin.py:115} INFO - [2022-06-07 08:44:23,973] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:44:23,978] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:44:24,074] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 08:44:54,119] {processor.py:153} INFO - Started process (PID=51012) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:44:54,121] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:44:54,122] {logging_mixin.py:115} INFO - [2022-06-07 08:44:54,122] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:44:54,189] {logging_mixin.py:115} INFO - [2022-06-07 08:44:54,187] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:44:54,190] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:44:54,289] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 08:45:24,505] {processor.py:153} INFO - Started process (PID=51086) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:45:24,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:45:24,510] {logging_mixin.py:115} INFO - [2022-06-07 08:45:24,510] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:45:24,570] {logging_mixin.py:115} INFO - [2022-06-07 08:45:24,568] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:45:24,571] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:45:24,669] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 08:45:54,787] {processor.py:153} INFO - Started process (PID=51146) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:45:54,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:45:54,791] {logging_mixin.py:115} INFO - [2022-06-07 08:45:54,791] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:45:54,847] {logging_mixin.py:115} INFO - [2022-06-07 08:45:54,845] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:45:54,848] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:45:54,944] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 08:46:25,317] {processor.py:153} INFO - Started process (PID=51214) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:46:25,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:46:25,320] {logging_mixin.py:115} INFO - [2022-06-07 08:46:25,320] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:46:25,383] {logging_mixin.py:115} INFO - [2022-06-07 08:46:25,381] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:46:25,385] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:46:25,488] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 08:46:55,846] {processor.py:153} INFO - Started process (PID=51284) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:46:55,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:46:55,851] {logging_mixin.py:115} INFO - [2022-06-07 08:46:55,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:46:55,917] {logging_mixin.py:115} INFO - [2022-06-07 08:46:55,915] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:46:55,918] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:46:56,024] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-07 08:47:26,323] {processor.py:153} INFO - Started process (PID=51355) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:47:26,325] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:47:26,326] {logging_mixin.py:115} INFO - [2022-06-07 08:47:26,326] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:47:26,395] {logging_mixin.py:115} INFO - [2022-06-07 08:47:26,392] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:47:26,396] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:47:26,515] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-07 08:47:56,873] {processor.py:153} INFO - Started process (PID=51423) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:47:56,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:47:56,876] {logging_mixin.py:115} INFO - [2022-06-07 08:47:56,876] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:47:56,968] {logging_mixin.py:115} INFO - [2022-06-07 08:47:56,965] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:47:56,969] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:47:57,098] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-07 08:48:27,172] {processor.py:153} INFO - Started process (PID=51482) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:48:27,174] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:48:27,175] {logging_mixin.py:115} INFO - [2022-06-07 08:48:27,175] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:48:27,248] {logging_mixin.py:115} INFO - [2022-06-07 08:48:27,246] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:48:27,249] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:48:27,356] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-07 08:48:57,512] {processor.py:153} INFO - Started process (PID=51554) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:48:57,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:48:57,518] {logging_mixin.py:115} INFO - [2022-06-07 08:48:57,517] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:48:57,580] {logging_mixin.py:115} INFO - [2022-06-07 08:48:57,578] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:48:57,582] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:48:57,675] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 08:49:27,904] {processor.py:153} INFO - Started process (PID=51623) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:49:27,907] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:49:27,909] {logging_mixin.py:115} INFO - [2022-06-07 08:49:27,909] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:49:27,979] {logging_mixin.py:115} INFO - [2022-06-07 08:49:27,976] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:49:27,980] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:49:28,078] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 08:49:58,359] {processor.py:153} INFO - Started process (PID=51693) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:49:58,361] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:49:58,363] {logging_mixin.py:115} INFO - [2022-06-07 08:49:58,363] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:49:58,413] {logging_mixin.py:115} INFO - [2022-06-07 08:49:58,411] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:49:58,414] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:49:58,511] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-07 08:50:28,765] {processor.py:153} INFO - Started process (PID=51750) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:50:28,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:50:28,771] {logging_mixin.py:115} INFO - [2022-06-07 08:50:28,771] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:50:28,860] {logging_mixin.py:115} INFO - [2022-06-07 08:50:28,858] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:50:28,861] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:50:28,968] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.210 seconds
[2022-06-07 08:50:59,444] {processor.py:153} INFO - Started process (PID=51815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:50:59,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:50:59,450] {logging_mixin.py:115} INFO - [2022-06-07 08:50:59,450] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:50:59,516] {logging_mixin.py:115} INFO - [2022-06-07 08:50:59,514] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:50:59,518] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:50:59,615] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 08:51:29,785] {processor.py:153} INFO - Started process (PID=51884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:51:29,788] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:51:29,790] {logging_mixin.py:115} INFO - [2022-06-07 08:51:29,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:51:29,876] {logging_mixin.py:115} INFO - [2022-06-07 08:51:29,873] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:51:29,878] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:51:29,977] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 08:52:00,231] {processor.py:153} INFO - Started process (PID=51950) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:52:00,235] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:52:00,237] {logging_mixin.py:115} INFO - [2022-06-07 08:52:00,237] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:52:00,301] {logging_mixin.py:115} INFO - [2022-06-07 08:52:00,299] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:52:00,303] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:52:00,404] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 08:52:31,292] {processor.py:153} INFO - Started process (PID=52017) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:52:31,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:52:31,302] {logging_mixin.py:115} INFO - [2022-06-07 08:52:31,302] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:52:31,393] {logging_mixin.py:115} INFO - [2022-06-07 08:52:31,390] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:52:31,395] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:52:31,508] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-07 08:53:02,512] {processor.py:153} INFO - Started process (PID=52078) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:53:02,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:53:02,517] {logging_mixin.py:115} INFO - [2022-06-07 08:53:02,517] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:53:02,574] {logging_mixin.py:115} INFO - [2022-06-07 08:53:02,571] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:53:02,575] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:53:02,672] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 08:53:33,214] {processor.py:153} INFO - Started process (PID=52144) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:53:33,217] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:53:33,219] {logging_mixin.py:115} INFO - [2022-06-07 08:53:33,218] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:53:33,306] {logging_mixin.py:115} INFO - [2022-06-07 08:53:33,304] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:53:33,308] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:53:33,411] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-07 08:54:04,029] {processor.py:153} INFO - Started process (PID=52212) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:54:04,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:54:04,035] {logging_mixin.py:115} INFO - [2022-06-07 08:54:04,034] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:54:04,126] {logging_mixin.py:115} INFO - [2022-06-07 08:54:04,123] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:54:04,127] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:54:04,235] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-07 08:54:34,584] {processor.py:153} INFO - Started process (PID=52281) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:54:34,587] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:54:34,590] {logging_mixin.py:115} INFO - [2022-06-07 08:54:34,590] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:54:34,654] {logging_mixin.py:115} INFO - [2022-06-07 08:54:34,651] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:54:34,656] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:54:34,751] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 08:55:05,647] {processor.py:153} INFO - Started process (PID=52348) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:55:05,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:55:05,650] {logging_mixin.py:115} INFO - [2022-06-07 08:55:05,650] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:55:05,735] {logging_mixin.py:115} INFO - [2022-06-07 08:55:05,731] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:55:05,737] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:55:05,856] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-07 08:55:36,840] {processor.py:153} INFO - Started process (PID=52404) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:55:36,842] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:55:36,843] {logging_mixin.py:115} INFO - [2022-06-07 08:55:36,843] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:55:36,900] {logging_mixin.py:115} INFO - [2022-06-07 08:55:36,898] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:55:36,903] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:55:36,997] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 08:56:07,242] {processor.py:153} INFO - Started process (PID=52471) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:56:07,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:56:07,247] {logging_mixin.py:115} INFO - [2022-06-07 08:56:07,247] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:56:07,313] {logging_mixin.py:115} INFO - [2022-06-07 08:56:07,310] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:56:07,314] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:56:07,416] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 08:56:37,910] {processor.py:153} INFO - Started process (PID=52538) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:56:37,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:56:37,916] {logging_mixin.py:115} INFO - [2022-06-07 08:56:37,916] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:56:37,987] {logging_mixin.py:115} INFO - [2022-06-07 08:56:37,985] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:56:37,989] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:56:38,091] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 08:57:08,855] {processor.py:153} INFO - Started process (PID=52608) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:57:08,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:57:08,859] {logging_mixin.py:115} INFO - [2022-06-07 08:57:08,858] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:57:08,915] {logging_mixin.py:115} INFO - [2022-06-07 08:57:08,912] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:57:08,916] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:57:09,015] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 08:57:39,815] {processor.py:153} INFO - Started process (PID=52682) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:57:39,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:57:39,818] {logging_mixin.py:115} INFO - [2022-06-07 08:57:39,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:57:39,882] {logging_mixin.py:115} INFO - [2022-06-07 08:57:39,879] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:57:39,884] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:57:39,989] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 08:58:10,929] {processor.py:153} INFO - Started process (PID=52739) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:58:10,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:58:10,932] {logging_mixin.py:115} INFO - [2022-06-07 08:58:10,932] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:58:10,993] {logging_mixin.py:115} INFO - [2022-06-07 08:58:10,991] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:58:10,994] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:58:11,090] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-07 08:58:41,533] {processor.py:153} INFO - Started process (PID=52808) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:58:41,536] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:58:41,538] {logging_mixin.py:115} INFO - [2022-06-07 08:58:41,538] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:58:41,605] {logging_mixin.py:115} INFO - [2022-06-07 08:58:41,602] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:58:41,606] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:58:41,701] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 08:59:11,987] {processor.py:153} INFO - Started process (PID=52878) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:59:11,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:59:11,993] {logging_mixin.py:115} INFO - [2022-06-07 08:59:11,993] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:59:12,064] {logging_mixin.py:115} INFO - [2022-06-07 08:59:12,062] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:59:12,065] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:59:12,160] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 08:59:42,216] {processor.py:153} INFO - Started process (PID=52945) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:59:42,219] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 08:59:42,220] {logging_mixin.py:115} INFO - [2022-06-07 08:59:42,220] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:59:42,279] {logging_mixin.py:115} INFO - [2022-06-07 08:59:42,277] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 08:59:42,280] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 08:59:42,374] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 09:00:13,001] {processor.py:153} INFO - Started process (PID=53015) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:00:13,002] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:00:13,004] {logging_mixin.py:115} INFO - [2022-06-07 09:00:13,004] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:00:13,153] {logging_mixin.py:115} INFO - [2022-06-07 09:00:13,151] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:00:13,156] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:00:13,300] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.305 seconds
[2022-06-07 09:00:43,357] {processor.py:153} INFO - Started process (PID=53069) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:00:43,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:00:43,362] {logging_mixin.py:115} INFO - [2022-06-07 09:00:43,362] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:00:43,437] {logging_mixin.py:115} INFO - [2022-06-07 09:00:43,435] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:00:43,439] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:00:43,531] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 09:01:14,267] {processor.py:153} INFO - Started process (PID=53142) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:01:14,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:01:14,270] {logging_mixin.py:115} INFO - [2022-06-07 09:01:14,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:01:14,315] {logging_mixin.py:115} INFO - [2022-06-07 09:01:14,313] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:01:14,317] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:01:14,410] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-07 09:01:45,079] {processor.py:153} INFO - Started process (PID=53209) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:01:45,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:01:45,084] {logging_mixin.py:115} INFO - [2022-06-07 09:01:45,083] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:01:45,154] {logging_mixin.py:115} INFO - [2022-06-07 09:01:45,152] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:01:45,155] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:01:45,250] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 09:02:16,306] {processor.py:153} INFO - Started process (PID=53277) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:02:16,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:02:16,311] {logging_mixin.py:115} INFO - [2022-06-07 09:02:16,311] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:02:16,366] {logging_mixin.py:115} INFO - [2022-06-07 09:02:16,364] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:02:16,368] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:02:16,462] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 09:02:46,668] {processor.py:153} INFO - Started process (PID=53333) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:02:46,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:02:46,675] {logging_mixin.py:115} INFO - [2022-06-07 09:02:46,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:02:46,751] {logging_mixin.py:115} INFO - [2022-06-07 09:02:46,748] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:02:46,752] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:02:46,860] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-07 09:03:16,945] {processor.py:153} INFO - Started process (PID=53398) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:03:16,946] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:03:16,947] {logging_mixin.py:115} INFO - [2022-06-07 09:03:16,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:03:17,001] {logging_mixin.py:115} INFO - [2022-06-07 09:03:16,998] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:03:17,003] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:03:17,105] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 09:03:47,690] {processor.py:153} INFO - Started process (PID=53466) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:03:47,692] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:03:47,695] {logging_mixin.py:115} INFO - [2022-06-07 09:03:47,695] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:03:47,779] {logging_mixin.py:115} INFO - [2022-06-07 09:03:47,776] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:03:47,780] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:03:47,880] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 09:04:18,719] {processor.py:153} INFO - Started process (PID=53534) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:04:18,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:04:18,721] {logging_mixin.py:115} INFO - [2022-06-07 09:04:18,721] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:04:18,767] {logging_mixin.py:115} INFO - [2022-06-07 09:04:18,764] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:04:18,768] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:04:18,861] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-07 09:04:49,513] {processor.py:153} INFO - Started process (PID=53606) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:04:49,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:04:49,518] {logging_mixin.py:115} INFO - [2022-06-07 09:04:49,518] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:04:49,586] {logging_mixin.py:115} INFO - [2022-06-07 09:04:49,584] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:04:49,587] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:04:49,682] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 09:05:20,659] {processor.py:153} INFO - Started process (PID=53674) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:05:20,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:05:20,662] {logging_mixin.py:115} INFO - [2022-06-07 09:05:20,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:05:20,718] {logging_mixin.py:115} INFO - [2022-06-07 09:05:20,715] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:05:20,720] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:05:20,831] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 09:05:51,707] {processor.py:153} INFO - Started process (PID=53731) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:05:51,708] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:05:51,709] {logging_mixin.py:115} INFO - [2022-06-07 09:05:51,709] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:05:51,775] {logging_mixin.py:115} INFO - [2022-06-07 09:05:51,772] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:05:51,776] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:05:51,899] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 09:06:22,156] {processor.py:153} INFO - Started process (PID=53799) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:06:22,159] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:06:22,162] {logging_mixin.py:115} INFO - [2022-06-07 09:06:22,162] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:06:22,224] {logging_mixin.py:115} INFO - [2022-06-07 09:06:22,222] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:06:22,225] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:06:22,323] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 09:06:52,521] {processor.py:153} INFO - Started process (PID=53867) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:06:52,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:06:52,526] {logging_mixin.py:115} INFO - [2022-06-07 09:06:52,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:06:52,606] {logging_mixin.py:115} INFO - [2022-06-07 09:06:52,603] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:06:52,607] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:06:52,704] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 09:07:22,793] {processor.py:153} INFO - Started process (PID=53936) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:07:22,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:07:22,798] {logging_mixin.py:115} INFO - [2022-06-07 09:07:22,798] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:07:22,845] {logging_mixin.py:115} INFO - [2022-06-07 09:07:22,843] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:07:22,846] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:07:22,946] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-07 09:07:53,054] {processor.py:153} INFO - Started process (PID=54001) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:07:53,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:07:53,059] {logging_mixin.py:115} INFO - [2022-06-07 09:07:53,059] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:07:53,132] {logging_mixin.py:115} INFO - [2022-06-07 09:07:53,130] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:07:53,134] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:07:53,232] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 09:08:23,431] {processor.py:153} INFO - Started process (PID=54059) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:08:23,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:08:23,437] {logging_mixin.py:115} INFO - [2022-06-07 09:08:23,437] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:08:23,518] {logging_mixin.py:115} INFO - [2022-06-07 09:08:23,515] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:08:23,519] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:08:23,634] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-07 09:08:53,723] {processor.py:153} INFO - Started process (PID=54128) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:08:53,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:08:53,725] {logging_mixin.py:115} INFO - [2022-06-07 09:08:53,725] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:08:53,785] {logging_mixin.py:115} INFO - [2022-06-07 09:08:53,783] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:08:53,788] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:08:53,900] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 09:09:24,348] {processor.py:153} INFO - Started process (PID=54194) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:09:24,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:09:24,353] {logging_mixin.py:115} INFO - [2022-06-07 09:09:24,353] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:09:24,424] {logging_mixin.py:115} INFO - [2022-06-07 09:09:24,422] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:09:24,425] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:09:24,520] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 09:09:54,777] {processor.py:153} INFO - Started process (PID=54261) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:09:54,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:09:54,779] {logging_mixin.py:115} INFO - [2022-06-07 09:09:54,779] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:09:54,832] {logging_mixin.py:115} INFO - [2022-06-07 09:09:54,829] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:09:54,835] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:09:54,944] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 09:10:25,262] {processor.py:153} INFO - Started process (PID=54327) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:10:25,264] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:10:25,266] {logging_mixin.py:115} INFO - [2022-06-07 09:10:25,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:10:25,327] {logging_mixin.py:115} INFO - [2022-06-07 09:10:25,323] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:10:25,328] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:10:25,421] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 09:10:55,520] {processor.py:153} INFO - Started process (PID=54385) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:10:55,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:10:55,527] {logging_mixin.py:115} INFO - [2022-06-07 09:10:55,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:10:55,587] {logging_mixin.py:115} INFO - [2022-06-07 09:10:55,585] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:10:55,589] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:10:55,685] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 09:11:26,074] {processor.py:153} INFO - Started process (PID=54451) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:11:26,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:11:26,077] {logging_mixin.py:115} INFO - [2022-06-07 09:11:26,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:11:26,144] {logging_mixin.py:115} INFO - [2022-06-07 09:11:26,142] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:11:26,145] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:11:26,244] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 09:11:56,536] {processor.py:153} INFO - Started process (PID=54518) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:11:56,538] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:11:56,539] {logging_mixin.py:115} INFO - [2022-06-07 09:11:56,539] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:11:56,599] {logging_mixin.py:115} INFO - [2022-06-07 09:11:56,596] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:11:56,600] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:11:56,702] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-07 09:12:26,907] {processor.py:153} INFO - Started process (PID=54588) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:12:26,909] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:12:26,912] {logging_mixin.py:115} INFO - [2022-06-07 09:12:26,911] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:12:26,997] {logging_mixin.py:115} INFO - [2022-06-07 09:12:26,993] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:12:26,998] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:12:27,098] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-07 09:12:57,288] {processor.py:153} INFO - Started process (PID=54654) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:12:57,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:12:57,292] {logging_mixin.py:115} INFO - [2022-06-07 09:12:57,292] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:12:57,361] {logging_mixin.py:115} INFO - [2022-06-07 09:12:57,359] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:12:57,362] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:12:57,477] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-07 09:13:27,969] {processor.py:153} INFO - Started process (PID=54711) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:13:27,972] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:13:27,973] {logging_mixin.py:115} INFO - [2022-06-07 09:13:27,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:13:28,029] {logging_mixin.py:115} INFO - [2022-06-07 09:13:28,027] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:13:28,031] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:13:28,130] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-07 09:13:58,206] {processor.py:153} INFO - Started process (PID=54779) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:13:58,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:13:58,209] {logging_mixin.py:115} INFO - [2022-06-07 09:13:58,209] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:13:58,265] {logging_mixin.py:115} INFO - [2022-06-07 09:13:58,263] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:13:58,266] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:13:58,362] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 09:14:28,708] {processor.py:153} INFO - Started process (PID=54849) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:14:28,711] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:14:28,712] {logging_mixin.py:115} INFO - [2022-06-07 09:14:28,712] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:14:28,763] {logging_mixin.py:115} INFO - [2022-06-07 09:14:28,761] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:14:28,764] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:14:28,863] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 09:14:58,986] {processor.py:153} INFO - Started process (PID=54922) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:14:58,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:14:58,988] {logging_mixin.py:115} INFO - [2022-06-07 09:14:58,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:14:59,036] {logging_mixin.py:115} INFO - [2022-06-07 09:14:59,033] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:14:59,037] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:14:59,132] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-07 09:15:29,266] {processor.py:153} INFO - Started process (PID=54982) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:15:29,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:15:29,272] {logging_mixin.py:115} INFO - [2022-06-07 09:15:29,272] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:15:29,342] {logging_mixin.py:115} INFO - [2022-06-07 09:15:29,340] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:15:29,344] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:15:29,442] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 09:15:59,862] {processor.py:153} INFO - Started process (PID=55050) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:15:59,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:15:59,865] {logging_mixin.py:115} INFO - [2022-06-07 09:15:59,865] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:15:59,911] {logging_mixin.py:115} INFO - [2022-06-07 09:15:59,908] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:15:59,912] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:16:00,005] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-07 09:16:30,149] {processor.py:153} INFO - Started process (PID=55118) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:16:30,152] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:16:30,155] {logging_mixin.py:115} INFO - [2022-06-07 09:16:30,155] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:16:30,219] {logging_mixin.py:115} INFO - [2022-06-07 09:16:30,217] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:16:30,220] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:16:30,315] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 09:17:00,538] {processor.py:153} INFO - Started process (PID=55187) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:17:00,539] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:17:00,540] {logging_mixin.py:115} INFO - [2022-06-07 09:17:00,540] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:17:00,607] {logging_mixin.py:115} INFO - [2022-06-07 09:17:00,605] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:17:00,609] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:17:00,719] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 09:17:30,920] {processor.py:153} INFO - Started process (PID=55255) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:17:30,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:17:30,923] {logging_mixin.py:115} INFO - [2022-06-07 09:17:30,923] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:17:31,015] {logging_mixin.py:115} INFO - [2022-06-07 09:17:31,012] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:17:31,017] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:17:31,149] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-07 09:18:01,223] {processor.py:153} INFO - Started process (PID=55312) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:18:01,226] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:18:01,228] {logging_mixin.py:115} INFO - [2022-06-07 09:18:01,228] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:18:01,286] {logging_mixin.py:115} INFO - [2022-06-07 09:18:01,284] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:18:01,287] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:18:01,387] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 09:18:31,566] {processor.py:153} INFO - Started process (PID=55380) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:18:31,568] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:18:31,569] {logging_mixin.py:115} INFO - [2022-06-07 09:18:31,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:18:31,628] {logging_mixin.py:115} INFO - [2022-06-07 09:18:31,626] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:18:31,630] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:18:31,736] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 09:19:01,910] {processor.py:153} INFO - Started process (PID=55446) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:19:01,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:19:01,915] {logging_mixin.py:115} INFO - [2022-06-07 09:19:01,915] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:19:01,993] {logging_mixin.py:115} INFO - [2022-06-07 09:19:01,991] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:19:01,994] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:19:02,089] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 09:19:32,292] {processor.py:153} INFO - Started process (PID=55512) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:19:32,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:19:32,296] {logging_mixin.py:115} INFO - [2022-06-07 09:19:32,296] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:19:32,349] {logging_mixin.py:115} INFO - [2022-06-07 09:19:32,347] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:19:32,351] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:19:32,446] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 09:20:02,564] {processor.py:153} INFO - Started process (PID=55569) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:20:02,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:20:02,568] {logging_mixin.py:115} INFO - [2022-06-07 09:20:02,568] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:20:02,660] {logging_mixin.py:115} INFO - [2022-06-07 09:20:02,656] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:20:02,661] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:20:02,776] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-07 09:20:33,011] {processor.py:153} INFO - Started process (PID=55640) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:20:33,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:20:33,016] {logging_mixin.py:115} INFO - [2022-06-07 09:20:33,016] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:20:33,082] {logging_mixin.py:115} INFO - [2022-06-07 09:20:33,079] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:20:33,083] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:20:33,180] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 09:21:04,128] {processor.py:153} INFO - Started process (PID=55711) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:21:04,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:21:04,133] {logging_mixin.py:115} INFO - [2022-06-07 09:21:04,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:21:04,204] {logging_mixin.py:115} INFO - [2022-06-07 09:21:04,202] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:21:04,205] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:21:04,305] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 09:21:34,447] {processor.py:153} INFO - Started process (PID=55778) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:21:34,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:21:34,451] {logging_mixin.py:115} INFO - [2022-06-07 09:21:34,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:21:34,517] {logging_mixin.py:115} INFO - [2022-06-07 09:21:34,514] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:21:34,518] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:21:34,612] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 09:22:04,738] {processor.py:153} INFO - Started process (PID=55834) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:22:04,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:22:04,742] {logging_mixin.py:115} INFO - [2022-06-07 09:22:04,742] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:22:04,804] {logging_mixin.py:115} INFO - [2022-06-07 09:22:04,802] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:22:04,807] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:22:04,917] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 09:22:35,298] {processor.py:153} INFO - Started process (PID=55902) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:22:35,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:22:35,302] {logging_mixin.py:115} INFO - [2022-06-07 09:22:35,302] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:22:35,363] {logging_mixin.py:115} INFO - [2022-06-07 09:22:35,361] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:22:35,365] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:22:35,461] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 09:23:06,076] {processor.py:153} INFO - Started process (PID=55971) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:23:06,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:23:06,082] {logging_mixin.py:115} INFO - [2022-06-07 09:23:06,082] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:23:06,154] {logging_mixin.py:115} INFO - [2022-06-07 09:23:06,151] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:23:06,155] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:23:06,250] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 09:23:36,654] {processor.py:153} INFO - Started process (PID=56035) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:23:36,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:23:36,659] {logging_mixin.py:115} INFO - [2022-06-07 09:23:36,658] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:23:36,719] {logging_mixin.py:115} INFO - [2022-06-07 09:23:36,717] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:23:36,720] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:23:36,816] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 09:24:07,073] {processor.py:153} INFO - Started process (PID=56109) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:24:07,076] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:24:07,078] {logging_mixin.py:115} INFO - [2022-06-07 09:24:07,078] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:24:07,240] {logging_mixin.py:115} INFO - [2022-06-07 09:24:07,237] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:24:07,242] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:24:07,386] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.317 seconds
[2022-06-07 09:24:37,481] {processor.py:153} INFO - Started process (PID=56166) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:24:37,484] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:24:37,487] {logging_mixin.py:115} INFO - [2022-06-07 09:24:37,487] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:24:37,552] {logging_mixin.py:115} INFO - [2022-06-07 09:24:37,550] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:24:37,553] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:24:37,653] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 09:25:08,121] {processor.py:153} INFO - Started process (PID=56232) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:25:08,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:25:08,123] {logging_mixin.py:115} INFO - [2022-06-07 09:25:08,123] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:25:08,199] {logging_mixin.py:115} INFO - [2022-06-07 09:25:08,195] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:25:08,201] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:25:08,297] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 09:25:39,179] {processor.py:153} INFO - Started process (PID=56297) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:25:39,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:25:39,184] {logging_mixin.py:115} INFO - [2022-06-07 09:25:39,184] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:25:39,252] {logging_mixin.py:115} INFO - [2022-06-07 09:25:39,250] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:25:39,253] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:25:39,356] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 09:26:09,649] {processor.py:153} INFO - Started process (PID=56366) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:26:09,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:26:09,654] {logging_mixin.py:115} INFO - [2022-06-07 09:26:09,654] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:26:09,721] {logging_mixin.py:115} INFO - [2022-06-07 09:26:09,718] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:26:09,724] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:26:09,817] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 09:26:40,016] {processor.py:153} INFO - Started process (PID=56425) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:26:40,018] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:26:40,020] {logging_mixin.py:115} INFO - [2022-06-07 09:26:40,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:26:40,078] {logging_mixin.py:115} INFO - [2022-06-07 09:26:40,075] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:26:40,079] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:26:40,176] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 09:27:10,395] {processor.py:153} INFO - Started process (PID=56492) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:27:10,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:27:10,400] {logging_mixin.py:115} INFO - [2022-06-07 09:27:10,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:27:10,474] {logging_mixin.py:115} INFO - [2022-06-07 09:27:10,471] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:27:10,475] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:27:10,572] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 09:27:40,989] {processor.py:153} INFO - Started process (PID=56559) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:27:40,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:27:40,994] {logging_mixin.py:115} INFO - [2022-06-07 09:27:40,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:27:41,069] {logging_mixin.py:115} INFO - [2022-06-07 09:27:41,067] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:27:41,070] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:27:41,169] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 09:28:11,584] {processor.py:153} INFO - Started process (PID=56625) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:28:11,587] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:28:11,589] {logging_mixin.py:115} INFO - [2022-06-07 09:28:11,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:28:11,650] {logging_mixin.py:115} INFO - [2022-06-07 09:28:11,647] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:28:11,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:28:11,747] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 09:28:41,995] {processor.py:153} INFO - Started process (PID=56681) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:28:41,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:28:42,000] {logging_mixin.py:115} INFO - [2022-06-07 09:28:42,000] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:28:42,079] {logging_mixin.py:115} INFO - [2022-06-07 09:28:42,076] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:28:42,080] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:28:42,182] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-07 09:29:12,229] {processor.py:153} INFO - Started process (PID=56748) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:29:12,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:29:12,233] {logging_mixin.py:115} INFO - [2022-06-07 09:29:12,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:29:12,282] {logging_mixin.py:115} INFO - [2022-06-07 09:29:12,280] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:29:12,283] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:29:12,379] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-07 09:29:42,824] {processor.py:153} INFO - Started process (PID=56817) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:29:42,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:29:42,829] {logging_mixin.py:115} INFO - [2022-06-07 09:29:42,829] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:29:42,922] {logging_mixin.py:115} INFO - [2022-06-07 09:29:42,920] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:29:42,924] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:29:43,027] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-07 09:30:13,603] {processor.py:153} INFO - Started process (PID=56888) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:30:13,605] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:30:13,607] {logging_mixin.py:115} INFO - [2022-06-07 09:30:13,607] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:30:13,672] {logging_mixin.py:115} INFO - [2022-06-07 09:30:13,668] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:30:13,675] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:30:13,785] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-07 09:30:44,099] {processor.py:153} INFO - Started process (PID=56944) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:30:44,101] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:30:44,103] {logging_mixin.py:115} INFO - [2022-06-07 09:30:44,103] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:30:44,205] {logging_mixin.py:115} INFO - [2022-06-07 09:30:44,200] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:30:44,207] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:30:44,326] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-07 09:31:15,222] {processor.py:153} INFO - Started process (PID=57009) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:31:15,225] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:31:15,226] {logging_mixin.py:115} INFO - [2022-06-07 09:31:15,226] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:31:15,298] {logging_mixin.py:115} INFO - [2022-06-07 09:31:15,295] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:31:15,300] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:31:15,398] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 09:31:45,752] {processor.py:153} INFO - Started process (PID=57078) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:31:45,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:31:45,755] {logging_mixin.py:115} INFO - [2022-06-07 09:31:45,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:31:45,833] {logging_mixin.py:115} INFO - [2022-06-07 09:31:45,831] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:31:45,835] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:31:45,928] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 09:32:16,259] {processor.py:153} INFO - Started process (PID=57142) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:32:16,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:32:16,268] {logging_mixin.py:115} INFO - [2022-06-07 09:32:16,268] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:32:16,328] {logging_mixin.py:115} INFO - [2022-06-07 09:32:16,325] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:32:16,329] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:32:16,425] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 09:32:46,655] {processor.py:153} INFO - Started process (PID=57212) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:32:46,656] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:32:46,657] {logging_mixin.py:115} INFO - [2022-06-07 09:32:46,657] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:32:46,727] {logging_mixin.py:115} INFO - [2022-06-07 09:32:46,724] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:32:46,728] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:32:46,830] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 09:33:17,499] {processor.py:153} INFO - Started process (PID=57267) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:33:17,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:33:17,503] {logging_mixin.py:115} INFO - [2022-06-07 09:33:17,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:33:17,560] {logging_mixin.py:115} INFO - [2022-06-07 09:33:17,558] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:33:17,561] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:33:17,659] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-07 09:33:47,896] {processor.py:153} INFO - Started process (PID=57331) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:33:47,897] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:33:47,898] {logging_mixin.py:115} INFO - [2022-06-07 09:33:47,898] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:33:47,964] {logging_mixin.py:115} INFO - [2022-06-07 09:33:47,961] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:33:47,965] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:33:48,066] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 09:34:18,409] {processor.py:153} INFO - Started process (PID=57399) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:34:18,412] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:34:18,414] {logging_mixin.py:115} INFO - [2022-06-07 09:34:18,414] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:34:18,475] {logging_mixin.py:115} INFO - [2022-06-07 09:34:18,473] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:34:18,476] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:34:18,571] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 09:34:49,246] {processor.py:153} INFO - Started process (PID=57467) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:34:49,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:34:49,249] {logging_mixin.py:115} INFO - [2022-06-07 09:34:49,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:34:49,319] {logging_mixin.py:115} INFO - [2022-06-07 09:34:49,316] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:34:49,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:34:49,416] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 09:35:19,862] {processor.py:153} INFO - Started process (PID=57522) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:35:19,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:35:19,864] {logging_mixin.py:115} INFO - [2022-06-07 09:35:19,864] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:35:19,921] {logging_mixin.py:115} INFO - [2022-06-07 09:35:19,918] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:35:19,922] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:35:20,027] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 09:35:50,832] {processor.py:153} INFO - Started process (PID=57596) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:35:50,836] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:35:50,839] {logging_mixin.py:115} INFO - [2022-06-07 09:35:50,838] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:35:50,906] {logging_mixin.py:115} INFO - [2022-06-07 09:35:50,903] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:35:50,907] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:35:51,001] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 09:36:21,762] {processor.py:153} INFO - Started process (PID=57663) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:36:21,764] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:36:21,764] {logging_mixin.py:115} INFO - [2022-06-07 09:36:21,764] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:36:21,820] {logging_mixin.py:115} INFO - [2022-06-07 09:36:21,817] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:36:21,822] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:36:21,919] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 09:36:52,531] {processor.py:153} INFO - Started process (PID=57730) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:36:52,533] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:36:52,535] {logging_mixin.py:115} INFO - [2022-06-07 09:36:52,535] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:36:52,606] {logging_mixin.py:115} INFO - [2022-06-07 09:36:52,602] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:36:52,607] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:36:52,701] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 09:37:23,100] {processor.py:153} INFO - Started process (PID=57797) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:37:23,101] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:37:23,103] {logging_mixin.py:115} INFO - [2022-06-07 09:37:23,103] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:37:23,196] {logging_mixin.py:115} INFO - [2022-06-07 09:37:23,191] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:37:23,198] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:37:23,385] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.291 seconds
[2022-06-07 09:37:54,340] {processor.py:153} INFO - Started process (PID=57854) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:37:54,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:37:54,343] {logging_mixin.py:115} INFO - [2022-06-07 09:37:54,343] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:37:54,417] {logging_mixin.py:115} INFO - [2022-06-07 09:37:54,415] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:37:54,419] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:37:54,513] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 09:38:25,454] {processor.py:153} INFO - Started process (PID=57920) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:38:25,457] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:38:25,459] {logging_mixin.py:115} INFO - [2022-06-07 09:38:25,459] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:38:25,521] {logging_mixin.py:115} INFO - [2022-06-07 09:38:25,519] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:38:25,524] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:38:25,616] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 09:38:55,779] {processor.py:153} INFO - Started process (PID=57993) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:38:55,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:38:55,783] {logging_mixin.py:115} INFO - [2022-06-07 09:38:55,783] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:38:55,848] {logging_mixin.py:115} INFO - [2022-06-07 09:38:55,846] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:38:55,849] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:38:55,945] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 09:39:26,426] {processor.py:153} INFO - Started process (PID=58058) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:39:26,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:39:26,430] {logging_mixin.py:115} INFO - [2022-06-07 09:39:26,430] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:39:26,493] {logging_mixin.py:115} INFO - [2022-06-07 09:39:26,490] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:39:26,495] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:39:26,589] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 09:39:56,815] {processor.py:153} INFO - Started process (PID=58115) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:39:56,818] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:39:56,819] {logging_mixin.py:115} INFO - [2022-06-07 09:39:56,819] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:39:56,887] {logging_mixin.py:115} INFO - [2022-06-07 09:39:56,885] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:39:56,888] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:39:56,987] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 09:40:27,198] {processor.py:153} INFO - Started process (PID=58183) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:40:27,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:40:27,204] {logging_mixin.py:115} INFO - [2022-06-07 09:40:27,204] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:40:27,275] {logging_mixin.py:115} INFO - [2022-06-07 09:40:27,271] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:40:27,278] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:40:27,378] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-07 09:40:57,489] {processor.py:153} INFO - Started process (PID=58249) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:40:57,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:40:57,492] {logging_mixin.py:115} INFO - [2022-06-07 09:40:57,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:40:57,587] {logging_mixin.py:115} INFO - [2022-06-07 09:40:57,584] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:40:57,588] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:40:57,697] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-07 09:41:28,281] {processor.py:153} INFO - Started process (PID=58319) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:41:28,283] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:41:28,285] {logging_mixin.py:115} INFO - [2022-06-07 09:41:28,285] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:41:28,345] {logging_mixin.py:115} INFO - [2022-06-07 09:41:28,343] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:41:28,347] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:41:28,445] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 09:41:58,587] {processor.py:153} INFO - Started process (PID=58379) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:41:58,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:41:58,590] {logging_mixin.py:115} INFO - [2022-06-07 09:41:58,590] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:41:58,637] {logging_mixin.py:115} INFO - [2022-06-07 09:41:58,635] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:41:58,638] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:41:58,736] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-07 09:42:28,949] {processor.py:153} INFO - Started process (PID=58448) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:42:28,952] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:42:28,954] {logging_mixin.py:115} INFO - [2022-06-07 09:42:28,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:42:29,043] {logging_mixin.py:115} INFO - [2022-06-07 09:42:29,040] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:42:29,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:42:29,144] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 09:42:59,954] {processor.py:153} INFO - Started process (PID=58516) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:42:59,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:42:59,957] {logging_mixin.py:115} INFO - [2022-06-07 09:42:59,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:43:00,020] {logging_mixin.py:115} INFO - [2022-06-07 09:43:00,017] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:43:00,021] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:43:00,140] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-07 09:43:30,534] {processor.py:153} INFO - Started process (PID=58585) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:43:30,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:43:30,539] {logging_mixin.py:115} INFO - [2022-06-07 09:43:30,539] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:43:30,627] {logging_mixin.py:115} INFO - [2022-06-07 09:43:30,622] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:43:30,628] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:43:30,725] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-07 09:44:00,911] {processor.py:153} INFO - Started process (PID=58654) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:44:00,914] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:44:00,915] {logging_mixin.py:115} INFO - [2022-06-07 09:44:00,915] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:44:00,986] {logging_mixin.py:115} INFO - [2022-06-07 09:44:00,982] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:44:00,993] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:44:01,186] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.278 seconds
[2022-06-07 09:44:31,874] {processor.py:153} INFO - Started process (PID=58713) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:44:31,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:44:31,878] {logging_mixin.py:115} INFO - [2022-06-07 09:44:31,878] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:44:31,951] {logging_mixin.py:115} INFO - [2022-06-07 09:44:31,949] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:44:31,953] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:44:32,047] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 09:45:02,192] {processor.py:153} INFO - Started process (PID=58785) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:45:02,195] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:45:02,197] {logging_mixin.py:115} INFO - [2022-06-07 09:45:02,197] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:45:02,264] {logging_mixin.py:115} INFO - [2022-06-07 09:45:02,262] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:45:02,266] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:45:02,370] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 09:45:32,493] {processor.py:153} INFO - Started process (PID=58854) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:45:32,495] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:45:32,497] {logging_mixin.py:115} INFO - [2022-06-07 09:45:32,496] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:45:32,563] {logging_mixin.py:115} INFO - [2022-06-07 09:45:32,561] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:45:32,565] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:45:32,657] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 09:46:03,232] {processor.py:153} INFO - Started process (PID=58922) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:46:03,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:46:03,235] {logging_mixin.py:115} INFO - [2022-06-07 09:46:03,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:46:03,296] {logging_mixin.py:115} INFO - [2022-06-07 09:46:03,294] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:46:03,298] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:46:03,406] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 09:46:33,977] {processor.py:153} INFO - Started process (PID=58978) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:46:33,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:46:33,981] {logging_mixin.py:115} INFO - [2022-06-07 09:46:33,981] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:46:34,065] {logging_mixin.py:115} INFO - [2022-06-07 09:46:34,063] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:46:34,067] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:46:34,173] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-07 09:47:05,119] {processor.py:153} INFO - Started process (PID=59045) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:47:05,121] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:47:05,123] {logging_mixin.py:115} INFO - [2022-06-07 09:47:05,123] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:47:05,177] {logging_mixin.py:115} INFO - [2022-06-07 09:47:05,175] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:47:05,179] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:47:05,278] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 09:47:35,414] {processor.py:153} INFO - Started process (PID=59115) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:47:35,416] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:47:35,417] {logging_mixin.py:115} INFO - [2022-06-07 09:47:35,417] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:47:35,475] {logging_mixin.py:115} INFO - [2022-06-07 09:47:35,472] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:47:35,476] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:47:35,571] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 09:48:06,106] {processor.py:153} INFO - Started process (PID=59184) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:48:06,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:48:06,111] {logging_mixin.py:115} INFO - [2022-06-07 09:48:06,111] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:48:06,168] {logging_mixin.py:115} INFO - [2022-06-07 09:48:06,165] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:48:06,169] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:48:06,266] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 09:48:37,107] {processor.py:153} INFO - Started process (PID=59251) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:48:37,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:48:37,110] {logging_mixin.py:115} INFO - [2022-06-07 09:48:37,110] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:48:37,170] {logging_mixin.py:115} INFO - [2022-06-07 09:48:37,167] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:48:37,171] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:48:37,339] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-07 09:49:07,641] {processor.py:153} INFO - Started process (PID=59311) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:49:07,643] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:49:07,645] {logging_mixin.py:115} INFO - [2022-06-07 09:49:07,645] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:49:07,731] {logging_mixin.py:115} INFO - [2022-06-07 09:49:07,728] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:49:07,732] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:49:07,834] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-07 09:49:37,880] {processor.py:153} INFO - Started process (PID=59381) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:49:37,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:49:37,884] {logging_mixin.py:115} INFO - [2022-06-07 09:49:37,884] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:49:37,936] {logging_mixin.py:115} INFO - [2022-06-07 09:49:37,934] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:49:37,938] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:49:38,043] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-07 09:50:08,749] {processor.py:153} INFO - Started process (PID=59448) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:50:08,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:50:08,751] {logging_mixin.py:115} INFO - [2022-06-07 09:50:08,751] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:50:08,809] {logging_mixin.py:115} INFO - [2022-06-07 09:50:08,807] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:50:08,810] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:50:08,907] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 09:50:39,102] {processor.py:153} INFO - Started process (PID=59517) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:50:39,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:50:39,107] {logging_mixin.py:115} INFO - [2022-06-07 09:50:39,107] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:50:39,220] {logging_mixin.py:115} INFO - [2022-06-07 09:50:39,217] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:50:39,222] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:50:39,434] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.338 seconds
[2022-06-07 09:51:09,472] {processor.py:153} INFO - Started process (PID=59576) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:51:09,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:51:09,474] {logging_mixin.py:115} INFO - [2022-06-07 09:51:09,474] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:51:09,520] {logging_mixin.py:115} INFO - [2022-06-07 09:51:09,518] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:51:09,521] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:51:09,615] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-07 09:51:39,805] {processor.py:153} INFO - Started process (PID=59646) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:51:39,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:51:39,810] {logging_mixin.py:115} INFO - [2022-06-07 09:51:39,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:51:39,867] {logging_mixin.py:115} INFO - [2022-06-07 09:51:39,865] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:51:39,869] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:51:39,963] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 09:52:10,077] {processor.py:153} INFO - Started process (PID=59714) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:52:10,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:52:10,083] {logging_mixin.py:115} INFO - [2022-06-07 09:52:10,082] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:52:10,153] {logging_mixin.py:115} INFO - [2022-06-07 09:52:10,150] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:52:10,154] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:52:10,248] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 09:52:40,516] {processor.py:153} INFO - Started process (PID=59778) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:52:40,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:52:40,528] {logging_mixin.py:115} INFO - [2022-06-07 09:52:40,520] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:52:40,699] {logging_mixin.py:115} INFO - [2022-06-07 09:52:40,697] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:52:40,701] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:52:40,912] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.399 seconds
[2022-06-07 09:53:11,372] {processor.py:153} INFO - Started process (PID=59835) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:53:11,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:53:11,376] {logging_mixin.py:115} INFO - [2022-06-07 09:53:11,376] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:53:11,464] {logging_mixin.py:115} INFO - [2022-06-07 09:53:11,462] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:53:11,466] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:53:11,566] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 09:53:42,230] {processor.py:153} INFO - Started process (PID=59903) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:53:42,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:53:42,236] {logging_mixin.py:115} INFO - [2022-06-07 09:53:42,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:53:42,291] {logging_mixin.py:115} INFO - [2022-06-07 09:53:42,289] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:53:42,293] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:53:42,385] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 09:54:12,993] {processor.py:153} INFO - Started process (PID=59971) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:54:12,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:54:12,997] {logging_mixin.py:115} INFO - [2022-06-07 09:54:12,997] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:54:13,083] {logging_mixin.py:115} INFO - [2022-06-07 09:54:13,080] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:54:13,085] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:54:13,183] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 09:54:43,903] {processor.py:153} INFO - Started process (PID=60040) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:54:43,905] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:54:43,907] {logging_mixin.py:115} INFO - [2022-06-07 09:54:43,907] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:54:43,961] {logging_mixin.py:115} INFO - [2022-06-07 09:54:43,959] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:54:43,962] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:54:44,057] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 09:55:14,561] {processor.py:153} INFO - Started process (PID=60113) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:55:14,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:55:14,565] {logging_mixin.py:115} INFO - [2022-06-07 09:55:14,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:55:14,626] {logging_mixin.py:115} INFO - [2022-06-07 09:55:14,624] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:55:14,627] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:55:14,758] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 09:55:45,671] {processor.py:153} INFO - Started process (PID=60170) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:55:45,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:55:45,676] {logging_mixin.py:115} INFO - [2022-06-07 09:55:45,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:55:45,744] {logging_mixin.py:115} INFO - [2022-06-07 09:55:45,741] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:55:45,746] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:55:45,846] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 09:56:15,903] {processor.py:153} INFO - Started process (PID=60239) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:56:15,905] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:56:15,906] {logging_mixin.py:115} INFO - [2022-06-07 09:56:15,906] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:56:15,960] {logging_mixin.py:115} INFO - [2022-06-07 09:56:15,958] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:56:15,961] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:56:16,057] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-07 09:56:47,020] {processor.py:153} INFO - Started process (PID=60307) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:56:47,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:56:47,022] {logging_mixin.py:115} INFO - [2022-06-07 09:56:47,022] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:56:47,090] {logging_mixin.py:115} INFO - [2022-06-07 09:56:47,087] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:56:47,091] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:56:47,189] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 09:57:17,255] {processor.py:153} INFO - Started process (PID=60376) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:57:17,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:57:17,260] {logging_mixin.py:115} INFO - [2022-06-07 09:57:17,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:57:17,317] {logging_mixin.py:115} INFO - [2022-06-07 09:57:17,314] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:57:17,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:57:17,411] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-07 09:57:48,027] {processor.py:153} INFO - Started process (PID=60440) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:57:48,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:57:48,030] {logging_mixin.py:115} INFO - [2022-06-07 09:57:48,030] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:57:48,084] {logging_mixin.py:115} INFO - [2022-06-07 09:57:48,082] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:57:48,085] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:57:48,194] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 09:58:18,380] {processor.py:153} INFO - Started process (PID=60495) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:58:18,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:58:18,386] {logging_mixin.py:115} INFO - [2022-06-07 09:58:18,386] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:58:18,466] {logging_mixin.py:115} INFO - [2022-06-07 09:58:18,463] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:58:18,468] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:58:18,566] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-07 09:58:48,644] {processor.py:153} INFO - Started process (PID=60562) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:58:48,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:58:48,647] {logging_mixin.py:115} INFO - [2022-06-07 09:58:48,647] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:58:48,701] {logging_mixin.py:115} INFO - [2022-06-07 09:58:48,699] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:58:48,703] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:58:48,809] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 09:59:18,954] {processor.py:153} INFO - Started process (PID=60630) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:59:18,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:59:18,960] {logging_mixin.py:115} INFO - [2022-06-07 09:59:18,960] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:59:19,034] {logging_mixin.py:115} INFO - [2022-06-07 09:59:19,031] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:59:19,036] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:59:19,129] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 09:59:50,030] {processor.py:153} INFO - Started process (PID=60700) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:59:50,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 09:59:50,033] {logging_mixin.py:115} INFO - [2022-06-07 09:59:50,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:59:50,098] {logging_mixin.py:115} INFO - [2022-06-07 09:59:50,096] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 09:59:50,100] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 09:59:50,201] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-07 10:00:20,368] {processor.py:153} INFO - Started process (PID=60767) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:00:20,370] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:00:20,371] {logging_mixin.py:115} INFO - [2022-06-07 10:00:20,371] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:00:20,517] {logging_mixin.py:115} INFO - [2022-06-07 10:00:20,513] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:00:20,519] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:00:20,631] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.266 seconds
[2022-06-07 10:00:51,044] {processor.py:153} INFO - Started process (PID=60823) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:00:51,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:00:51,048] {logging_mixin.py:115} INFO - [2022-06-07 10:00:51,048] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:00:51,130] {logging_mixin.py:115} INFO - [2022-06-07 10:00:51,126] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:00:51,131] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:00:51,241] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-07 10:01:21,550] {processor.py:153} INFO - Started process (PID=60888) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:01:21,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:01:21,556] {logging_mixin.py:115} INFO - [2022-06-07 10:01:21,556] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:01:21,609] {logging_mixin.py:115} INFO - [2022-06-07 10:01:21,607] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:01:21,611] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:01:21,706] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 10:01:52,377] {processor.py:153} INFO - Started process (PID=60959) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:01:52,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:01:52,380] {logging_mixin.py:115} INFO - [2022-06-07 10:01:52,380] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:01:52,438] {logging_mixin.py:115} INFO - [2022-06-07 10:01:52,436] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:01:52,439] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:01:52,533] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 10:02:23,018] {processor.py:153} INFO - Started process (PID=61028) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:02:23,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:02:23,028] {logging_mixin.py:115} INFO - [2022-06-07 10:02:23,027] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:02:23,087] {logging_mixin.py:115} INFO - [2022-06-07 10:02:23,084] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:02:23,088] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:02:23,181] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 10:02:53,852] {processor.py:153} INFO - Started process (PID=61093) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:02:53,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:02:53,855] {logging_mixin.py:115} INFO - [2022-06-07 10:02:53,855] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:02:53,933] {logging_mixin.py:115} INFO - [2022-06-07 10:02:53,930] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:02:53,935] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:02:54,071] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-07 10:03:24,396] {processor.py:153} INFO - Started process (PID=61153) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:03:24,399] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:03:24,400] {logging_mixin.py:115} INFO - [2022-06-07 10:03:24,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:03:24,460] {logging_mixin.py:115} INFO - [2022-06-07 10:03:24,458] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:03:24,462] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:03:24,558] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 10:03:55,302] {processor.py:153} INFO - Started process (PID=61223) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:03:55,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:03:55,304] {logging_mixin.py:115} INFO - [2022-06-07 10:03:55,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:03:55,378] {logging_mixin.py:115} INFO - [2022-06-07 10:03:55,371] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:03:55,380] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:03:55,477] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 10:04:25,678] {processor.py:153} INFO - Started process (PID=61291) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:04:25,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:04:25,684] {logging_mixin.py:115} INFO - [2022-06-07 10:04:25,684] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:04:25,757] {logging_mixin.py:115} INFO - [2022-06-07 10:04:25,755] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:04:25,758] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:04:25,855] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 10:04:56,003] {processor.py:153} INFO - Started process (PID=61359) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:04:56,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:04:56,006] {logging_mixin.py:115} INFO - [2022-06-07 10:04:56,006] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:04:56,117] {logging_mixin.py:115} INFO - [2022-06-07 10:04:56,113] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:04:56,120] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:04:56,304] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.303 seconds
[2022-06-07 10:05:26,366] {processor.py:153} INFO - Started process (PID=61416) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:05:26,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:05:26,370] {logging_mixin.py:115} INFO - [2022-06-07 10:05:26,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:05:26,457] {logging_mixin.py:115} INFO - [2022-06-07 10:05:26,454] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:05:26,459] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:05:26,562] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 10:05:56,691] {processor.py:153} INFO - Started process (PID=61486) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:05:56,692] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:05:56,693] {logging_mixin.py:115} INFO - [2022-06-07 10:05:56,693] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:05:56,749] {logging_mixin.py:115} INFO - [2022-06-07 10:05:56,747] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:05:56,751] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:05:56,847] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 10:06:26,954] {processor.py:153} INFO - Started process (PID=61556) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:06:26,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:06:26,957] {logging_mixin.py:115} INFO - [2022-06-07 10:06:26,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:06:27,018] {logging_mixin.py:115} INFO - [2022-06-07 10:06:27,015] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:06:27,019] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:06:27,117] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 10:06:57,531] {processor.py:153} INFO - Started process (PID=61625) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:06:57,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:06:57,541] {logging_mixin.py:115} INFO - [2022-06-07 10:06:57,541] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:06:57,649] {logging_mixin.py:115} INFO - [2022-06-07 10:06:57,646] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:06:57,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:06:57,861] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.336 seconds
[2022-06-07 10:07:28,757] {processor.py:153} INFO - Started process (PID=61685) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:07:28,760] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:07:28,762] {logging_mixin.py:115} INFO - [2022-06-07 10:07:28,762] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:07:28,823] {logging_mixin.py:115} INFO - [2022-06-07 10:07:28,821] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:07:28,824] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:07:28,923] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 10:07:59,566] {processor.py:153} INFO - Started process (PID=61758) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:07:59,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:07:59,572] {logging_mixin.py:115} INFO - [2022-06-07 10:07:59,572] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:07:59,679] {logging_mixin.py:115} INFO - [2022-06-07 10:07:59,675] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:07:59,680] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:07:59,801] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-07 10:25:46,413] {processor.py:153} INFO - Started process (PID=61791) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:25:46,414] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:25:46,416] {logging_mixin.py:115} INFO - [2022-06-07 10:25:46,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:25:46,631] {logging_mixin.py:115} INFO - [2022-06-07 10:25:46,627] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:25:46,641] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:25:46,874] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.465 seconds
[2022-06-07 10:26:16,953] {processor.py:153} INFO - Started process (PID=61859) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:26:16,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:26:16,956] {logging_mixin.py:115} INFO - [2022-06-07 10:26:16,956] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:26:17,018] {logging_mixin.py:115} INFO - [2022-06-07 10:26:17,015] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:26:17,019] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:26:17,122] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 10:26:47,301] {processor.py:153} INFO - Started process (PID=61911) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:26:47,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:26:47,304] {logging_mixin.py:115} INFO - [2022-06-07 10:26:47,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:26:47,366] {logging_mixin.py:115} INFO - [2022-06-07 10:26:47,364] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:26:47,367] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:26:47,465] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 10:27:17,688] {processor.py:153} INFO - Started process (PID=61977) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:27:17,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:27:17,691] {logging_mixin.py:115} INFO - [2022-06-07 10:27:17,691] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:27:17,765] {logging_mixin.py:115} INFO - [2022-06-07 10:27:17,763] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:27:17,766] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:27:17,864] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 10:27:48,029] {processor.py:153} INFO - Started process (PID=62044) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:27:48,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:27:48,033] {logging_mixin.py:115} INFO - [2022-06-07 10:27:48,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:27:48,088] {logging_mixin.py:115} INFO - [2022-06-07 10:27:48,086] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:27:48,089] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:27:48,182] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 10:28:18,324] {processor.py:153} INFO - Started process (PID=62114) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:28:18,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:28:18,330] {logging_mixin.py:115} INFO - [2022-06-07 10:28:18,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:28:18,387] {logging_mixin.py:115} INFO - [2022-06-07 10:28:18,385] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:28:18,388] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:28:18,482] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 10:28:48,694] {processor.py:153} INFO - Started process (PID=62180) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:28:48,696] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:28:48,698] {logging_mixin.py:115} INFO - [2022-06-07 10:28:48,698] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:28:48,768] {logging_mixin.py:115} INFO - [2022-06-07 10:28:48,766] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:28:48,771] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:28:48,876] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-07 10:29:18,983] {processor.py:153} INFO - Started process (PID=62240) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:29:18,986] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:29:18,988] {logging_mixin.py:115} INFO - [2022-06-07 10:29:18,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:29:19,046] {logging_mixin.py:115} INFO - [2022-06-07 10:29:19,044] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:29:19,048] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:29:19,140] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 10:29:49,292] {processor.py:153} INFO - Started process (PID=62307) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:29:49,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:29:49,295] {logging_mixin.py:115} INFO - [2022-06-07 10:29:49,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:29:49,350] {logging_mixin.py:115} INFO - [2022-06-07 10:29:49,347] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:29:49,352] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:29:49,448] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 10:30:19,539] {processor.py:153} INFO - Started process (PID=62374) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:30:19,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:30:19,542] {logging_mixin.py:115} INFO - [2022-06-07 10:30:19,542] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:30:19,598] {logging_mixin.py:115} INFO - [2022-06-07 10:30:19,596] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:30:19,599] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:30:19,689] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-07 10:30:49,854] {processor.py:153} INFO - Started process (PID=62441) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:30:49,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:30:49,856] {logging_mixin.py:115} INFO - [2022-06-07 10:30:49,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:30:49,908] {logging_mixin.py:115} INFO - [2022-06-07 10:30:49,906] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:30:49,909] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:30:49,997] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-07 10:31:20,197] {processor.py:153} INFO - Started process (PID=62500) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:31:20,198] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:31:20,199] {logging_mixin.py:115} INFO - [2022-06-07 10:31:20,199] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:31:20,249] {logging_mixin.py:115} INFO - [2022-06-07 10:31:20,247] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:31:20,250] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:31:20,349] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-07 10:31:50,615] {processor.py:153} INFO - Started process (PID=62566) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:31:50,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:31:50,619] {logging_mixin.py:115} INFO - [2022-06-07 10:31:50,619] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:31:50,678] {logging_mixin.py:115} INFO - [2022-06-07 10:31:50,676] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:31:50,680] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:31:50,765] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-07 10:32:20,818] {processor.py:153} INFO - Started process (PID=62634) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:32:20,820] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:32:20,822] {logging_mixin.py:115} INFO - [2022-06-07 10:32:20,822] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:32:20,890] {logging_mixin.py:115} INFO - [2022-06-07 10:32:20,888] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:32:20,891] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:32:20,984] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 10:32:51,893] {processor.py:153} INFO - Started process (PID=62701) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:32:51,896] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:32:51,897] {logging_mixin.py:115} INFO - [2022-06-07 10:32:51,897] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:32:51,952] {logging_mixin.py:115} INFO - [2022-06-07 10:32:51,950] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:32:51,953] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:32:52,040] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-07 10:33:22,104] {processor.py:153} INFO - Started process (PID=62771) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:33:22,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:33:22,106] {logging_mixin.py:115} INFO - [2022-06-07 10:33:22,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:33:22,150] {logging_mixin.py:115} INFO - [2022-06-07 10:33:22,148] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:33:22,151] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:33:22,248] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-07 10:33:52,455] {processor.py:153} INFO - Started process (PID=62830) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:33:52,462] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:33:52,464] {logging_mixin.py:115} INFO - [2022-06-07 10:33:52,464] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:33:52,529] {logging_mixin.py:115} INFO - [2022-06-07 10:33:52,526] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:33:52,531] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:33:52,659] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-07 10:34:22,904] {processor.py:153} INFO - Started process (PID=62896) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:34:22,907] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:34:22,909] {logging_mixin.py:115} INFO - [2022-06-07 10:34:22,909] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:34:22,965] {logging_mixin.py:115} INFO - [2022-06-07 10:34:22,963] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:34:22,968] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:34:23,059] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 10:34:53,257] {processor.py:153} INFO - Started process (PID=62967) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:34:53,260] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:34:53,262] {logging_mixin.py:115} INFO - [2022-06-07 10:34:53,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:34:53,339] {logging_mixin.py:115} INFO - [2022-06-07 10:34:53,336] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:34:53,340] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:34:53,436] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 10:35:24,458] {processor.py:153} INFO - Started process (PID=63038) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:35:24,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:35:24,460] {logging_mixin.py:115} INFO - [2022-06-07 10:35:24,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:35:24,510] {logging_mixin.py:115} INFO - [2022-06-07 10:35:24,508] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:35:24,511] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:35:24,602] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-07 10:35:55,547] {processor.py:153} INFO - Started process (PID=63108) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:35:55,550] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:35:55,552] {logging_mixin.py:115} INFO - [2022-06-07 10:35:55,552] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:35:55,608] {logging_mixin.py:115} INFO - [2022-06-07 10:35:55,606] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:35:55,610] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:35:55,703] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 10:36:25,960] {processor.py:153} INFO - Started process (PID=63179) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:36:25,961] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:36:25,963] {logging_mixin.py:115} INFO - [2022-06-07 10:36:25,963] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:36:26,006] {logging_mixin.py:115} INFO - [2022-06-07 10:36:26,003] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:36:26,008] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:36:26,099] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.142 seconds
[2022-06-07 10:36:56,475] {processor.py:153} INFO - Started process (PID=63239) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:36:56,479] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:36:56,481] {logging_mixin.py:115} INFO - [2022-06-07 10:36:56,481] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:36:56,555] {logging_mixin.py:115} INFO - [2022-06-07 10:36:56,553] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:36:56,557] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:36:56,651] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 10:37:26,855] {processor.py:153} INFO - Started process (PID=63302) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:37:26,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:37:26,861] {logging_mixin.py:115} INFO - [2022-06-07 10:37:26,861] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:37:26,921] {logging_mixin.py:115} INFO - [2022-06-07 10:37:26,919] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:37:26,923] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:37:27,015] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 10:37:57,255] {processor.py:153} INFO - Started process (PID=63369) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:37:57,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:37:57,261] {logging_mixin.py:115} INFO - [2022-06-07 10:37:57,261] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:37:57,316] {logging_mixin.py:115} INFO - [2022-06-07 10:37:57,314] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:37:57,316] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:37:57,410] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 10:38:27,631] {processor.py:153} INFO - Started process (PID=63442) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:38:27,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:38:27,636] {logging_mixin.py:115} INFO - [2022-06-07 10:38:27,636] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:38:27,695] {logging_mixin.py:115} INFO - [2022-06-07 10:38:27,692] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:38:27,697] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:38:27,793] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 10:38:58,524] {processor.py:153} INFO - Started process (PID=63507) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:38:58,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:38:58,526] {logging_mixin.py:115} INFO - [2022-06-07 10:38:58,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:38:58,581] {logging_mixin.py:115} INFO - [2022-06-07 10:38:58,578] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:38:58,582] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:38:58,694] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 10:39:29,490] {processor.py:153} INFO - Started process (PID=63567) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:39:29,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:39:29,494] {logging_mixin.py:115} INFO - [2022-06-07 10:39:29,494] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:39:29,563] {logging_mixin.py:115} INFO - [2022-06-07 10:39:29,561] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:39:29,565] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:39:29,660] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 10:39:59,744] {processor.py:153} INFO - Started process (PID=63633) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:39:59,746] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:39:59,747] {logging_mixin.py:115} INFO - [2022-06-07 10:39:59,747] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:39:59,798] {logging_mixin.py:115} INFO - [2022-06-07 10:39:59,796] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:39:59,799] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:39:59,895] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-07 10:40:30,317] {processor.py:153} INFO - Started process (PID=63706) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:40:30,321] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:40:30,323] {logging_mixin.py:115} INFO - [2022-06-07 10:40:30,323] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:40:30,378] {logging_mixin.py:115} INFO - [2022-06-07 10:40:30,376] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:40:30,380] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:40:30,472] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 10:41:00,811] {processor.py:153} INFO - Started process (PID=63772) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:41:00,813] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:41:00,815] {logging_mixin.py:115} INFO - [2022-06-07 10:41:00,815] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:41:00,869] {logging_mixin.py:115} INFO - [2022-06-07 10:41:00,866] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:41:00,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:41:00,965] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-07 10:41:31,325] {processor.py:153} INFO - Started process (PID=63828) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:41:31,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:41:31,331] {logging_mixin.py:115} INFO - [2022-06-07 10:41:31,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:41:31,455] {logging_mixin.py:115} INFO - [2022-06-07 10:41:31,453] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:41:31,456] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:41:31,557] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-07 10:58:25,800] {processor.py:153} INFO - Started process (PID=63884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:58:25,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:58:25,803] {logging_mixin.py:115} INFO - [2022-06-07 10:58:25,803] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:58:25,850] {logging_mixin.py:115} INFO - [2022-06-07 10:58:25,848] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:58:25,852] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:58:25,945] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-07 10:58:56,096] {processor.py:153} INFO - Started process (PID=63942) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:58:56,099] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 10:58:56,100] {logging_mixin.py:115} INFO - [2022-06-07 10:58:56,100] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:58:56,175] {logging_mixin.py:115} INFO - [2022-06-07 10:58:56,172] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 10:58:56,176] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 10:58:56,281] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-07 11:00:12,798] {processor.py:153} INFO - Started process (PID=64009) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:00:12,800] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:00:12,801] {logging_mixin.py:115} INFO - [2022-06-07 11:00:12,801] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:00:12,899] {logging_mixin.py:115} INFO - [2022-06-07 11:00:12,897] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:00:12,901] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:00:13,014] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-07 11:00:43,965] {processor.py:153} INFO - Started process (PID=64081) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:00:43,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:00:43,967] {logging_mixin.py:115} INFO - [2022-06-07 11:00:43,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:00:44,034] {logging_mixin.py:115} INFO - [2022-06-07 11:00:44,030] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:00:44,035] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:00:44,136] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 11:01:14,964] {processor.py:153} INFO - Started process (PID=64150) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:01:14,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:01:14,967] {logging_mixin.py:115} INFO - [2022-06-07 11:01:14,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:01:15,024] {logging_mixin.py:115} INFO - [2022-06-07 11:01:15,022] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:01:15,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:01:15,118] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 11:02:32,380] {processor.py:153} INFO - Started process (PID=64208) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:02:32,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:02:32,383] {logging_mixin.py:115} INFO - [2022-06-07 11:02:32,383] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:02:32,439] {logging_mixin.py:115} INFO - [2022-06-07 11:02:32,437] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:02:32,440] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:02:32,539] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 11:03:49,800] {processor.py:153} INFO - Started process (PID=64280) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:03:49,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:03:49,802] {logging_mixin.py:115} INFO - [2022-06-07 11:03:49,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:03:49,855] {logging_mixin.py:115} INFO - [2022-06-07 11:03:49,853] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:03:49,857] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:03:49,951] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-07 11:04:20,071] {processor.py:153} INFO - Started process (PID=64347) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:04:20,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:04:20,075] {logging_mixin.py:115} INFO - [2022-06-07 11:04:20,075] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:04:20,136] {logging_mixin.py:115} INFO - [2022-06-07 11:04:20,134] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:04:20,137] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:04:20,235] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 11:05:36,074] {processor.py:153} INFO - Started process (PID=64413) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:05:36,076] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:05:36,077] {logging_mixin.py:115} INFO - [2022-06-07 11:05:36,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:05:36,209] {logging_mixin.py:115} INFO - [2022-06-07 11:05:36,204] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:05:36,213] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:05:36,360] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.289 seconds
[2022-06-07 11:06:07,221] {processor.py:153} INFO - Started process (PID=64472) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:06:07,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:06:07,227] {logging_mixin.py:115} INFO - [2022-06-07 11:06:07,226] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:06:07,286] {logging_mixin.py:115} INFO - [2022-06-07 11:06:07,284] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:06:07,287] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:06:07,384] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 11:07:26,017] {processor.py:153} INFO - Started process (PID=64541) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:07:26,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:07:26,020] {logging_mixin.py:115} INFO - [2022-06-07 11:07:26,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:07:26,076] {logging_mixin.py:115} INFO - [2022-06-07 11:07:26,074] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:07:26,078] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:07:26,184] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 11:08:37,264] {processor.py:153} INFO - Started process (PID=64612) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:08:37,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:08:37,266] {logging_mixin.py:115} INFO - [2022-06-07 11:08:37,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:08:37,322] {logging_mixin.py:115} INFO - [2022-06-07 11:08:37,320] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:08:37,323] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:08:37,420] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-07 11:09:08,408] {processor.py:153} INFO - Started process (PID=64677) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:09:08,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:09:08,411] {logging_mixin.py:115} INFO - [2022-06-07 11:09:08,411] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:09:08,460] {logging_mixin.py:115} INFO - [2022-06-07 11:09:08,458] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:09:08,462] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:09:08,563] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-07 11:10:24,950] {processor.py:153} INFO - Started process (PID=64735) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:10:24,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:10:24,955] {logging_mixin.py:115} INFO - [2022-06-07 11:10:24,955] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:10:25,009] {logging_mixin.py:115} INFO - [2022-06-07 11:10:25,007] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:10:25,011] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:10:25,103] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 11:10:55,436] {processor.py:153} INFO - Started process (PID=64807) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:10:55,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:10:55,439] {logging_mixin.py:115} INFO - [2022-06-07 11:10:55,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:10:55,546] {logging_mixin.py:115} INFO - [2022-06-07 11:10:55,542] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:10:55,549] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:10:55,658] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-07 11:11:26,681] {processor.py:153} INFO - Started process (PID=64875) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:11:26,683] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:11:26,684] {logging_mixin.py:115} INFO - [2022-06-07 11:11:26,684] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:11:26,735] {logging_mixin.py:115} INFO - [2022-06-07 11:11:26,732] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:11:26,737] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:11:26,828] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-07 11:11:57,663] {processor.py:153} INFO - Started process (PID=64944) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:11:57,664] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:11:57,666] {logging_mixin.py:115} INFO - [2022-06-07 11:11:57,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:11:57,729] {logging_mixin.py:115} INFO - [2022-06-07 11:11:57,726] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:11:57,729] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:11:57,828] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 11:12:28,597] {processor.py:153} INFO - Started process (PID=65002) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:12:28,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:12:28,602] {logging_mixin.py:115} INFO - [2022-06-07 11:12:28,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:12:28,659] {logging_mixin.py:115} INFO - [2022-06-07 11:12:28,655] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:12:28,660] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:12:28,752] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 11:12:59,166] {processor.py:153} INFO - Started process (PID=65071) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:12:59,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:12:59,170] {logging_mixin.py:115} INFO - [2022-06-07 11:12:59,170] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:12:59,230] {logging_mixin.py:115} INFO - [2022-06-07 11:12:59,227] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:12:59,233] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:12:59,328] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 11:13:30,013] {processor.py:153} INFO - Started process (PID=65140) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:13:30,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:13:30,017] {logging_mixin.py:115} INFO - [2022-06-07 11:13:30,017] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:13:30,079] {logging_mixin.py:115} INFO - [2022-06-07 11:13:30,077] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:13:30,081] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:13:30,173] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 11:14:00,923] {processor.py:153} INFO - Started process (PID=65206) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:14:00,925] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:14:00,928] {logging_mixin.py:115} INFO - [2022-06-07 11:14:00,928] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:14:00,986] {logging_mixin.py:115} INFO - [2022-06-07 11:14:00,984] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:14:00,987] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:14:01,082] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 11:14:31,980] {processor.py:153} INFO - Started process (PID=65274) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:14:31,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:14:31,986] {logging_mixin.py:115} INFO - [2022-06-07 11:14:31,986] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:14:32,046] {logging_mixin.py:115} INFO - [2022-06-07 11:14:32,042] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:14:32,048] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:14:32,138] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 11:15:02,755] {processor.py:153} INFO - Started process (PID=65332) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:15:02,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:15:02,757] {logging_mixin.py:115} INFO - [2022-06-07 11:15:02,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:15:02,805] {logging_mixin.py:115} INFO - [2022-06-07 11:15:02,803] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:15:02,806] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:15:02,907] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-07 11:15:33,394] {processor.py:153} INFO - Started process (PID=65401) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:15:33,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:15:33,398] {logging_mixin.py:115} INFO - [2022-06-07 11:15:33,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:15:33,450] {logging_mixin.py:115} INFO - [2022-06-07 11:15:33,448] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:15:33,451] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:15:33,543] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-07 11:16:04,071] {processor.py:153} INFO - Started process (PID=65465) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:16:04,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:16:04,076] {logging_mixin.py:115} INFO - [2022-06-07 11:16:04,075] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:16:04,143] {logging_mixin.py:115} INFO - [2022-06-07 11:16:04,141] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:16:04,144] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:16:04,241] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 11:16:34,301] {processor.py:153} INFO - Started process (PID=65533) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:16:34,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:16:34,304] {logging_mixin.py:115} INFO - [2022-06-07 11:16:34,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:16:34,353] {logging_mixin.py:115} INFO - [2022-06-07 11:16:34,351] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:16:34,354] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:16:34,447] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-07 11:17:04,689] {processor.py:153} INFO - Started process (PID=65601) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:17:04,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:17:04,691] {logging_mixin.py:115} INFO - [2022-06-07 11:17:04,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:17:04,737] {logging_mixin.py:115} INFO - [2022-06-07 11:17:04,735] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:17:04,738] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:17:04,845] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-07 11:17:35,004] {processor.py:153} INFO - Started process (PID=65656) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:17:35,006] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:17:35,007] {logging_mixin.py:115} INFO - [2022-06-07 11:17:35,007] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:17:35,054] {logging_mixin.py:115} INFO - [2022-06-07 11:17:35,052] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:17:35,055] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:17:35,151] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-07 11:18:05,808] {processor.py:153} INFO - Started process (PID=65728) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:18:05,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:18:05,813] {logging_mixin.py:115} INFO - [2022-06-07 11:18:05,813] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:18:05,874] {logging_mixin.py:115} INFO - [2022-06-07 11:18:05,872] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:18:05,876] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:18:05,967] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-07 11:18:36,960] {processor.py:153} INFO - Started process (PID=65794) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:18:36,961] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:18:36,962] {logging_mixin.py:115} INFO - [2022-06-07 11:18:36,962] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:18:37,007] {logging_mixin.py:115} INFO - [2022-06-07 11:18:37,004] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:18:37,008] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:18:37,104] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-07 11:19:07,809] {processor.py:153} INFO - Started process (PID=65860) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:19:07,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:19:07,813] {logging_mixin.py:115} INFO - [2022-06-07 11:19:07,813] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:19:07,868] {logging_mixin.py:115} INFO - [2022-06-07 11:19:07,866] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:19:07,870] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:19:07,964] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 11:19:38,018] {processor.py:153} INFO - Started process (PID=65930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:19:38,027] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:19:38,028] {logging_mixin.py:115} INFO - [2022-06-07 11:19:38,028] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:19:38,106] {logging_mixin.py:115} INFO - [2022-06-07 11:19:38,103] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:19:38,107] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:19:38,232] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-07 11:20:08,297] {processor.py:153} INFO - Started process (PID=65989) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:20:08,301] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:20:08,303] {logging_mixin.py:115} INFO - [2022-06-07 11:20:08,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:20:08,355] {logging_mixin.py:115} INFO - [2022-06-07 11:20:08,353] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:20:08,357] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:20:08,446] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-07 11:20:39,022] {processor.py:153} INFO - Started process (PID=66055) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:20:39,023] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:20:39,025] {logging_mixin.py:115} INFO - [2022-06-07 11:20:39,024] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:20:39,075] {logging_mixin.py:115} INFO - [2022-06-07 11:20:39,072] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:20:39,082] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:20:39,174] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-07 11:21:10,056] {processor.py:153} INFO - Started process (PID=66122) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:21:10,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:21:10,059] {logging_mixin.py:115} INFO - [2022-06-07 11:21:10,059] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:21:10,120] {logging_mixin.py:115} INFO - [2022-06-07 11:21:10,117] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:21:10,124] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:21:10,216] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 11:21:40,449] {processor.py:153} INFO - Started process (PID=66187) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:21:40,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:21:40,453] {logging_mixin.py:115} INFO - [2022-06-07 11:21:40,453] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:21:40,513] {logging_mixin.py:115} INFO - [2022-06-07 11:21:40,511] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:21:40,514] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:21:40,606] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 11:22:11,267] {processor.py:153} INFO - Started process (PID=66260) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:22:11,268] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:22:11,270] {logging_mixin.py:115} INFO - [2022-06-07 11:22:11,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:22:11,329] {logging_mixin.py:115} INFO - [2022-06-07 11:22:11,326] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:22:11,330] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:22:11,560] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.296 seconds
[2022-06-07 11:22:41,946] {processor.py:153} INFO - Started process (PID=66316) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:22:41,949] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:22:41,950] {logging_mixin.py:115} INFO - [2022-06-07 11:22:41,950] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:22:42,016] {logging_mixin.py:115} INFO - [2022-06-07 11:22:42,014] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:22:42,017] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:22:42,110] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 11:23:13,136] {processor.py:153} INFO - Started process (PID=66382) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:23:13,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:23:13,143] {logging_mixin.py:115} INFO - [2022-06-07 11:23:13,143] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:23:13,206] {logging_mixin.py:115} INFO - [2022-06-07 11:23:13,203] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:23:13,207] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:23:13,299] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 11:23:44,030] {processor.py:153} INFO - Started process (PID=66447) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:23:44,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:23:44,034] {logging_mixin.py:115} INFO - [2022-06-07 11:23:44,034] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:23:44,092] {logging_mixin.py:115} INFO - [2022-06-07 11:23:44,090] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:23:44,094] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:23:44,186] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 11:24:15,094] {processor.py:153} INFO - Started process (PID=66515) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:24:15,095] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:24:15,097] {logging_mixin.py:115} INFO - [2022-06-07 11:24:15,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:24:15,141] {logging_mixin.py:115} INFO - [2022-06-07 11:24:15,139] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:24:15,142] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:24:15,236] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-07 11:24:45,975] {processor.py:153} INFO - Started process (PID=66588) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:24:45,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:24:45,977] {logging_mixin.py:115} INFO - [2022-06-07 11:24:45,977] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:24:46,021] {logging_mixin.py:115} INFO - [2022-06-07 11:24:46,019] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:24:46,024] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:24:46,122] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-07 11:25:16,733] {processor.py:153} INFO - Started process (PID=66647) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:25:16,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:25:16,738] {logging_mixin.py:115} INFO - [2022-06-07 11:25:16,737] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:25:16,809] {logging_mixin.py:115} INFO - [2022-06-07 11:25:16,806] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:25:16,810] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:25:16,909] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-07 11:25:47,312] {processor.py:153} INFO - Started process (PID=66711) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:25:47,315] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:25:47,316] {logging_mixin.py:115} INFO - [2022-06-07 11:25:47,316] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:25:47,373] {logging_mixin.py:115} INFO - [2022-06-07 11:25:47,371] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:25:47,375] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:25:47,470] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 11:42:10,730] {processor.py:153} INFO - Started process (PID=66758) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:42:10,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:42:10,746] {logging_mixin.py:115} INFO - [2022-06-07 11:42:10,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:42:11,066] {logging_mixin.py:115} INFO - [2022-06-07 11:42:11,060] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:42:11,069] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:42:11,504] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.798 seconds
[2022-06-07 11:42:41,951] {processor.py:153} INFO - Started process (PID=66828) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:42:41,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:42:41,957] {logging_mixin.py:115} INFO - [2022-06-07 11:42:41,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:42:42,048] {logging_mixin.py:115} INFO - [2022-06-07 11:42:42,045] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:42:42,050] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:42:42,176] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-07 11:58:30,426] {processor.py:153} INFO - Started process (PID=66883) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:58:30,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:58:30,438] {logging_mixin.py:115} INFO - [2022-06-07 11:58:30,438] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:58:30,801] {logging_mixin.py:115} INFO - [2022-06-07 11:58:30,791] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:58:30,803] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:58:31,038] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.615 seconds
[2022-06-07 11:59:01,441] {processor.py:153} INFO - Started process (PID=66949) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:59:01,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 11:59:01,444] {logging_mixin.py:115} INFO - [2022-06-07 11:59:01,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:59:01,563] {logging_mixin.py:115} INFO - [2022-06-07 11:59:01,561] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 11:59:01,568] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 11:59:01,681] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-07 12:00:11,176] {processor.py:153} INFO - Started process (PID=67005) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:00:11,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:00:11,179] {logging_mixin.py:115} INFO - [2022-06-07 12:00:11,179] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:00:11,233] {logging_mixin.py:115} INFO - [2022-06-07 12:00:11,231] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:00:11,234] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:00:11,332] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 12:00:41,687] {processor.py:153} INFO - Started process (PID=67075) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:00:41,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:00:41,690] {logging_mixin.py:115} INFO - [2022-06-07 12:00:41,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:00:41,757] {logging_mixin.py:115} INFO - [2022-06-07 12:00:41,755] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:00:41,759] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:00:41,855] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-07 12:02:03,513] {processor.py:153} INFO - Started process (PID=67142) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:02:03,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:02:03,516] {logging_mixin.py:115} INFO - [2022-06-07 12:02:03,516] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:02:03,563] {logging_mixin.py:115} INFO - [2022-06-07 12:02:03,561] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:02:03,564] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:02:03,658] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-07 12:02:34,477] {processor.py:153} INFO - Started process (PID=67213) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:02:34,483] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:02:34,488] {logging_mixin.py:115} INFO - [2022-06-07 12:02:34,488] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:02:34,539] {logging_mixin.py:115} INFO - [2022-06-07 12:02:34,538] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:02:34,540] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:02:34,632] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 12:03:43,556] {processor.py:153} INFO - Started process (PID=67271) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:03:43,558] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:03:43,558] {logging_mixin.py:115} INFO - [2022-06-07 12:03:43,558] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:03:43,631] {logging_mixin.py:115} INFO - [2022-06-07 12:03:43,629] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:03:43,632] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:03:43,741] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 12:04:57,401] {processor.py:153} INFO - Started process (PID=67337) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:04:57,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:04:57,404] {logging_mixin.py:115} INFO - [2022-06-07 12:04:57,404] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:04:57,470] {logging_mixin.py:115} INFO - [2022-06-07 12:04:57,468] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:04:57,471] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:04:57,589] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-07 12:05:27,899] {processor.py:153} INFO - Started process (PID=67408) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:05:27,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:05:27,902] {logging_mixin.py:115} INFO - [2022-06-07 12:05:27,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:05:27,975] {logging_mixin.py:115} INFO - [2022-06-07 12:05:27,972] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:05:27,976] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:05:28,069] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 12:06:45,659] {processor.py:153} INFO - Started process (PID=67477) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:06:45,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:06:45,661] {logging_mixin.py:115} INFO - [2022-06-07 12:06:45,661] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:06:45,716] {logging_mixin.py:115} INFO - [2022-06-07 12:06:45,712] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:06:45,717] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:06:45,843] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 12:07:24,755] {processor.py:153} INFO - Started process (PID=67536) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:07:24,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:07:24,757] {logging_mixin.py:115} INFO - [2022-06-07 12:07:24,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:07:24,852] {logging_mixin.py:115} INFO - [2022-06-07 12:07:24,849] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:07:24,854] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:07:24,965] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-07 12:07:55,414] {processor.py:153} INFO - Started process (PID=67603) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:07:55,415] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:07:55,416] {logging_mixin.py:115} INFO - [2022-06-07 12:07:55,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:07:55,465] {logging_mixin.py:115} INFO - [2022-06-07 12:07:55,463] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:07:55,466] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:07:55,559] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-07 12:09:16,376] {processor.py:153} INFO - Started process (PID=67671) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:09:16,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:09:16,378] {logging_mixin.py:115} INFO - [2022-06-07 12:09:16,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:09:16,457] {logging_mixin.py:115} INFO - [2022-06-07 12:09:16,455] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:09:16,459] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:09:16,555] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 12:09:47,310] {processor.py:153} INFO - Started process (PID=67739) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:09:47,312] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:09:47,313] {logging_mixin.py:115} INFO - [2022-06-07 12:09:47,313] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:09:47,364] {logging_mixin.py:115} INFO - [2022-06-07 12:09:47,361] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:09:47,365] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:09:47,462] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-07 12:11:04,346] {processor.py:153} INFO - Started process (PID=67801) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:11:04,349] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:11:04,350] {logging_mixin.py:115} INFO - [2022-06-07 12:11:04,350] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:11:04,412] {logging_mixin.py:115} INFO - [2022-06-07 12:11:04,410] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:11:04,415] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:11:04,524] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 12:11:34,891] {processor.py:153} INFO - Started process (PID=67870) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:11:34,894] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:11:34,896] {logging_mixin.py:115} INFO - [2022-06-07 12:11:34,896] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:11:34,972] {logging_mixin.py:115} INFO - [2022-06-07 12:11:34,970] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:11:34,973] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:11:35,068] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 12:12:05,742] {processor.py:153} INFO - Started process (PID=67938) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:12:05,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:12:05,746] {logging_mixin.py:115} INFO - [2022-06-07 12:12:05,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:12:05,831] {logging_mixin.py:115} INFO - [2022-06-07 12:12:05,829] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:12:05,834] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:12:05,957] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-07 12:12:36,073] {processor.py:153} INFO - Started process (PID=68005) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:12:36,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:12:36,077] {logging_mixin.py:115} INFO - [2022-06-07 12:12:36,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:12:36,145] {logging_mixin.py:115} INFO - [2022-06-07 12:12:36,142] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:12:36,146] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:12:36,251] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 12:13:06,405] {processor.py:153} INFO - Started process (PID=68076) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:13:06,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:13:06,408] {logging_mixin.py:115} INFO - [2022-06-07 12:13:06,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:13:06,470] {logging_mixin.py:115} INFO - [2022-06-07 12:13:06,468] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:13:06,471] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:13:06,608] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-07 12:13:37,523] {processor.py:153} INFO - Started process (PID=68133) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:13:37,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:13:37,526] {logging_mixin.py:115} INFO - [2022-06-07 12:13:37,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:13:37,595] {logging_mixin.py:115} INFO - [2022-06-07 12:13:37,593] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:13:37,596] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:13:37,694] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 12:14:08,634] {processor.py:153} INFO - Started process (PID=68203) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:14:08,637] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:14:08,639] {logging_mixin.py:115} INFO - [2022-06-07 12:14:08,639] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:14:08,704] {logging_mixin.py:115} INFO - [2022-06-07 12:14:08,701] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:14:08,705] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:14:08,798] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 12:14:39,139] {processor.py:153} INFO - Started process (PID=68272) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:14:39,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:14:39,142] {logging_mixin.py:115} INFO - [2022-06-07 12:14:39,142] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:14:39,185] {logging_mixin.py:115} INFO - [2022-06-07 12:14:39,183] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:14:39,187] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:14:39,291] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-07 12:15:10,259] {processor.py:153} INFO - Started process (PID=68340) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:15:10,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:15:10,264] {logging_mixin.py:115} INFO - [2022-06-07 12:15:10,264] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:15:10,318] {logging_mixin.py:115} INFO - [2022-06-07 12:15:10,316] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:15:10,320] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:15:10,416] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 12:15:41,167] {processor.py:153} INFO - Started process (PID=68408) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:15:41,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:15:41,170] {logging_mixin.py:115} INFO - [2022-06-07 12:15:41,170] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:15:41,229] {logging_mixin.py:115} INFO - [2022-06-07 12:15:41,227] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:15:41,231] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:15:41,324] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 12:16:12,038] {processor.py:153} INFO - Started process (PID=68476) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:16:12,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:16:12,041] {logging_mixin.py:115} INFO - [2022-06-07 12:16:12,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:16:12,088] {logging_mixin.py:115} INFO - [2022-06-07 12:16:12,086] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:16:12,090] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:16:12,193] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-07 12:16:42,942] {processor.py:153} INFO - Started process (PID=68545) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:16:42,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:16:42,944] {logging_mixin.py:115} INFO - [2022-06-07 12:16:42,944] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:16:42,990] {logging_mixin.py:115} INFO - [2022-06-07 12:16:42,987] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:16:42,992] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:16:43,100] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 12:17:13,284] {processor.py:153} INFO - Started process (PID=68603) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:17:13,286] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:17:13,289] {logging_mixin.py:115} INFO - [2022-06-07 12:17:13,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:17:13,359] {logging_mixin.py:115} INFO - [2022-06-07 12:17:13,356] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:17:13,361] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:17:13,455] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 12:17:43,577] {processor.py:153} INFO - Started process (PID=68669) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:17:43,580] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:17:43,582] {logging_mixin.py:115} INFO - [2022-06-07 12:17:43,582] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:17:43,636] {logging_mixin.py:115} INFO - [2022-06-07 12:17:43,634] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:17:43,639] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:17:43,731] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-07 12:18:14,353] {processor.py:153} INFO - Started process (PID=68738) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:18:14,356] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:18:14,358] {logging_mixin.py:115} INFO - [2022-06-07 12:18:14,358] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:18:14,415] {logging_mixin.py:115} INFO - [2022-06-07 12:18:14,413] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:18:14,416] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:18:14,510] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 12:18:45,490] {processor.py:153} INFO - Started process (PID=68806) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:18:45,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:18:45,492] {logging_mixin.py:115} INFO - [2022-06-07 12:18:45,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:18:45,535] {logging_mixin.py:115} INFO - [2022-06-07 12:18:45,532] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:18:45,537] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:18:45,631] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-07 12:19:16,442] {processor.py:153} INFO - Started process (PID=68874) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:19:16,444] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:19:16,446] {logging_mixin.py:115} INFO - [2022-06-07 12:19:16,446] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:19:16,522] {logging_mixin.py:115} INFO - [2022-06-07 12:19:16,520] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:19:16,523] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:19:16,623] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-07 12:19:47,534] {processor.py:153} INFO - Started process (PID=68941) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:19:47,535] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:19:47,536] {logging_mixin.py:115} INFO - [2022-06-07 12:19:47,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:19:47,592] {logging_mixin.py:115} INFO - [2022-06-07 12:19:47,589] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:19:47,593] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:19:47,700] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 12:20:18,503] {processor.py:153} INFO - Started process (PID=68999) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:20:18,505] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:20:18,506] {logging_mixin.py:115} INFO - [2022-06-07 12:20:18,506] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:20:18,556] {logging_mixin.py:115} INFO - [2022-06-07 12:20:18,554] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:20:18,557] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:20:18,659] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-07 12:20:49,463] {processor.py:153} INFO - Started process (PID=69070) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:20:49,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:20:49,468] {logging_mixin.py:115} INFO - [2022-06-07 12:20:49,468] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:20:49,525] {logging_mixin.py:115} INFO - [2022-06-07 12:20:49,524] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:20:49,527] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:20:49,623] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 12:21:19,805] {processor.py:153} INFO - Started process (PID=69135) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:21:19,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:21:19,809] {logging_mixin.py:115} INFO - [2022-06-07 12:21:19,809] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:21:19,883] {logging_mixin.py:115} INFO - [2022-06-07 12:21:19,881] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:21:19,885] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:21:19,994] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-07 12:21:50,684] {processor.py:153} INFO - Started process (PID=69203) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:21:50,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:21:50,686] {logging_mixin.py:115} INFO - [2022-06-07 12:21:50,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:21:50,748] {logging_mixin.py:115} INFO - [2022-06-07 12:21:50,746] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:21:50,749] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:21:50,857] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 12:22:21,862] {processor.py:153} INFO - Started process (PID=69271) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:22:21,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:22:21,868] {logging_mixin.py:115} INFO - [2022-06-07 12:22:21,868] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:22:21,919] {logging_mixin.py:115} INFO - [2022-06-07 12:22:21,917] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:22:21,921] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:22:22,014] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-07 12:22:52,105] {processor.py:153} INFO - Started process (PID=69337) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:22:52,107] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:22:52,108] {logging_mixin.py:115} INFO - [2022-06-07 12:22:52,108] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:22:52,172] {logging_mixin.py:115} INFO - [2022-06-07 12:22:52,170] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:22:52,176] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:22:52,273] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 12:23:22,705] {processor.py:153} INFO - Started process (PID=69394) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:23:22,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:23:22,707] {logging_mixin.py:115} INFO - [2022-06-07 12:23:22,707] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:23:22,758] {logging_mixin.py:115} INFO - [2022-06-07 12:23:22,755] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:23:22,760] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:23:22,865] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 12:23:52,911] {processor.py:153} INFO - Started process (PID=69463) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:23:52,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:23:52,913] {logging_mixin.py:115} INFO - [2022-06-07 12:23:52,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:23:52,958] {logging_mixin.py:115} INFO - [2022-06-07 12:23:52,956] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:23:52,959] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:23:53,054] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-07 12:24:23,470] {processor.py:153} INFO - Started process (PID=69531) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:24:23,472] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:24:23,473] {logging_mixin.py:115} INFO - [2022-06-07 12:24:23,473] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:24:23,549] {logging_mixin.py:115} INFO - [2022-06-07 12:24:23,546] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:24:23,551] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:24:23,667] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 12:24:53,755] {processor.py:153} INFO - Started process (PID=69598) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:24:53,758] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:24:53,760] {logging_mixin.py:115} INFO - [2022-06-07 12:24:53,760] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:24:53,820] {logging_mixin.py:115} INFO - [2022-06-07 12:24:53,818] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:24:53,823] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:24:53,930] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 12:25:24,751] {processor.py:153} INFO - Started process (PID=69666) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:25:24,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:25:24,756] {logging_mixin.py:115} INFO - [2022-06-07 12:25:24,756] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:25:24,814] {logging_mixin.py:115} INFO - [2022-06-07 12:25:24,811] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:25:24,815] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:25:24,909] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 12:25:55,532] {processor.py:153} INFO - Started process (PID=69724) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:25:55,534] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:25:55,537] {logging_mixin.py:115} INFO - [2022-06-07 12:25:55,537] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:25:55,593] {logging_mixin.py:115} INFO - [2022-06-07 12:25:55,590] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:25:55,594] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:25:55,703] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 12:26:26,730] {processor.py:153} INFO - Started process (PID=69793) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:26:26,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:26:26,732] {logging_mixin.py:115} INFO - [2022-06-07 12:26:26,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:26:26,799] {logging_mixin.py:115} INFO - [2022-06-07 12:26:26,790] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:26:26,799] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:26:26,904] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 12:27:13,581] {processor.py:153} INFO - Started process (PID=69842) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:27:13,583] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:27:13,584] {logging_mixin.py:115} INFO - [2022-06-07 12:27:13,584] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:27:13,650] {logging_mixin.py:115} INFO - [2022-06-07 12:27:13,648] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:27:13,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:27:13,767] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-07 12:27:43,838] {processor.py:153} INFO - Started process (PID=69910) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:27:43,840] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:27:43,841] {logging_mixin.py:115} INFO - [2022-06-07 12:27:43,841] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:27:43,889] {logging_mixin.py:115} INFO - [2022-06-07 12:27:43,887] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:27:43,890] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:27:43,982] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-07 12:29:03,944] {processor.py:153} INFO - Started process (PID=69977) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:29:03,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:29:03,949] {logging_mixin.py:115} INFO - [2022-06-07 12:29:03,949] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:29:04,113] {logging_mixin.py:115} INFO - [2022-06-07 12:29:04,103] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:29:04,117] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:29:04,219] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.284 seconds
[2022-06-07 12:29:34,367] {processor.py:153} INFO - Started process (PID=70035) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:29:34,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:29:34,370] {logging_mixin.py:115} INFO - [2022-06-07 12:29:34,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:29:34,431] {logging_mixin.py:115} INFO - [2022-06-07 12:29:34,428] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:29:34,432] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:29:34,547] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 12:30:05,052] {processor.py:153} INFO - Started process (PID=70102) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:30:05,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:30:05,057] {logging_mixin.py:115} INFO - [2022-06-07 12:30:05,057] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:30:05,153] {logging_mixin.py:115} INFO - [2022-06-07 12:30:05,151] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:30:05,154] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:30:05,278] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-07 12:30:35,645] {processor.py:153} INFO - Started process (PID=70170) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:30:35,647] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:30:35,648] {logging_mixin.py:115} INFO - [2022-06-07 12:30:35,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:30:35,711] {logging_mixin.py:115} INFO - [2022-06-07 12:30:35,709] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:30:35,712] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:30:35,814] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 12:31:46,532] {processor.py:153} INFO - Started process (PID=70239) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:31:46,534] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:31:46,536] {logging_mixin.py:115} INFO - [2022-06-07 12:31:46,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:31:46,628] {logging_mixin.py:115} INFO - [2022-06-07 12:31:46,626] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:31:46,631] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:31:46,727] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-07 12:32:16,857] {processor.py:153} INFO - Started process (PID=70296) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:32:16,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:32:16,859] {logging_mixin.py:115} INFO - [2022-06-07 12:32:16,859] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:32:16,913] {logging_mixin.py:115} INFO - [2022-06-07 12:32:16,911] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:32:16,914] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:32:17,015] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 12:33:36,425] {processor.py:153} INFO - Started process (PID=70363) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:33:36,427] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:33:36,429] {logging_mixin.py:115} INFO - [2022-06-07 12:33:36,429] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:33:36,493] {logging_mixin.py:115} INFO - [2022-06-07 12:33:36,491] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:33:36,496] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:33:36,587] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-07 12:34:59,043] {processor.py:153} INFO - Started process (PID=70431) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:34:59,045] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:34:59,047] {logging_mixin.py:115} INFO - [2022-06-07 12:34:59,047] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:34:59,135] {logging_mixin.py:115} INFO - [2022-06-07 12:34:59,132] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:34:59,137] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:34:59,258] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-07 12:35:29,531] {processor.py:153} INFO - Started process (PID=70499) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:35:29,533] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:35:29,534] {logging_mixin.py:115} INFO - [2022-06-07 12:35:29,534] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:35:29,604] {logging_mixin.py:115} INFO - [2022-06-07 12:35:29,602] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:35:29,607] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:35:29,713] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 12:36:38,675] {processor.py:153} INFO - Started process (PID=70556) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:36:38,677] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:36:38,678] {logging_mixin.py:115} INFO - [2022-06-07 12:36:38,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:36:38,738] {logging_mixin.py:115} INFO - [2022-06-07 12:36:38,736] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:36:38,739] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:36:38,835] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 12:37:09,631] {processor.py:153} INFO - Started process (PID=70622) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:37:09,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:37:09,634] {logging_mixin.py:115} INFO - [2022-06-07 12:37:09,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:37:09,682] {logging_mixin.py:115} INFO - [2022-06-07 12:37:09,680] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:37:09,683] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:37:09,778] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-07 12:38:21,930] {processor.py:153} INFO - Started process (PID=70685) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:38:21,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:38:21,933] {logging_mixin.py:115} INFO - [2022-06-07 12:38:21,933] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:38:22,005] {logging_mixin.py:115} INFO - [2022-06-07 12:38:22,003] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:38:22,006] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:38:22,104] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 12:39:32,590] {processor.py:153} INFO - Started process (PID=70752) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:39:32,592] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:39:32,594] {logging_mixin.py:115} INFO - [2022-06-07 12:39:32,594] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:39:32,659] {logging_mixin.py:115} INFO - [2022-06-07 12:39:32,656] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:39:32,660] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:39:32,766] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 12:40:03,669] {processor.py:153} INFO - Started process (PID=70825) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:40:03,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:40:03,673] {logging_mixin.py:115} INFO - [2022-06-07 12:40:03,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:40:03,739] {logging_mixin.py:115} INFO - [2022-06-07 12:40:03,737] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:40:03,740] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:40:03,835] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 12:41:23,501] {processor.py:153} INFO - Started process (PID=70884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:41:23,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:41:23,504] {logging_mixin.py:115} INFO - [2022-06-07 12:41:23,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:41:23,559] {logging_mixin.py:115} INFO - [2022-06-07 12:41:23,556] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:41:23,560] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:41:23,656] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 12:41:54,027] {processor.py:153} INFO - Started process (PID=70948) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:41:54,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:41:54,031] {logging_mixin.py:115} INFO - [2022-06-07 12:41:54,031] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:41:54,118] {logging_mixin.py:115} INFO - [2022-06-07 12:41:54,116] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:41:54,120] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:41:54,222] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-07 12:42:24,315] {processor.py:153} INFO - Started process (PID=71018) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:42:24,316] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:42:24,317] {logging_mixin.py:115} INFO - [2022-06-07 12:42:24,317] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:42:24,362] {logging_mixin.py:115} INFO - [2022-06-07 12:42:24,359] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:42:24,363] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:42:24,456] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-07 12:43:41,057] {processor.py:153} INFO - Started process (PID=71075) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:43:41,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:43:41,059] {logging_mixin.py:115} INFO - [2022-06-07 12:43:41,059] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:43:41,138] {logging_mixin.py:115} INFO - [2022-06-07 12:43:41,135] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:43:41,139] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:43:41,241] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 12:45:06,111] {processor.py:153} INFO - Started process (PID=71141) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:45:06,113] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:45:06,114] {logging_mixin.py:115} INFO - [2022-06-07 12:45:06,114] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:45:06,170] {logging_mixin.py:115} INFO - [2022-06-07 12:45:06,167] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:45:06,171] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:45:06,287] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 12:45:37,093] {processor.py:153} INFO - Started process (PID=71211) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:45:37,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:45:37,096] {logging_mixin.py:115} INFO - [2022-06-07 12:45:37,096] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:45:37,155] {logging_mixin.py:115} INFO - [2022-06-07 12:45:37,153] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:45:37,157] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:45:37,251] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 12:46:54,938] {processor.py:153} INFO - Started process (PID=71279) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:46:54,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:46:54,941] {logging_mixin.py:115} INFO - [2022-06-07 12:46:54,941] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:46:54,991] {logging_mixin.py:115} INFO - [2022-06-07 12:46:54,989] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:46:54,992] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:46:55,088] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-07 12:47:25,785] {processor.py:153} INFO - Started process (PID=71337) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:47:25,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:47:25,790] {logging_mixin.py:115} INFO - [2022-06-07 12:47:25,789] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:47:25,849] {logging_mixin.py:115} INFO - [2022-06-07 12:47:25,847] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:47:25,851] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:47:25,957] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 12:48:47,120] {processor.py:153} INFO - Started process (PID=71404) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:48:47,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:48:47,123] {logging_mixin.py:115} INFO - [2022-06-07 12:48:47,123] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:48:47,215] {logging_mixin.py:115} INFO - [2022-06-07 12:48:47,211] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:48:47,216] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:48:47,314] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 12:50:10,170] {processor.py:153} INFO - Started process (PID=71472) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:50:10,171] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:50:10,172] {logging_mixin.py:115} INFO - [2022-06-07 12:50:10,172] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:50:10,215] {logging_mixin.py:115} INFO - [2022-06-07 12:50:10,213] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:50:10,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:50:10,311] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-07 12:50:41,235] {processor.py:153} INFO - Started process (PID=71539) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:50:41,238] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:50:41,240] {logging_mixin.py:115} INFO - [2022-06-07 12:50:41,239] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:50:41,313] {logging_mixin.py:115} INFO - [2022-06-07 12:50:41,310] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:50:41,314] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:50:41,412] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 12:52:05,781] {processor.py:153} INFO - Started process (PID=71595) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:52:05,782] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:52:05,784] {logging_mixin.py:115} INFO - [2022-06-07 12:52:05,784] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:52:05,829] {logging_mixin.py:115} INFO - [2022-06-07 12:52:05,827] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:52:05,831] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:52:05,926] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-07 12:52:35,962] {processor.py:153} INFO - Started process (PID=71663) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:52:35,964] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:52:35,965] {logging_mixin.py:115} INFO - [2022-06-07 12:52:35,965] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:52:36,026] {logging_mixin.py:115} INFO - [2022-06-07 12:52:36,015] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:52:36,028] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:52:36,148] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-07 12:53:48,901] {processor.py:153} INFO - Started process (PID=71730) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:53:48,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:53:48,906] {logging_mixin.py:115} INFO - [2022-06-07 12:53:48,906] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:53:49,013] {logging_mixin.py:115} INFO - [2022-06-07 12:53:49,011] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:53:49,015] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:53:49,115] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-07 12:54:19,920] {processor.py:153} INFO - Started process (PID=71801) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:54:19,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:54:19,922] {logging_mixin.py:115} INFO - [2022-06-07 12:54:19,922] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:54:19,968] {logging_mixin.py:115} INFO - [2022-06-07 12:54:19,966] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:54:19,970] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:54:20,064] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-07 12:55:36,302] {processor.py:153} INFO - Started process (PID=71860) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:55:36,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:55:36,306] {logging_mixin.py:115} INFO - [2022-06-07 12:55:36,306] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:55:36,414] {logging_mixin.py:115} INFO - [2022-06-07 12:55:36,408] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:55:36,416] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:55:36,536] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-07 12:56:06,653] {processor.py:153} INFO - Started process (PID=71928) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:56:06,658] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:56:06,667] {logging_mixin.py:115} INFO - [2022-06-07 12:56:06,667] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:56:07,296] {logging_mixin.py:115} INFO - [2022-06-07 12:56:07,287] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:56:07,310] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:56:07,471] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.828 seconds
[2022-06-07 12:56:37,636] {processor.py:153} INFO - Started process (PID=71995) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:56:37,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:56:37,647] {logging_mixin.py:115} INFO - [2022-06-07 12:56:37,647] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:56:37,783] {logging_mixin.py:115} INFO - [2022-06-07 12:56:37,776] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:56:37,785] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:56:37,936] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.310 seconds
[2022-06-07 12:57:08,242] {processor.py:153} INFO - Started process (PID=72052) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:57:08,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:57:08,275] {logging_mixin.py:115} INFO - [2022-06-07 12:57:08,275] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:57:08,458] {logging_mixin.py:115} INFO - [2022-06-07 12:57:08,450] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:57:08,479] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:57:08,803] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.587 seconds
[2022-06-07 12:57:39,434] {processor.py:153} INFO - Started process (PID=72119) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:57:39,437] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:57:39,445] {logging_mixin.py:115} INFO - [2022-06-07 12:57:39,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:57:39,624] {logging_mixin.py:115} INFO - [2022-06-07 12:57:39,618] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:57:39,628] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:57:39,809] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.380 seconds
[2022-06-07 12:58:09,967] {processor.py:153} INFO - Started process (PID=72175) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:58:09,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:58:09,979] {logging_mixin.py:115} INFO - [2022-06-07 12:58:09,978] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:58:10,179] {logging_mixin.py:115} INFO - [2022-06-07 12:58:10,165] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:58:10,184] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:58:10,648] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.698 seconds
[2022-06-07 12:58:41,419] {processor.py:153} INFO - Started process (PID=72242) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:58:41,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:58:41,426] {logging_mixin.py:115} INFO - [2022-06-07 12:58:41,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:58:41,613] {logging_mixin.py:115} INFO - [2022-06-07 12:58:41,607] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:58:41,623] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:58:41,853] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.462 seconds
[2022-06-07 12:59:12,821] {processor.py:153} INFO - Started process (PID=72297) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:59:12,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:59:12,826] {logging_mixin.py:115} INFO - [2022-06-07 12:59:12,826] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:59:12,997] {logging_mixin.py:115} INFO - [2022-06-07 12:59:12,989] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:59:13,019] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:59:13,288] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.474 seconds
[2022-06-07 12:59:43,664] {processor.py:153} INFO - Started process (PID=72366) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:59:43,669] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 12:59:43,673] {logging_mixin.py:115} INFO - [2022-06-07 12:59:43,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:59:43,924] {logging_mixin.py:115} INFO - [2022-06-07 12:59:43,916] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 12:59:43,927] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 12:59:44,299] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.652 seconds
[2022-06-07 13:00:14,899] {processor.py:153} INFO - Started process (PID=72423) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:00:14,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:00:14,902] {logging_mixin.py:115} INFO - [2022-06-07 13:00:14,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:00:15,008] {logging_mixin.py:115} INFO - [2022-06-07 13:00:15,004] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:00:15,013] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:00:15,165] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.278 seconds
[2022-06-07 13:00:45,305] {processor.py:153} INFO - Started process (PID=72489) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:00:45,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:00:45,312] {logging_mixin.py:115} INFO - [2022-06-07 13:00:45,311] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:00:45,406] {logging_mixin.py:115} INFO - [2022-06-07 13:00:45,403] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:00:45,408] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:00:45,533] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-07 13:01:16,417] {processor.py:153} INFO - Started process (PID=72559) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:01:16,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:01:16,423] {logging_mixin.py:115} INFO - [2022-06-07 13:01:16,423] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:01:16,505] {logging_mixin.py:115} INFO - [2022-06-07 13:01:16,503] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:01:16,508] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:01:16,614] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-07 13:01:46,714] {processor.py:153} INFO - Started process (PID=72617) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:01:46,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:01:46,720] {logging_mixin.py:115} INFO - [2022-06-07 13:01:46,719] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:01:46,797] {logging_mixin.py:115} INFO - [2022-06-07 13:01:46,795] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:01:46,799] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:01:46,897] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-07 13:02:17,375] {processor.py:153} INFO - Started process (PID=72685) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:02:17,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:02:17,378] {logging_mixin.py:115} INFO - [2022-06-07 13:02:17,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:02:17,467] {logging_mixin.py:115} INFO - [2022-06-07 13:02:17,464] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:02:17,468] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:02:17,592] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-07 13:02:47,739] {processor.py:153} INFO - Started process (PID=72752) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:02:47,741] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:02:47,742] {logging_mixin.py:115} INFO - [2022-06-07 13:02:47,742] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:02:47,851] {logging_mixin.py:115} INFO - [2022-06-07 13:02:47,848] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:02:47,854] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:02:47,997] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.261 seconds
[2022-06-07 13:03:18,127] {processor.py:153} INFO - Started process (PID=72820) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:03:18,130] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:03:18,131] {logging_mixin.py:115} INFO - [2022-06-07 13:03:18,131] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:03:18,228] {logging_mixin.py:115} INFO - [2022-06-07 13:03:18,226] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:03:18,229] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:03:18,350] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-07 13:03:48,531] {processor.py:153} INFO - Started process (PID=72888) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:03:48,533] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:03:48,535] {logging_mixin.py:115} INFO - [2022-06-07 13:03:48,535] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:03:48,639] {logging_mixin.py:115} INFO - [2022-06-07 13:03:48,636] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:03:48,640] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:03:48,747] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-07 13:04:18,874] {processor.py:153} INFO - Started process (PID=72948) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:04:18,877] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:04:18,880] {logging_mixin.py:115} INFO - [2022-06-07 13:04:18,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:04:18,952] {logging_mixin.py:115} INFO - [2022-06-07 13:04:18,950] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:04:18,953] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:04:19,049] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 13:04:49,422] {processor.py:153} INFO - Started process (PID=73014) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:04:49,424] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:04:49,425] {logging_mixin.py:115} INFO - [2022-06-07 13:04:49,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:04:49,470] {logging_mixin.py:115} INFO - [2022-06-07 13:04:49,468] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:04:49,473] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:04:49,567] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-07 13:05:20,525] {processor.py:153} INFO - Started process (PID=73081) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:05:20,527] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:05:20,528] {logging_mixin.py:115} INFO - [2022-06-07 13:05:20,528] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:05:20,598] {logging_mixin.py:115} INFO - [2022-06-07 13:05:20,595] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:05:20,599] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:05:20,718] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-07 13:05:51,073] {processor.py:153} INFO - Started process (PID=73149) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:05:51,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:05:51,076] {logging_mixin.py:115} INFO - [2022-06-07 13:05:51,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:05:51,137] {logging_mixin.py:115} INFO - [2022-06-07 13:05:51,135] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:05:51,139] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:05:51,236] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 13:06:21,464] {processor.py:153} INFO - Started process (PID=73217) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:06:21,468] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:06:21,471] {logging_mixin.py:115} INFO - [2022-06-07 13:06:21,470] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:06:21,537] {logging_mixin.py:115} INFO - [2022-06-07 13:06:21,532] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:06:21,538] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:06:21,642] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 13:06:51,759] {processor.py:153} INFO - Started process (PID=73276) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:06:51,762] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:06:51,764] {logging_mixin.py:115} INFO - [2022-06-07 13:06:51,764] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:06:51,853] {logging_mixin.py:115} INFO - [2022-06-07 13:06:51,850] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:06:51,854] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:06:51,965] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-07 13:07:22,140] {processor.py:153} INFO - Started process (PID=73343) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:07:22,142] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:07:22,144] {logging_mixin.py:115} INFO - [2022-06-07 13:07:22,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:07:22,199] {logging_mixin.py:115} INFO - [2022-06-07 13:07:22,197] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:07:22,201] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:07:22,302] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 13:07:52,497] {processor.py:153} INFO - Started process (PID=73415) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:07:52,501] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:07:52,503] {logging_mixin.py:115} INFO - [2022-06-07 13:07:52,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:07:52,556] {logging_mixin.py:115} INFO - [2022-06-07 13:07:52,554] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:07:52,558] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:07:52,651] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 13:08:22,689] {processor.py:153} INFO - Started process (PID=73485) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:08:22,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:08:22,692] {logging_mixin.py:115} INFO - [2022-06-07 13:08:22,691] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:08:22,752] {logging_mixin.py:115} INFO - [2022-06-07 13:08:22,750] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:08:22,753] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:08:22,850] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 13:08:53,188] {processor.py:153} INFO - Started process (PID=73551) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:08:53,190] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:08:53,192] {logging_mixin.py:115} INFO - [2022-06-07 13:08:53,192] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:08:53,242] {logging_mixin.py:115} INFO - [2022-06-07 13:08:53,240] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:08:53,244] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:08:53,341] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-07 13:09:23,589] {processor.py:153} INFO - Started process (PID=73607) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:09:23,590] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:09:23,591] {logging_mixin.py:115} INFO - [2022-06-07 13:09:23,591] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:09:23,655] {logging_mixin.py:115} INFO - [2022-06-07 13:09:23,651] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:09:23,657] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:09:23,763] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 13:09:54,558] {processor.py:153} INFO - Started process (PID=73674) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:09:54,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:09:54,562] {logging_mixin.py:115} INFO - [2022-06-07 13:09:54,562] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:09:54,622] {logging_mixin.py:115} INFO - [2022-06-07 13:09:54,620] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:09:54,623] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:09:54,720] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 13:10:24,819] {processor.py:153} INFO - Started process (PID=73746) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:10:24,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:10:24,825] {logging_mixin.py:115} INFO - [2022-06-07 13:10:24,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:10:24,894] {logging_mixin.py:115} INFO - [2022-06-07 13:10:24,890] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:10:24,896] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:10:25,012] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 13:10:55,374] {processor.py:153} INFO - Started process (PID=73817) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:10:55,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:10:55,381] {logging_mixin.py:115} INFO - [2022-06-07 13:10:55,381] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:10:55,457] {logging_mixin.py:115} INFO - [2022-06-07 13:10:55,455] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:10:55,458] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:10:55,555] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 13:11:26,322] {processor.py:153} INFO - Started process (PID=73888) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:11:26,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:11:26,327] {logging_mixin.py:115} INFO - [2022-06-07 13:11:26,327] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:11:26,413] {logging_mixin.py:115} INFO - [2022-06-07 13:11:26,410] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:11:26,415] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:11:26,510] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 13:11:56,806] {processor.py:153} INFO - Started process (PID=73946) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:11:56,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:11:56,810] {logging_mixin.py:115} INFO - [2022-06-07 13:11:56,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:11:56,874] {logging_mixin.py:115} INFO - [2022-06-07 13:11:56,872] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:11:56,876] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:11:56,972] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 13:12:27,246] {processor.py:153} INFO - Started process (PID=74015) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:12:27,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:12:27,251] {logging_mixin.py:115} INFO - [2022-06-07 13:12:27,251] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:12:27,317] {logging_mixin.py:115} INFO - [2022-06-07 13:12:27,315] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:12:27,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:12:27,417] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 13:12:57,472] {processor.py:153} INFO - Started process (PID=74084) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:12:57,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:12:57,475] {logging_mixin.py:115} INFO - [2022-06-07 13:12:57,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:12:57,548] {logging_mixin.py:115} INFO - [2022-06-07 13:12:57,546] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:12:57,549] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:12:57,663] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-07 13:13:27,994] {processor.py:153} INFO - Started process (PID=74151) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:13:27,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:13:27,998] {logging_mixin.py:115} INFO - [2022-06-07 13:13:27,997] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:13:28,060] {logging_mixin.py:115} INFO - [2022-06-07 13:13:28,058] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:13:28,062] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:13:28,160] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 13:13:58,253] {processor.py:153} INFO - Started process (PID=74217) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:13:58,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:13:58,256] {logging_mixin.py:115} INFO - [2022-06-07 13:13:58,256] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:13:58,306] {logging_mixin.py:115} INFO - [2022-06-07 13:13:58,303] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:13:58,307] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:13:58,428] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 13:14:29,389] {processor.py:153} INFO - Started process (PID=74276) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:14:29,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:14:29,394] {logging_mixin.py:115} INFO - [2022-06-07 13:14:29,393] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:14:29,460] {logging_mixin.py:115} INFO - [2022-06-07 13:14:29,457] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:14:29,462] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:14:29,559] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 13:14:59,719] {processor.py:153} INFO - Started process (PID=74342) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:14:59,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:14:59,722] {logging_mixin.py:115} INFO - [2022-06-07 13:14:59,721] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:14:59,780] {logging_mixin.py:115} INFO - [2022-06-07 13:14:59,777] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:14:59,781] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:14:59,876] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-07 13:15:29,943] {processor.py:153} INFO - Started process (PID=74411) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:15:29,945] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:15:29,946] {logging_mixin.py:115} INFO - [2022-06-07 13:15:29,946] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:15:30,008] {logging_mixin.py:115} INFO - [2022-06-07 13:15:30,005] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:15:30,010] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:15:30,117] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 13:16:00,311] {processor.py:153} INFO - Started process (PID=74477) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:16:00,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:16:00,315] {logging_mixin.py:115} INFO - [2022-06-07 13:16:00,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:16:00,388] {logging_mixin.py:115} INFO - [2022-06-07 13:16:00,386] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:16:00,390] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:16:00,485] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 13:16:30,976] {processor.py:153} INFO - Started process (PID=74542) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:16:30,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:16:30,980] {logging_mixin.py:115} INFO - [2022-06-07 13:16:30,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:16:31,040] {logging_mixin.py:115} INFO - [2022-06-07 13:16:31,037] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:16:31,042] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:16:31,150] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 13:17:01,552] {processor.py:153} INFO - Started process (PID=74602) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:17:01,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:17:01,556] {logging_mixin.py:115} INFO - [2022-06-07 13:17:01,555] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:17:01,626] {logging_mixin.py:115} INFO - [2022-06-07 13:17:01,623] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:17:01,628] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:17:01,723] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-07 13:17:31,881] {processor.py:153} INFO - Started process (PID=74670) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:17:31,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:17:31,885] {logging_mixin.py:115} INFO - [2022-06-07 13:17:31,885] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:17:31,947] {logging_mixin.py:115} INFO - [2022-06-07 13:17:31,944] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:17:31,948] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:17:32,045] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 13:18:02,388] {processor.py:153} INFO - Started process (PID=74738) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:18:02,390] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:18:02,392] {logging_mixin.py:115} INFO - [2022-06-07 13:18:02,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:18:02,486] {logging_mixin.py:115} INFO - [2022-06-07 13:18:02,483] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:18:02,489] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:18:02,615] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-07 13:18:32,765] {processor.py:153} INFO - Started process (PID=74807) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:18:32,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:18:32,770] {logging_mixin.py:115} INFO - [2022-06-07 13:18:32,770] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:18:32,830] {logging_mixin.py:115} INFO - [2022-06-07 13:18:32,827] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:18:32,830] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:18:32,938] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 13:19:03,186] {processor.py:153} INFO - Started process (PID=74866) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:19:03,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:19:03,189] {logging_mixin.py:115} INFO - [2022-06-07 13:19:03,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:19:03,254] {logging_mixin.py:115} INFO - [2022-06-07 13:19:03,251] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:19:03,256] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:19:03,368] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 13:19:33,635] {processor.py:153} INFO - Started process (PID=74934) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:19:33,638] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:19:33,640] {logging_mixin.py:115} INFO - [2022-06-07 13:19:33,639] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:19:33,710] {logging_mixin.py:115} INFO - [2022-06-07 13:19:33,707] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:19:33,711] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:19:33,810] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 13:20:04,698] {processor.py:153} INFO - Started process (PID=75003) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:20:04,702] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:20:04,704] {logging_mixin.py:115} INFO - [2022-06-07 13:20:04,704] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:20:04,786] {logging_mixin.py:115} INFO - [2022-06-07 13:20:04,784] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:20:04,789] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:20:04,885] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-07 13:20:35,007] {processor.py:153} INFO - Started process (PID=75071) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:20:35,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:20:35,012] {logging_mixin.py:115} INFO - [2022-06-07 13:20:35,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:20:35,074] {logging_mixin.py:115} INFO - [2022-06-07 13:20:35,072] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:20:35,076] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:20:35,170] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 13:21:05,449] {processor.py:153} INFO - Started process (PID=75138) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:21:05,452] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:21:05,453] {logging_mixin.py:115} INFO - [2022-06-07 13:21:05,453] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:21:05,522] {logging_mixin.py:115} INFO - [2022-06-07 13:21:05,519] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:21:05,523] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:21:05,636] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-07 13:21:35,915] {processor.py:153} INFO - Started process (PID=75207) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:21:35,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:21:35,918] {logging_mixin.py:115} INFO - [2022-06-07 13:21:35,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:21:36,009] {logging_mixin.py:115} INFO - [2022-06-07 13:21:36,006] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:21:36,010] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:21:36,127] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-07 13:22:06,238] {processor.py:153} INFO - Started process (PID=75268) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:22:06,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:22:06,242] {logging_mixin.py:115} INFO - [2022-06-07 13:22:06,242] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:22:06,310] {logging_mixin.py:115} INFO - [2022-06-07 13:22:06,307] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:22:06,311] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:22:06,409] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 13:22:36,634] {processor.py:153} INFO - Started process (PID=75337) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:22:36,637] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:22:36,638] {logging_mixin.py:115} INFO - [2022-06-07 13:22:36,638] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:22:36,728] {logging_mixin.py:115} INFO - [2022-06-07 13:22:36,725] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:22:36,730] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:22:36,830] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.205 seconds
[2022-06-07 13:23:07,489] {processor.py:153} INFO - Started process (PID=75403) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:23:07,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:23:07,492] {logging_mixin.py:115} INFO - [2022-06-07 13:23:07,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:23:07,566] {logging_mixin.py:115} INFO - [2022-06-07 13:23:07,562] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:23:07,567] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:23:07,822] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.336 seconds
[2022-06-07 13:23:37,892] {processor.py:153} INFO - Started process (PID=75470) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:23:37,894] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:23:37,895] {logging_mixin.py:115} INFO - [2022-06-07 13:23:37,895] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:23:37,971] {logging_mixin.py:115} INFO - [2022-06-07 13:23:37,968] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:23:37,974] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:23:38,078] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-07 13:24:08,127] {processor.py:153} INFO - Started process (PID=75527) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:24:08,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:24:08,130] {logging_mixin.py:115} INFO - [2022-06-07 13:24:08,130] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:24:08,196] {logging_mixin.py:115} INFO - [2022-06-07 13:24:08,193] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:24:08,198] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:24:08,301] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 13:24:38,426] {processor.py:153} INFO - Started process (PID=75593) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:24:38,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:24:38,430] {logging_mixin.py:115} INFO - [2022-06-07 13:24:38,430] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:24:38,487] {logging_mixin.py:115} INFO - [2022-06-07 13:24:38,485] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:24:38,489] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:24:38,594] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-07 13:25:08,808] {processor.py:153} INFO - Started process (PID=75661) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:25:08,810] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:25:08,811] {logging_mixin.py:115} INFO - [2022-06-07 13:25:08,811] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:25:08,890] {logging_mixin.py:115} INFO - [2022-06-07 13:25:08,886] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:25:08,891] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:25:09,002] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-07 13:25:39,218] {processor.py:153} INFO - Started process (PID=75731) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:25:39,219] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:25:39,220] {logging_mixin.py:115} INFO - [2022-06-07 13:25:39,220] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:25:39,284] {logging_mixin.py:115} INFO - [2022-06-07 13:25:39,279] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:25:39,286] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:25:39,384] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 13:26:09,883] {processor.py:153} INFO - Started process (PID=75796) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:26:09,885] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:26:09,886] {logging_mixin.py:115} INFO - [2022-06-07 13:26:09,886] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:26:09,937] {logging_mixin.py:115} INFO - [2022-06-07 13:26:09,933] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:26:09,937] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:26:10,032] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-07 13:26:40,178] {processor.py:153} INFO - Started process (PID=75854) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:26:40,180] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:26:40,181] {logging_mixin.py:115} INFO - [2022-06-07 13:26:40,181] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:26:40,242] {logging_mixin.py:115} INFO - [2022-06-07 13:26:40,239] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:26:40,244] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:26:40,365] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-07 13:27:10,483] {processor.py:153} INFO - Started process (PID=75922) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:27:10,486] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:27:10,489] {logging_mixin.py:115} INFO - [2022-06-07 13:27:10,489] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:27:10,549] {logging_mixin.py:115} INFO - [2022-06-07 13:27:10,547] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:27:10,550] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:27:10,646] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 13:27:40,769] {processor.py:153} INFO - Started process (PID=75989) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:27:40,771] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:27:40,772] {logging_mixin.py:115} INFO - [2022-06-07 13:27:40,772] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:27:40,856] {logging_mixin.py:115} INFO - [2022-06-07 13:27:40,852] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:27:40,859] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:27:40,977] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-07 13:28:11,645] {processor.py:153} INFO - Started process (PID=76058) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:28:11,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:28:11,647] {logging_mixin.py:115} INFO - [2022-06-07 13:28:11,647] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:28:11,694] {logging_mixin.py:115} INFO - [2022-06-07 13:28:11,692] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:28:11,695] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:28:11,788] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-07 13:28:42,648] {processor.py:153} INFO - Started process (PID=76125) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:28:42,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:28:42,654] {logging_mixin.py:115} INFO - [2022-06-07 13:28:42,654] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:28:42,727] {logging_mixin.py:115} INFO - [2022-06-07 13:28:42,725] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:28:42,729] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:28:42,825] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-07 13:29:13,584] {processor.py:153} INFO - Started process (PID=76192) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:29:13,587] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:29:13,589] {logging_mixin.py:115} INFO - [2022-06-07 13:29:13,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:29:13,665] {logging_mixin.py:115} INFO - [2022-06-07 13:29:13,662] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:29:13,667] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:29:13,761] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-07 13:29:44,300] {processor.py:153} INFO - Started process (PID=76249) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:29:44,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:29:44,303] {logging_mixin.py:115} INFO - [2022-06-07 13:29:44,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:29:44,353] {logging_mixin.py:115} INFO - [2022-06-07 13:29:44,351] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:29:44,355] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:29:44,456] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 13:30:15,104] {processor.py:153} INFO - Started process (PID=76319) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:30:15,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:30:15,106] {logging_mixin.py:115} INFO - [2022-06-07 13:30:15,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:30:15,170] {logging_mixin.py:115} INFO - [2022-06-07 13:30:15,167] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:30:15,171] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:30:15,268] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-07 13:30:46,014] {processor.py:153} INFO - Started process (PID=76388) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:30:46,018] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:30:46,020] {logging_mixin.py:115} INFO - [2022-06-07 13:30:46,019] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:30:46,113] {logging_mixin.py:115} INFO - [2022-06-07 13:30:46,111] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:30:46,115] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:30:46,240] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-07 13:31:16,458] {processor.py:153} INFO - Started process (PID=76455) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:31:16,461] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:31:16,464] {logging_mixin.py:115} INFO - [2022-06-07 13:31:16,463] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:31:16,535] {logging_mixin.py:115} INFO - [2022-06-07 13:31:16,533] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:31:16,538] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:31:16,648] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 13:31:47,207] {processor.py:153} INFO - Started process (PID=76523) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:31:47,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:31:47,210] {logging_mixin.py:115} INFO - [2022-06-07 13:31:47,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:31:47,262] {logging_mixin.py:115} INFO - [2022-06-07 13:31:47,259] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:31:47,262] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:31:47,359] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-07 13:32:18,001] {processor.py:153} INFO - Started process (PID=76591) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:32:18,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:32:18,007] {logging_mixin.py:115} INFO - [2022-06-07 13:32:18,007] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:32:18,087] {logging_mixin.py:115} INFO - [2022-06-07 13:32:18,084] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:32:18,089] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:32:18,188] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 13:32:48,651] {processor.py:153} INFO - Started process (PID=76647) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:32:48,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:32:48,657] {logging_mixin.py:115} INFO - [2022-06-07 13:32:48,656] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:32:48,734] {logging_mixin.py:115} INFO - [2022-06-07 13:32:48,730] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:32:48,736] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:32:48,857] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-07 13:33:18,929] {processor.py:153} INFO - Started process (PID=76717) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:33:18,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:33:18,933] {logging_mixin.py:115} INFO - [2022-06-07 13:33:18,933] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:33:19,011] {logging_mixin.py:115} INFO - [2022-06-07 13:33:19,009] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:33:19,024] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:33:19,138] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-07 13:33:49,383] {processor.py:153} INFO - Started process (PID=76790) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:33:49,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:33:49,388] {logging_mixin.py:115} INFO - [2022-06-07 13:33:49,388] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:33:49,460] {logging_mixin.py:115} INFO - [2022-06-07 13:33:49,458] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:33:49,461] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:33:49,557] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-07 13:34:19,785] {processor.py:153} INFO - Started process (PID=76858) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:34:19,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:34:19,789] {logging_mixin.py:115} INFO - [2022-06-07 13:34:19,789] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:34:19,872] {logging_mixin.py:115} INFO - [2022-06-07 13:34:19,869] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:34:19,873] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:34:19,977] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-07 13:34:50,745] {processor.py:153} INFO - Started process (PID=76927) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:34:50,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:34:50,748] {logging_mixin.py:115} INFO - [2022-06-07 13:34:50,748] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:34:50,797] {logging_mixin.py:115} INFO - [2022-06-07 13:34:50,795] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:34:50,799] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:34:50,893] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-07 13:35:21,681] {processor.py:153} INFO - Started process (PID=76995) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:35:21,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:35:21,685] {logging_mixin.py:115} INFO - [2022-06-07 13:35:21,685] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:35:21,747] {logging_mixin.py:115} INFO - [2022-06-07 13:35:21,743] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:35:21,748] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:35:21,864] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 13:35:52,618] {processor.py:153} INFO - Started process (PID=77053) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:35:52,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:35:52,621] {logging_mixin.py:115} INFO - [2022-06-07 13:35:52,621] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:35:52,681] {logging_mixin.py:115} INFO - [2022-06-07 13:35:52,677] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:35:52,682] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:35:52,776] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-07 13:36:22,837] {processor.py:153} INFO - Started process (PID=77117) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:36:22,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:36:22,839] {logging_mixin.py:115} INFO - [2022-06-07 13:36:22,839] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:36:22,909] {logging_mixin.py:115} INFO - [2022-06-07 13:36:22,905] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:36:22,910] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:36:23,029] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-07 13:36:53,097] {processor.py:153} INFO - Started process (PID=77184) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:36:53,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:36:53,107] {logging_mixin.py:115} INFO - [2022-06-07 13:36:53,107] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:36:53,170] {logging_mixin.py:115} INFO - [2022-06-07 13:36:53,168] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:36:53,171] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:36:53,272] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 13:37:23,445] {processor.py:153} INFO - Started process (PID=77252) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:37:23,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:37:23,448] {logging_mixin.py:115} INFO - [2022-06-07 13:37:23,448] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:37:23,509] {logging_mixin.py:115} INFO - [2022-06-07 13:37:23,507] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:37:23,511] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:37:23,603] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-07 13:37:54,366] {processor.py:153} INFO - Started process (PID=77320) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:37:54,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:37:54,372] {logging_mixin.py:115} INFO - [2022-06-07 13:37:54,372] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:37:54,462] {logging_mixin.py:115} INFO - [2022-06-07 13:37:54,459] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:37:54,465] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:37:54,611] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.248 seconds
[2022-06-07 13:38:25,151] {processor.py:153} INFO - Started process (PID=77378) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:38:25,154] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:38:25,156] {logging_mixin.py:115} INFO - [2022-06-07 13:38:25,156] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:38:25,221] {logging_mixin.py:115} INFO - [2022-06-07 13:38:25,219] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:38:25,222] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:38:25,319] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 13:38:56,164] {processor.py:153} INFO - Started process (PID=77445) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:38:56,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:38:56,168] {logging_mixin.py:115} INFO - [2022-06-07 13:38:56,168] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:38:56,234] {logging_mixin.py:115} INFO - [2022-06-07 13:38:56,231] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:38:56,236] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:38:56,336] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-07 13:39:26,919] {processor.py:153} INFO - Started process (PID=77513) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:39:26,921] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:39:26,924] {logging_mixin.py:115} INFO - [2022-06-07 13:39:26,924] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:39:26,985] {logging_mixin.py:115} INFO - [2022-06-07 13:39:26,983] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:39:26,986] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:39:27,085] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 13:39:57,582] {processor.py:153} INFO - Started process (PID=77582) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:39:57,584] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:39:57,586] {logging_mixin.py:115} INFO - [2022-06-07 13:39:57,586] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:39:57,652] {logging_mixin.py:115} INFO - [2022-06-07 13:39:57,650] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:39:57,654] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:39:57,747] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 13:40:28,133] {processor.py:153} INFO - Started process (PID=77650) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:40:28,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:40:28,136] {logging_mixin.py:115} INFO - [2022-06-07 13:40:28,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:40:28,187] {logging_mixin.py:115} INFO - [2022-06-07 13:40:28,184] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:40:28,189] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:40:28,319] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-07 13:40:59,045] {processor.py:153} INFO - Started process (PID=77707) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:40:59,047] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:40:59,048] {logging_mixin.py:115} INFO - [2022-06-07 13:40:59,048] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:40:59,153] {logging_mixin.py:115} INFO - [2022-06-07 13:40:59,151] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:40:59,156] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:40:59,269] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-07 13:41:29,416] {processor.py:153} INFO - Started process (PID=77775) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:41:29,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:41:29,418] {logging_mixin.py:115} INFO - [2022-06-07 13:41:29,418] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:41:29,500] {logging_mixin.py:115} INFO - [2022-06-07 13:41:29,498] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:41:29,501] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:41:29,600] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 13:42:00,141] {processor.py:153} INFO - Started process (PID=77845) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:42:00,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:42:00,145] {logging_mixin.py:115} INFO - [2022-06-07 13:42:00,145] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:42:00,209] {logging_mixin.py:115} INFO - [2022-06-07 13:42:00,202] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:42:00,211] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:42:00,346] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.208 seconds
[2022-06-07 13:42:30,895] {processor.py:153} INFO - Started process (PID=77915) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:42:30,897] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:42:30,899] {logging_mixin.py:115} INFO - [2022-06-07 13:42:30,899] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:42:30,961] {logging_mixin.py:115} INFO - [2022-06-07 13:42:30,958] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:42:30,962] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:42:31,059] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 13:43:01,703] {processor.py:153} INFO - Started process (PID=77982) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:43:01,705] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:43:01,706] {logging_mixin.py:115} INFO - [2022-06-07 13:43:01,706] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:43:01,774] {logging_mixin.py:115} INFO - [2022-06-07 13:43:01,771] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:43:01,775] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:43:01,885] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 13:43:31,966] {processor.py:153} INFO - Started process (PID=78038) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:43:31,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:43:31,971] {logging_mixin.py:115} INFO - [2022-06-07 13:43:31,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:43:32,028] {logging_mixin.py:115} INFO - [2022-06-07 13:43:32,025] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:43:32,030] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:43:32,126] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-07 13:44:02,292] {processor.py:153} INFO - Started process (PID=78105) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:44:02,296] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:44:02,298] {logging_mixin.py:115} INFO - [2022-06-07 13:44:02,297] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:44:02,375] {logging_mixin.py:115} INFO - [2022-06-07 13:44:02,373] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:44:02,376] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:44:02,473] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-07 13:44:32,588] {processor.py:153} INFO - Started process (PID=78172) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:44:32,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:44:32,591] {logging_mixin.py:115} INFO - [2022-06-07 13:44:32,591] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:44:32,677] {logging_mixin.py:115} INFO - [2022-06-07 13:44:32,675] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:44:32,679] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:44:32,812] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-07 13:45:03,462] {processor.py:153} INFO - Started process (PID=78238) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:45:03,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:45:03,465] {logging_mixin.py:115} INFO - [2022-06-07 13:45:03,465] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:45:03,564] {logging_mixin.py:115} INFO - [2022-06-07 13:45:03,560] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:45:03,566] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:45:03,686] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-07 13:45:34,108] {processor.py:153} INFO - Started process (PID=78303) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:45:34,110] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:45:34,111] {logging_mixin.py:115} INFO - [2022-06-07 13:45:34,111] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:45:34,187] {logging_mixin.py:115} INFO - [2022-06-07 13:45:34,185] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:45:34,190] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:45:34,306] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-07 13:46:05,048] {processor.py:153} INFO - Started process (PID=78362) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:46:05,051] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:46:05,053] {logging_mixin.py:115} INFO - [2022-06-07 13:46:05,053] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:46:05,130] {logging_mixin.py:115} INFO - [2022-06-07 13:46:05,127] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:46:05,131] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:46:05,234] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 13:46:35,487] {processor.py:153} INFO - Started process (PID=78426) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:46:35,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:46:35,493] {logging_mixin.py:115} INFO - [2022-06-07 13:46:35,493] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:46:35,594] {logging_mixin.py:115} INFO - [2022-06-07 13:46:35,592] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:46:35,596] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:46:35,697] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-07 13:47:05,838] {processor.py:153} INFO - Started process (PID=78493) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:47:05,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:47:05,855] {logging_mixin.py:115} INFO - [2022-06-07 13:47:05,855] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:47:06,112] {logging_mixin.py:115} INFO - [2022-06-07 13:47:06,103] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:47:06,114] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:47:06,311] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.495 seconds
[2022-06-07 13:47:36,970] {processor.py:153} INFO - Started process (PID=78562) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:47:36,972] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:47:36,973] {logging_mixin.py:115} INFO - [2022-06-07 13:47:36,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:47:37,034] {logging_mixin.py:115} INFO - [2022-06-07 13:47:37,032] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:47:37,036] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:47:37,134] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 13:48:07,719] {processor.py:153} INFO - Started process (PID=78629) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:48:07,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:48:07,723] {logging_mixin.py:115} INFO - [2022-06-07 13:48:07,722] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:48:07,778] {logging_mixin.py:115} INFO - [2022-06-07 13:48:07,775] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:48:07,779] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:48:07,874] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-07 13:48:38,676] {processor.py:153} INFO - Started process (PID=78686) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:48:38,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:48:38,682] {logging_mixin.py:115} INFO - [2022-06-07 13:48:38,682] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:48:38,761] {logging_mixin.py:115} INFO - [2022-06-07 13:48:38,758] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:48:38,762] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:48:38,860] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-07 13:49:09,405] {processor.py:153} INFO - Started process (PID=78755) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:49:09,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:49:09,407] {logging_mixin.py:115} INFO - [2022-06-07 13:49:09,407] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:49:09,450] {logging_mixin.py:115} INFO - [2022-06-07 13:49:09,449] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:49:09,452] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:49:09,546] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-07 13:49:40,120] {processor.py:153} INFO - Started process (PID=78824) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:49:40,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:49:40,123] {logging_mixin.py:115} INFO - [2022-06-07 13:49:40,123] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:49:40,248] {logging_mixin.py:115} INFO - [2022-06-07 13:49:40,245] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:49:40,250] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:49:40,383] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.267 seconds
[2022-06-07 13:50:11,332] {processor.py:153} INFO - Started process (PID=78893) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:50:11,335] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:50:11,337] {logging_mixin.py:115} INFO - [2022-06-07 13:50:11,337] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:50:11,411] {logging_mixin.py:115} INFO - [2022-06-07 13:50:11,408] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:50:11,412] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:50:11,506] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 13:50:41,665] {processor.py:153} INFO - Started process (PID=78961) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:50:41,668] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:50:41,671] {logging_mixin.py:115} INFO - [2022-06-07 13:50:41,671] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:50:41,733] {logging_mixin.py:115} INFO - [2022-06-07 13:50:41,730] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:50:41,734] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:50:41,854] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-07 13:51:12,076] {processor.py:153} INFO - Started process (PID=79026) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:51:12,077] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:51:12,079] {logging_mixin.py:115} INFO - [2022-06-07 13:51:12,079] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:51:12,150] {logging_mixin.py:115} INFO - [2022-06-07 13:51:12,147] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:51:12,152] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:51:12,267] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-07 13:51:42,533] {processor.py:153} INFO - Started process (PID=79087) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:51:42,535] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:51:42,536] {logging_mixin.py:115} INFO - [2022-06-07 13:51:42,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:51:42,591] {logging_mixin.py:115} INFO - [2022-06-07 13:51:42,589] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:51:42,593] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:51:42,703] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 13:52:12,771] {processor.py:153} INFO - Started process (PID=79154) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:52:12,774] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:52:12,775] {logging_mixin.py:115} INFO - [2022-06-07 13:52:12,775] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:52:12,848] {logging_mixin.py:115} INFO - [2022-06-07 13:52:12,846] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:52:12,850] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:52:12,951] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-07 13:52:43,053] {processor.py:153} INFO - Started process (PID=79222) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:52:43,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:52:43,057] {logging_mixin.py:115} INFO - [2022-06-07 13:52:43,056] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:52:43,121] {logging_mixin.py:115} INFO - [2022-06-07 13:52:43,119] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:52:43,123] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:52:43,225] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 13:53:13,903] {processor.py:153} INFO - Started process (PID=79289) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:53:13,906] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:53:13,909] {logging_mixin.py:115} INFO - [2022-06-07 13:53:13,909] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:53:13,980] {logging_mixin.py:115} INFO - [2022-06-07 13:53:13,978] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:53:13,982] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:53:14,081] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-07 13:53:44,512] {processor.py:153} INFO - Started process (PID=79359) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:53:44,513] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:53:44,515] {logging_mixin.py:115} INFO - [2022-06-07 13:53:44,515] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:53:44,573] {logging_mixin.py:115} INFO - [2022-06-07 13:53:44,571] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:53:44,574] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:53:44,678] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-07 13:54:15,385] {processor.py:153} INFO - Started process (PID=79416) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:54:15,390] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:54:15,392] {logging_mixin.py:115} INFO - [2022-06-07 13:54:15,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:54:15,452] {logging_mixin.py:115} INFO - [2022-06-07 13:54:15,450] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:54:15,454] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:54:15,549] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 13:54:46,203] {processor.py:153} INFO - Started process (PID=79484) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:54:46,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:54:46,207] {logging_mixin.py:115} INFO - [2022-06-07 13:54:46,207] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:54:46,275] {logging_mixin.py:115} INFO - [2022-06-07 13:54:46,272] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:54:46,276] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:54:46,386] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-07 13:55:17,164] {processor.py:153} INFO - Started process (PID=79552) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:55:17,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:55:17,167] {logging_mixin.py:115} INFO - [2022-06-07 13:55:17,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:55:17,230] {logging_mixin.py:115} INFO - [2022-06-07 13:55:17,227] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:55:17,232] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:55:17,340] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 13:55:47,899] {processor.py:153} INFO - Started process (PID=79622) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:55:47,902] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:55:47,904] {logging_mixin.py:115} INFO - [2022-06-07 13:55:47,904] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:55:47,969] {logging_mixin.py:115} INFO - [2022-06-07 13:55:47,966] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:55:47,970] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:55:48,063] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 13:56:18,531] {processor.py:153} INFO - Started process (PID=79690) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:56:18,535] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:56:18,537] {logging_mixin.py:115} INFO - [2022-06-07 13:56:18,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:56:18,606] {logging_mixin.py:115} INFO - [2022-06-07 13:56:18,604] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:56:18,607] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:56:18,701] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 13:56:49,278] {processor.py:153} INFO - Started process (PID=79758) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:56:49,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:56:49,282] {logging_mixin.py:115} INFO - [2022-06-07 13:56:49,282] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:56:49,336] {logging_mixin.py:115} INFO - [2022-06-07 13:56:49,333] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:56:49,337] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:56:49,443] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-07 13:57:20,164] {processor.py:153} INFO - Started process (PID=79815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:57:20,167] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:57:20,169] {logging_mixin.py:115} INFO - [2022-06-07 13:57:20,169] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:57:20,238] {logging_mixin.py:115} INFO - [2022-06-07 13:57:20,236] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:57:20,239] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:57:20,334] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 13:57:50,856] {processor.py:153} INFO - Started process (PID=79885) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:57:50,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:57:50,861] {logging_mixin.py:115} INFO - [2022-06-07 13:57:50,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:57:50,914] {logging_mixin.py:115} INFO - [2022-06-07 13:57:50,912] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:57:50,915] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:57:51,012] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-07 13:58:21,670] {processor.py:153} INFO - Started process (PID=79954) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:58:21,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:58:21,673] {logging_mixin.py:115} INFO - [2022-06-07 13:58:21,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:58:21,740] {logging_mixin.py:115} INFO - [2022-06-07 13:58:21,737] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:58:21,741] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:58:21,849] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-07 13:58:52,599] {processor.py:153} INFO - Started process (PID=80024) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:58:52,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:58:52,604] {logging_mixin.py:115} INFO - [2022-06-07 13:58:52,604] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:58:52,665] {logging_mixin.py:115} INFO - [2022-06-07 13:58:52,663] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:58:52,667] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:58:52,767] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-07 13:59:23,406] {processor.py:153} INFO - Started process (PID=80090) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:59:23,407] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:59:23,409] {logging_mixin.py:115} INFO - [2022-06-07 13:59:23,409] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:59:23,483] {logging_mixin.py:115} INFO - [2022-06-07 13:59:23,480] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:59:23,484] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:59:23,579] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-07 13:59:54,011] {processor.py:153} INFO - Started process (PID=80159) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:59:54,012] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 13:59:54,014] {logging_mixin.py:115} INFO - [2022-06-07 13:59:54,013] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:59:54,081] {logging_mixin.py:115} INFO - [2022-06-07 13:59:54,076] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 13:59:54,083] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 13:59:54,215] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-07 14:00:24,657] {processor.py:153} INFO - Started process (PID=80216) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:00:24,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:00:24,662] {logging_mixin.py:115} INFO - [2022-06-07 14:00:24,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:00:24,721] {logging_mixin.py:115} INFO - [2022-06-07 14:00:24,718] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:00:24,722] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:00:24,820] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 14:00:55,541] {processor.py:153} INFO - Started process (PID=80284) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:00:55,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:00:55,545] {logging_mixin.py:115} INFO - [2022-06-07 14:00:55,545] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:00:55,627] {logging_mixin.py:115} INFO - [2022-06-07 14:00:55,625] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:00:55,629] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:00:55,727] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-07 14:01:26,276] {processor.py:153} INFO - Started process (PID=80354) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:01:26,277] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:01:26,279] {logging_mixin.py:115} INFO - [2022-06-07 14:01:26,279] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:01:26,350] {logging_mixin.py:115} INFO - [2022-06-07 14:01:26,347] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:01:26,351] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:01:26,467] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-07 14:01:56,612] {processor.py:153} INFO - Started process (PID=80421) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:01:56,614] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:01:56,618] {logging_mixin.py:115} INFO - [2022-06-07 14:01:56,618] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:01:56,705] {logging_mixin.py:115} INFO - [2022-06-07 14:01:56,701] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:01:56,708] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:01:56,813] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-07 14:02:26,854] {processor.py:153} INFO - Started process (PID=80490) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:02:26,856] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:02:26,858] {logging_mixin.py:115} INFO - [2022-06-07 14:02:26,858] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:02:26,931] {logging_mixin.py:115} INFO - [2022-06-07 14:02:26,928] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:02:26,933] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:02:27,051] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 14:02:57,372] {processor.py:153} INFO - Started process (PID=80551) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:02:57,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:02:57,379] {logging_mixin.py:115} INFO - [2022-06-07 14:02:57,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:02:57,452] {logging_mixin.py:115} INFO - [2022-06-07 14:02:57,449] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:02:57,453] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:02:57,553] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-07 14:03:27,888] {processor.py:153} INFO - Started process (PID=80621) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:03:27,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:03:27,892] {logging_mixin.py:115} INFO - [2022-06-07 14:03:27,892] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:03:27,955] {logging_mixin.py:115} INFO - [2022-06-07 14:03:27,953] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:03:27,956] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:03:28,066] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 14:03:58,323] {processor.py:153} INFO - Started process (PID=80689) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:03:58,324] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:03:58,326] {logging_mixin.py:115} INFO - [2022-06-07 14:03:58,326] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:03:58,388] {logging_mixin.py:115} INFO - [2022-06-07 14:03:58,386] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:03:58,389] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:03:58,491] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-07 14:04:28,582] {processor.py:153} INFO - Started process (PID=80747) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:04:28,584] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:04:28,587] {logging_mixin.py:115} INFO - [2022-06-07 14:04:28,586] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:04:28,682] {logging_mixin.py:115} INFO - [2022-06-07 14:04:28,680] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:04:28,684] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:04:28,822] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-07 14:04:58,896] {processor.py:153} INFO - Started process (PID=80815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:04:58,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:04:58,900] {logging_mixin.py:115} INFO - [2022-06-07 14:04:58,900] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:04:58,969] {logging_mixin.py:115} INFO - [2022-06-07 14:04:58,966] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:04:58,970] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:04:59,060] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-07 14:05:29,434] {processor.py:153} INFO - Started process (PID=80884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:05:29,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:05:29,440] {logging_mixin.py:115} INFO - [2022-06-07 14:05:29,440] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:05:29,521] {logging_mixin.py:115} INFO - [2022-06-07 14:05:29,518] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:05:29,523] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:05:29,639] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-07 14:06:00,101] {processor.py:153} INFO - Started process (PID=80951) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:06:00,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:06:00,104] {logging_mixin.py:115} INFO - [2022-06-07 14:06:00,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:06:00,180] {logging_mixin.py:115} INFO - [2022-06-07 14:06:00,177] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:06:00,181] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:06:00,287] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-07 14:06:30,643] {processor.py:153} INFO - Started process (PID=81018) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:06:30,645] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:06:30,648] {logging_mixin.py:115} INFO - [2022-06-07 14:06:30,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:06:30,715] {logging_mixin.py:115} INFO - [2022-06-07 14:06:30,712] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:06:30,718] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:06:30,848] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-07 14:07:01,448] {processor.py:153} INFO - Started process (PID=81075) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:07:01,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:07:01,453] {logging_mixin.py:115} INFO - [2022-06-07 14:07:01,453] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:07:01,562] {logging_mixin.py:115} INFO - [2022-06-07 14:07:01,560] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:07:01,565] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:07:01,694] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-07 14:07:31,908] {processor.py:153} INFO - Started process (PID=81142) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:07:31,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:07:31,914] {logging_mixin.py:115} INFO - [2022-06-07 14:07:31,914] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:07:32,002] {logging_mixin.py:115} INFO - [2022-06-07 14:07:31,998] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:07:32,003] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:07:32,106] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-07 14:08:02,155] {processor.py:153} INFO - Started process (PID=81200) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:08:02,158] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:08:02,159] {logging_mixin.py:115} INFO - [2022-06-07 14:08:02,159] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:08:02,260] {logging_mixin.py:115} INFO - [2022-06-07 14:08:02,256] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:08:02,261] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:08:02,403] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-07 14:08:32,858] {processor.py:153} INFO - Started process (PID=81265) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:08:32,861] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:08:32,864] {logging_mixin.py:115} INFO - [2022-06-07 14:08:32,864] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:08:32,976] {logging_mixin.py:115} INFO - [2022-06-07 14:08:32,972] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:08:32,979] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:08:33,132] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.281 seconds
[2022-06-07 14:09:03,423] {processor.py:153} INFO - Started process (PID=81321) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:09:03,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:09:03,437] {logging_mixin.py:115} INFO - [2022-06-07 14:09:03,437] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:09:03,653] {logging_mixin.py:115} INFO - [2022-06-07 14:09:03,648] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:09:03,656] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:09:03,960] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.563 seconds
[2022-06-07 14:09:34,243] {processor.py:153} INFO - Started process (PID=81376) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:09:34,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:09:34,259] {logging_mixin.py:115} INFO - [2022-06-07 14:09:34,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:09:34,537] {logging_mixin.py:115} INFO - [2022-06-07 14:09:34,519] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:09:34,548] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:09:34,869] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.657 seconds
[2022-06-07 14:10:05,227] {processor.py:153} INFO - Started process (PID=81431) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:10:05,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:10:05,247] {logging_mixin.py:115} INFO - [2022-06-07 14:10:05,247] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:10:05,897] {logging_mixin.py:115} INFO - [2022-06-07 14:10:05,873] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:10:05,926] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:10:07,465] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 2.276 seconds
[2022-06-07 14:10:37,945] {processor.py:153} INFO - Started process (PID=81495) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:10:37,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:10:37,961] {logging_mixin.py:115} INFO - [2022-06-07 14:10:37,961] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:10:38,342] {logging_mixin.py:115} INFO - [2022-06-07 14:10:38,330] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:10:38,353] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:10:39,214] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 1.350 seconds
[2022-06-07 14:11:09,862] {processor.py:153} INFO - Started process (PID=81550) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:11:09,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:11:09,876] {logging_mixin.py:115} INFO - [2022-06-07 14:11:09,875] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:11:10,020] {logging_mixin.py:115} INFO - [2022-06-07 14:11:10,013] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:11:10,023] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:11:10,259] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.405 seconds
[2022-06-07 14:11:40,435] {processor.py:153} INFO - Started process (PID=81605) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:11:40,440] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:11:40,467] {logging_mixin.py:115} INFO - [2022-06-07 14:11:40,467] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:11:40,630] {logging_mixin.py:115} INFO - [2022-06-07 14:11:40,627] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:11:40,633] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:11:40,886] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.456 seconds
[2022-06-07 14:12:11,107] {processor.py:153} INFO - Started process (PID=81672) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:12:11,110] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:12:11,112] {logging_mixin.py:115} INFO - [2022-06-07 14:12:11,112] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:12:11,185] {logging_mixin.py:115} INFO - [2022-06-07 14:12:11,182] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:12:11,187] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:12:11,284] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-07 14:12:42,042] {processor.py:153} INFO - Started process (PID=81739) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:12:42,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:12:42,059] {logging_mixin.py:115} INFO - [2022-06-07 14:12:42,059] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:12:42,144] {logging_mixin.py:115} INFO - [2022-06-07 14:12:42,139] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:12:42,145] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:12:42,275] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-07 14:13:12,316] {processor.py:153} INFO - Started process (PID=81796) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:13:12,318] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:13:12,319] {logging_mixin.py:115} INFO - [2022-06-07 14:13:12,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:13:12,401] {logging_mixin.py:115} INFO - [2022-06-07 14:13:12,398] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:13:12,404] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:13:12,511] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-07 14:13:42,670] {processor.py:153} INFO - Started process (PID=81867) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:13:42,673] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:13:42,676] {logging_mixin.py:115} INFO - [2022-06-07 14:13:42,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:13:42,765] {logging_mixin.py:115} INFO - [2022-06-07 14:13:42,763] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:13:42,767] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:13:42,870] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-07 14:14:13,577] {processor.py:153} INFO - Started process (PID=81940) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:14:13,578] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:14:13,580] {logging_mixin.py:115} INFO - [2022-06-07 14:14:13,580] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:14:13,664] {logging_mixin.py:115} INFO - [2022-06-07 14:14:13,662] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:14:13,666] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:14:13,764] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-07 14:14:44,302] {processor.py:153} INFO - Started process (PID=82008) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:14:44,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:14:44,308] {logging_mixin.py:115} INFO - [2022-06-07 14:14:44,308] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:14:44,363] {logging_mixin.py:115} INFO - [2022-06-07 14:14:44,361] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:14:44,366] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:14:44,463] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 14:15:14,948] {processor.py:153} INFO - Started process (PID=82076) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:15:14,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:15:14,951] {logging_mixin.py:115} INFO - [2022-06-07 14:15:14,951] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:15:15,015] {logging_mixin.py:115} INFO - [2022-06-07 14:15:15,013] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:15:15,016] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:15:15,116] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-07 14:15:45,642] {processor.py:153} INFO - Started process (PID=82134) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:15:45,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:15:45,648] {logging_mixin.py:115} INFO - [2022-06-07 14:15:45,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:15:45,706] {logging_mixin.py:115} INFO - [2022-06-07 14:15:45,703] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:15:45,707] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:15:45,810] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-07 14:16:16,648] {processor.py:153} INFO - Started process (PID=82202) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:16:16,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:16:16,655] {logging_mixin.py:115} INFO - [2022-06-07 14:16:16,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:16:16,755] {logging_mixin.py:115} INFO - [2022-06-07 14:16:16,751] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:16:16,756] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:16:16,873] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-07 14:16:47,535] {processor.py:153} INFO - Started process (PID=82270) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:16:47,540] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:16:47,542] {logging_mixin.py:115} INFO - [2022-06-07 14:16:47,542] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:16:47,614] {logging_mixin.py:115} INFO - [2022-06-07 14:16:47,612] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:16:47,615] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:16:47,711] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 14:17:17,893] {processor.py:153} INFO - Started process (PID=82337) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:17:17,896] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:17:17,897] {logging_mixin.py:115} INFO - [2022-06-07 14:17:17,897] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:17:17,948] {logging_mixin.py:115} INFO - [2022-06-07 14:17:17,945] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:17:17,949] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:17:18,053] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-07 14:17:48,734] {processor.py:153} INFO - Started process (PID=82406) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:17:48,736] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:17:48,737] {logging_mixin.py:115} INFO - [2022-06-07 14:17:48,737] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:17:48,810] {logging_mixin.py:115} INFO - [2022-06-07 14:17:48,805] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:17:48,812] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:17:48,923] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-07 14:18:19,466] {processor.py:153} INFO - Started process (PID=82476) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:18:19,468] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:18:19,471] {logging_mixin.py:115} INFO - [2022-06-07 14:18:19,471] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:18:19,544] {logging_mixin.py:115} INFO - [2022-06-07 14:18:19,542] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:18:19,546] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:18:19,642] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-07 14:18:49,885] {processor.py:153} INFO - Started process (PID=82533) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:18:49,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:18:49,894] {logging_mixin.py:115} INFO - [2022-06-07 14:18:49,894] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:18:50,086] {logging_mixin.py:115} INFO - [2022-06-07 14:18:50,078] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:18:50,091] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:18:50,291] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.423 seconds
[2022-06-07 14:19:20,969] {processor.py:153} INFO - Started process (PID=82602) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:19:20,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:19:20,981] {logging_mixin.py:115} INFO - [2022-06-07 14:19:20,981] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:19:21,149] {logging_mixin.py:115} INFO - [2022-06-07 14:19:21,143] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:19:21,151] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:19:21,339] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.378 seconds
[2022-06-07 14:19:51,929] {processor.py:153} INFO - Started process (PID=82658) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:19:51,936] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:19:51,940] {logging_mixin.py:115} INFO - [2022-06-07 14:19:51,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:19:52,300] {logging_mixin.py:115} INFO - [2022-06-07 14:19:52,289] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:19:52,310] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:19:52,608] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.701 seconds
[2022-06-07 14:20:22,677] {processor.py:153} INFO - Started process (PID=82733) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:20:22,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:20:22,683] {logging_mixin.py:115} INFO - [2022-06-07 14:20:22,682] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:20:22,765] {logging_mixin.py:115} INFO - [2022-06-07 14:20:22,763] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:20:22,767] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:20:22,871] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-07 14:20:53,589] {processor.py:153} INFO - Started process (PID=82799) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:20:53,591] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:20:53,593] {logging_mixin.py:115} INFO - [2022-06-07 14:20:53,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:20:53,689] {logging_mixin.py:115} INFO - [2022-06-07 14:20:53,687] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:20:53,695] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:20:53,806] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-07 14:21:23,900] {processor.py:153} INFO - Started process (PID=82854) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:21:23,901] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:21:23,903] {logging_mixin.py:115} INFO - [2022-06-07 14:21:23,903] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:21:24,004] {logging_mixin.py:115} INFO - [2022-06-07 14:21:23,999] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:21:24,009] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:21:24,162] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.267 seconds
[2022-06-07 14:21:54,422] {processor.py:153} INFO - Started process (PID=82923) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:21:54,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:21:54,425] {logging_mixin.py:115} INFO - [2022-06-07 14:21:54,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:21:54,534] {logging_mixin.py:115} INFO - [2022-06-07 14:21:54,531] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:21:54,536] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:21:54,717] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.301 seconds
[2022-06-07 14:22:24,970] {processor.py:153} INFO - Started process (PID=82989) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:22:24,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:22:24,984] {logging_mixin.py:115} INFO - [2022-06-07 14:22:24,983] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:22:25,145] {logging_mixin.py:115} INFO - [2022-06-07 14:22:25,141] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:22:25,147] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:22:25,355] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.399 seconds
[2022-06-07 14:22:56,169] {processor.py:153} INFO - Started process (PID=83057) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:22:56,170] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:22:56,171] {logging_mixin.py:115} INFO - [2022-06-07 14:22:56,171] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:22:56,250] {logging_mixin.py:115} INFO - [2022-06-07 14:22:56,248] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:22:56,251] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:22:56,354] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-07 14:23:26,435] {processor.py:153} INFO - Started process (PID=83114) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:23:26,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:23:26,439] {logging_mixin.py:115} INFO - [2022-06-07 14:23:26,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:23:26,559] {logging_mixin.py:115} INFO - [2022-06-07 14:23:26,557] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:23:26,561] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:23:26,684] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.260 seconds
[2022-06-07 14:23:57,526] {processor.py:153} INFO - Started process (PID=83183) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:23:57,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:23:57,530] {logging_mixin.py:115} INFO - [2022-06-07 14:23:57,530] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:23:57,675] {logging_mixin.py:115} INFO - [2022-06-07 14:23:57,662] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:23:57,689] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:23:57,958] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.442 seconds
[2022-06-07 14:24:28,437] {processor.py:153} INFO - Started process (PID=83253) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:24:28,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:24:28,446] {logging_mixin.py:115} INFO - [2022-06-07 14:24:28,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:24:28,569] {logging_mixin.py:115} INFO - [2022-06-07 14:24:28,566] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:24:28,571] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:24:28,697] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.271 seconds
[2022-06-07 14:24:58,975] {processor.py:153} INFO - Started process (PID=83314) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:24:58,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:24:58,980] {logging_mixin.py:115} INFO - [2022-06-07 14:24:58,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:24:59,068] {logging_mixin.py:115} INFO - [2022-06-07 14:24:59,066] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:24:59,070] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:24:59,222] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-07 14:25:29,350] {processor.py:153} INFO - Started process (PID=83381) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:25:29,353] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:25:29,355] {logging_mixin.py:115} INFO - [2022-06-07 14:25:29,355] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:25:29,472] {logging_mixin.py:115} INFO - [2022-06-07 14:25:29,469] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:25:29,474] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:25:29,580] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-07 14:25:59,864] {processor.py:153} INFO - Started process (PID=83452) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:25:59,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:25:59,870] {logging_mixin.py:115} INFO - [2022-06-07 14:25:59,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:26:00,062] {logging_mixin.py:115} INFO - [2022-06-07 14:26:00,051] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:26:00,072] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:26:00,334] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.491 seconds
[2022-06-07 14:26:30,749] {processor.py:153} INFO - Started process (PID=83511) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:26:30,753] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:26:30,755] {logging_mixin.py:115} INFO - [2022-06-07 14:26:30,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:26:30,901] {logging_mixin.py:115} INFO - [2022-06-07 14:26:30,897] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:26:30,905] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:26:31,036] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.292 seconds
[2022-06-07 14:27:01,423] {processor.py:153} INFO - Started process (PID=83577) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:27:01,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:27:01,428] {logging_mixin.py:115} INFO - [2022-06-07 14:27:01,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:27:01,541] {logging_mixin.py:115} INFO - [2022-06-07 14:27:01,538] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:27:01,543] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:27:01,674] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-07 14:27:31,808] {processor.py:153} INFO - Started process (PID=83637) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:27:31,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:27:31,813] {logging_mixin.py:115} INFO - [2022-06-07 14:27:31,813] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:27:31,906] {logging_mixin.py:115} INFO - [2022-06-07 14:27:31,903] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:27:31,908] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:27:32,011] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-07 14:28:02,275] {processor.py:153} INFO - Started process (PID=83704) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:28:02,277] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:28:02,279] {logging_mixin.py:115} INFO - [2022-06-07 14:28:02,279] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:28:02,407] {logging_mixin.py:115} INFO - [2022-06-07 14:28:02,404] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:28:02,408] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:28:02,560] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.294 seconds
[2022-06-07 14:28:33,167] {processor.py:153} INFO - Started process (PID=83772) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:28:33,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:28:33,169] {logging_mixin.py:115} INFO - [2022-06-07 14:28:33,169] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:28:33,232] {logging_mixin.py:115} INFO - [2022-06-07 14:28:33,230] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:28:33,234] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:28:33,330] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-07 14:29:04,042] {processor.py:153} INFO - Started process (PID=83831) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:29:04,044] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:29:04,046] {logging_mixin.py:115} INFO - [2022-06-07 14:29:04,046] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:29:04,127] {logging_mixin.py:115} INFO - [2022-06-07 14:29:04,125] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:29:04,129] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:29:04,232] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-07 14:29:34,310] {processor.py:153} INFO - Started process (PID=83897) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:29:34,312] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:29:34,313] {logging_mixin.py:115} INFO - [2022-06-07 14:29:34,313] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:29:34,382] {logging_mixin.py:115} INFO - [2022-06-07 14:29:34,379] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:29:34,384] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:29:34,482] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-07 14:30:04,859] {processor.py:153} INFO - Started process (PID=83964) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:30:04,862] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:30:04,863] {logging_mixin.py:115} INFO - [2022-06-07 14:30:04,863] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:30:04,948] {logging_mixin.py:115} INFO - [2022-06-07 14:30:04,945] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:30:04,950] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:30:05,065] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.210 seconds
[2022-06-07 14:30:35,226] {processor.py:153} INFO - Started process (PID=84022) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:30:35,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:30:35,234] {logging_mixin.py:115} INFO - [2022-06-07 14:30:35,234] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:30:35,352] {logging_mixin.py:115} INFO - [2022-06-07 14:30:35,349] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:30:35,353] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:30:35,463] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-07 14:31:05,871] {processor.py:153} INFO - Started process (PID=84087) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:31:05,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:31:05,882] {logging_mixin.py:115} INFO - [2022-06-07 14:31:05,882] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:31:06,491] {logging_mixin.py:115} INFO - [2022-06-07 14:31:06,482] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:31:06,496] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:31:06,907] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 1.067 seconds
[2022-06-07 14:31:37,244] {processor.py:153} INFO - Started process (PID=84142) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:31:37,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:31:37,249] {logging_mixin.py:115} INFO - [2022-06-07 14:31:37,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:31:37,404] {logging_mixin.py:115} INFO - [2022-06-07 14:31:37,400] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:31:37,406] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:31:37,570] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.331 seconds
[2022-06-07 14:32:08,426] {processor.py:153} INFO - Started process (PID=84212) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:32:08,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:32:08,436] {logging_mixin.py:115} INFO - [2022-06-07 14:32:08,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:32:08,626] {logging_mixin.py:115} INFO - [2022-06-07 14:32:08,615] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:32:08,629] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:32:08,909] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.489 seconds
[2022-06-07 14:32:39,813] {processor.py:153} INFO - Started process (PID=84269) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:32:39,815] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:32:39,817] {logging_mixin.py:115} INFO - [2022-06-07 14:32:39,817] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:32:39,941] {logging_mixin.py:115} INFO - [2022-06-07 14:32:39,937] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:32:39,943] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:32:40,084] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.281 seconds
[2022-06-07 14:33:10,332] {processor.py:153} INFO - Started process (PID=84335) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:33:10,334] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:33:10,335] {logging_mixin.py:115} INFO - [2022-06-07 14:33:10,335] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:33:10,407] {logging_mixin.py:115} INFO - [2022-06-07 14:33:10,404] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:33:10,409] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:33:10,533] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.205 seconds
[2022-06-07 14:33:40,822] {processor.py:153} INFO - Started process (PID=84401) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:33:40,825] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-07 14:33:40,826] {logging_mixin.py:115} INFO - [2022-06-07 14:33:40,826] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:33:40,937] {logging_mixin.py:115} INFO - [2022-06-07 14:33:40,934] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-07 14:33:40,939] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-07 14:33:41,069] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.251 seconds
