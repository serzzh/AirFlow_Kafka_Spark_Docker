[2022-06-05 06:27:09,455] {processor.py:153} INFO - Started process (PID=36) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:27:09,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:27:09,460] {logging_mixin.py:115} INFO - [2022-06-05 06:27:09,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:27:09,783] {logging_mixin.py:115} INFO - [2022-06-05 06:27:09,778] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:27:09,785] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:27:12,123] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 2.677 seconds
[2022-06-05 06:27:43,410] {processor.py:153} INFO - Started process (PID=109) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:27:43,412] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:27:43,414] {logging_mixin.py:115} INFO - [2022-06-05 06:27:43,414] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:27:46,188] {logging_mixin.py:115} INFO - [2022-06-05 06:27:46,180] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:27:46,190] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:27:47,702] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 4.298 seconds
[2022-06-05 06:28:30,052] {processor.py:153} INFO - Started process (PID=165) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:28:30,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:28:30,054] {logging_mixin.py:115} INFO - [2022-06-05 06:28:30,054] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:28:30,260] {logging_mixin.py:115} INFO - [2022-06-05 06:28:30,254] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:28:30,261] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:28:30,375] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.325 seconds
[2022-06-05 06:34:40,604] {processor.py:153} INFO - Started process (PID=33) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:34:40,606] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:34:40,608] {logging_mixin.py:115} INFO - [2022-06-05 06:34:40,607] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:34:40,827] {logging_mixin.py:115} INFO - [2022-06-05 06:34:40,824] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:34:40,829] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:34:41,130] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.529 seconds
[2022-06-05 06:35:11,612] {processor.py:153} INFO - Started process (PID=100) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:35:11,614] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:35:11,616] {logging_mixin.py:115} INFO - [2022-06-05 06:35:11,615] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:35:11,749] {logging_mixin.py:115} INFO - [2022-06-05 06:35:11,747] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:35:11,750] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:35:11,842] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 06:35:42,260] {processor.py:153} INFO - Started process (PID=170) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:35:42,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:35:42,264] {logging_mixin.py:115} INFO - [2022-06-05 06:35:42,264] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:35:42,696] {logging_mixin.py:115} INFO - [2022-06-05 06:35:42,690] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:35:42,700] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:35:42,894] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.640 seconds
[2022-06-05 06:36:13,785] {processor.py:153} INFO - Started process (PID=226) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:36:13,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:36:13,790] {logging_mixin.py:115} INFO - [2022-06-05 06:36:13,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:36:14,061] {logging_mixin.py:115} INFO - [2022-06-05 06:36:14,059] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:36:14,062] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:36:14,179] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.400 seconds
[2022-06-05 06:36:44,230] {processor.py:153} INFO - Started process (PID=293) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:36:44,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:36:44,235] {logging_mixin.py:115} INFO - [2022-06-05 06:36:44,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:36:44,371] {logging_mixin.py:115} INFO - [2022-06-05 06:36:44,369] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:36:44,372] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:36:44,467] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.242 seconds
[2022-06-05 06:37:15,083] {processor.py:153} INFO - Started process (PID=360) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:37:15,086] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:37:15,087] {logging_mixin.py:115} INFO - [2022-06-05 06:37:15,087] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:37:15,287] {logging_mixin.py:115} INFO - [2022-06-05 06:37:15,285] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:37:15,288] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:37:15,382] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.304 seconds
[2022-06-05 06:37:45,781] {processor.py:153} INFO - Started process (PID=429) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:37:45,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:37:45,786] {logging_mixin.py:115} INFO - [2022-06-05 06:37:45,786] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:37:46,072] {logging_mixin.py:115} INFO - [2022-06-05 06:37:46,069] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:37:46,075] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:37:46,196] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.418 seconds
[2022-06-05 06:38:16,401] {processor.py:153} INFO - Started process (PID=495) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:38:16,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:38:16,405] {logging_mixin.py:115} INFO - [2022-06-05 06:38:16,405] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:38:16,537] {logging_mixin.py:115} INFO - [2022-06-05 06:38:16,535] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:38:16,538] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:38:16,671] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.274 seconds
[2022-06-05 06:38:46,858] {processor.py:153} INFO - Started process (PID=553) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:38:46,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:38:46,869] {logging_mixin.py:115} INFO - [2022-06-05 06:38:46,868] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:38:47,018] {logging_mixin.py:115} INFO - [2022-06-05 06:38:47,015] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:38:47,019] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:38:47,112] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.259 seconds
[2022-06-05 06:39:17,832] {processor.py:153} INFO - Started process (PID=619) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:39:17,834] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:39:17,836] {logging_mixin.py:115} INFO - [2022-06-05 06:39:17,835] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:39:17,964] {logging_mixin.py:115} INFO - [2022-06-05 06:39:17,961] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:39:17,966] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:39:18,061] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 06:39:48,645] {processor.py:153} INFO - Started process (PID=686) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:39:48,647] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:39:48,648] {logging_mixin.py:115} INFO - [2022-06-05 06:39:48,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:39:48,800] {logging_mixin.py:115} INFO - [2022-06-05 06:39:48,798] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:39:48,802] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:39:48,893] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.251 seconds
[2022-06-05 06:40:19,631] {processor.py:153} INFO - Started process (PID=753) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:40:19,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:40:19,635] {logging_mixin.py:115} INFO - [2022-06-05 06:40:19,635] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:40:19,866] {logging_mixin.py:115} INFO - [2022-06-05 06:40:19,864] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:40:19,867] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:40:19,972] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.346 seconds
[2022-06-05 06:40:50,185] {processor.py:153} INFO - Started process (PID=821) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:40:50,188] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:40:50,189] {logging_mixin.py:115} INFO - [2022-06-05 06:40:50,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:40:50,438] {logging_mixin.py:115} INFO - [2022-06-05 06:40:50,436] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:40:50,440] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:40:50,551] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.375 seconds
[2022-06-05 06:41:21,075] {processor.py:153} INFO - Started process (PID=878) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:41:21,076] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:41:21,077] {logging_mixin.py:115} INFO - [2022-06-05 06:41:21,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:41:21,229] {logging_mixin.py:115} INFO - [2022-06-05 06:41:21,227] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:41:21,233] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:41:21,334] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-05 06:41:52,082] {processor.py:153} INFO - Started process (PID=947) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:41:52,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:41:52,087] {logging_mixin.py:115} INFO - [2022-06-05 06:41:52,087] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:41:52,434] {logging_mixin.py:115} INFO - [2022-06-05 06:41:52,431] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:41:52,435] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:41:52,562] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.489 seconds
[2022-06-05 06:42:23,565] {processor.py:153} INFO - Started process (PID=1016) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:42:23,567] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:42:23,569] {logging_mixin.py:115} INFO - [2022-06-05 06:42:23,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:42:23,785] {logging_mixin.py:115} INFO - [2022-06-05 06:42:23,783] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:42:23,788] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:42:23,887] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.331 seconds
[2022-06-05 06:42:54,181] {processor.py:153} INFO - Started process (PID=1089) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:42:54,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:42:54,183] {logging_mixin.py:115} INFO - [2022-06-05 06:42:54,183] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:42:54,300] {logging_mixin.py:115} INFO - [2022-06-05 06:42:54,297] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:42:54,301] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:42:54,396] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-05 06:43:24,521] {processor.py:153} INFO - Started process (PID=1161) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:43:24,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:43:24,525] {logging_mixin.py:115} INFO - [2022-06-05 06:43:24,525] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:43:24,790] {logging_mixin.py:115} INFO - [2022-06-05 06:43:24,786] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:43:24,793] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:43:24,916] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.399 seconds
[2022-06-05 06:43:55,806] {processor.py:153} INFO - Started process (PID=1217) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:43:55,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:43:55,810] {logging_mixin.py:115} INFO - [2022-06-05 06:43:55,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:43:55,985] {logging_mixin.py:115} INFO - [2022-06-05 06:43:55,983] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:43:55,986] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:43:56,090] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.291 seconds
[2022-06-05 06:44:26,917] {processor.py:153} INFO - Started process (PID=1287) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:44:26,920] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:44:26,922] {logging_mixin.py:115} INFO - [2022-06-05 06:44:26,922] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:44:27,058] {logging_mixin.py:115} INFO - [2022-06-05 06:44:27,055] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:44:27,060] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:44:27,152] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 06:44:57,943] {processor.py:153} INFO - Started process (PID=1355) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:44:57,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:44:57,948] {logging_mixin.py:115} INFO - [2022-06-05 06:44:57,948] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:44:58,081] {logging_mixin.py:115} INFO - [2022-06-05 06:44:58,079] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:44:58,082] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:44:58,176] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 06:45:28,238] {processor.py:153} INFO - Started process (PID=1421) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:45:28,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:45:28,242] {logging_mixin.py:115} INFO - [2022-06-05 06:45:28,242] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:45:28,383] {logging_mixin.py:115} INFO - [2022-06-05 06:45:28,381] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:45:28,386] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:45:28,476] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-05 06:45:58,803] {processor.py:153} INFO - Started process (PID=1489) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:45:58,806] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:45:58,808] {logging_mixin.py:115} INFO - [2022-06-05 06:45:58,808] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:45:58,933] {logging_mixin.py:115} INFO - [2022-06-05 06:45:58,931] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:45:58,934] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:45:59,028] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-05 06:46:29,575] {processor.py:153} INFO - Started process (PID=1546) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:46:29,579] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:46:29,581] {logging_mixin.py:115} INFO - [2022-06-05 06:46:29,581] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:46:29,819] {logging_mixin.py:115} INFO - [2022-06-05 06:46:29,816] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:46:29,820] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:46:29,918] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.352 seconds
[2022-06-05 06:47:00,576] {processor.py:153} INFO - Started process (PID=1613) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:47:00,579] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:47:00,580] {logging_mixin.py:115} INFO - [2022-06-05 06:47:00,580] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:47:00,811] {logging_mixin.py:115} INFO - [2022-06-05 06:47:00,808] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:47:00,813] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:47:00,919] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.351 seconds
[2022-06-05 06:47:31,885] {processor.py:153} INFO - Started process (PID=1678) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:47:31,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:47:31,889] {logging_mixin.py:115} INFO - [2022-06-05 06:47:31,889] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:47:32,027] {logging_mixin.py:115} INFO - [2022-06-05 06:47:32,025] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:47:32,028] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:47:32,119] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 06:48:02,284] {processor.py:153} INFO - Started process (PID=1746) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:48:02,287] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:48:02,291] {logging_mixin.py:115} INFO - [2022-06-05 06:48:02,291] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:48:02,501] {logging_mixin.py:115} INFO - [2022-06-05 06:48:02,498] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:48:02,505] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:48:02,635] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.355 seconds
[2022-06-05 06:48:32,734] {processor.py:153} INFO - Started process (PID=1815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:48:32,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:48:32,736] {logging_mixin.py:115} INFO - [2022-06-05 06:48:32,736] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:48:32,866] {logging_mixin.py:115} INFO - [2022-06-05 06:48:32,863] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:48:32,867] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:48:32,967] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 06:49:03,284] {processor.py:153} INFO - Started process (PID=1870) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:49:03,285] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:49:03,286] {logging_mixin.py:115} INFO - [2022-06-05 06:49:03,286] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:49:03,419] {logging_mixin.py:115} INFO - [2022-06-05 06:49:03,417] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:49:03,421] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:49:03,519] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 06:49:33,656] {processor.py:153} INFO - Started process (PID=1938) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:49:33,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:49:33,661] {logging_mixin.py:115} INFO - [2022-06-05 06:49:33,661] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:49:33,898] {logging_mixin.py:115} INFO - [2022-06-05 06:49:33,894] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:49:33,899] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:49:33,994] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.346 seconds
[2022-06-05 06:50:04,964] {processor.py:153} INFO - Started process (PID=2005) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:50:04,968] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:50:04,971] {logging_mixin.py:115} INFO - [2022-06-05 06:50:04,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:50:05,247] {logging_mixin.py:115} INFO - [2022-06-05 06:50:05,243] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:50:05,257] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:50:05,384] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.432 seconds
[2022-06-05 06:50:35,927] {processor.py:153} INFO - Started process (PID=2072) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:50:35,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:50:35,930] {logging_mixin.py:115} INFO - [2022-06-05 06:50:35,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:50:36,153] {logging_mixin.py:115} INFO - [2022-06-05 06:50:36,150] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:50:36,155] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:50:36,299] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.376 seconds
[2022-06-05 06:51:06,763] {processor.py:153} INFO - Started process (PID=2138) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:51:06,764] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:51:06,766] {logging_mixin.py:115} INFO - [2022-06-05 06:51:06,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:51:06,999] {logging_mixin.py:115} INFO - [2022-06-05 06:51:06,996] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:51:07,001] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:51:07,105] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.352 seconds
[2022-06-05 06:51:37,317] {processor.py:153} INFO - Started process (PID=2199) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:51:37,319] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:51:37,321] {logging_mixin.py:115} INFO - [2022-06-05 06:51:37,321] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:51:37,524] {logging_mixin.py:115} INFO - [2022-06-05 06:51:37,522] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:51:37,525] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:51:37,629] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.320 seconds
[2022-06-05 06:52:08,057] {processor.py:153} INFO - Started process (PID=2267) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:52:08,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:52:08,060] {logging_mixin.py:115} INFO - [2022-06-05 06:52:08,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:52:08,269] {logging_mixin.py:115} INFO - [2022-06-05 06:52:08,267] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:52:08,271] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:52:08,374] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.320 seconds
[2022-06-05 06:52:39,069] {processor.py:153} INFO - Started process (PID=2333) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:52:39,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:52:39,074] {logging_mixin.py:115} INFO - [2022-06-05 06:52:39,074] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:52:39,318] {logging_mixin.py:115} INFO - [2022-06-05 06:52:39,315] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:52:39,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:52:39,438] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.376 seconds
[2022-06-05 06:53:10,340] {processor.py:153} INFO - Started process (PID=2402) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:53:10,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:53:10,345] {logging_mixin.py:115} INFO - [2022-06-05 06:53:10,345] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:53:10,567] {logging_mixin.py:115} INFO - [2022-06-05 06:53:10,564] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:53:10,568] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:53:10,666] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.333 seconds
[2022-06-05 06:53:40,984] {processor.py:153} INFO - Started process (PID=2466) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:53:40,986] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:53:40,988] {logging_mixin.py:115} INFO - [2022-06-05 06:53:40,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:53:41,354] {logging_mixin.py:115} INFO - [2022-06-05 06:53:41,350] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:53:41,355] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:53:41,498] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.519 seconds
[2022-06-05 06:54:12,326] {processor.py:153} INFO - Started process (PID=2527) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:54:12,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:54:12,330] {logging_mixin.py:115} INFO - [2022-06-05 06:54:12,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:54:12,568] {logging_mixin.py:115} INFO - [2022-06-05 06:54:12,566] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:54:12,571] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:54:12,703] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.382 seconds
[2022-06-05 06:54:42,949] {processor.py:153} INFO - Started process (PID=2596) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:54:42,952] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:54:42,954] {logging_mixin.py:115} INFO - [2022-06-05 06:54:42,953] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:54:43,175] {logging_mixin.py:115} INFO - [2022-06-05 06:54:43,173] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:54:43,177] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:54:43,297] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.355 seconds
[2022-06-05 06:55:14,008] {processor.py:153} INFO - Started process (PID=2665) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:55:14,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:55:14,012] {logging_mixin.py:115} INFO - [2022-06-05 06:55:14,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:55:14,257] {logging_mixin.py:115} INFO - [2022-06-05 06:55:14,255] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:55:14,258] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:55:14,354] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.351 seconds
[2022-06-05 06:55:45,423] {processor.py:153} INFO - Started process (PID=2737) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:55:45,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:55:45,436] {logging_mixin.py:115} INFO - [2022-06-05 06:55:45,435] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:55:45,780] {logging_mixin.py:115} INFO - [2022-06-05 06:55:45,777] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:55:45,783] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:55:45,903] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.501 seconds
[2022-06-05 06:59:00,332] {processor.py:153} INFO - Started process (PID=37) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:59:00,334] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:59:00,336] {logging_mixin.py:115} INFO - [2022-06-05 06:59:00,336] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:59:00,542] {logging_mixin.py:115} INFO - [2022-06-05 06:59:00,540] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:59:00,543] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:59:00,817] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.494 seconds
[2022-06-05 06:59:31,487] {processor.py:153} INFO - Started process (PID=103) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:59:31,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 06:59:31,490] {logging_mixin.py:115} INFO - [2022-06-05 06:59:31,490] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:59:31,700] {logging_mixin.py:115} INFO - [2022-06-05 06:59:31,697] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 06:59:31,702] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 06:59:31,808] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.325 seconds
[2022-06-05 07:00:02,114] {processor.py:153} INFO - Started process (PID=173) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:00:02,117] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:00:02,119] {logging_mixin.py:115} INFO - [2022-06-05 07:00:02,119] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:00:02,346] {logging_mixin.py:115} INFO - [2022-06-05 07:00:02,343] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:00:02,348] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:00:02,448] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.344 seconds
[2022-06-05 07:00:32,773] {processor.py:153} INFO - Started process (PID=239) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:00:32,775] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:00:32,776] {logging_mixin.py:115} INFO - [2022-06-05 07:00:32,776] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:00:32,988] {logging_mixin.py:115} INFO - [2022-06-05 07:00:32,983] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:00:32,991] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:00:33,116] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.346 seconds
[2022-06-05 07:01:04,013] {processor.py:153} INFO - Started process (PID=294) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:01:04,015] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:01:04,016] {logging_mixin.py:115} INFO - [2022-06-05 07:01:04,016] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:01:04,418] {logging_mixin.py:115} INFO - [2022-06-05 07:01:04,412] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:01:04,421] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:01:04,569] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.561 seconds
[2022-06-05 07:01:35,308] {processor.py:153} INFO - Started process (PID=358) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:01:35,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:01:35,312] {logging_mixin.py:115} INFO - [2022-06-05 07:01:35,312] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:01:35,635] {logging_mixin.py:115} INFO - [2022-06-05 07:01:35,633] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:01:35,643] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:01:35,799] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.494 seconds
[2022-06-05 07:02:06,674] {processor.py:153} INFO - Started process (PID=427) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:02:06,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:02:06,678] {logging_mixin.py:115} INFO - [2022-06-05 07:02:06,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:02:06,823] {logging_mixin.py:115} INFO - [2022-06-05 07:02:06,821] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:02:06,824] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:02:06,915] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-05 07:02:37,642] {processor.py:153} INFO - Started process (PID=494) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:02:37,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:02:37,648] {logging_mixin.py:115} INFO - [2022-06-05 07:02:37,648] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:02:37,831] {logging_mixin.py:115} INFO - [2022-06-05 07:02:37,829] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:02:37,832] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:02:37,925] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.292 seconds
[2022-06-05 07:03:08,546] {processor.py:153} INFO - Started process (PID=560) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:03:08,547] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:03:08,549] {logging_mixin.py:115} INFO - [2022-06-05 07:03:08,549] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:03:08,676] {logging_mixin.py:115} INFO - [2022-06-05 07:03:08,674] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:03:08,677] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:03:08,770] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 07:03:39,624] {processor.py:153} INFO - Started process (PID=624) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:03:39,626] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:03:39,628] {logging_mixin.py:115} INFO - [2022-06-05 07:03:39,628] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:03:39,770] {logging_mixin.py:115} INFO - [2022-06-05 07:03:39,768] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:03:39,772] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:03:39,879] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.259 seconds
[2022-06-05 07:04:10,897] {processor.py:153} INFO - Started process (PID=683) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:04:10,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:04:10,900] {logging_mixin.py:115} INFO - [2022-06-05 07:04:10,900] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:04:11,045] {logging_mixin.py:115} INFO - [2022-06-05 07:04:11,043] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:04:11,046] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:04:11,148] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.254 seconds
[2022-06-05 07:04:41,355] {processor.py:153} INFO - Started process (PID=750) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:04:41,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:04:41,363] {logging_mixin.py:115} INFO - [2022-06-05 07:04:41,363] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:04:41,502] {logging_mixin.py:115} INFO - [2022-06-05 07:04:41,500] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:04:41,503] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:04:41,595] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-05 07:05:11,808] {processor.py:153} INFO - Started process (PID=817) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:05:11,810] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:05:11,811] {logging_mixin.py:115} INFO - [2022-06-05 07:05:11,811] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:05:11,955] {logging_mixin.py:115} INFO - [2022-06-05 07:05:11,953] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:05:11,957] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:05:12,050] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.248 seconds
[2022-06-05 07:05:42,750] {processor.py:153} INFO - Started process (PID=886) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:05:42,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:05:42,757] {logging_mixin.py:115} INFO - [2022-06-05 07:05:42,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:05:42,889] {logging_mixin.py:115} INFO - [2022-06-05 07:05:42,887] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:05:42,890] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:05:42,984] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.242 seconds
[2022-06-05 07:06:13,333] {processor.py:153} INFO - Started process (PID=954) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:06:13,335] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:06:13,336] {logging_mixin.py:115} INFO - [2022-06-05 07:06:13,336] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:06:13,464] {logging_mixin.py:115} INFO - [2022-06-05 07:06:13,461] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:06:13,466] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:06:13,558] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 07:06:44,228] {processor.py:153} INFO - Started process (PID=1014) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:06:44,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:06:44,230] {logging_mixin.py:115} INFO - [2022-06-05 07:06:44,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:06:44,431] {logging_mixin.py:115} INFO - [2022-06-05 07:06:44,428] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:06:44,432] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:06:44,544] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.321 seconds
[2022-06-05 07:07:14,919] {processor.py:153} INFO - Started process (PID=1088) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:07:14,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:07:14,924] {logging_mixin.py:115} INFO - [2022-06-05 07:07:14,924] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:07:15,059] {logging_mixin.py:115} INFO - [2022-06-05 07:07:15,057] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:07:15,061] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:07:15,151] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 07:07:45,310] {processor.py:153} INFO - Started process (PID=1154) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:07:45,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:07:45,315] {logging_mixin.py:115} INFO - [2022-06-05 07:07:45,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:07:45,451] {logging_mixin.py:115} INFO - [2022-06-05 07:07:45,449] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:07:45,452] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:07:45,542] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 07:08:15,952] {processor.py:153} INFO - Started process (PID=1220) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:08:15,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:08:15,955] {logging_mixin.py:115} INFO - [2022-06-05 07:08:15,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:08:16,117] {logging_mixin.py:115} INFO - [2022-06-05 07:08:16,113] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:08:16,119] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:08:16,212] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-05 07:08:46,399] {processor.py:153} INFO - Started process (PID=1289) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:08:46,401] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:08:46,402] {logging_mixin.py:115} INFO - [2022-06-05 07:08:46,402] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:08:46,526] {logging_mixin.py:115} INFO - [2022-06-05 07:08:46,523] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:08:46,527] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:08:46,620] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 07:09:16,826] {processor.py:153} INFO - Started process (PID=1353) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:09:16,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:09:16,830] {logging_mixin.py:115} INFO - [2022-06-05 07:09:16,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:09:16,973] {logging_mixin.py:115} INFO - [2022-06-05 07:09:16,970] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:09:16,975] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:09:17,092] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.269 seconds
[2022-06-05 07:09:47,195] {processor.py:153} INFO - Started process (PID=1414) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:09:47,197] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:09:47,198] {logging_mixin.py:115} INFO - [2022-06-05 07:09:47,198] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:09:47,320] {logging_mixin.py:115} INFO - [2022-06-05 07:09:47,318] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:09:47,321] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:09:47,421] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 07:10:17,733] {processor.py:153} INFO - Started process (PID=1481) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:10:17,736] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:10:17,742] {logging_mixin.py:115} INFO - [2022-06-05 07:10:17,742] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:10:17,866] {logging_mixin.py:115} INFO - [2022-06-05 07:10:17,865] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:10:17,868] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:10:17,965] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 07:10:48,249] {processor.py:153} INFO - Started process (PID=1552) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:10:48,251] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:10:48,251] {logging_mixin.py:115} INFO - [2022-06-05 07:10:48,251] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:10:48,371] {logging_mixin.py:115} INFO - [2022-06-05 07:10:48,369] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:10:48,372] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:10:48,462] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-05 07:11:19,123] {processor.py:153} INFO - Started process (PID=1624) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:11:19,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:11:19,128] {logging_mixin.py:115} INFO - [2022-06-05 07:11:19,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:11:19,304] {logging_mixin.py:115} INFO - [2022-06-05 07:11:19,301] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:11:19,305] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:11:19,404] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.287 seconds
[2022-06-05 07:11:50,406] {processor.py:153} INFO - Started process (PID=1690) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:11:50,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:11:50,409] {logging_mixin.py:115} INFO - [2022-06-05 07:11:50,409] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:11:50,532] {logging_mixin.py:115} INFO - [2022-06-05 07:11:50,529] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:11:50,536] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:11:50,632] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 07:12:20,723] {processor.py:153} INFO - Started process (PID=1748) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:12:20,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:12:20,727] {logging_mixin.py:115} INFO - [2022-06-05 07:12:20,727] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:12:20,858] {logging_mixin.py:115} INFO - [2022-06-05 07:12:20,856] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:12:20,859] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:12:20,964] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-05 07:12:51,325] {processor.py:153} INFO - Started process (PID=1819) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:12:51,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:12:51,330] {logging_mixin.py:115} INFO - [2022-06-05 07:12:51,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:12:51,465] {logging_mixin.py:115} INFO - [2022-06-05 07:12:51,462] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:12:51,467] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:12:51,557] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 07:13:21,807] {processor.py:153} INFO - Started process (PID=1889) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:13:21,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:13:21,812] {logging_mixin.py:115} INFO - [2022-06-05 07:13:21,812] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:13:21,944] {logging_mixin.py:115} INFO - [2022-06-05 07:13:21,942] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:13:21,945] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:13:22,035] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 07:13:52,358] {processor.py:153} INFO - Started process (PID=1957) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:13:52,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:13:52,360] {logging_mixin.py:115} INFO - [2022-06-05 07:13:52,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:13:52,490] {logging_mixin.py:115} INFO - [2022-06-05 07:13:52,488] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:13:52,493] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:13:52,584] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 07:14:23,094] {processor.py:153} INFO - Started process (PID=2025) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:14:23,097] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:14:23,099] {logging_mixin.py:115} INFO - [2022-06-05 07:14:23,099] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:14:23,238] {logging_mixin.py:115} INFO - [2022-06-05 07:14:23,236] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:14:23,240] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:14:23,329] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 07:14:54,243] {processor.py:153} INFO - Started process (PID=2095) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:14:54,244] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:14:54,245] {logging_mixin.py:115} INFO - [2022-06-05 07:14:54,245] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:14:54,400] {logging_mixin.py:115} INFO - [2022-06-05 07:14:54,397] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:14:54,401] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:14:54,519] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.281 seconds
[2022-06-05 07:15:24,711] {processor.py:153} INFO - Started process (PID=2161) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:15:24,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:15:24,714] {logging_mixin.py:115} INFO - [2022-06-05 07:15:24,714] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:15:24,835] {logging_mixin.py:115} INFO - [2022-06-05 07:15:24,832] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:15:24,836] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:15:24,926] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-05 07:15:55,212] {processor.py:153} INFO - Started process (PID=2229) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:15:55,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:15:55,215] {logging_mixin.py:115} INFO - [2022-06-05 07:15:55,215] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:15:55,336] {logging_mixin.py:115} INFO - [2022-06-05 07:15:55,334] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:15:55,339] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:15:55,428] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-05 07:16:25,883] {processor.py:153} INFO - Started process (PID=2300) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:16:25,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:16:25,889] {logging_mixin.py:115} INFO - [2022-06-05 07:16:25,889] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:16:26,019] {logging_mixin.py:115} INFO - [2022-06-05 07:16:26,016] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:16:26,020] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:16:26,110] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 07:16:57,020] {processor.py:153} INFO - Started process (PID=2367) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:16:57,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:16:57,025] {logging_mixin.py:115} INFO - [2022-06-05 07:16:57,025] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:16:57,149] {logging_mixin.py:115} INFO - [2022-06-05 07:16:57,147] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:16:57,151] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:16:57,239] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-05 07:17:27,503] {processor.py:153} INFO - Started process (PID=2432) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:17:27,504] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:17:27,505] {logging_mixin.py:115} INFO - [2022-06-05 07:17:27,505] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:17:27,626] {logging_mixin.py:115} INFO - [2022-06-05 07:17:27,625] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:17:27,628] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:17:27,718] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-05 07:17:57,953] {processor.py:153} INFO - Started process (PID=2492) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:17:57,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:17:57,959] {logging_mixin.py:115} INFO - [2022-06-05 07:17:57,959] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:17:58,092] {logging_mixin.py:115} INFO - [2022-06-05 07:17:58,090] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:17:58,093] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:17:58,202] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-05 07:18:28,528] {processor.py:153} INFO - Started process (PID=2562) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:18:28,531] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:18:28,533] {logging_mixin.py:115} INFO - [2022-06-05 07:18:28,533] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:18:28,669] {logging_mixin.py:115} INFO - [2022-06-05 07:18:28,666] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:18:28,672] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:18:28,769] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 07:18:58,851] {processor.py:153} INFO - Started process (PID=2628) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:18:58,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:18:58,856] {logging_mixin.py:115} INFO - [2022-06-05 07:18:58,855] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:18:58,982] {logging_mixin.py:115} INFO - [2022-06-05 07:18:58,980] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:18:58,983] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:18:59,075] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-05 07:19:29,586] {processor.py:153} INFO - Started process (PID=2695) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:19:29,589] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:19:29,592] {logging_mixin.py:115} INFO - [2022-06-05 07:19:29,592] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:19:29,732] {logging_mixin.py:115} INFO - [2022-06-05 07:19:29,730] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:19:29,735] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:19:29,827] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-05 07:20:00,161] {processor.py:153} INFO - Started process (PID=2762) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:20:00,164] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:20:00,166] {logging_mixin.py:115} INFO - [2022-06-05 07:20:00,166] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:20:00,377] {logging_mixin.py:115} INFO - [2022-06-05 07:20:00,375] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:20:00,379] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:20:00,477] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.322 seconds
[2022-06-05 07:20:30,939] {processor.py:153} INFO - Started process (PID=2823) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:20:30,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:20:30,943] {logging_mixin.py:115} INFO - [2022-06-05 07:20:30,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:20:31,187] {logging_mixin.py:115} INFO - [2022-06-05 07:20:31,184] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:20:31,190] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:20:31,324] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.391 seconds
[2022-06-05 07:21:01,790] {processor.py:153} INFO - Started process (PID=2890) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:21:01,791] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:21:01,792] {logging_mixin.py:115} INFO - [2022-06-05 07:21:01,792] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:21:02,054] {logging_mixin.py:115} INFO - [2022-06-05 07:21:02,048] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:21:02,055] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:21:02,169] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.383 seconds
[2022-06-05 07:22:05,557] {processor.py:153} INFO - Started process (PID=34) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:22:05,562] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:22:05,564] {logging_mixin.py:115} INFO - [2022-06-05 07:22:05,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:22:05,805] {logging_mixin.py:115} INFO - [2022-06-05 07:22:05,802] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:22:05,806] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:22:05,953] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.399 seconds
[2022-06-05 07:22:36,978] {processor.py:153} INFO - Started process (PID=106) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:22:36,980] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:22:36,982] {logging_mixin.py:115} INFO - [2022-06-05 07:22:36,982] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:22:37,222] {logging_mixin.py:115} INFO - [2022-06-05 07:22:37,218] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:22:37,223] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:22:37,379] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.405 seconds
[2022-06-05 07:23:07,789] {processor.py:153} INFO - Started process (PID=174) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:23:07,791] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:23:07,792] {logging_mixin.py:115} INFO - [2022-06-05 07:23:07,792] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:23:07,910] {logging_mixin.py:115} INFO - [2022-06-05 07:23:07,908] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:23:07,912] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:23:08,006] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-05 07:23:38,191] {processor.py:153} INFO - Started process (PID=232) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:23:38,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:23:38,195] {logging_mixin.py:115} INFO - [2022-06-05 07:23:38,195] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:23:38,352] {logging_mixin.py:115} INFO - [2022-06-05 07:23:38,350] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:23:38,354] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:23:38,447] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.261 seconds
[2022-06-05 07:24:08,755] {processor.py:153} INFO - Started process (PID=301) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:24:08,757] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:24:08,759] {logging_mixin.py:115} INFO - [2022-06-05 07:24:08,759] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:24:08,885] {logging_mixin.py:115} INFO - [2022-06-05 07:24:08,883] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:24:08,886] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:24:08,977] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 07:24:39,105] {processor.py:153} INFO - Started process (PID=371) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:24:39,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:24:39,110] {logging_mixin.py:115} INFO - [2022-06-05 07:24:39,110] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:24:39,255] {logging_mixin.py:115} INFO - [2022-06-05 07:24:39,253] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:24:39,256] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:24:39,353] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-05 07:25:09,527] {processor.py:153} INFO - Started process (PID=439) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:25:09,530] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:25:09,533] {logging_mixin.py:115} INFO - [2022-06-05 07:25:09,533] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:25:09,674] {logging_mixin.py:115} INFO - [2022-06-05 07:25:09,672] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:25:09,675] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:25:09,768] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-05 07:25:39,799] {processor.py:153} INFO - Started process (PID=504) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:25:39,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:25:39,802] {logging_mixin.py:115} INFO - [2022-06-05 07:25:39,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:25:39,968] {logging_mixin.py:115} INFO - [2022-06-05 07:25:39,966] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:25:39,969] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:25:40,092] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.297 seconds
[2022-06-05 07:26:10,295] {processor.py:153} INFO - Started process (PID=564) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:26:10,297] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:26:10,299] {logging_mixin.py:115} INFO - [2022-06-05 07:26:10,299] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:26:10,420] {logging_mixin.py:115} INFO - [2022-06-05 07:26:10,418] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:26:10,422] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:26:10,514] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 07:26:41,442] {processor.py:153} INFO - Started process (PID=630) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:26:41,444] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:26:41,446] {logging_mixin.py:115} INFO - [2022-06-05 07:26:41,446] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:26:41,582] {logging_mixin.py:115} INFO - [2022-06-05 07:26:41,580] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:26:41,584] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:26:41,685] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.248 seconds
[2022-06-05 07:27:11,975] {processor.py:153} INFO - Started process (PID=698) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:27:11,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:27:11,978] {logging_mixin.py:115} INFO - [2022-06-05 07:27:11,978] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:27:12,095] {logging_mixin.py:115} INFO - [2022-06-05 07:27:12,093] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:27:12,096] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:27:12,188] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-05 07:27:42,227] {processor.py:153} INFO - Started process (PID=764) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:27:42,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:27:42,233] {logging_mixin.py:115} INFO - [2022-06-05 07:27:42,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:27:42,363] {logging_mixin.py:115} INFO - [2022-06-05 07:27:42,361] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:27:42,365] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:27:42,457] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 07:28:12,593] {processor.py:153} INFO - Started process (PID=832) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:28:12,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:28:12,596] {logging_mixin.py:115} INFO - [2022-06-05 07:28:12,596] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:28:12,747] {logging_mixin.py:115} INFO - [2022-06-05 07:28:12,743] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:28:12,748] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:28:12,856] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.266 seconds
[2022-06-05 07:28:43,793] {processor.py:153} INFO - Started process (PID=891) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:28:43,797] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:28:43,799] {logging_mixin.py:115} INFO - [2022-06-05 07:28:43,798] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:28:43,931] {logging_mixin.py:115} INFO - [2022-06-05 07:28:43,929] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:28:43,933] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:28:44,029] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 07:29:14,307] {processor.py:153} INFO - Started process (PID=960) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:29:14,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:29:14,311] {logging_mixin.py:115} INFO - [2022-06-05 07:29:14,311] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:29:14,454] {logging_mixin.py:115} INFO - [2022-06-05 07:29:14,452] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:29:14,455] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:29:14,547] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-05 07:29:44,902] {processor.py:153} INFO - Started process (PID=1029) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:29:44,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:29:44,906] {logging_mixin.py:115} INFO - [2022-06-05 07:29:44,906] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:29:45,043] {logging_mixin.py:115} INFO - [2022-06-05 07:29:45,042] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:29:45,046] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:29:45,141] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 07:30:16,084] {processor.py:153} INFO - Started process (PID=1095) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:30:16,086] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:30:16,089] {logging_mixin.py:115} INFO - [2022-06-05 07:30:16,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:30:16,233] {logging_mixin.py:115} INFO - [2022-06-05 07:30:16,231] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:30:16,234] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:30:16,328] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.250 seconds
[2022-06-05 07:30:46,391] {processor.py:153} INFO - Started process (PID=1162) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:30:46,393] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:30:46,395] {logging_mixin.py:115} INFO - [2022-06-05 07:30:46,395] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:30:46,541] {logging_mixin.py:115} INFO - [2022-06-05 07:30:46,539] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:30:46,543] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:30:46,635] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-05 07:31:17,145] {processor.py:153} INFO - Started process (PID=1229) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:31:17,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:31:17,147] {logging_mixin.py:115} INFO - [2022-06-05 07:31:17,147] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:31:17,273] {logging_mixin.py:115} INFO - [2022-06-05 07:31:17,270] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:31:17,275] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:31:17,374] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 07:31:47,606] {processor.py:153} INFO - Started process (PID=1286) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:31:47,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:31:47,609] {logging_mixin.py:115} INFO - [2022-06-05 07:31:47,609] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:31:47,743] {logging_mixin.py:115} INFO - [2022-06-05 07:31:47,741] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:31:47,744] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:31:47,840] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 07:32:18,103] {processor.py:153} INFO - Started process (PID=1353) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:32:18,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:32:18,106] {logging_mixin.py:115} INFO - [2022-06-05 07:32:18,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:32:18,240] {logging_mixin.py:115} INFO - [2022-06-05 07:32:18,238] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:32:18,241] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:32:18,340] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 07:32:48,490] {processor.py:153} INFO - Started process (PID=1420) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:32:48,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:32:48,495] {logging_mixin.py:115} INFO - [2022-06-05 07:32:48,495] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:32:48,627] {logging_mixin.py:115} INFO - [2022-06-05 07:32:48,625] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:32:48,629] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:32:48,721] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 07:33:18,781] {processor.py:153} INFO - Started process (PID=1489) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:33:18,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:33:18,787] {logging_mixin.py:115} INFO - [2022-06-05 07:33:18,786] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:33:18,923] {logging_mixin.py:115} INFO - [2022-06-05 07:33:18,921] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:33:18,926] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:33:19,019] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-05 07:33:49,155] {processor.py:153} INFO - Started process (PID=1559) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:33:49,157] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:33:49,158] {logging_mixin.py:115} INFO - [2022-06-05 07:33:49,158] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:33:49,295] {logging_mixin.py:115} INFO - [2022-06-05 07:33:49,293] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:33:49,296] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:33:49,417] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.265 seconds
[2022-06-05 07:34:20,147] {processor.py:153} INFO - Started process (PID=1618) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:34:20,150] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:34:20,151] {logging_mixin.py:115} INFO - [2022-06-05 07:34:20,151] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:34:20,291] {logging_mixin.py:115} INFO - [2022-06-05 07:34:20,289] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:34:20,293] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:34:20,393] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.251 seconds
[2022-06-05 07:34:51,181] {processor.py:153} INFO - Started process (PID=1686) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:34:51,184] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:34:51,186] {logging_mixin.py:115} INFO - [2022-06-05 07:34:51,186] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:34:51,353] {logging_mixin.py:115} INFO - [2022-06-05 07:34:51,351] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:34:51,355] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:34:51,448] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.273 seconds
[2022-06-05 07:35:21,568] {processor.py:153} INFO - Started process (PID=1755) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:35:21,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:35:21,574] {logging_mixin.py:115} INFO - [2022-06-05 07:35:21,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:35:21,706] {logging_mixin.py:115} INFO - [2022-06-05 07:35:21,702] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:35:21,708] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:35:21,799] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 07:35:51,934] {processor.py:153} INFO - Started process (PID=1822) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:35:51,936] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:35:51,938] {logging_mixin.py:115} INFO - [2022-06-05 07:35:51,937] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:35:52,065] {logging_mixin.py:115} INFO - [2022-06-05 07:35:52,063] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:35:52,067] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:35:52,160] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 07:36:22,253] {processor.py:153} INFO - Started process (PID=1891) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:36:22,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:36:22,258] {logging_mixin.py:115} INFO - [2022-06-05 07:36:22,258] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:36:22,387] {logging_mixin.py:115} INFO - [2022-06-05 07:36:22,385] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:36:22,388] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:36:22,478] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 07:36:52,661] {processor.py:153} INFO - Started process (PID=1957) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:36:52,664] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:36:52,666] {logging_mixin.py:115} INFO - [2022-06-05 07:36:52,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:36:52,809] {logging_mixin.py:115} INFO - [2022-06-05 07:36:52,807] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:36:52,810] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:36:52,902] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-05 07:37:23,297] {processor.py:153} INFO - Started process (PID=2013) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:37:23,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:37:23,302] {logging_mixin.py:115} INFO - [2022-06-05 07:37:23,302] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:37:23,434] {logging_mixin.py:115} INFO - [2022-06-05 07:37:23,432] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:37:23,437] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:37:23,528] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 07:37:53,803] {processor.py:153} INFO - Started process (PID=2080) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:37:53,806] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:37:53,808] {logging_mixin.py:115} INFO - [2022-06-05 07:37:53,808] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:37:53,973] {logging_mixin.py:115} INFO - [2022-06-05 07:37:53,971] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:37:53,974] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:37:54,085] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.288 seconds
[2022-06-05 07:38:25,035] {processor.py:153} INFO - Started process (PID=2149) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:38:25,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:38:25,042] {logging_mixin.py:115} INFO - [2022-06-05 07:38:25,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:38:25,166] {logging_mixin.py:115} INFO - [2022-06-05 07:38:25,164] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:38:25,167] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:38:25,261] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 07:38:56,149] {processor.py:153} INFO - Started process (PID=2217) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:38:56,152] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:38:56,154] {logging_mixin.py:115} INFO - [2022-06-05 07:38:56,154] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:38:56,281] {logging_mixin.py:115} INFO - [2022-06-05 07:38:56,280] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:38:56,282] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:38:56,376] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 07:39:27,367] {processor.py:153} INFO - Started process (PID=2285) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:39:27,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:39:27,370] {logging_mixin.py:115} INFO - [2022-06-05 07:39:27,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:39:27,486] {logging_mixin.py:115} INFO - [2022-06-05 07:39:27,484] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:39:27,487] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:39:27,579] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-05 07:39:58,057] {processor.py:153} INFO - Started process (PID=2351) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:39:58,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:39:58,059] {logging_mixin.py:115} INFO - [2022-06-05 07:39:58,059] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:39:58,180] {logging_mixin.py:115} INFO - [2022-06-05 07:39:58,178] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:39:58,182] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:39:58,283] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 07:40:29,262] {processor.py:153} INFO - Started process (PID=2419) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:40:29,264] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:40:29,268] {logging_mixin.py:115} INFO - [2022-06-05 07:40:29,268] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:40:29,395] {logging_mixin.py:115} INFO - [2022-06-05 07:40:29,393] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:40:29,397] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:40:29,491] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 07:40:59,620] {processor.py:153} INFO - Started process (PID=2477) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:40:59,622] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:40:59,623] {logging_mixin.py:115} INFO - [2022-06-05 07:40:59,623] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:40:59,780] {logging_mixin.py:115} INFO - [2022-06-05 07:40:59,778] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:40:59,782] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:40:59,880] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-05 07:41:30,107] {processor.py:153} INFO - Started process (PID=2543) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:41:30,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:41:30,110] {logging_mixin.py:115} INFO - [2022-06-05 07:41:30,109] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:41:30,234] {logging_mixin.py:115} INFO - [2022-06-05 07:41:30,232] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:41:30,235] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:41:30,337] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 07:42:00,416] {processor.py:153} INFO - Started process (PID=2610) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:42:00,419] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:42:00,421] {logging_mixin.py:115} INFO - [2022-06-05 07:42:00,421] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:42:00,573] {logging_mixin.py:115} INFO - [2022-06-05 07:42:00,570] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:42:00,575] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:42:00,667] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-05 07:42:30,857] {processor.py:153} INFO - Started process (PID=2675) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:42:30,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:42:30,860] {logging_mixin.py:115} INFO - [2022-06-05 07:42:30,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:42:30,979] {logging_mixin.py:115} INFO - [2022-06-05 07:42:30,977] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:42:30,980] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:42:31,074] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-05 07:43:01,294] {processor.py:153} INFO - Started process (PID=2743) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:43:01,296] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:43:01,297] {logging_mixin.py:115} INFO - [2022-06-05 07:43:01,297] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:43:01,411] {logging_mixin.py:115} INFO - [2022-06-05 07:43:01,409] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:43:01,412] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:43:01,505] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-05 07:43:31,705] {processor.py:153} INFO - Started process (PID=2812) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:43:31,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:43:31,708] {logging_mixin.py:115} INFO - [2022-06-05 07:43:31,708] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:43:31,835] {logging_mixin.py:115} INFO - [2022-06-05 07:43:31,833] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:43:31,836] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:43:31,930] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-05 07:44:02,063] {processor.py:153} INFO - Started process (PID=2872) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:44:02,064] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:44:02,065] {logging_mixin.py:115} INFO - [2022-06-05 07:44:02,065] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:44:02,198] {logging_mixin.py:115} INFO - [2022-06-05 07:44:02,195] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:44:02,200] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:44:02,308] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-05 07:44:32,496] {processor.py:153} INFO - Started process (PID=2941) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:44:32,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:44:32,498] {logging_mixin.py:115} INFO - [2022-06-05 07:44:32,498] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:44:32,615] {logging_mixin.py:115} INFO - [2022-06-05 07:44:32,613] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:44:32,616] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:44:32,708] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-05 07:45:03,606] {processor.py:153} INFO - Started process (PID=3007) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:45:03,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:45:03,610] {logging_mixin.py:115} INFO - [2022-06-05 07:45:03,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:45:03,732] {logging_mixin.py:115} INFO - [2022-06-05 07:45:03,730] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:45:03,734] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:45:03,828] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-05 07:45:33,896] {processor.py:153} INFO - Started process (PID=3075) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:45:33,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:45:33,901] {logging_mixin.py:115} INFO - [2022-06-05 07:45:33,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:45:34,026] {logging_mixin.py:115} INFO - [2022-06-05 07:45:34,024] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:45:34,028] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:45:34,117] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-05 07:46:05,105] {processor.py:153} INFO - Started process (PID=3145) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:46:05,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:46:05,107] {logging_mixin.py:115} INFO - [2022-06-05 07:46:05,107] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:46:05,228] {logging_mixin.py:115} INFO - [2022-06-05 07:46:05,226] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:46:05,229] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:46:05,321] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-05 07:46:35,539] {processor.py:153} INFO - Started process (PID=3211) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:46:35,540] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:46:35,541] {logging_mixin.py:115} INFO - [2022-06-05 07:46:35,541] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:46:35,665] {logging_mixin.py:115} INFO - [2022-06-05 07:46:35,662] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:46:35,666] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:46:35,762] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-05 07:47:06,709] {processor.py:153} INFO - Started process (PID=3268) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:47:06,710] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:47:06,711] {logging_mixin.py:115} INFO - [2022-06-05 07:47:06,711] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:47:06,833] {logging_mixin.py:115} INFO - [2022-06-05 07:47:06,831] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:47:06,834] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:47:06,958] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-05 07:47:37,261] {processor.py:153} INFO - Started process (PID=3336) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:47:37,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:47:37,264] {logging_mixin.py:115} INFO - [2022-06-05 07:47:37,264] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:47:37,411] {logging_mixin.py:115} INFO - [2022-06-05 07:47:37,410] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:47:37,414] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:47:37,522] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-05 07:48:08,463] {processor.py:153} INFO - Started process (PID=3405) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:48:08,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:48:08,467] {logging_mixin.py:115} INFO - [2022-06-05 07:48:08,467] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:48:08,604] {logging_mixin.py:115} INFO - [2022-06-05 07:48:08,602] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:48:08,605] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:48:08,695] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 07:48:39,400] {processor.py:153} INFO - Started process (PID=3476) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:48:39,402] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:48:39,403] {logging_mixin.py:115} INFO - [2022-06-05 07:48:39,403] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:48:39,558] {logging_mixin.py:115} INFO - [2022-06-05 07:48:39,557] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:48:39,560] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:48:39,662] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.265 seconds
[2022-06-05 07:49:10,266] {processor.py:153} INFO - Started process (PID=3544) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:49:10,268] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:49:10,270] {logging_mixin.py:115} INFO - [2022-06-05 07:49:10,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:49:10,413] {logging_mixin.py:115} INFO - [2022-06-05 07:49:10,411] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:49:10,414] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:49:10,503] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-05 07:49:41,177] {processor.py:153} INFO - Started process (PID=3611) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:49:41,180] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:49:41,182] {logging_mixin.py:115} INFO - [2022-06-05 07:49:41,182] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:49:41,330] {logging_mixin.py:115} INFO - [2022-06-05 07:49:41,328] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:49:41,332] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:49:41,427] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-05 07:50:11,911] {processor.py:153} INFO - Started process (PID=3679) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:50:11,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:50:11,913] {logging_mixin.py:115} INFO - [2022-06-05 07:50:11,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:50:12,039] {logging_mixin.py:115} INFO - [2022-06-05 07:50:12,037] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:50:12,040] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:50:12,132] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-05 07:50:42,227] {processor.py:153} INFO - Started process (PID=3737) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:50:42,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:50:42,229] {logging_mixin.py:115} INFO - [2022-06-05 07:50:42,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:50:42,357] {logging_mixin.py:115} INFO - [2022-06-05 07:50:42,355] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:50:42,359] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:50:42,456] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 07:51:12,490] {processor.py:153} INFO - Started process (PID=3805) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:51:12,492] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:51:12,493] {logging_mixin.py:115} INFO - [2022-06-05 07:51:12,493] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:51:12,618] {logging_mixin.py:115} INFO - [2022-06-05 07:51:12,615] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:51:12,619] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:51:12,719] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 07:51:42,824] {processor.py:153} INFO - Started process (PID=3873) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:51:42,826] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:51:42,828] {logging_mixin.py:115} INFO - [2022-06-05 07:51:42,828] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:51:42,946] {logging_mixin.py:115} INFO - [2022-06-05 07:51:42,944] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:51:42,948] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:51:43,041] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-05 07:52:13,337] {processor.py:153} INFO - Started process (PID=3940) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:52:13,339] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:52:13,341] {logging_mixin.py:115} INFO - [2022-06-05 07:52:13,341] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:52:13,460] {logging_mixin.py:115} INFO - [2022-06-05 07:52:13,458] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:52:13,461] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:52:13,552] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-05 07:52:43,590] {processor.py:153} INFO - Started process (PID=4010) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:52:43,592] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:52:43,594] {logging_mixin.py:115} INFO - [2022-06-05 07:52:43,594] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:52:43,710] {logging_mixin.py:115} INFO - [2022-06-05 07:52:43,708] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:52:43,711] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:52:43,803] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-05 07:53:14,202] {processor.py:153} INFO - Started process (PID=4078) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:53:14,204] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:53:14,205] {logging_mixin.py:115} INFO - [2022-06-05 07:53:14,205] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:53:14,329] {logging_mixin.py:115} INFO - [2022-06-05 07:53:14,326] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:53:14,331] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:53:14,426] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-05 07:53:44,991] {processor.py:153} INFO - Started process (PID=4138) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:53:44,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:53:44,994] {logging_mixin.py:115} INFO - [2022-06-05 07:53:44,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:53:45,111] {logging_mixin.py:115} INFO - [2022-06-05 07:53:45,108] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:53:45,112] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:53:45,206] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-05 07:54:15,881] {processor.py:153} INFO - Started process (PID=4205) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:54:15,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:54:15,883] {logging_mixin.py:115} INFO - [2022-06-05 07:54:15,883] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:54:16,005] {logging_mixin.py:115} INFO - [2022-06-05 07:54:16,004] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:54:16,008] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:54:16,101] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 07:54:47,029] {processor.py:153} INFO - Started process (PID=4271) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:54:47,035] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:54:47,038] {logging_mixin.py:115} INFO - [2022-06-05 07:54:47,038] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:54:47,180] {logging_mixin.py:115} INFO - [2022-06-05 07:54:47,178] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:54:47,182] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:54:47,272] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-05 07:55:18,244] {processor.py:153} INFO - Started process (PID=4337) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:55:18,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:55:18,249] {logging_mixin.py:115} INFO - [2022-06-05 07:55:18,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:55:18,394] {logging_mixin.py:115} INFO - [2022-06-05 07:55:18,392] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:55:18,397] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:55:18,492] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-05 07:55:48,689] {processor.py:153} INFO - Started process (PID=4405) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:55:48,692] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:55:48,694] {logging_mixin.py:115} INFO - [2022-06-05 07:55:48,694] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:55:48,823] {logging_mixin.py:115} INFO - [2022-06-05 07:55:48,821] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:55:48,824] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:55:48,920] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 07:56:19,010] {processor.py:153} INFO - Started process (PID=4473) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:56:19,012] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:56:19,014] {logging_mixin.py:115} INFO - [2022-06-05 07:56:19,014] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:56:19,131] {logging_mixin.py:115} INFO - [2022-06-05 07:56:19,128] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:56:19,133] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:56:19,226] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-05 07:56:49,597] {processor.py:153} INFO - Started process (PID=4530) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:56:49,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:56:49,602] {logging_mixin.py:115} INFO - [2022-06-05 07:56:49,601] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:56:49,725] {logging_mixin.py:115} INFO - [2022-06-05 07:56:49,723] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:56:49,726] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:56:49,823] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 07:57:20,088] {processor.py:153} INFO - Started process (PID=4597) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:57:20,090] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:57:20,092] {logging_mixin.py:115} INFO - [2022-06-05 07:57:20,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:57:20,243] {logging_mixin.py:115} INFO - [2022-06-05 07:57:20,238] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:57:20,245] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:57:20,357] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.271 seconds
[2022-06-05 07:57:50,530] {processor.py:153} INFO - Started process (PID=4664) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:57:50,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:57:50,533] {logging_mixin.py:115} INFO - [2022-06-05 07:57:50,533] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:57:50,663] {logging_mixin.py:115} INFO - [2022-06-05 07:57:50,660] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:57:50,664] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:57:50,757] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 07:58:20,843] {processor.py:153} INFO - Started process (PID=4732) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:58:20,844] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:58:20,845] {logging_mixin.py:115} INFO - [2022-06-05 07:58:20,845] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:58:20,967] {logging_mixin.py:115} INFO - [2022-06-05 07:58:20,965] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:58:20,970] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:58:21,060] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-05 07:58:51,902] {processor.py:153} INFO - Started process (PID=4800) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:58:51,905] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:58:51,907] {logging_mixin.py:115} INFO - [2022-06-05 07:58:51,907] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:58:52,044] {logging_mixin.py:115} INFO - [2022-06-05 07:58:52,041] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:58:52,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:58:52,139] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 07:59:22,241] {processor.py:153} INFO - Started process (PID=4869) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:59:22,243] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:59:22,244] {logging_mixin.py:115} INFO - [2022-06-05 07:59:22,244] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:59:22,393] {logging_mixin.py:115} INFO - [2022-06-05 07:59:22,390] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:59:22,394] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:59:22,491] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-05 07:59:52,670] {processor.py:153} INFO - Started process (PID=4926) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:59:52,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 07:59:52,674] {logging_mixin.py:115} INFO - [2022-06-05 07:59:52,674] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:59:52,819] {logging_mixin.py:115} INFO - [2022-06-05 07:59:52,817] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 07:59:52,821] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 07:59:52,928] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.260 seconds
[2022-06-05 08:00:23,086] {processor.py:153} INFO - Started process (PID=4996) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:00:23,090] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:00:23,092] {logging_mixin.py:115} INFO - [2022-06-05 08:00:23,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:00:23,215] {logging_mixin.py:115} INFO - [2022-06-05 08:00:23,214] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:00:23,216] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:00:23,308] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-05 08:00:53,476] {processor.py:153} INFO - Started process (PID=5062) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:00:53,479] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:00:53,481] {logging_mixin.py:115} INFO - [2022-06-05 08:00:53,481] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:00:53,619] {logging_mixin.py:115} INFO - [2022-06-05 08:00:53,617] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:00:53,620] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:00:53,716] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-05 08:01:23,956] {processor.py:153} INFO - Started process (PID=5130) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:01:23,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:01:23,961] {logging_mixin.py:115} INFO - [2022-06-05 08:01:23,961] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:01:24,110] {logging_mixin.py:115} INFO - [2022-06-05 08:01:24,108] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:01:24,111] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:01:24,203] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.257 seconds
[2022-06-05 08:01:54,270] {processor.py:153} INFO - Started process (PID=5201) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:01:54,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:01:54,277] {logging_mixin.py:115} INFO - [2022-06-05 08:01:54,277] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:01:54,406] {logging_mixin.py:115} INFO - [2022-06-05 08:01:54,403] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:01:54,407] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:01:54,506] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 08:02:24,916] {processor.py:153} INFO - Started process (PID=5255) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:02:24,918] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:02:24,920] {logging_mixin.py:115} INFO - [2022-06-05 08:02:24,920] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:02:25,050] {logging_mixin.py:115} INFO - [2022-06-05 08:02:25,048] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:02:25,051] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:02:25,171] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.258 seconds
[2022-06-05 08:02:55,323] {processor.py:153} INFO - Started process (PID=5322) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:02:55,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:02:55,328] {logging_mixin.py:115} INFO - [2022-06-05 08:02:55,328] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:02:55,462] {logging_mixin.py:115} INFO - [2022-06-05 08:02:55,460] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:02:55,464] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:02:55,555] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 08:03:26,247] {processor.py:153} INFO - Started process (PID=5390) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:03:26,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:03:26,250] {logging_mixin.py:115} INFO - [2022-06-05 08:03:26,250] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:03:26,369] {logging_mixin.py:115} INFO - [2022-06-05 08:03:26,366] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:03:26,370] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:03:26,458] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-05 08:03:56,501] {processor.py:153} INFO - Started process (PID=5458) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:03:56,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:03:56,505] {logging_mixin.py:115} INFO - [2022-06-05 08:03:56,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:03:56,624] {logging_mixin.py:115} INFO - [2022-06-05 08:03:56,622] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:03:56,626] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:03:56,717] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-05 08:04:26,787] {processor.py:153} INFO - Started process (PID=5528) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:04:26,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:04:26,792] {logging_mixin.py:115} INFO - [2022-06-05 08:04:26,792] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:04:26,925] {logging_mixin.py:115} INFO - [2022-06-05 08:04:26,924] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:04:26,926] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:04:27,019] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 08:04:57,258] {processor.py:153} INFO - Started process (PID=5587) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:04:57,260] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:04:57,263] {logging_mixin.py:115} INFO - [2022-06-05 08:04:57,262] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:04:57,406] {logging_mixin.py:115} INFO - [2022-06-05 08:04:57,404] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:04:57,408] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:04:57,508] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-05 08:05:28,372] {processor.py:153} INFO - Started process (PID=5654) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:05:28,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:05:28,375] {logging_mixin.py:115} INFO - [2022-06-05 08:05:28,375] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:05:28,496] {logging_mixin.py:115} INFO - [2022-06-05 08:05:28,495] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:05:28,498] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:05:28,595] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-05 08:05:59,226] {processor.py:153} INFO - Started process (PID=5721) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:05:59,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:05:59,231] {logging_mixin.py:115} INFO - [2022-06-05 08:05:59,231] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:05:59,370] {logging_mixin.py:115} INFO - [2022-06-05 08:05:59,367] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:05:59,370] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:05:59,464] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 08:06:30,339] {processor.py:153} INFO - Started process (PID=5790) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:06:30,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:06:30,344] {logging_mixin.py:115} INFO - [2022-06-05 08:06:30,344] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:06:30,471] {logging_mixin.py:115} INFO - [2022-06-05 08:06:30,469] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:06:30,472] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:06:30,568] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 08:07:01,133] {processor.py:153} INFO - Started process (PID=5859) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:07:01,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:07:01,141] {logging_mixin.py:115} INFO - [2022-06-05 08:07:01,141] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:07:01,272] {logging_mixin.py:115} INFO - [2022-06-05 08:07:01,270] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:07:01,273] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:07:01,371] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 08:07:32,240] {processor.py:153} INFO - Started process (PID=5930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:07:32,243] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:07:32,245] {logging_mixin.py:115} INFO - [2022-06-05 08:07:32,245] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:07:32,382] {logging_mixin.py:115} INFO - [2022-06-05 08:07:32,380] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:07:32,383] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:07:32,478] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-05 08:08:02,700] {processor.py:153} INFO - Started process (PID=5998) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:08:02,701] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:08:02,702] {logging_mixin.py:115} INFO - [2022-06-05 08:08:02,702] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:08:02,832] {logging_mixin.py:115} INFO - [2022-06-05 08:08:02,829] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:08:02,833] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:08:02,943] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.248 seconds
[2022-06-05 08:08:33,340] {processor.py:153} INFO - Started process (PID=6055) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:08:33,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:08:33,344] {logging_mixin.py:115} INFO - [2022-06-05 08:08:33,344] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:08:33,467] {logging_mixin.py:115} INFO - [2022-06-05 08:08:33,465] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:08:33,469] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:08:33,562] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-05 08:09:03,845] {processor.py:153} INFO - Started process (PID=6124) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:09:03,848] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:09:03,852] {logging_mixin.py:115} INFO - [2022-06-05 08:09:03,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:09:03,981] {logging_mixin.py:115} INFO - [2022-06-05 08:09:03,979] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:09:03,982] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:09:04,073] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 08:09:34,220] {processor.py:153} INFO - Started process (PID=6195) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:09:34,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:09:34,223] {logging_mixin.py:115} INFO - [2022-06-05 08:09:34,223] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:09:34,339] {logging_mixin.py:115} INFO - [2022-06-05 08:09:34,337] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:09:34,341] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:09:34,433] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-05 08:10:04,642] {processor.py:153} INFO - Started process (PID=6267) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:10:04,645] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:10:04,647] {logging_mixin.py:115} INFO - [2022-06-05 08:10:04,647] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:10:04,779] {logging_mixin.py:115} INFO - [2022-06-05 08:10:04,777] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:10:04,780] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:10:04,872] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 08:10:34,908] {processor.py:153} INFO - Started process (PID=6337) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:10:34,910] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:10:34,912] {logging_mixin.py:115} INFO - [2022-06-05 08:10:34,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:10:35,050] {logging_mixin.py:115} INFO - [2022-06-05 08:10:35,047] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:10:35,052] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:10:35,152] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-05 08:11:05,211] {processor.py:153} INFO - Started process (PID=6394) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:11:05,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:11:05,216] {logging_mixin.py:115} INFO - [2022-06-05 08:11:05,215] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:11:05,338] {logging_mixin.py:115} INFO - [2022-06-05 08:11:05,336] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:11:05,339] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:11:05,431] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-05 08:11:35,577] {processor.py:153} INFO - Started process (PID=6466) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:11:35,581] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:11:35,583] {logging_mixin.py:115} INFO - [2022-06-05 08:11:35,583] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:11:35,724] {logging_mixin.py:115} INFO - [2022-06-05 08:11:35,722] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:11:35,726] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:11:35,822] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.250 seconds
[2022-06-05 08:12:06,212] {processor.py:153} INFO - Started process (PID=6532) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:12:06,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:12:06,216] {logging_mixin.py:115} INFO - [2022-06-05 08:12:06,216] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:12:06,352] {logging_mixin.py:115} INFO - [2022-06-05 08:12:06,350] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:12:06,353] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:12:06,447] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 08:12:36,700] {processor.py:153} INFO - Started process (PID=6600) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:12:36,704] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:12:36,706] {logging_mixin.py:115} INFO - [2022-06-05 08:12:36,706] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:12:36,841] {logging_mixin.py:115} INFO - [2022-06-05 08:12:36,838] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:12:36,843] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:12:36,933] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 08:13:07,905] {processor.py:153} INFO - Started process (PID=6669) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:13:07,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:13:07,910] {logging_mixin.py:115} INFO - [2022-06-05 08:13:07,910] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:13:08,031] {logging_mixin.py:115} INFO - [2022-06-05 08:13:08,029] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:13:08,033] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:13:08,128] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 08:13:39,107] {processor.py:153} INFO - Started process (PID=6738) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:13:39,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:13:39,111] {logging_mixin.py:115} INFO - [2022-06-05 08:13:39,111] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:13:39,230] {logging_mixin.py:115} INFO - [2022-06-05 08:13:39,228] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:13:39,231] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:13:39,329] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.224 seconds
[2022-06-05 08:14:09,420] {processor.py:153} INFO - Started process (PID=6795) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:14:09,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:14:09,422] {logging_mixin.py:115} INFO - [2022-06-05 08:14:09,422] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:14:09,541] {logging_mixin.py:115} INFO - [2022-06-05 08:14:09,539] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:14:09,542] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:14:09,634] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-05 08:14:40,073] {processor.py:153} INFO - Started process (PID=6863) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:14:40,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:14:40,075] {logging_mixin.py:115} INFO - [2022-06-05 08:14:40,075] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:14:40,208] {logging_mixin.py:115} INFO - [2022-06-05 08:14:40,204] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:14:40,210] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:14:40,308] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 08:15:10,350] {processor.py:153} INFO - Started process (PID=6930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:15:10,353] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:15:10,354] {logging_mixin.py:115} INFO - [2022-06-05 08:15:10,354] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:15:10,484] {logging_mixin.py:115} INFO - [2022-06-05 08:15:10,475] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:15:10,486] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:15:10,577] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 08:15:40,891] {processor.py:153} INFO - Started process (PID=6999) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:15:40,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:15:40,894] {logging_mixin.py:115} INFO - [2022-06-05 08:15:40,894] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:15:41,007] {logging_mixin.py:115} INFO - [2022-06-05 08:15:41,004] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:15:41,008] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:15:41,098] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.210 seconds
[2022-06-05 08:16:11,200] {processor.py:153} INFO - Started process (PID=7065) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:16:11,202] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:16:11,203] {logging_mixin.py:115} INFO - [2022-06-05 08:16:11,203] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:16:11,317] {logging_mixin.py:115} INFO - [2022-06-05 08:16:11,315] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:16:11,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:16:11,410] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-05 08:16:41,599] {processor.py:153} INFO - Started process (PID=7137) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:16:41,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:16:41,602] {logging_mixin.py:115} INFO - [2022-06-05 08:16:41,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:16:41,746] {logging_mixin.py:115} INFO - [2022-06-05 08:16:41,744] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:16:41,747] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:16:41,867] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.271 seconds
[2022-06-05 08:17:12,132] {processor.py:153} INFO - Started process (PID=7195) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:17:12,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:17:12,137] {logging_mixin.py:115} INFO - [2022-06-05 08:17:12,137] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:17:12,263] {logging_mixin.py:115} INFO - [2022-06-05 08:17:12,260] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:17:12,265] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:17:12,356] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 08:17:42,491] {processor.py:153} INFO - Started process (PID=7264) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:17:42,492] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:17:42,494] {logging_mixin.py:115} INFO - [2022-06-05 08:17:42,494] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:17:42,610] {logging_mixin.py:115} INFO - [2022-06-05 08:17:42,606] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:17:42,611] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:17:42,704] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-05 08:18:12,913] {processor.py:153} INFO - Started process (PID=7334) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:18:12,916] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:18:12,917] {logging_mixin.py:115} INFO - [2022-06-05 08:18:12,917] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:18:13,047] {logging_mixin.py:115} INFO - [2022-06-05 08:18:13,044] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:18:13,049] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:18:13,141] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 08:18:43,311] {processor.py:153} INFO - Started process (PID=7400) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:18:43,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:18:43,315] {logging_mixin.py:115} INFO - [2022-06-05 08:18:43,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:18:43,443] {logging_mixin.py:115} INFO - [2022-06-05 08:18:43,440] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:18:43,444] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:18:43,536] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 08:19:13,783] {processor.py:153} INFO - Started process (PID=7470) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:19:13,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:19:13,790] {logging_mixin.py:115} INFO - [2022-06-05 08:19:13,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:19:13,916] {logging_mixin.py:115} INFO - [2022-06-05 08:19:13,915] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:19:13,918] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:19:14,010] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 08:19:44,297] {processor.py:153} INFO - Started process (PID=7529) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:19:44,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:19:44,302] {logging_mixin.py:115} INFO - [2022-06-05 08:19:44,302] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:19:44,462] {logging_mixin.py:115} INFO - [2022-06-05 08:19:44,459] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:19:44,463] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:19:44,558] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.267 seconds
[2022-06-05 08:20:14,892] {processor.py:153} INFO - Started process (PID=7596) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:20:14,894] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:20:14,895] {logging_mixin.py:115} INFO - [2022-06-05 08:20:14,895] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:20:15,022] {logging_mixin.py:115} INFO - [2022-06-05 08:20:15,020] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:20:15,023] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:20:15,124] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 08:20:45,253] {processor.py:153} INFO - Started process (PID=7666) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:20:45,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:20:45,259] {logging_mixin.py:115} INFO - [2022-06-05 08:20:45,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:20:45,393] {logging_mixin.py:115} INFO - [2022-06-05 08:20:45,390] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:20:45,394] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:20:45,487] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 08:21:15,651] {processor.py:153} INFO - Started process (PID=7734) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:21:15,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:21:15,655] {logging_mixin.py:115} INFO - [2022-06-05 08:21:15,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:21:15,774] {logging_mixin.py:115} INFO - [2022-06-05 08:21:15,772] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:21:15,776] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:21:15,868] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 08:21:46,030] {processor.py:153} INFO - Started process (PID=7800) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:21:46,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:21:46,035] {logging_mixin.py:115} INFO - [2022-06-05 08:21:46,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:21:46,171] {logging_mixin.py:115} INFO - [2022-06-05 08:21:46,168] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:21:46,173] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:21:46,266] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 08:22:16,512] {processor.py:153} INFO - Started process (PID=7871) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:22:16,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:22:16,515] {logging_mixin.py:115} INFO - [2022-06-05 08:22:16,515] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:22:16,637] {logging_mixin.py:115} INFO - [2022-06-05 08:22:16,634] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:22:16,638] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:22:16,743] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 08:22:47,210] {processor.py:153} INFO - Started process (PID=7927) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:22:47,212] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:22:47,214] {logging_mixin.py:115} INFO - [2022-06-05 08:22:47,213] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:22:47,330] {logging_mixin.py:115} INFO - [2022-06-05 08:22:47,327] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:22:47,331] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:22:47,424] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-05 08:23:17,695] {processor.py:153} INFO - Started process (PID=7996) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:23:17,697] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:23:17,699] {logging_mixin.py:115} INFO - [2022-06-05 08:23:17,699] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:23:17,825] {logging_mixin.py:115} INFO - [2022-06-05 08:23:17,823] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:23:17,826] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:23:17,918] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-05 08:23:48,257] {processor.py:153} INFO - Started process (PID=8065) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:23:48,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:23:48,260] {logging_mixin.py:115} INFO - [2022-06-05 08:23:48,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:23:48,389] {logging_mixin.py:115} INFO - [2022-06-05 08:23:48,384] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:23:48,390] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:23:48,481] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-05 08:24:18,674] {processor.py:153} INFO - Started process (PID=8131) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:24:18,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:24:18,677] {logging_mixin.py:115} INFO - [2022-06-05 08:24:18,677] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:24:18,801] {logging_mixin.py:115} INFO - [2022-06-05 08:24:18,799] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:24:18,803] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:24:18,903] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 08:24:49,417] {processor.py:153} INFO - Started process (PID=8198) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:24:49,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:24:49,423] {logging_mixin.py:115} INFO - [2022-06-05 08:24:49,423] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:24:49,556] {logging_mixin.py:115} INFO - [2022-06-05 08:24:49,553] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:24:49,557] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:24:49,651] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 08:25:19,908] {processor.py:153} INFO - Started process (PID=8256) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:25:19,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:25:19,913] {logging_mixin.py:115} INFO - [2022-06-05 08:25:19,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:25:20,051] {logging_mixin.py:115} INFO - [2022-06-05 08:25:20,049] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:25:20,052] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:25:20,151] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-05 08:25:50,517] {processor.py:153} INFO - Started process (PID=8323) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:25:50,519] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:25:50,520] {logging_mixin.py:115} INFO - [2022-06-05 08:25:50,520] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:25:50,649] {logging_mixin.py:115} INFO - [2022-06-05 08:25:50,646] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:25:50,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:25:50,743] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 08:26:20,994] {processor.py:153} INFO - Started process (PID=8392) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:26:20,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:26:20,998] {logging_mixin.py:115} INFO - [2022-06-05 08:26:20,998] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:26:21,118] {logging_mixin.py:115} INFO - [2022-06-05 08:26:21,115] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:26:21,119] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:26:21,211] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-05 08:26:51,847] {processor.py:153} INFO - Started process (PID=8459) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:26:51,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:26:51,851] {logging_mixin.py:115} INFO - [2022-06-05 08:26:51,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:26:51,982] {logging_mixin.py:115} INFO - [2022-06-05 08:26:51,980] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:26:51,983] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:26:52,076] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 08:27:22,514] {processor.py:153} INFO - Started process (PID=8528) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:27:22,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:27:22,516] {logging_mixin.py:115} INFO - [2022-06-05 08:27:22,516] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:27:22,636] {logging_mixin.py:115} INFO - [2022-06-05 08:27:22,634] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:27:22,639] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:27:22,730] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-05 08:27:53,708] {processor.py:153} INFO - Started process (PID=8598) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:27:53,710] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:27:53,711] {logging_mixin.py:115} INFO - [2022-06-05 08:27:53,711] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:27:53,867] {logging_mixin.py:115} INFO - [2022-06-05 08:27:53,864] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:27:53,868] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:27:53,967] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.261 seconds
[2022-06-05 08:28:24,386] {processor.py:153} INFO - Started process (PID=8666) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:28:24,388] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:28:24,389] {logging_mixin.py:115} INFO - [2022-06-05 08:28:24,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:28:24,522] {logging_mixin.py:115} INFO - [2022-06-05 08:28:24,520] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:28:24,523] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:28:24,624] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 08:28:55,250] {processor.py:153} INFO - Started process (PID=8724) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:28:55,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:28:55,255] {logging_mixin.py:115} INFO - [2022-06-05 08:28:55,255] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:28:55,391] {logging_mixin.py:115} INFO - [2022-06-05 08:28:55,389] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:28:55,392] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:28:55,481] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 08:29:26,300] {processor.py:153} INFO - Started process (PID=8790) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:29:26,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:29:26,303] {logging_mixin.py:115} INFO - [2022-06-05 08:29:26,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:29:26,427] {logging_mixin.py:115} INFO - [2022-06-05 08:29:26,425] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:29:26,431] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:29:26,533] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 08:29:56,896] {processor.py:153} INFO - Started process (PID=8857) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:29:56,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:29:56,899] {logging_mixin.py:115} INFO - [2022-06-05 08:29:56,899] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:29:57,089] {logging_mixin.py:115} INFO - [2022-06-05 08:29:57,085] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:29:57,090] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:29:57,193] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.302 seconds
[2022-06-05 08:30:49,328] {processor.py:153} INFO - Started process (PID=33) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:30:49,330] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:30:49,332] {logging_mixin.py:115} INFO - [2022-06-05 08:30:49,332] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:30:49,604] {logging_mixin.py:115} INFO - [2022-06-05 08:30:49,597] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:30:49,609] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:30:49,808] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.487 seconds
[2022-06-05 08:31:20,376] {processor.py:153} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:31:20,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:31:20,380] {logging_mixin.py:115} INFO - [2022-06-05 08:31:20,380] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:31:20,518] {logging_mixin.py:115} INFO - [2022-06-05 08:31:20,515] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:31:20,519] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:31:20,611] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.242 seconds
[2022-06-05 08:31:51,441] {processor.py:153} INFO - Started process (PID=156) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:31:51,448] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:31:51,451] {logging_mixin.py:115} INFO - [2022-06-05 08:31:51,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:31:52,122] {logging_mixin.py:115} INFO - [2022-06-05 08:31:52,090] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:31:52,133] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:31:52,701] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 1.278 seconds
[2022-06-05 08:32:23,146] {processor.py:153} INFO - Started process (PID=220) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:32:23,149] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:32:23,151] {logging_mixin.py:115} INFO - [2022-06-05 08:32:23,151] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:32:23,380] {logging_mixin.py:115} INFO - [2022-06-05 08:32:23,378] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:32:23,381] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:32:23,486] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.348 seconds
[2022-06-05 08:32:54,055] {processor.py:153} INFO - Started process (PID=285) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:32:54,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:32:54,061] {logging_mixin.py:115} INFO - [2022-06-05 08:32:54,061] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:32:54,210] {logging_mixin.py:115} INFO - [2022-06-05 08:32:54,208] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:32:54,212] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:32:54,305] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.257 seconds
[2022-06-05 08:33:24,817] {processor.py:153} INFO - Started process (PID=353) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:33:24,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:33:24,823] {logging_mixin.py:115} INFO - [2022-06-05 08:33:24,823] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:33:24,957] {logging_mixin.py:115} INFO - [2022-06-05 08:33:24,953] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:33:24,960] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:33:25,059] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-05 08:33:55,129] {processor.py:153} INFO - Started process (PID=424) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:33:55,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:33:55,133] {logging_mixin.py:115} INFO - [2022-06-05 08:33:55,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:33:55,333] {logging_mixin.py:115} INFO - [2022-06-05 08:33:55,331] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:33:55,336] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:33:55,449] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.325 seconds
[2022-06-05 08:34:25,560] {processor.py:153} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:34:25,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:34:25,563] {logging_mixin.py:115} INFO - [2022-06-05 08:34:25,563] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:34:25,842] {logging_mixin.py:115} INFO - [2022-06-05 08:34:25,840] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:34:25,843] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:34:25,985] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.429 seconds
[2022-06-05 08:34:57,013] {processor.py:153} INFO - Started process (PID=547) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:34:57,018] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:34:57,021] {logging_mixin.py:115} INFO - [2022-06-05 08:34:57,021] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:34:57,216] {logging_mixin.py:115} INFO - [2022-06-05 08:34:57,214] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:34:57,218] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:34:57,323] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.316 seconds
[2022-06-05 08:35:27,557] {processor.py:153} INFO - Started process (PID=617) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:35:27,559] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:35:27,560] {logging_mixin.py:115} INFO - [2022-06-05 08:35:27,560] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:35:27,798] {logging_mixin.py:115} INFO - [2022-06-05 08:35:27,795] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:35:27,800] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:35:27,902] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.349 seconds
[2022-06-05 08:35:58,510] {processor.py:153} INFO - Started process (PID=687) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:35:58,513] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:35:58,515] {logging_mixin.py:115} INFO - [2022-06-05 08:35:58,515] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:35:58,733] {logging_mixin.py:115} INFO - [2022-06-05 08:35:58,730] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:35:58,734] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:35:58,843] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.339 seconds
[2022-06-05 08:36:29,589] {processor.py:153} INFO - Started process (PID=762) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:36:29,592] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:36:29,593] {logging_mixin.py:115} INFO - [2022-06-05 08:36:29,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:36:29,826] {logging_mixin.py:115} INFO - [2022-06-05 08:36:29,823] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:36:29,828] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:36:29,932] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.350 seconds
[2022-06-05 08:37:00,875] {processor.py:153} INFO - Started process (PID=832) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:37:00,877] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:37:00,878] {logging_mixin.py:115} INFO - [2022-06-05 08:37:00,878] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:37:01,044] {logging_mixin.py:115} INFO - [2022-06-05 08:37:01,042] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:37:01,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:37:01,158] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.287 seconds
[2022-06-05 08:37:31,886] {processor.py:153} INFO - Started process (PID=891) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:37:31,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:37:31,889] {logging_mixin.py:115} INFO - [2022-06-05 08:37:31,889] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:37:32,109] {logging_mixin.py:115} INFO - [2022-06-05 08:37:32,106] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:37:32,111] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:37:32,219] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.340 seconds
[2022-06-05 08:38:02,362] {processor.py:153} INFO - Started process (PID=956) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:38:02,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:38:02,366] {logging_mixin.py:115} INFO - [2022-06-05 08:38:02,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:38:02,545] {logging_mixin.py:115} INFO - [2022-06-05 08:38:02,541] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:38:02,548] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:38:02,663] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.308 seconds
[2022-06-05 08:38:32,933] {processor.py:153} INFO - Started process (PID=1022) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:38:32,935] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:38:32,940] {logging_mixin.py:115} INFO - [2022-06-05 08:38:32,940] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:38:33,112] {logging_mixin.py:115} INFO - [2022-06-05 08:38:33,109] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:38:33,115] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:38:33,222] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.292 seconds
[2022-06-05 08:39:03,467] {processor.py:153} INFO - Started process (PID=1093) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:39:03,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:39:03,476] {logging_mixin.py:115} INFO - [2022-06-05 08:39:03,476] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:39:03,747] {logging_mixin.py:115} INFO - [2022-06-05 08:39:03,742] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:39:03,749] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:39:03,932] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.471 seconds
[2022-06-05 08:39:34,865] {processor.py:153} INFO - Started process (PID=1163) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:39:34,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:39:34,869] {logging_mixin.py:115} INFO - [2022-06-05 08:39:34,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:39:35,156] {logging_mixin.py:115} INFO - [2022-06-05 08:39:35,153] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:39:35,160] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:39:35,276] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.413 seconds
[2022-06-05 08:40:06,240] {processor.py:153} INFO - Started process (PID=1220) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:40:06,243] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:40:06,245] {logging_mixin.py:115} INFO - [2022-06-05 08:40:06,244] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:40:06,478] {logging_mixin.py:115} INFO - [2022-06-05 08:40:06,476] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:40:06,479] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:40:06,596] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.363 seconds
[2022-06-05 08:40:37,584] {processor.py:153} INFO - Started process (PID=1285) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:40:37,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:40:37,588] {logging_mixin.py:115} INFO - [2022-06-05 08:40:37,588] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:40:37,816] {logging_mixin.py:115} INFO - [2022-06-05 08:40:37,814] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:40:37,818] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:40:37,930] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.356 seconds
[2022-06-05 08:41:35,194] {processor.py:153} INFO - Started process (PID=34) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:41:35,197] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:41:35,199] {logging_mixin.py:115} INFO - [2022-06-05 08:41:35,199] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:41:35,427] {logging_mixin.py:115} INFO - [2022-06-05 08:41:35,423] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:41:35,429] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:41:35,687] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.497 seconds
[2022-06-05 08:42:06,323] {processor.py:153} INFO - Started process (PID=100) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:42:06,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:42:06,328] {logging_mixin.py:115} INFO - [2022-06-05 08:42:06,328] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:42:06,520] {logging_mixin.py:115} INFO - [2022-06-05 08:42:06,517] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:42:06,522] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:42:06,614] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.298 seconds
[2022-06-05 08:42:36,927] {processor.py:153} INFO - Started process (PID=159) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:42:36,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:42:36,930] {logging_mixin.py:115} INFO - [2022-06-05 08:42:36,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:42:37,124] {logging_mixin.py:115} INFO - [2022-06-05 08:42:37,122] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:42:37,125] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:42:37,225] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.300 seconds
[2022-06-05 08:43:07,629] {processor.py:153} INFO - Started process (PID=227) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:43:07,631] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:43:07,632] {logging_mixin.py:115} INFO - [2022-06-05 08:43:07,632] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:43:07,797] {logging_mixin.py:115} INFO - [2022-06-05 08:43:07,795] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:43:07,798] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:43:07,894] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.269 seconds
[2022-06-05 08:43:38,841] {processor.py:153} INFO - Started process (PID=295) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:43:38,844] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:43:38,845] {logging_mixin.py:115} INFO - [2022-06-05 08:43:38,845] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:43:38,964] {logging_mixin.py:115} INFO - [2022-06-05 08:43:38,962] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:43:38,966] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:43:39,061] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-05 08:44:09,292] {processor.py:153} INFO - Started process (PID=365) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:44:09,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:44:09,295] {logging_mixin.py:115} INFO - [2022-06-05 08:44:09,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:44:09,473] {logging_mixin.py:115} INFO - [2022-06-05 08:44:09,471] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:44:09,475] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:44:09,589] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.297 seconds
[2022-06-05 08:44:39,865] {processor.py:153} INFO - Started process (PID=430) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:44:39,867] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:44:39,870] {logging_mixin.py:115} INFO - [2022-06-05 08:44:39,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:44:40,160] {logging_mixin.py:115} INFO - [2022-06-05 08:44:40,149] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:44:40,163] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:44:40,377] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.515 seconds
[2022-06-05 08:45:10,464] {processor.py:153} INFO - Started process (PID=493) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:45:10,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:45:10,468] {logging_mixin.py:115} INFO - [2022-06-05 08:45:10,468] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:45:10,697] {logging_mixin.py:115} INFO - [2022-06-05 08:45:10,693] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:45:10,698] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:45:10,807] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.347 seconds
[2022-06-05 08:45:41,802] {processor.py:153} INFO - Started process (PID=561) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:45:41,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:45:41,810] {logging_mixin.py:115} INFO - [2022-06-05 08:45:41,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:45:42,133] {logging_mixin.py:115} INFO - [2022-06-05 08:45:42,130] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:45:42,136] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:45:42,262] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.465 seconds
[2022-06-05 08:46:13,009] {processor.py:153} INFO - Started process (PID=627) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:46:13,012] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:46:13,015] {logging_mixin.py:115} INFO - [2022-06-05 08:46:13,015] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:46:13,155] {logging_mixin.py:115} INFO - [2022-06-05 08:46:13,152] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:46:13,156] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:46:13,246] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-05 08:46:43,427] {processor.py:153} INFO - Started process (PID=694) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:46:43,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:46:43,431] {logging_mixin.py:115} INFO - [2022-06-05 08:46:43,431] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:46:43,664] {logging_mixin.py:115} INFO - [2022-06-05 08:46:43,660] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:46:43,666] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:46:43,778] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.355 seconds
[2022-06-05 08:47:14,410] {processor.py:153} INFO - Started process (PID=752) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:47:14,412] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:47:14,414] {logging_mixin.py:115} INFO - [2022-06-05 08:47:14,414] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:47:14,629] {logging_mixin.py:115} INFO - [2022-06-05 08:47:14,627] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:47:14,631] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:47:14,729] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.324 seconds
[2022-06-05 08:47:45,052] {processor.py:153} INFO - Started process (PID=820) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:47:45,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:47:45,057] {logging_mixin.py:115} INFO - [2022-06-05 08:47:45,057] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:47:45,418] {logging_mixin.py:115} INFO - [2022-06-05 08:47:45,403] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:47:45,428] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:47:45,580] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.537 seconds
[2022-06-05 08:48:16,567] {processor.py:153} INFO - Started process (PID=887) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:48:16,570] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:48:16,572] {logging_mixin.py:115} INFO - [2022-06-05 08:48:16,572] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:48:16,771] {logging_mixin.py:115} INFO - [2022-06-05 08:48:16,769] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:48:16,773] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:48:16,870] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.309 seconds
[2022-06-05 08:48:47,684] {processor.py:153} INFO - Started process (PID=953) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:48:47,687] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:48:47,688] {logging_mixin.py:115} INFO - [2022-06-05 08:48:47,688] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:48:47,930] {logging_mixin.py:115} INFO - [2022-06-05 08:48:47,925] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:48:47,933] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:48:48,044] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.365 seconds
[2022-06-05 08:49:18,457] {processor.py:153} INFO - Started process (PID=1018) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:49:18,460] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:49:18,462] {logging_mixin.py:115} INFO - [2022-06-05 08:49:18,462] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:49:18,904] {logging_mixin.py:115} INFO - [2022-06-05 08:49:18,902] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:49:18,906] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:49:19,032] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.585 seconds
[2022-06-05 08:49:49,209] {processor.py:153} INFO - Started process (PID=1073) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:49:49,211] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:49:49,214] {logging_mixin.py:115} INFO - [2022-06-05 08:49:49,213] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:49:49,408] {logging_mixin.py:115} INFO - [2022-06-05 08:49:49,406] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:49:49,409] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:49:49,510] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.307 seconds
[2022-06-05 08:50:19,610] {processor.py:153} INFO - Started process (PID=1140) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:50:19,611] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:50:19,613] {logging_mixin.py:115} INFO - [2022-06-05 08:50:19,613] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:50:20,076] {logging_mixin.py:115} INFO - [2022-06-05 08:50:20,072] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:50:20,080] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:50:20,244] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.638 seconds
[2022-06-05 08:50:50,325] {processor.py:153} INFO - Started process (PID=1207) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:50:50,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:50:50,328] {logging_mixin.py:115} INFO - [2022-06-05 08:50:50,328] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:50:50,524] {logging_mixin.py:115} INFO - [2022-06-05 08:50:50,517] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:50:50,525] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:50:50,625] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.305 seconds
[2022-06-05 08:51:21,378] {processor.py:153} INFO - Started process (PID=1275) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:51:21,380] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:51:21,383] {logging_mixin.py:115} INFO - [2022-06-05 08:51:21,382] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:51:21,730] {logging_mixin.py:115} INFO - [2022-06-05 08:51:21,727] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:51:21,734] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:51:21,913] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.556 seconds
[2022-06-05 08:51:52,287] {processor.py:153} INFO - Started process (PID=1333) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:51:52,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:51:52,292] {logging_mixin.py:115} INFO - [2022-06-05 08:51:52,292] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:51:52,643] {logging_mixin.py:115} INFO - [2022-06-05 08:51:52,638] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:51:52,645] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:51:52,805] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.523 seconds
[2022-06-05 08:52:23,753] {processor.py:153} INFO - Started process (PID=1399) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:52:23,764] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:52:23,767] {logging_mixin.py:115} INFO - [2022-06-05 08:52:23,767] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:52:24,028] {logging_mixin.py:115} INFO - [2022-06-05 08:52:24,026] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:52:24,030] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:52:24,140] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.392 seconds
[2022-06-05 08:52:55,017] {processor.py:153} INFO - Started process (PID=1467) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:52:55,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:52:55,021] {logging_mixin.py:115} INFO - [2022-06-05 08:52:55,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:52:55,318] {logging_mixin.py:115} INFO - [2022-06-05 08:52:55,311] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:52:55,321] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:52:55,466] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.453 seconds
[2022-06-05 08:53:26,164] {processor.py:153} INFO - Started process (PID=1534) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:53:26,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:53:26,167] {logging_mixin.py:115} INFO - [2022-06-05 08:53:26,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:53:26,382] {logging_mixin.py:115} INFO - [2022-06-05 08:53:26,380] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:53:26,384] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:53:26,474] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.313 seconds
[2022-06-05 08:53:56,542] {processor.py:153} INFO - Started process (PID=1592) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:53:56,545] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:53:56,546] {logging_mixin.py:115} INFO - [2022-06-05 08:53:56,546] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:53:56,741] {logging_mixin.py:115} INFO - [2022-06-05 08:53:56,737] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:53:56,743] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:53:56,948] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.413 seconds
[2022-06-05 08:54:27,869] {processor.py:153} INFO - Started process (PID=1661) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:54:27,871] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:54:27,872] {logging_mixin.py:115} INFO - [2022-06-05 08:54:27,872] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:54:28,087] {logging_mixin.py:115} INFO - [2022-06-05 08:54:28,081] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:54:28,089] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:54:28,227] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.362 seconds
[2022-06-05 08:55:12,529] {processor.py:153} INFO - Started process (PID=32) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:55:12,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:55:12,534] {logging_mixin.py:115} INFO - [2022-06-05 08:55:12,534] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:55:13,013] {logging_mixin.py:115} INFO - [2022-06-05 08:55:13,010] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:55:13,015] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:55:13,389] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.873 seconds
[2022-06-05 08:55:43,777] {processor.py:153} INFO - Started process (PID=100) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:55:43,778] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:55:43,779] {logging_mixin.py:115} INFO - [2022-06-05 08:55:43,779] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:55:43,901] {logging_mixin.py:115} INFO - [2022-06-05 08:55:43,899] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:55:43,903] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:55:44,002] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 08:56:14,488] {processor.py:153} INFO - Started process (PID=156) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:56:14,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:56:14,492] {logging_mixin.py:115} INFO - [2022-06-05 08:56:14,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:56:14,704] {logging_mixin.py:115} INFO - [2022-06-05 08:56:14,701] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:56:14,705] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:56:14,826] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.344 seconds
[2022-06-05 08:56:45,828] {processor.py:153} INFO - Started process (PID=223) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:56:45,831] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:56:45,833] {logging_mixin.py:115} INFO - [2022-06-05 08:56:45,833] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:56:46,193] {logging_mixin.py:115} INFO - [2022-06-05 08:56:46,184] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:56:46,195] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:56:46,324] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.506 seconds
[2022-06-05 08:57:17,198] {processor.py:153} INFO - Started process (PID=289) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:57:17,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:57:17,202] {logging_mixin.py:115} INFO - [2022-06-05 08:57:17,202] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:57:17,385] {logging_mixin.py:115} INFO - [2022-06-05 08:57:17,383] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:57:17,387] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:57:17,482] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.290 seconds
[2022-06-05 08:57:47,733] {processor.py:153} INFO - Started process (PID=357) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:57:47,734] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:57:47,735] {logging_mixin.py:115} INFO - [2022-06-05 08:57:47,735] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:57:47,996] {logging_mixin.py:115} INFO - [2022-06-05 08:57:47,991] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:57:47,998] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:57:48,124] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.395 seconds
[2022-06-05 08:58:32,848] {processor.py:153} INFO - Started process (PID=34) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:58:32,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:58:32,855] {logging_mixin.py:115} INFO - [2022-06-05 08:58:32,855] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:58:33,233] {logging_mixin.py:115} INFO - [2022-06-05 08:58:33,224] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:58:33,237] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:58:33,462] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.620 seconds
[2022-06-05 08:59:04,256] {processor.py:153} INFO - Started process (PID=101) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:59:04,258] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:59:04,259] {logging_mixin.py:115} INFO - [2022-06-05 08:59:04,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:59:04,446] {logging_mixin.py:115} INFO - [2022-06-05 08:59:04,443] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:59:04,448] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:59:04,554] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.303 seconds
[2022-06-05 08:59:34,883] {processor.py:153} INFO - Started process (PID=158) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:59:34,885] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 08:59:34,890] {logging_mixin.py:115} INFO - [2022-06-05 08:59:34,890] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:59:35,347] {logging_mixin.py:115} INFO - [2022-06-05 08:59:35,341] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 08:59:35,351] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 08:59:35,586] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.707 seconds
[2022-06-05 09:00:05,909] {processor.py:153} INFO - Started process (PID=227) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:00:05,910] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:00:05,912] {logging_mixin.py:115} INFO - [2022-06-05 09:00:05,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:00:06,091] {logging_mixin.py:115} INFO - [2022-06-05 09:00:06,089] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:00:06,092] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:00:06,189] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.284 seconds
[2022-06-05 09:00:37,158] {processor.py:153} INFO - Started process (PID=294) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:00:37,160] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:00:37,161] {logging_mixin.py:115} INFO - [2022-06-05 09:00:37,161] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:00:37,475] {logging_mixin.py:115} INFO - [2022-06-05 09:00:37,469] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:00:37,484] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:00:37,590] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.439 seconds
[2022-06-05 09:01:07,790] {processor.py:153} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:01:07,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:01:07,795] {logging_mixin.py:115} INFO - [2022-06-05 09:01:07,795] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:01:08,278] {logging_mixin.py:115} INFO - [2022-06-05 09:01:08,271] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:01:08,280] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:01:08,767] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.999 seconds
[2022-06-05 09:01:39,601] {processor.py:153} INFO - Started process (PID=418) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:01:39,605] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:01:39,607] {logging_mixin.py:115} INFO - [2022-06-05 09:01:39,607] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:01:40,124] {logging_mixin.py:115} INFO - [2022-06-05 09:01:40,118] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:01:40,129] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:01:40,632] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 1.036 seconds
[2022-06-05 09:02:11,361] {processor.py:153} INFO - Started process (PID=489) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:02:11,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:02:11,371] {logging_mixin.py:115} INFO - [2022-06-05 09:02:11,371] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:02:11,853] {logging_mixin.py:115} INFO - [2022-06-05 09:02:11,850] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:02:11,854] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:02:12,183] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.828 seconds
[2022-06-05 09:02:42,360] {processor.py:153} INFO - Started process (PID=550) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:02:42,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:02:42,366] {logging_mixin.py:115} INFO - [2022-06-05 09:02:42,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:02:42,723] {logging_mixin.py:115} INFO - [2022-06-05 09:02:42,713] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:02:42,725] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:02:42,937] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.581 seconds
[2022-06-05 09:03:13,033] {processor.py:153} INFO - Started process (PID=620) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:03:13,035] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:03:13,036] {logging_mixin.py:115} INFO - [2022-06-05 09:03:13,036] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:03:13,353] {logging_mixin.py:115} INFO - [2022-06-05 09:03:13,347] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:03:13,354] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:03:13,511] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.482 seconds
[2022-06-05 09:03:43,640] {processor.py:153} INFO - Started process (PID=675) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:03:43,643] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:03:43,645] {logging_mixin.py:115} INFO - [2022-06-05 09:03:43,645] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:03:44,051] {logging_mixin.py:115} INFO - [2022-06-05 09:03:44,045] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:03:44,053] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:03:44,379] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.746 seconds
[2022-06-05 09:04:15,099] {processor.py:153} INFO - Started process (PID=739) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:04:15,101] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:04:15,103] {logging_mixin.py:115} INFO - [2022-06-05 09:04:15,103] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:04:15,388] {logging_mixin.py:115} INFO - [2022-06-05 09:04:15,385] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:04:15,389] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:04:15,675] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.582 seconds
[2022-06-05 09:04:46,567] {processor.py:153} INFO - Started process (PID=793) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:04:46,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:04:46,573] {logging_mixin.py:115} INFO - [2022-06-05 09:04:46,573] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:04:46,890] {logging_mixin.py:115} INFO - [2022-06-05 09:04:46,886] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:04:46,893] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:04:47,077] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.514 seconds
[2022-06-05 09:05:17,465] {processor.py:153} INFO - Started process (PID=866) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:05:17,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:05:17,467] {logging_mixin.py:115} INFO - [2022-06-05 09:05:17,467] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:05:17,716] {logging_mixin.py:115} INFO - [2022-06-05 09:05:17,713] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:05:17,717] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:05:17,872] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.412 seconds
[2022-06-05 09:05:47,970] {processor.py:153} INFO - Started process (PID=922) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:05:47,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:05:47,987] {logging_mixin.py:115} INFO - [2022-06-05 09:05:47,987] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:05:48,446] {logging_mixin.py:115} INFO - [2022-06-05 09:05:48,440] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:05:48,448] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:05:48,740] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.790 seconds
[2022-06-05 09:06:19,052] {processor.py:153} INFO - Started process (PID=986) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:06:19,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:06:19,063] {logging_mixin.py:115} INFO - [2022-06-05 09:06:19,063] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:06:20,030] {logging_mixin.py:115} INFO - [2022-06-05 09:06:20,005] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:06:20,040] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:06:20,383] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 1.344 seconds
[2022-06-05 09:06:50,682] {processor.py:153} INFO - Started process (PID=1042) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:06:50,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:06:50,686] {logging_mixin.py:115} INFO - [2022-06-05 09:06:50,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:06:50,977] {logging_mixin.py:115} INFO - [2022-06-05 09:06:50,970] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:06:50,978] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:06:51,204] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.525 seconds
[2022-06-05 09:07:21,885] {processor.py:153} INFO - Started process (PID=1110) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:07:21,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:07:21,889] {logging_mixin.py:115} INFO - [2022-06-05 09:07:21,889] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:07:22,096] {logging_mixin.py:115} INFO - [2022-06-05 09:07:22,092] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:07:22,098] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:07:22,254] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.373 seconds
[2022-06-05 09:07:52,592] {processor.py:153} INFO - Started process (PID=1165) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:07:52,594] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:07:52,596] {logging_mixin.py:115} INFO - [2022-06-05 09:07:52,596] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:07:52,782] {logging_mixin.py:115} INFO - [2022-06-05 09:07:52,778] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:07:52,785] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:07:52,991] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.405 seconds
[2022-06-05 09:08:23,053] {processor.py:153} INFO - Started process (PID=1235) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:08:23,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:08:23,055] {logging_mixin.py:115} INFO - [2022-06-05 09:08:23,055] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:08:23,215] {logging_mixin.py:115} INFO - [2022-06-05 09:08:23,213] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:08:23,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:08:23,309] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.257 seconds
[2022-06-05 09:08:53,933] {processor.py:153} INFO - Started process (PID=1303) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:08:53,935] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:08:53,936] {logging_mixin.py:115} INFO - [2022-06-05 09:08:53,936] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:08:54,155] {logging_mixin.py:115} INFO - [2022-06-05 09:08:54,153] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:08:54,156] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:08:54,246] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.315 seconds
[2022-06-05 09:09:42,988] {processor.py:153} INFO - Started process (PID=33) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:09:42,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:09:42,992] {logging_mixin.py:115} INFO - [2022-06-05 09:09:42,992] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:09:43,339] {logging_mixin.py:115} INFO - [2022-06-05 09:09:43,332] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:09:43,344] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:09:43,729] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.748 seconds
[2022-06-05 09:10:14,308] {processor.py:153} INFO - Started process (PID=100) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:10:14,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:10:14,312] {logging_mixin.py:115} INFO - [2022-06-05 09:10:14,312] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:10:14,537] {logging_mixin.py:115} INFO - [2022-06-05 09:10:14,534] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:10:14,538] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:10:14,642] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.340 seconds
[2022-06-05 09:10:45,427] {processor.py:153} INFO - Started process (PID=169) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:10:45,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:10:45,431] {logging_mixin.py:115} INFO - [2022-06-05 09:10:45,431] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:10:45,579] {logging_mixin.py:115} INFO - [2022-06-05 09:10:45,577] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:10:45,581] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:10:45,688] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.266 seconds
[2022-06-05 09:11:16,137] {processor.py:153} INFO - Started process (PID=224) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:11:16,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:11:16,142] {logging_mixin.py:115} INFO - [2022-06-05 09:11:16,142] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:11:16,306] {logging_mixin.py:115} INFO - [2022-06-05 09:11:16,303] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:11:16,308] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:11:16,427] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.298 seconds
[2022-06-05 09:12:05,378] {processor.py:153} INFO - Started process (PID=33) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:12:05,383] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:12:05,390] {logging_mixin.py:115} INFO - [2022-06-05 09:12:05,390] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:12:05,720] {logging_mixin.py:115} INFO - [2022-06-05 09:12:05,715] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:12:05,721] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:12:06,073] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.702 seconds
[2022-06-05 09:12:36,566] {processor.py:153} INFO - Started process (PID=102) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:12:36,568] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:12:36,570] {logging_mixin.py:115} INFO - [2022-06-05 09:12:36,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:12:36,771] {logging_mixin.py:115} INFO - [2022-06-05 09:12:36,768] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:12:36,773] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:12:36,935] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.374 seconds
[2022-06-05 09:13:07,984] {processor.py:153} INFO - Started process (PID=177) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:13:07,986] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:13:07,987] {logging_mixin.py:115} INFO - [2022-06-05 09:13:07,987] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:13:08,218] {logging_mixin.py:115} INFO - [2022-06-05 09:13:08,216] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:13:08,220] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:13:08,330] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.354 seconds
[2022-06-05 09:13:38,489] {processor.py:153} INFO - Started process (PID=234) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:13:38,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:13:38,492] {logging_mixin.py:115} INFO - [2022-06-05 09:13:38,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:13:38,740] {logging_mixin.py:115} INFO - [2022-06-05 09:13:38,737] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:13:38,742] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:13:38,842] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.361 seconds
[2022-06-05 09:14:09,798] {processor.py:153} INFO - Started process (PID=302) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:14:09,800] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:14:09,801] {logging_mixin.py:115} INFO - [2022-06-05 09:14:09,801] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:14:09,974] {logging_mixin.py:115} INFO - [2022-06-05 09:14:09,972] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:14:09,975] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:14:10,077] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.281 seconds
[2022-06-05 09:14:40,218] {processor.py:153} INFO - Started process (PID=369) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:14:40,220] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:14:40,221] {logging_mixin.py:115} INFO - [2022-06-05 09:14:40,221] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:14:40,341] {logging_mixin.py:115} INFO - [2022-06-05 09:14:40,339] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:14:40,343] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:14:40,437] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 09:15:10,611] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:15:10,614] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:15:10,615] {logging_mixin.py:115} INFO - [2022-06-05 09:15:10,615] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:15:10,763] {logging_mixin.py:115} INFO - [2022-06-05 09:15:10,761] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:15:10,764] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:15:10,857] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.257 seconds
[2022-06-05 09:15:40,968] {processor.py:153} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:15:40,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:15:40,970] {logging_mixin.py:115} INFO - [2022-06-05 09:15:40,970] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:15:41,105] {logging_mixin.py:115} INFO - [2022-06-05 09:15:41,102] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:15:41,106] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:15:41,201] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 09:16:11,726] {processor.py:153} INFO - Started process (PID=570) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:16:11,728] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:16:11,729] {logging_mixin.py:115} INFO - [2022-06-05 09:16:11,729] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:16:11,868] {logging_mixin.py:115} INFO - [2022-06-05 09:16:11,864] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:16:11,869] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:16:11,988] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-05 09:16:42,859] {processor.py:153} INFO - Started process (PID=628) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:16:42,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:16:42,865] {logging_mixin.py:115} INFO - [2022-06-05 09:16:42,864] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:16:42,996] {logging_mixin.py:115} INFO - [2022-06-05 09:16:42,993] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:16:42,998] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:16:43,097] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 09:17:13,644] {processor.py:153} INFO - Started process (PID=696) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:17:13,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:17:13,652] {logging_mixin.py:115} INFO - [2022-06-05 09:17:13,652] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:17:13,772] {logging_mixin.py:115} INFO - [2022-06-05 09:17:13,770] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:17:13,774] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:17:13,866] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-05 09:17:44,014] {processor.py:153} INFO - Started process (PID=768) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:17:44,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:17:44,018] {logging_mixin.py:115} INFO - [2022-06-05 09:17:44,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:17:44,156] {logging_mixin.py:115} INFO - [2022-06-05 09:17:44,155] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:17:44,159] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:17:44,251] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.242 seconds
[2022-06-05 09:18:14,448] {processor.py:153} INFO - Started process (PID=836) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:18:14,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:18:14,452] {logging_mixin.py:115} INFO - [2022-06-05 09:18:14,452] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:18:14,582] {logging_mixin.py:115} INFO - [2022-06-05 09:18:14,580] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:18:14,584] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:18:14,676] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 09:18:45,573] {processor.py:153} INFO - Started process (PID=907) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:18:45,575] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:18:45,576] {logging_mixin.py:115} INFO - [2022-06-05 09:18:45,576] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:18:45,704] {logging_mixin.py:115} INFO - [2022-06-05 09:18:45,702] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:18:45,705] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:18:45,799] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 09:19:16,649] {processor.py:153} INFO - Started process (PID=977) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:19:16,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:19:16,654] {logging_mixin.py:115} INFO - [2022-06-05 09:19:16,654] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:19:16,774] {logging_mixin.py:115} INFO - [2022-06-05 09:19:16,771] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:19:16,775] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:19:16,870] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-05 09:19:47,498] {processor.py:153} INFO - Started process (PID=1034) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:19:47,500] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:19:47,502] {logging_mixin.py:115} INFO - [2022-06-05 09:19:47,502] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:19:47,627] {logging_mixin.py:115} INFO - [2022-06-05 09:19:47,625] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:19:47,629] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:19:47,720] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 09:20:18,541] {processor.py:153} INFO - Started process (PID=1106) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:20:18,543] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:20:18,545] {logging_mixin.py:115} INFO - [2022-06-05 09:20:18,545] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:20:18,674] {logging_mixin.py:115} INFO - [2022-06-05 09:20:18,672] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:20:18,676] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:20:18,769] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 09:20:48,824] {processor.py:153} INFO - Started process (PID=1175) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:20:48,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:20:48,830] {logging_mixin.py:115} INFO - [2022-06-05 09:20:48,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:20:48,961] {logging_mixin.py:115} INFO - [2022-06-05 09:20:48,959] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:20:48,962] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:20:49,056] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 09:21:19,452] {processor.py:153} INFO - Started process (PID=1243) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:21:19,453] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:21:19,454] {logging_mixin.py:115} INFO - [2022-06-05 09:21:19,454] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:21:19,582] {logging_mixin.py:115} INFO - [2022-06-05 09:21:19,580] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:21:19,584] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:21:19,675] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-05 09:21:49,749] {processor.py:153} INFO - Started process (PID=1307) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:21:49,751] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:21:49,752] {logging_mixin.py:115} INFO - [2022-06-05 09:21:49,752] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:21:49,886] {logging_mixin.py:115} INFO - [2022-06-05 09:21:49,884] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:21:49,888] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:21:49,980] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 09:22:20,309] {processor.py:153} INFO - Started process (PID=1364) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:22:20,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:22:20,317] {logging_mixin.py:115} INFO - [2022-06-05 09:22:20,316] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:22:20,496] {logging_mixin.py:115} INFO - [2022-06-05 09:22:20,485] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:22:20,498] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:22:20,631] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.326 seconds
[2022-06-05 09:22:51,639] {processor.py:153} INFO - Started process (PID=1432) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:22:51,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:22:51,644] {logging_mixin.py:115} INFO - [2022-06-05 09:22:51,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:22:51,786] {logging_mixin.py:115} INFO - [2022-06-05 09:22:51,784] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:22:51,788] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:22:51,879] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-05 09:23:22,448] {processor.py:153} INFO - Started process (PID=1502) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:23:22,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:23:22,453] {logging_mixin.py:115} INFO - [2022-06-05 09:23:22,452] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:23:22,586] {logging_mixin.py:115} INFO - [2022-06-05 09:23:22,584] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:23:22,588] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:23:22,680] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 09:23:52,864] {processor.py:153} INFO - Started process (PID=1568) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:23:52,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:23:52,867] {logging_mixin.py:115} INFO - [2022-06-05 09:23:52,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:23:52,982] {logging_mixin.py:115} INFO - [2022-06-05 09:23:52,980] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:23:52,983] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:23:53,073] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-05 09:24:23,240] {processor.py:153} INFO - Started process (PID=1633) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:24:23,244] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:24:23,246] {logging_mixin.py:115} INFO - [2022-06-05 09:24:23,246] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:24:23,368] {logging_mixin.py:115} INFO - [2022-06-05 09:24:23,366] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:24:23,370] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:24:23,461] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 09:24:53,752] {processor.py:153} INFO - Started process (PID=1702) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:24:53,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:24:53,755] {logging_mixin.py:115} INFO - [2022-06-05 09:24:53,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:24:53,989] {logging_mixin.py:115} INFO - [2022-06-05 09:24:53,981] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:24:53,990] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:24:54,164] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.414 seconds
[2022-06-05 09:25:24,241] {processor.py:153} INFO - Started process (PID=1758) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:25:24,243] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:25:24,246] {logging_mixin.py:115} INFO - [2022-06-05 09:25:24,246] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:25:24,383] {logging_mixin.py:115} INFO - [2022-06-05 09:25:24,381] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:25:24,384] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:25:24,477] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 09:25:54,535] {processor.py:153} INFO - Started process (PID=1824) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:25:54,537] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:25:54,538] {logging_mixin.py:115} INFO - [2022-06-05 09:25:54,538] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:25:54,669] {logging_mixin.py:115} INFO - [2022-06-05 09:25:54,667] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:25:54,670] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:25:54,762] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 09:26:25,380] {processor.py:153} INFO - Started process (PID=1892) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:26:25,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:26:25,385] {logging_mixin.py:115} INFO - [2022-06-05 09:26:25,385] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:26:25,509] {logging_mixin.py:115} INFO - [2022-06-05 09:26:25,507] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:26:25,511] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:26:25,604] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-05 09:26:55,681] {processor.py:153} INFO - Started process (PID=1959) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:26:55,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:26:55,685] {logging_mixin.py:115} INFO - [2022-06-05 09:26:55,685] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:26:55,814] {logging_mixin.py:115} INFO - [2022-06-05 09:26:55,812] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:26:55,816] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:26:55,908] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 09:27:26,152] {processor.py:153} INFO - Started process (PID=2017) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:27:26,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:27:26,154] {logging_mixin.py:115} INFO - [2022-06-05 09:27:26,154] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:27:26,273] {logging_mixin.py:115} INFO - [2022-06-05 09:27:26,271] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:27:26,274] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:27:26,365] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-05 09:27:56,735] {processor.py:153} INFO - Started process (PID=2085) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:27:56,739] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:27:56,741] {logging_mixin.py:115} INFO - [2022-06-05 09:27:56,741] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:27:56,876] {logging_mixin.py:115} INFO - [2022-06-05 09:27:56,874] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:27:56,878] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:27:56,968] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 09:28:27,225] {processor.py:153} INFO - Started process (PID=2154) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:28:27,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:28:27,231] {logging_mixin.py:115} INFO - [2022-06-05 09:28:27,231] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:28:27,360] {logging_mixin.py:115} INFO - [2022-06-05 09:28:27,358] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:28:27,361] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:28:27,452] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 09:28:57,518] {processor.py:153} INFO - Started process (PID=2220) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:28:57,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:28:57,522] {logging_mixin.py:115} INFO - [2022-06-05 09:28:57,522] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:28:57,650] {logging_mixin.py:115} INFO - [2022-06-05 09:28:57,647] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:28:57,652] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:28:57,742] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 09:29:28,695] {processor.py:153} INFO - Started process (PID=2286) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:29:28,697] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:29:28,698] {logging_mixin.py:115} INFO - [2022-06-05 09:29:28,698] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:29:28,815] {logging_mixin.py:115} INFO - [2022-06-05 09:29:28,812] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:29:28,816] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:29:28,905] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-05 09:29:59,149] {processor.py:153} INFO - Started process (PID=2347) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:29:59,151] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:29:59,152] {logging_mixin.py:115} INFO - [2022-06-05 09:29:59,152] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:29:59,291] {logging_mixin.py:115} INFO - [2022-06-05 09:29:59,288] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:29:59,293] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:29:59,398] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-05 09:30:29,847] {processor.py:153} INFO - Started process (PID=2412) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:30:29,850] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:30:29,853] {logging_mixin.py:115} INFO - [2022-06-05 09:30:29,853] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:30:29,978] {logging_mixin.py:115} INFO - [2022-06-05 09:30:29,975] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:30:29,979] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:30:30,070] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 09:31:00,931] {processor.py:153} INFO - Started process (PID=2483) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:31:00,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:31:00,933] {logging_mixin.py:115} INFO - [2022-06-05 09:31:00,933] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:31:01,063] {logging_mixin.py:115} INFO - [2022-06-05 09:31:01,060] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:31:01,065] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:31:01,154] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 09:31:32,033] {processor.py:153} INFO - Started process (PID=2553) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:31:32,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:31:32,038] {logging_mixin.py:115} INFO - [2022-06-05 09:31:32,038] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:31:32,178] {logging_mixin.py:115} INFO - [2022-06-05 09:31:32,176] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:31:32,179] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:31:32,275] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.248 seconds
[2022-06-05 09:32:03,242] {processor.py:153} INFO - Started process (PID=2621) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:32:03,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:32:03,247] {logging_mixin.py:115} INFO - [2022-06-05 09:32:03,247] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:32:03,386] {logging_mixin.py:115} INFO - [2022-06-05 09:32:03,384] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:32:03,388] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:32:03,485] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-05 09:32:33,736] {processor.py:153} INFO - Started process (PID=2694) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:32:33,739] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:32:33,740] {logging_mixin.py:115} INFO - [2022-06-05 09:32:33,740] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:32:33,860] {logging_mixin.py:115} INFO - [2022-06-05 09:32:33,858] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:32:33,861] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:32:33,953] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 09:33:04,554] {processor.py:153} INFO - Started process (PID=2750) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:33:04,558] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:33:04,561] {logging_mixin.py:115} INFO - [2022-06-05 09:33:04,561] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:33:04,689] {logging_mixin.py:115} INFO - [2022-06-05 09:33:04,687] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:33:04,690] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:33:04,787] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 09:33:34,974] {processor.py:153} INFO - Started process (PID=2823) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:33:34,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:33:34,978] {logging_mixin.py:115} INFO - [2022-06-05 09:33:34,978] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:33:35,100] {logging_mixin.py:115} INFO - [2022-06-05 09:33:35,098] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:33:35,101] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:33:35,195] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.224 seconds
[2022-06-05 09:34:05,780] {processor.py:153} INFO - Started process (PID=2892) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:34:05,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:34:05,785] {logging_mixin.py:115} INFO - [2022-06-05 09:34:05,785] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:34:05,933] {logging_mixin.py:115} INFO - [2022-06-05 09:34:05,931] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:34:05,934] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:34:06,031] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.260 seconds
[2022-06-05 09:34:36,691] {processor.py:153} INFO - Started process (PID=2960) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:34:36,694] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:34:36,695] {logging_mixin.py:115} INFO - [2022-06-05 09:34:36,695] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:34:36,821] {logging_mixin.py:115} INFO - [2022-06-05 09:34:36,819] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:34:36,823] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:34:36,915] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-05 09:35:07,345] {processor.py:153} INFO - Started process (PID=3025) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:35:07,349] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:35:07,351] {logging_mixin.py:115} INFO - [2022-06-05 09:35:07,351] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:35:07,499] {logging_mixin.py:115} INFO - [2022-06-05 09:35:07,497] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:35:07,501] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:35:07,594] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.254 seconds
[2022-06-05 09:35:38,329] {processor.py:153} INFO - Started process (PID=3080) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:35:38,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:35:38,334] {logging_mixin.py:115} INFO - [2022-06-05 09:35:38,333] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:35:38,544] {logging_mixin.py:115} INFO - [2022-06-05 09:35:38,542] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:35:38,546] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:35:38,659] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.335 seconds
[2022-06-05 09:36:09,463] {processor.py:153} INFO - Started process (PID=3149) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:36:09,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:36:09,468] {logging_mixin.py:115} INFO - [2022-06-05 09:36:09,468] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:36:09,589] {logging_mixin.py:115} INFO - [2022-06-05 09:36:09,587] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:36:09,590] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:36:09,697] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 09:36:40,531] {processor.py:153} INFO - Started process (PID=3214) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:36:40,533] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:36:40,535] {logging_mixin.py:115} INFO - [2022-06-05 09:36:40,535] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:36:40,764] {logging_mixin.py:115} INFO - [2022-06-05 09:36:40,761] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:36:40,766] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:36:40,868] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.342 seconds
[2022-06-05 09:37:11,156] {processor.py:153} INFO - Started process (PID=3282) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:37:11,158] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:37:11,165] {logging_mixin.py:115} INFO - [2022-06-05 09:37:11,163] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:37:11,422] {logging_mixin.py:115} INFO - [2022-06-05 09:37:11,420] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:37:11,423] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:37:11,527] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.380 seconds
[2022-06-05 09:37:42,221] {processor.py:153} INFO - Started process (PID=3349) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:37:42,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:37:42,224] {logging_mixin.py:115} INFO - [2022-06-05 09:37:42,224] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:37:42,472] {logging_mixin.py:115} INFO - [2022-06-05 09:37:42,470] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:37:42,474] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:37:42,586] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.369 seconds
[2022-06-05 09:38:13,646] {processor.py:153} INFO - Started process (PID=3405) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:38:13,650] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:38:13,651] {logging_mixin.py:115} INFO - [2022-06-05 09:38:13,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:38:13,926] {logging_mixin.py:115} INFO - [2022-06-05 09:38:13,923] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:38:13,927] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:38:14,057] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.421 seconds
[2022-06-05 09:38:44,811] {processor.py:153} INFO - Started process (PID=3473) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:38:44,813] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:38:44,815] {logging_mixin.py:115} INFO - [2022-06-05 09:38:44,815] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:38:45,056] {logging_mixin.py:115} INFO - [2022-06-05 09:38:45,052] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:38:45,060] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:38:45,161] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.357 seconds
[2022-06-05 09:39:15,269] {processor.py:153} INFO - Started process (PID=3541) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:39:15,272] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:39:15,274] {logging_mixin.py:115} INFO - [2022-06-05 09:39:15,274] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:39:15,513] {logging_mixin.py:115} INFO - [2022-06-05 09:39:15,505] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:39:15,515] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:39:15,623] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.360 seconds
[2022-06-05 09:39:45,850] {processor.py:153} INFO - Started process (PID=3608) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:39:45,856] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:39:45,861] {logging_mixin.py:115} INFO - [2022-06-05 09:39:45,861] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:39:46,243] {logging_mixin.py:115} INFO - [2022-06-05 09:39:46,239] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:39:46,245] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:39:46,407] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.574 seconds
[2022-06-05 09:40:17,214] {processor.py:153} INFO - Started process (PID=3674) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:40:17,216] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:40:17,218] {logging_mixin.py:115} INFO - [2022-06-05 09:40:17,218] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:40:17,598] {logging_mixin.py:115} INFO - [2022-06-05 09:40:17,594] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:40:17,600] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:40:17,772] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.564 seconds
[2022-06-05 09:40:47,963] {processor.py:153} INFO - Started process (PID=3733) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:40:47,965] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:40:47,966] {logging_mixin.py:115} INFO - [2022-06-05 09:40:47,966] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:40:48,251] {logging_mixin.py:115} INFO - [2022-06-05 09:40:48,241] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:40:48,253] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:40:48,365] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.405 seconds
[2022-06-05 09:41:18,524] {processor.py:153} INFO - Started process (PID=3802) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:41:18,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:41:18,527] {logging_mixin.py:115} INFO - [2022-06-05 09:41:18,527] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:41:18,831] {logging_mixin.py:115} INFO - [2022-06-05 09:41:18,823] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:41:18,835] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:41:18,961] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.440 seconds
[2022-06-05 09:41:49,729] {processor.py:153} INFO - Started process (PID=3871) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:41:49,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:41:49,733] {logging_mixin.py:115} INFO - [2022-06-05 09:41:49,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:41:49,963] {logging_mixin.py:115} INFO - [2022-06-05 09:41:49,959] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:41:49,965] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:41:50,069] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.347 seconds
[2022-06-05 09:42:20,599] {processor.py:153} INFO - Started process (PID=3940) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:42:20,602] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:42:20,604] {logging_mixin.py:115} INFO - [2022-06-05 09:42:20,603] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:42:20,730] {logging_mixin.py:115} INFO - [2022-06-05 09:42:20,728] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:42:20,732] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:42:20,840] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-05 09:42:51,770] {processor.py:153} INFO - Started process (PID=4011) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:42:51,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:42:51,775] {logging_mixin.py:115} INFO - [2022-06-05 09:42:51,775] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:42:51,906] {logging_mixin.py:115} INFO - [2022-06-05 09:42:51,904] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:42:51,907] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:42:51,998] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 09:43:22,438] {processor.py:153} INFO - Started process (PID=4081) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:43:22,440] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:43:22,443] {logging_mixin.py:115} INFO - [2022-06-05 09:43:22,443] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:43:22,564] {logging_mixin.py:115} INFO - [2022-06-05 09:43:22,562] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:43:22,567] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:43:22,657] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-05 09:43:52,775] {processor.py:153} INFO - Started process (PID=4152) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:43:52,778] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:43:52,779] {logging_mixin.py:115} INFO - [2022-06-05 09:43:52,779] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:43:52,954] {logging_mixin.py:115} INFO - [2022-06-05 09:43:52,952] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:43:52,955] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:43:53,084] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.312 seconds
[2022-06-05 09:44:23,599] {processor.py:153} INFO - Started process (PID=4210) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:44:23,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:44:23,602] {logging_mixin.py:115} INFO - [2022-06-05 09:44:23,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:44:23,741] {logging_mixin.py:115} INFO - [2022-06-05 09:44:23,739] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:44:23,742] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:44:23,840] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 09:44:54,752] {processor.py:153} INFO - Started process (PID=4276) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:44:54,755] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:44:54,758] {logging_mixin.py:115} INFO - [2022-06-05 09:44:54,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:44:54,894] {logging_mixin.py:115} INFO - [2022-06-05 09:44:54,892] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:44:54,895] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:44:54,992] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-05 09:45:25,247] {processor.py:153} INFO - Started process (PID=4345) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:45:25,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:45:25,250] {logging_mixin.py:115} INFO - [2022-06-05 09:45:25,250] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:45:25,445] {logging_mixin.py:115} INFO - [2022-06-05 09:45:25,442] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:45:25,447] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:45:25,605] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.361 seconds
[2022-06-05 09:45:55,863] {processor.py:153} INFO - Started process (PID=4413) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:45:55,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:45:55,869] {logging_mixin.py:115} INFO - [2022-06-05 09:45:55,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:45:56,047] {logging_mixin.py:115} INFO - [2022-06-05 09:45:56,045] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:45:56,048] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:45:56,146] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.291 seconds
[2022-06-05 09:46:26,180] {processor.py:153} INFO - Started process (PID=4479) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:46:26,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:46:26,183] {logging_mixin.py:115} INFO - [2022-06-05 09:46:26,183] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:46:26,365] {logging_mixin.py:115} INFO - [2022-06-05 09:46:26,361] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:46:26,376] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:46:26,513] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.336 seconds
[2022-06-05 09:46:57,012] {processor.py:153} INFO - Started process (PID=4535) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:46:57,014] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:46:57,016] {logging_mixin.py:115} INFO - [2022-06-05 09:46:57,016] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:46:57,140] {logging_mixin.py:115} INFO - [2022-06-05 09:46:57,138] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:46:57,141] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:46:57,232] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.224 seconds
[2022-06-05 09:47:28,180] {processor.py:153} INFO - Started process (PID=4604) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:47:28,184] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:47:28,186] {logging_mixin.py:115} INFO - [2022-06-05 09:47:28,186] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:47:28,318] {logging_mixin.py:115} INFO - [2022-06-05 09:47:28,316] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:47:28,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:47:28,413] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 09:47:58,552] {processor.py:153} INFO - Started process (PID=4671) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:47:58,555] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:47:58,557] {logging_mixin.py:115} INFO - [2022-06-05 09:47:58,557] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:47:58,686] {logging_mixin.py:115} INFO - [2022-06-05 09:47:58,685] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:47:58,688] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:47:58,781] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 09:48:29,780] {processor.py:153} INFO - Started process (PID=4743) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:48:29,782] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:48:29,784] {logging_mixin.py:115} INFO - [2022-06-05 09:48:29,783] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:48:29,960] {logging_mixin.py:115} INFO - [2022-06-05 09:48:29,955] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:48:29,961] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:48:30,067] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.295 seconds
[2022-06-05 09:49:00,281] {processor.py:153} INFO - Started process (PID=4815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:49:00,285] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:49:00,287] {logging_mixin.py:115} INFO - [2022-06-05 09:49:00,287] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:49:00,431] {logging_mixin.py:115} INFO - [2022-06-05 09:49:00,429] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:49:00,433] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:49:00,527] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-05 09:49:30,629] {processor.py:153} INFO - Started process (PID=4871) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:49:30,631] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:49:30,634] {logging_mixin.py:115} INFO - [2022-06-05 09:49:30,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:49:30,882] {logging_mixin.py:115} INFO - [2022-06-05 09:49:30,879] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:49:30,883] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:49:31,018] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.392 seconds
[2022-06-05 09:50:01,408] {processor.py:153} INFO - Started process (PID=4936) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:50:01,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:50:01,411] {logging_mixin.py:115} INFO - [2022-06-05 09:50:01,411] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:50:01,582] {logging_mixin.py:115} INFO - [2022-06-05 09:50:01,579] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:50:01,584] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:50:01,681] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.276 seconds
[2022-06-05 09:50:32,535] {processor.py:153} INFO - Started process (PID=5000) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:50:32,538] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:50:32,540] {logging_mixin.py:115} INFO - [2022-06-05 09:50:32,540] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:50:32,806] {logging_mixin.py:115} INFO - [2022-06-05 09:50:32,803] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:50:32,807] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:50:32,932] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.425 seconds
[2022-06-05 09:51:03,123] {processor.py:153} INFO - Started process (PID=5069) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:51:03,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:51:03,128] {logging_mixin.py:115} INFO - [2022-06-05 09:51:03,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:51:03,260] {logging_mixin.py:115} INFO - [2022-06-05 09:51:03,257] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:51:03,262] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:51:03,353] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 09:51:33,415] {processor.py:153} INFO - Started process (PID=5135) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:51:33,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:51:33,419] {logging_mixin.py:115} INFO - [2022-06-05 09:51:33,419] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:51:33,599] {logging_mixin.py:115} INFO - [2022-06-05 09:51:33,597] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:51:33,600] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:51:33,729] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.323 seconds
[2022-06-05 09:52:03,920] {processor.py:153} INFO - Started process (PID=5193) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:52:03,924] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:52:03,926] {logging_mixin.py:115} INFO - [2022-06-05 09:52:03,926] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:52:04,062] {logging_mixin.py:115} INFO - [2022-06-05 09:52:04,060] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:52:04,064] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:52:04,164] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.250 seconds
[2022-06-05 09:52:34,422] {processor.py:153} INFO - Started process (PID=5264) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:52:34,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:52:34,428] {logging_mixin.py:115} INFO - [2022-06-05 09:52:34,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:52:34,577] {logging_mixin.py:115} INFO - [2022-06-05 09:52:34,574] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:52:34,578] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:52:34,669] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-05 09:53:04,888] {processor.py:153} INFO - Started process (PID=5329) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:53:04,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:53:04,893] {logging_mixin.py:115} INFO - [2022-06-05 09:53:04,893] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:53:05,035] {logging_mixin.py:115} INFO - [2022-06-05 09:53:05,032] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:53:05,037] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:53:05,148] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-05 09:53:35,234] {processor.py:153} INFO - Started process (PID=5396) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:53:35,237] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:53:35,238] {logging_mixin.py:115} INFO - [2022-06-05 09:53:35,238] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:53:35,364] {logging_mixin.py:115} INFO - [2022-06-05 09:53:35,362] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:53:35,365] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:53:35,464] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 09:54:05,831] {processor.py:153} INFO - Started process (PID=5454) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:54:05,834] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:54:05,841] {logging_mixin.py:115} INFO - [2022-06-05 09:54:05,841] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:54:05,994] {logging_mixin.py:115} INFO - [2022-06-05 09:54:05,991] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:54:05,996] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:54:06,107] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.282 seconds
[2022-06-05 09:54:36,365] {processor.py:153} INFO - Started process (PID=5525) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:54:36,368] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:54:36,370] {logging_mixin.py:115} INFO - [2022-06-05 09:54:36,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:54:36,626] {logging_mixin.py:115} INFO - [2022-06-05 09:54:36,624] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:54:36,628] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:54:36,734] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.374 seconds
[2022-06-05 09:55:07,583] {processor.py:153} INFO - Started process (PID=5594) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:55:07,585] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:55:07,588] {logging_mixin.py:115} INFO - [2022-06-05 09:55:07,588] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:55:07,743] {logging_mixin.py:115} INFO - [2022-06-05 09:55:07,741] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:55:07,744] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:55:07,838] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.259 seconds
[2022-06-05 09:55:38,467] {processor.py:153} INFO - Started process (PID=5662) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:55:38,470] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:55:38,472] {logging_mixin.py:115} INFO - [2022-06-05 09:55:38,472] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:55:38,678] {logging_mixin.py:115} INFO - [2022-06-05 09:55:38,675] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:55:38,681] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:55:38,778] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.316 seconds
[2022-06-05 09:56:09,126] {processor.py:153} INFO - Started process (PID=5732) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:56:09,129] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:56:09,131] {logging_mixin.py:115} INFO - [2022-06-05 09:56:09,131] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:56:09,261] {logging_mixin.py:115} INFO - [2022-06-05 09:56:09,258] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:56:09,262] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:56:09,358] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-05 09:56:39,617] {processor.py:153} INFO - Started process (PID=5798) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:56:39,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:56:39,622] {logging_mixin.py:115} INFO - [2022-06-05 09:56:39,622] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:56:39,946] {logging_mixin.py:115} INFO - [2022-06-05 09:56:39,939] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:56:39,950] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:56:40,128] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.515 seconds
[2022-06-05 09:57:10,585] {processor.py:153} INFO - Started process (PID=5856) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:57:10,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:57:10,590] {logging_mixin.py:115} INFO - [2022-06-05 09:57:10,590] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:57:10,819] {logging_mixin.py:115} INFO - [2022-06-05 09:57:10,818] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:57:10,820] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:57:10,920] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.339 seconds
[2022-06-05 09:57:41,541] {processor.py:153} INFO - Started process (PID=5925) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:57:41,543] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:57:41,544] {logging_mixin.py:115} INFO - [2022-06-05 09:57:41,544] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:57:41,729] {logging_mixin.py:115} INFO - [2022-06-05 09:57:41,726] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:57:41,731] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:57:41,827] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.291 seconds
[2022-06-05 09:58:11,955] {processor.py:153} INFO - Started process (PID=5995) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:58:11,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:58:11,958] {logging_mixin.py:115} INFO - [2022-06-05 09:58:11,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:58:12,195] {logging_mixin.py:115} INFO - [2022-06-05 09:58:12,193] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:58:12,197] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:58:12,292] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.345 seconds
[2022-06-05 09:58:42,395] {processor.py:153} INFO - Started process (PID=6065) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:58:42,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:58:42,400] {logging_mixin.py:115} INFO - [2022-06-05 09:58:42,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:58:42,603] {logging_mixin.py:115} INFO - [2022-06-05 09:58:42,599] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:58:42,606] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:58:42,707] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.315 seconds
[2022-06-05 09:59:13,403] {processor.py:153} INFO - Started process (PID=6122) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:59:13,405] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:59:13,407] {logging_mixin.py:115} INFO - [2022-06-05 09:59:13,407] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:59:13,685] {logging_mixin.py:115} INFO - [2022-06-05 09:59:13,683] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:59:13,689] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:59:13,808] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.411 seconds
[2022-06-05 09:59:43,852] {processor.py:153} INFO - Started process (PID=6188) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:59:43,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 09:59:43,856] {logging_mixin.py:115} INFO - [2022-06-05 09:59:43,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:59:44,051] {logging_mixin.py:115} INFO - [2022-06-05 09:59:44,049] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 09:59:44,053] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 09:59:44,139] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.291 seconds
[2022-06-05 10:00:14,562] {processor.py:153} INFO - Started process (PID=6256) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:00:14,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:00:14,566] {logging_mixin.py:115} INFO - [2022-06-05 10:00:14,566] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:00:14,798] {logging_mixin.py:115} INFO - [2022-06-05 10:00:14,794] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:00:14,799] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:00:14,903] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.349 seconds
[2022-06-05 10:00:45,873] {processor.py:153} INFO - Started process (PID=6325) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:00:45,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:00:45,876] {logging_mixin.py:115} INFO - [2022-06-05 10:00:45,876] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:00:46,130] {logging_mixin.py:115} INFO - [2022-06-05 10:00:46,126] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:00:46,131] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:00:46,238] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.367 seconds
[2022-06-05 10:01:17,269] {processor.py:153} INFO - Started process (PID=6392) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:01:17,276] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:01:17,278] {logging_mixin.py:115} INFO - [2022-06-05 10:01:17,278] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:01:17,479] {logging_mixin.py:115} INFO - [2022-06-05 10:01:17,476] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:01:17,480] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:01:17,585] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.321 seconds
[2022-06-05 10:01:48,284] {processor.py:153} INFO - Started process (PID=6448) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:01:48,287] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:01:48,288] {logging_mixin.py:115} INFO - [2022-06-05 10:01:48,288] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:01:48,497] {logging_mixin.py:115} INFO - [2022-06-05 10:01:48,494] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:01:48,499] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:01:48,614] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.337 seconds
[2022-06-05 10:02:19,535] {processor.py:153} INFO - Started process (PID=6514) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:02:19,536] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:02:19,538] {logging_mixin.py:115} INFO - [2022-06-05 10:02:19,538] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:02:19,800] {logging_mixin.py:115} INFO - [2022-06-05 10:02:19,798] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:02:19,802] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:02:19,910] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.382 seconds
[2022-06-05 10:03:52,198] {processor.py:153} INFO - Started process (PID=34) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:03:52,205] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:03:52,211] {logging_mixin.py:115} INFO - [2022-06-05 10:03:52,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:03:52,539] {logging_mixin.py:115} INFO - [2022-06-05 10:03:52,533] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:03:52,540] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:03:52,886] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.694 seconds
[2022-06-05 10:04:23,854] {processor.py:153} INFO - Started process (PID=102) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:04:23,856] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:04:23,858] {logging_mixin.py:115} INFO - [2022-06-05 10:04:23,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:04:24,016] {logging_mixin.py:115} INFO - [2022-06-05 10:04:24,013] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:04:24,018] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:04:24,110] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.263 seconds
[2022-06-05 10:10:17,768] {processor.py:153} INFO - Started process (PID=33) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:10:17,774] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:10:17,778] {logging_mixin.py:115} INFO - [2022-06-05 10:10:17,776] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:10:18,146] {logging_mixin.py:115} INFO - [2022-06-05 10:10:18,139] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:10:18,148] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:10:18,511] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.774 seconds
[2022-06-05 10:10:48,831] {processor.py:153} INFO - Started process (PID=97) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:10:48,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:10:48,834] {logging_mixin.py:115} INFO - [2022-06-05 10:10:48,834] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:10:48,967] {logging_mixin.py:115} INFO - [2022-06-05 10:10:48,964] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:10:48,969] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:10:49,061] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 10:11:19,851] {processor.py:153} INFO - Started process (PID=166) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:11:19,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:11:19,855] {logging_mixin.py:115} INFO - [2022-06-05 10:11:19,855] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:11:20,004] {logging_mixin.py:115} INFO - [2022-06-05 10:11:20,002] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:11:20,005] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:11:20,102] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-05 10:11:50,228] {processor.py:153} INFO - Started process (PID=225) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:11:50,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:11:50,232] {logging_mixin.py:115} INFO - [2022-06-05 10:11:50,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:11:50,370] {logging_mixin.py:115} INFO - [2022-06-05 10:11:50,369] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:11:50,373] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:11:50,468] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-05 10:12:20,818] {processor.py:153} INFO - Started process (PID=292) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:12:20,825] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:12:20,827] {logging_mixin.py:115} INFO - [2022-06-05 10:12:20,827] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:12:20,996] {logging_mixin.py:115} INFO - [2022-06-05 10:12:20,993] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:12:20,998] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:12:21,119] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.307 seconds
[2022-06-05 10:12:51,739] {processor.py:153} INFO - Started process (PID=358) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:12:51,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:12:51,744] {logging_mixin.py:115} INFO - [2022-06-05 10:12:51,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:12:51,928] {logging_mixin.py:115} INFO - [2022-06-05 10:12:51,926] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:12:51,930] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:12:52,024] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.292 seconds
[2022-06-05 10:13:22,072] {processor.py:153} INFO - Started process (PID=417) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:13:22,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:13:22,075] {logging_mixin.py:115} INFO - [2022-06-05 10:13:22,075] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:13:22,408] {logging_mixin.py:115} INFO - [2022-06-05 10:13:22,399] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:13:22,411] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:13:22,944] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.877 seconds
[2022-06-05 10:13:53,468] {processor.py:153} INFO - Started process (PID=485) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:13:53,471] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:13:53,473] {logging_mixin.py:115} INFO - [2022-06-05 10:13:53,472] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:13:53,692] {logging_mixin.py:115} INFO - [2022-06-05 10:13:53,689] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:13:53,693] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:13:53,801] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.339 seconds
[2022-06-05 10:14:24,215] {processor.py:153} INFO - Started process (PID=549) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:14:24,218] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:14:24,219] {logging_mixin.py:115} INFO - [2022-06-05 10:14:24,219] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:14:24,585] {logging_mixin.py:115} INFO - [2022-06-05 10:14:24,581] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:14:24,596] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:14:24,748] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.542 seconds
[2022-06-05 10:14:54,854] {processor.py:153} INFO - Started process (PID=624) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:14:54,860] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:14:54,863] {logging_mixin.py:115} INFO - [2022-06-05 10:14:54,862] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:14:55,018] {logging_mixin.py:115} INFO - [2022-06-05 10:14:55,017] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:14:55,020] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:14:55,115] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.271 seconds
[2022-06-05 10:15:25,608] {processor.py:153} INFO - Started process (PID=691) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:15:25,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:15:25,612] {logging_mixin.py:115} INFO - [2022-06-05 10:15:25,612] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:15:25,734] {logging_mixin.py:115} INFO - [2022-06-05 10:15:25,732] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:15:25,735] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:15:25,831] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 10:15:56,142] {processor.py:153} INFO - Started process (PID=748) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:15:56,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:15:56,145] {logging_mixin.py:115} INFO - [2022-06-05 10:15:56,145] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:15:56,337] {logging_mixin.py:115} INFO - [2022-06-05 10:15:56,332] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:15:56,338] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:15:56,454] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.315 seconds
[2022-06-05 10:16:26,734] {processor.py:153} INFO - Started process (PID=817) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:16:26,736] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:16:26,738] {logging_mixin.py:115} INFO - [2022-06-05 10:16:26,738] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:16:27,037] {logging_mixin.py:115} INFO - [2022-06-05 10:16:27,034] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:16:27,040] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:16:27,180] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.454 seconds
[2022-06-05 10:16:57,261] {processor.py:153} INFO - Started process (PID=884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:16:57,263] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:16:57,266] {logging_mixin.py:115} INFO - [2022-06-05 10:16:57,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:16:57,472] {logging_mixin.py:115} INFO - [2022-06-05 10:16:57,470] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:16:57,473] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:16:57,573] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.318 seconds
[2022-06-05 10:17:27,614] {processor.py:153} INFO - Started process (PID=950) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:17:27,616] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:17:27,618] {logging_mixin.py:115} INFO - [2022-06-05 10:17:27,618] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:17:27,752] {logging_mixin.py:115} INFO - [2022-06-05 10:17:27,750] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:17:27,754] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:17:27,848] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 10:17:58,234] {processor.py:153} INFO - Started process (PID=1019) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:17:58,235] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:17:58,236] {logging_mixin.py:115} INFO - [2022-06-05 10:17:58,236] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:17:58,383] {logging_mixin.py:115} INFO - [2022-06-05 10:17:58,381] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:17:58,385] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:17:58,489] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.258 seconds
[2022-06-05 10:18:28,659] {processor.py:153} INFO - Started process (PID=1075) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:18:28,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:18:28,661] {logging_mixin.py:115} INFO - [2022-06-05 10:18:28,661] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:18:28,803] {logging_mixin.py:115} INFO - [2022-06-05 10:18:28,800] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:18:28,805] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:18:28,906] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-05 10:18:58,956] {processor.py:153} INFO - Started process (PID=1147) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:18:58,958] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:18:58,959] {logging_mixin.py:115} INFO - [2022-06-05 10:18:58,959] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:18:59,076] {logging_mixin.py:115} INFO - [2022-06-05 10:18:59,073] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:18:59,078] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:18:59,168] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-05 10:19:29,306] {processor.py:153} INFO - Started process (PID=1215) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:19:29,308] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:19:29,309] {logging_mixin.py:115} INFO - [2022-06-05 10:19:29,309] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:19:29,433] {logging_mixin.py:115} INFO - [2022-06-05 10:19:29,432] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:19:29,436] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:19:29,534] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-05 10:20:00,202] {processor.py:153} INFO - Started process (PID=1283) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:20:00,205] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:20:00,207] {logging_mixin.py:115} INFO - [2022-06-05 10:20:00,206] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:20:00,347] {logging_mixin.py:115} INFO - [2022-06-05 10:20:00,345] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:20:00,348] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:20:00,446] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-05 10:20:30,540] {processor.py:153} INFO - Started process (PID=1352) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:20:30,542] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:20:30,543] {logging_mixin.py:115} INFO - [2022-06-05 10:20:30,543] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:20:30,686] {logging_mixin.py:115} INFO - [2022-06-05 10:20:30,684] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:20:30,688] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:20:30,793] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-05 10:21:01,118] {processor.py:153} INFO - Started process (PID=1410) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:21:01,120] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:21:01,122] {logging_mixin.py:115} INFO - [2022-06-05 10:21:01,122] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:21:01,241] {logging_mixin.py:115} INFO - [2022-06-05 10:21:01,238] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:21:01,242] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:21:01,333] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-05 10:21:32,359] {processor.py:153} INFO - Started process (PID=1478) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:21:32,361] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:21:32,363] {logging_mixin.py:115} INFO - [2022-06-05 10:21:32,363] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:21:32,485] {logging_mixin.py:115} INFO - [2022-06-05 10:21:32,483] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:21:32,486] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:21:32,597] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 10:22:02,668] {processor.py:153} INFO - Started process (PID=1546) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:22:02,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:22:02,671] {logging_mixin.py:115} INFO - [2022-06-05 10:22:02,671] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:22:02,802] {logging_mixin.py:115} INFO - [2022-06-05 10:22:02,800] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:22:02,806] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:22:02,902] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 10:22:32,976] {processor.py:153} INFO - Started process (PID=1615) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:22:32,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:22:32,980] {logging_mixin.py:115} INFO - [2022-06-05 10:22:32,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:22:33,106] {logging_mixin.py:115} INFO - [2022-06-05 10:22:33,103] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:22:33,108] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:22:33,199] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 10:23:03,357] {processor.py:153} INFO - Started process (PID=1683) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:23:03,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:23:03,360] {logging_mixin.py:115} INFO - [2022-06-05 10:23:03,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:23:03,483] {logging_mixin.py:115} INFO - [2022-06-05 10:23:03,481] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:23:03,485] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:23:03,582] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 10:23:34,083] {processor.py:153} INFO - Started process (PID=1753) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:23:34,086] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:23:34,087] {logging_mixin.py:115} INFO - [2022-06-05 10:23:34,087] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:23:34,228] {logging_mixin.py:115} INFO - [2022-06-05 10:23:34,227] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:23:34,230] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:23:34,322] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-05 10:24:05,302] {processor.py:153} INFO - Started process (PID=1820) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:24:05,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:24:05,306] {logging_mixin.py:115} INFO - [2022-06-05 10:24:05,306] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:24:05,463] {logging_mixin.py:115} INFO - [2022-06-05 10:24:05,460] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:24:05,464] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:24:05,563] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-05 10:24:36,208] {processor.py:153} INFO - Started process (PID=1882) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:24:36,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:24:36,212] {logging_mixin.py:115} INFO - [2022-06-05 10:24:36,212] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:24:36,481] {logging_mixin.py:115} INFO - [2022-06-05 10:24:36,479] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:24:36,482] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:24:36,604] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.402 seconds
[2022-06-05 10:25:06,800] {processor.py:153} INFO - Started process (PID=1950) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:25:06,803] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:25:06,805] {logging_mixin.py:115} INFO - [2022-06-05 10:25:06,805] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:25:06,933] {logging_mixin.py:115} INFO - [2022-06-05 10:25:06,930] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:25:06,934] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:25:07,024] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 10:25:37,279] {processor.py:153} INFO - Started process (PID=2018) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:25:37,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:25:37,284] {logging_mixin.py:115} INFO - [2022-06-05 10:25:37,284] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:25:37,413] {logging_mixin.py:115} INFO - [2022-06-05 10:25:37,410] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:25:37,414] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:25:37,507] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 10:26:07,542] {processor.py:153} INFO - Started process (PID=2087) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:26:07,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:26:07,545] {logging_mixin.py:115} INFO - [2022-06-05 10:26:07,545] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:26:07,668] {logging_mixin.py:115} INFO - [2022-06-05 10:26:07,666] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:26:07,670] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:26:07,771] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 10:26:38,121] {processor.py:153} INFO - Started process (PID=2152) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:26:38,123] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:26:38,124] {logging_mixin.py:115} INFO - [2022-06-05 10:26:38,124] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:26:38,240] {logging_mixin.py:115} INFO - [2022-06-05 10:26:38,238] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:26:38,241] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:26:38,335] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-05 10:27:08,733] {processor.py:153} INFO - Started process (PID=2210) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:27:08,734] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:27:08,735] {logging_mixin.py:115} INFO - [2022-06-05 10:27:08,735] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:27:08,872] {logging_mixin.py:115} INFO - [2022-06-05 10:27:08,870] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:27:08,875] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:27:08,981] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-05 10:27:39,185] {processor.py:153} INFO - Started process (PID=2278) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:27:39,188] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:27:39,190] {logging_mixin.py:115} INFO - [2022-06-05 10:27:39,190] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:27:39,332] {logging_mixin.py:115} INFO - [2022-06-05 10:27:39,330] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:27:39,334] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:27:39,425] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-05 10:28:09,719] {processor.py:153} INFO - Started process (PID=2346) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:28:09,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:28:09,726] {logging_mixin.py:115} INFO - [2022-06-05 10:28:09,726] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:28:09,860] {logging_mixin.py:115} INFO - [2022-06-05 10:28:09,858] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:28:09,862] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:28:09,953] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 10:28:40,965] {processor.py:153} INFO - Started process (PID=2416) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:28:40,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:28:40,967] {logging_mixin.py:115} INFO - [2022-06-05 10:28:40,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:28:41,084] {logging_mixin.py:115} INFO - [2022-06-05 10:28:41,083] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:28:41,086] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:28:41,178] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-05 10:29:12,148] {processor.py:153} INFO - Started process (PID=2483) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:29:12,150] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:29:12,151] {logging_mixin.py:115} INFO - [2022-06-05 10:29:12,151] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:29:12,265] {logging_mixin.py:115} INFO - [2022-06-05 10:29:12,262] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:29:12,266] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:29:12,358] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-05 10:29:43,059] {processor.py:153} INFO - Started process (PID=2551) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:29:43,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:29:43,062] {logging_mixin.py:115} INFO - [2022-06-05 10:29:43,062] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:29:43,178] {logging_mixin.py:115} INFO - [2022-06-05 10:29:43,176] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:29:43,180] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:29:43,273] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-05 10:30:13,993] {processor.py:153} INFO - Started process (PID=2619) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:30:13,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:30:13,997] {logging_mixin.py:115} INFO - [2022-06-05 10:30:13,997] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:30:14,140] {logging_mixin.py:115} INFO - [2022-06-05 10:30:14,136] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:30:14,141] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:30:14,239] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.251 seconds
[2022-06-05 10:30:44,312] {processor.py:153} INFO - Started process (PID=2675) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:30:44,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:30:44,315] {logging_mixin.py:115} INFO - [2022-06-05 10:30:44,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:30:44,439] {logging_mixin.py:115} INFO - [2022-06-05 10:30:44,437] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:30:44,442] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:30:44,547] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 10:31:14,627] {processor.py:153} INFO - Started process (PID=2742) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:31:14,629] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:31:14,630] {logging_mixin.py:115} INFO - [2022-06-05 10:31:14,630] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:31:14,748] {logging_mixin.py:115} INFO - [2022-06-05 10:31:14,746] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:31:14,749] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:31:14,840] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-05 10:31:44,934] {processor.py:153} INFO - Started process (PID=2810) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:31:44,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:31:44,939] {logging_mixin.py:115} INFO - [2022-06-05 10:31:44,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:31:45,062] {logging_mixin.py:115} INFO - [2022-06-05 10:31:45,060] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:31:45,064] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:31:45,156] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-05 10:32:15,410] {processor.py:153} INFO - Started process (PID=2879) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:32:15,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:32:15,415] {logging_mixin.py:115} INFO - [2022-06-05 10:32:15,415] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:32:15,551] {logging_mixin.py:115} INFO - [2022-06-05 10:32:15,547] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:32:15,552] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:32:15,656] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-05 10:32:45,760] {processor.py:153} INFO - Started process (PID=2946) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:32:45,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:32:45,765] {logging_mixin.py:115} INFO - [2022-06-05 10:32:45,765] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:32:45,921] {logging_mixin.py:115} INFO - [2022-06-05 10:32:45,919] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:32:45,923] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:32:46,019] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-05 10:33:16,550] {processor.py:153} INFO - Started process (PID=3004) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:33:16,552] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:33:16,554] {logging_mixin.py:115} INFO - [2022-06-05 10:33:16,553] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:33:16,686] {logging_mixin.py:115} INFO - [2022-06-05 10:33:16,683] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:33:16,688] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:33:16,793] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-05 10:33:47,717] {processor.py:153} INFO - Started process (PID=3072) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:33:47,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:33:47,720] {logging_mixin.py:115} INFO - [2022-06-05 10:33:47,720] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:33:47,838] {logging_mixin.py:115} INFO - [2022-06-05 10:33:47,836] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:33:47,840] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:33:47,940] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-05 10:34:18,130] {processor.py:153} INFO - Started process (PID=3142) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:34:18,132] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:34:18,134] {logging_mixin.py:115} INFO - [2022-06-05 10:34:18,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:34:18,258] {logging_mixin.py:115} INFO - [2022-06-05 10:34:18,256] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:34:18,260] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:34:18,351] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 10:34:49,202] {processor.py:153} INFO - Started process (PID=3212) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:34:49,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:34:49,208] {logging_mixin.py:115} INFO - [2022-06-05 10:34:49,208] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:34:49,353] {logging_mixin.py:115} INFO - [2022-06-05 10:34:49,351] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:34:49,354] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:34:49,453] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.258 seconds
[2022-06-05 10:35:19,562] {processor.py:153} INFO - Started process (PID=3277) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:35:19,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:35:19,564] {logging_mixin.py:115} INFO - [2022-06-05 10:35:19,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:35:19,681] {logging_mixin.py:115} INFO - [2022-06-05 10:35:19,679] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:35:19,683] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:35:19,783] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-05 10:35:49,997] {processor.py:153} INFO - Started process (PID=3345) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:35:50,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:35:50,002] {logging_mixin.py:115} INFO - [2022-06-05 10:35:50,002] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:35:50,160] {logging_mixin.py:115} INFO - [2022-06-05 10:35:50,158] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:35:50,161] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:35:50,264] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.272 seconds
[2022-06-05 10:36:20,315] {processor.py:153} INFO - Started process (PID=3415) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:36:20,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:36:20,318] {logging_mixin.py:115} INFO - [2022-06-05 10:36:20,317] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:36:20,466] {logging_mixin.py:115} INFO - [2022-06-05 10:36:20,462] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:36:20,467] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:36:20,597] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.286 seconds
[2022-06-05 10:36:50,691] {processor.py:153} INFO - Started process (PID=3471) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:36:50,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:36:50,694] {logging_mixin.py:115} INFO - [2022-06-05 10:36:50,694] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:36:50,812] {logging_mixin.py:115} INFO - [2022-06-05 10:36:50,810] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:36:50,813] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:36:50,905] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-05 10:37:21,124] {processor.py:153} INFO - Started process (PID=3539) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:37:21,127] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:37:21,129] {logging_mixin.py:115} INFO - [2022-06-05 10:37:21,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:37:21,265] {logging_mixin.py:115} INFO - [2022-06-05 10:37:21,262] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:37:21,267] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:37:21,363] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 10:37:51,454] {processor.py:153} INFO - Started process (PID=3604) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:37:51,457] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:37:51,460] {logging_mixin.py:115} INFO - [2022-06-05 10:37:51,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:37:51,601] {logging_mixin.py:115} INFO - [2022-06-05 10:37:51,599] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:37:51,602] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:37:51,698] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.250 seconds
[2022-06-05 10:38:21,997] {processor.py:153} INFO - Started process (PID=3674) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:38:21,999] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:38:22,000] {logging_mixin.py:115} INFO - [2022-06-05 10:38:22,000] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:38:22,121] {logging_mixin.py:115} INFO - [2022-06-05 10:38:22,119] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:38:22,123] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:38:22,214] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-05 10:38:53,009] {processor.py:153} INFO - Started process (PID=3741) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:38:53,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:38:53,012] {logging_mixin.py:115} INFO - [2022-06-05 10:38:53,011] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:38:53,169] {logging_mixin.py:115} INFO - [2022-06-05 10:38:53,167] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:38:53,171] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:38:53,278] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.275 seconds
[2022-06-05 10:39:23,939] {processor.py:153} INFO - Started process (PID=3801) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:39:23,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:39:23,942] {logging_mixin.py:115} INFO - [2022-06-05 10:39:23,942] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:39:24,059] {logging_mixin.py:115} INFO - [2022-06-05 10:39:24,056] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:39:24,061] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:39:24,150] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-05 10:39:54,702] {processor.py:153} INFO - Started process (PID=3870) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:39:54,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:39:54,708] {logging_mixin.py:115} INFO - [2022-06-05 10:39:54,708] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:39:54,845] {logging_mixin.py:115} INFO - [2022-06-05 10:39:54,842] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:39:54,846] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:39:54,940] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 10:40:25,868] {processor.py:153} INFO - Started process (PID=3941) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:40:25,869] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:40:25,870] {logging_mixin.py:115} INFO - [2022-06-05 10:40:25,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:40:26,001] {logging_mixin.py:115} INFO - [2022-06-05 10:40:25,999] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:40:26,003] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:40:26,106] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 10:40:57,034] {processor.py:153} INFO - Started process (PID=4013) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:40:57,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:40:57,037] {logging_mixin.py:115} INFO - [2022-06-05 10:40:57,037] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:40:57,166] {logging_mixin.py:115} INFO - [2022-06-05 10:40:57,164] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:40:57,168] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:40:57,270] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 10:41:28,094] {processor.py:153} INFO - Started process (PID=4079) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:41:28,095] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:41:28,097] {logging_mixin.py:115} INFO - [2022-06-05 10:41:28,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:41:28,233] {logging_mixin.py:115} INFO - [2022-06-05 10:41:28,230] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:41:28,234] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:41:28,335] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 10:41:58,867] {processor.py:153} INFO - Started process (PID=4145) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:41:58,869] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:41:58,871] {logging_mixin.py:115} INFO - [2022-06-05 10:41:58,871] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:41:58,993] {logging_mixin.py:115} INFO - [2022-06-05 10:41:58,991] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:41:58,995] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:41:59,087] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-05 10:42:30,029] {processor.py:153} INFO - Started process (PID=4213) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:42:30,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:42:30,033] {logging_mixin.py:115} INFO - [2022-06-05 10:42:30,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:42:30,175] {logging_mixin.py:115} INFO - [2022-06-05 10:42:30,172] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:42:30,177] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:42:30,298] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.273 seconds
[2022-06-05 10:43:00,565] {processor.py:153} INFO - Started process (PID=4272) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:43:00,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:43:00,571] {logging_mixin.py:115} INFO - [2022-06-05 10:43:00,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:43:00,706] {logging_mixin.py:115} INFO - [2022-06-05 10:43:00,703] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:43:00,707] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:43:00,804] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-05 10:43:30,897] {processor.py:153} INFO - Started process (PID=4339) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:43:30,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:43:30,901] {logging_mixin.py:115} INFO - [2022-06-05 10:43:30,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:43:31,047] {logging_mixin.py:115} INFO - [2022-06-05 10:43:31,045] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:43:31,048] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:43:31,149] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.254 seconds
[2022-06-05 10:44:01,327] {processor.py:153} INFO - Started process (PID=4404) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:44:01,331] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:44:01,333] {logging_mixin.py:115} INFO - [2022-06-05 10:44:01,332] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:44:01,461] {logging_mixin.py:115} INFO - [2022-06-05 10:44:01,459] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:44:01,463] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:44:01,567] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.248 seconds
[2022-06-05 10:44:31,648] {processor.py:153} INFO - Started process (PID=4479) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:44:31,650] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:44:31,652] {logging_mixin.py:115} INFO - [2022-06-05 10:44:31,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:44:31,793] {logging_mixin.py:115} INFO - [2022-06-05 10:44:31,791] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:44:31,794] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:44:31,886] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-05 10:45:01,933] {processor.py:153} INFO - Started process (PID=4536) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:45:01,935] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:45:01,936] {logging_mixin.py:115} INFO - [2022-06-05 10:45:01,936] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:45:02,062] {logging_mixin.py:115} INFO - [2022-06-05 10:45:02,060] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:45:02,064] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:45:02,162] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 10:45:32,761] {processor.py:153} INFO - Started process (PID=4605) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:45:32,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:45:32,765] {logging_mixin.py:115} INFO - [2022-06-05 10:45:32,765] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:45:32,899] {logging_mixin.py:115} INFO - [2022-06-05 10:45:32,895] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:45:32,900] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:45:32,995] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 10:46:04,039] {processor.py:153} INFO - Started process (PID=4676) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:46:04,041] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:46:04,045] {logging_mixin.py:115} INFO - [2022-06-05 10:46:04,045] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:46:04,182] {logging_mixin.py:115} INFO - [2022-06-05 10:46:04,180] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:46:04,183] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:46:04,276] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-05 10:46:35,053] {processor.py:153} INFO - Started process (PID=4745) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:46:35,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:46:35,056] {logging_mixin.py:115} INFO - [2022-06-05 10:46:35,056] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:46:35,198] {logging_mixin.py:115} INFO - [2022-06-05 10:46:35,196] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:46:35,199] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:46:35,292] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-05 10:47:06,101] {processor.py:153} INFO - Started process (PID=4813) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:47:06,103] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:47:06,106] {logging_mixin.py:115} INFO - [2022-06-05 10:47:06,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:47:06,244] {logging_mixin.py:115} INFO - [2022-06-05 10:47:06,242] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:47:06,249] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:47:06,349] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.251 seconds
[2022-06-05 10:47:36,640] {processor.py:153} INFO - Started process (PID=4886) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:47:36,644] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:47:36,647] {logging_mixin.py:115} INFO - [2022-06-05 10:47:36,647] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:47:36,787] {logging_mixin.py:115} INFO - [2022-06-05 10:47:36,782] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:47:36,788] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:47:36,889] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-05 10:48:06,995] {processor.py:153} INFO - Started process (PID=4943) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:48:06,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:48:07,000] {logging_mixin.py:115} INFO - [2022-06-05 10:48:07,000] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:48:07,134] {logging_mixin.py:115} INFO - [2022-06-05 10:48:07,131] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:48:07,136] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:48:07,253] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-05 10:48:38,273] {processor.py:153} INFO - Started process (PID=5009) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:48:38,276] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:48:38,279] {logging_mixin.py:115} INFO - [2022-06-05 10:48:38,279] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:48:38,422] {logging_mixin.py:115} INFO - [2022-06-05 10:48:38,420] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:48:38,424] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:48:38,519] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-05 10:49:08,611] {processor.py:153} INFO - Started process (PID=5079) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:49:08,613] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:49:08,615] {logging_mixin.py:115} INFO - [2022-06-05 10:49:08,615] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:49:08,744] {logging_mixin.py:115} INFO - [2022-06-05 10:49:08,742] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:49:08,744] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:49:08,837] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 10:49:38,990] {processor.py:153} INFO - Started process (PID=5151) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:49:38,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:49:38,994] {logging_mixin.py:115} INFO - [2022-06-05 10:49:38,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:49:39,117] {logging_mixin.py:115} INFO - [2022-06-05 10:49:39,115] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:49:39,118] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:49:39,213] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-05 10:50:09,776] {processor.py:153} INFO - Started process (PID=5218) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:50:09,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:50:09,781] {logging_mixin.py:115} INFO - [2022-06-05 10:50:09,781] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:50:09,990] {logging_mixin.py:115} INFO - [2022-06-05 10:50:09,988] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:50:09,991] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:50:10,094] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.324 seconds
[2022-06-05 10:50:40,249] {processor.py:153} INFO - Started process (PID=5279) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:50:40,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:50:40,256] {logging_mixin.py:115} INFO - [2022-06-05 10:50:40,256] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:50:40,438] {logging_mixin.py:115} INFO - [2022-06-05 10:50:40,435] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:50:40,441] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:50:40,574] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.329 seconds
[2022-06-05 10:51:10,776] {processor.py:153} INFO - Started process (PID=5345) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:51:10,777] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:51:10,778] {logging_mixin.py:115} INFO - [2022-06-05 10:51:10,778] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:51:10,899] {logging_mixin.py:115} INFO - [2022-06-05 10:51:10,896] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:51:10,900] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:51:10,991] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-05 10:51:41,408] {processor.py:153} INFO - Started process (PID=5412) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:51:41,411] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:51:41,413] {logging_mixin.py:115} INFO - [2022-06-05 10:51:41,413] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:51:41,562] {logging_mixin.py:115} INFO - [2022-06-05 10:51:41,560] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:51:41,564] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:51:41,654] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-05 10:52:11,870] {processor.py:153} INFO - Started process (PID=5481) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:52:11,873] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:52:11,875] {logging_mixin.py:115} INFO - [2022-06-05 10:52:11,875] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:52:12,008] {logging_mixin.py:115} INFO - [2022-06-05 10:52:12,005] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:52:12,010] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:52:12,102] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 10:52:43,005] {processor.py:153} INFO - Started process (PID=5549) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:52:43,006] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:52:43,008] {logging_mixin.py:115} INFO - [2022-06-05 10:52:43,008] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:52:43,160] {logging_mixin.py:115} INFO - [2022-06-05 10:52:43,157] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:52:43,163] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:52:43,267] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.265 seconds
[2022-06-05 10:53:14,165] {processor.py:153} INFO - Started process (PID=5617) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:53:14,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:53:14,167] {logging_mixin.py:115} INFO - [2022-06-05 10:53:14,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:53:14,281] {logging_mixin.py:115} INFO - [2022-06-05 10:53:14,279] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:53:14,282] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:53:14,373] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.210 seconds
[2022-06-05 10:53:45,318] {processor.py:153} INFO - Started process (PID=5675) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:53:45,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:53:45,329] {logging_mixin.py:115} INFO - [2022-06-05 10:53:45,329] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:53:45,579] {logging_mixin.py:115} INFO - [2022-06-05 10:53:45,568] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:53:45,581] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:53:45,783] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.473 seconds
[2022-06-05 10:54:15,881] {processor.py:153} INFO - Started process (PID=5742) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:54:15,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:54:15,887] {logging_mixin.py:115} INFO - [2022-06-05 10:54:15,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:54:16,018] {logging_mixin.py:115} INFO - [2022-06-05 10:54:16,016] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:54:16,020] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:54:16,113] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 10:54:46,625] {processor.py:153} INFO - Started process (PID=5813) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:54:46,627] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:54:46,628] {logging_mixin.py:115} INFO - [2022-06-05 10:54:46,628] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:54:46,777] {logging_mixin.py:115} INFO - [2022-06-05 10:54:46,775] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:54:46,779] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:54:46,877] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-05 10:55:16,946] {processor.py:153} INFO - Started process (PID=5882) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:55:16,948] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:55:16,950] {logging_mixin.py:115} INFO - [2022-06-05 10:55:16,950] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:55:17,064] {logging_mixin.py:115} INFO - [2022-06-05 10:55:17,061] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:55:17,065] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:55:17,158] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-05 10:55:48,133] {processor.py:153} INFO - Started process (PID=5953) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:55:48,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:55:48,136] {logging_mixin.py:115} INFO - [2022-06-05 10:55:48,136] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:55:48,271] {logging_mixin.py:115} INFO - [2022-06-05 10:55:48,268] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:55:48,272] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:55:48,379] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-05 10:56:19,406] {processor.py:153} INFO - Started process (PID=6018) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:56:19,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:56:19,412] {logging_mixin.py:115} INFO - [2022-06-05 10:56:19,412] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:56:19,539] {logging_mixin.py:115} INFO - [2022-06-05 10:56:19,537] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:56:19,540] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:56:19,631] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 10:56:49,765] {processor.py:153} INFO - Started process (PID=6076) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:56:49,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:56:49,770] {logging_mixin.py:115} INFO - [2022-06-05 10:56:49,770] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:56:49,913] {logging_mixin.py:115} INFO - [2022-06-05 10:56:49,911] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:56:49,915] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:56:50,007] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.248 seconds
[2022-06-05 10:57:20,421] {processor.py:153} INFO - Started process (PID=6149) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:57:20,424] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:57:20,425] {logging_mixin.py:115} INFO - [2022-06-05 10:57:20,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:57:20,561] {logging_mixin.py:115} INFO - [2022-06-05 10:57:20,559] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:57:20,563] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:57:20,657] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 10:57:50,811] {processor.py:153} INFO - Started process (PID=6216) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:57:50,813] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:57:50,814] {logging_mixin.py:115} INFO - [2022-06-05 10:57:50,814] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:57:50,937] {logging_mixin.py:115} INFO - [2022-06-05 10:57:50,935] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:57:50,939] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:57:51,044] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 10:58:21,183] {processor.py:153} INFO - Started process (PID=6289) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:58:21,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:58:21,187] {logging_mixin.py:115} INFO - [2022-06-05 10:58:21,187] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:58:21,320] {logging_mixin.py:115} INFO - [2022-06-05 10:58:21,318] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:58:21,321] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:58:21,416] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 10:58:51,682] {processor.py:153} INFO - Started process (PID=6364) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:58:51,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:58:51,686] {logging_mixin.py:115} INFO - [2022-06-05 10:58:51,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:58:51,814] {logging_mixin.py:115} INFO - [2022-06-05 10:58:51,812] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:58:51,815] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:58:51,907] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 10:59:21,967] {processor.py:153} INFO - Started process (PID=6422) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:59:21,968] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:59:21,970] {logging_mixin.py:115} INFO - [2022-06-05 10:59:21,969] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:59:22,082] {logging_mixin.py:115} INFO - [2022-06-05 10:59:22,080] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:59:22,084] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:59:22,176] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-05 10:59:52,404] {processor.py:153} INFO - Started process (PID=6487) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:59:52,407] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 10:59:52,409] {logging_mixin.py:115} INFO - [2022-06-05 10:59:52,409] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:59:52,549] {logging_mixin.py:115} INFO - [2022-06-05 10:59:52,547] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 10:59:52,549] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 10:59:52,641] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-05 11:00:22,954] {processor.py:153} INFO - Started process (PID=6554) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:00:22,957] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:00:22,959] {logging_mixin.py:115} INFO - [2022-06-05 11:00:22,959] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:00:23,106] {logging_mixin.py:115} INFO - [2022-06-05 11:00:23,104] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:00:23,108] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:00:23,203] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.254 seconds
[2022-06-05 11:00:53,406] {processor.py:153} INFO - Started process (PID=6626) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:00:53,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:00:53,410] {logging_mixin.py:115} INFO - [2022-06-05 11:00:53,410] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:00:53,528] {logging_mixin.py:115} INFO - [2022-06-05 11:00:53,526] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:00:53,530] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:00:53,624] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 11:01:23,759] {processor.py:153} INFO - Started process (PID=6691) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:01:23,760] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:01:23,761] {logging_mixin.py:115} INFO - [2022-06-05 11:01:23,761] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:01:23,878] {logging_mixin.py:115} INFO - [2022-06-05 11:01:23,876] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:01:23,880] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:01:23,972] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-05 11:01:54,444] {processor.py:153} INFO - Started process (PID=6749) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:01:54,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:01:54,449] {logging_mixin.py:115} INFO - [2022-06-05 11:01:54,449] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:01:54,573] {logging_mixin.py:115} INFO - [2022-06-05 11:01:54,572] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:01:54,575] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:01:54,668] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 11:02:25,209] {processor.py:153} INFO - Started process (PID=6816) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:02:25,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:02:25,211] {logging_mixin.py:115} INFO - [2022-06-05 11:02:25,211] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:02:25,333] {logging_mixin.py:115} INFO - [2022-06-05 11:02:25,331] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:02:25,334] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:02:25,426] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-05 11:02:55,993] {processor.py:153} INFO - Started process (PID=6887) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:02:55,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:02:55,997] {logging_mixin.py:115} INFO - [2022-06-05 11:02:55,997] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:02:56,124] {logging_mixin.py:115} INFO - [2022-06-05 11:02:56,121] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:02:56,125] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:02:56,219] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-05 11:03:26,402] {processor.py:153} INFO - Started process (PID=6954) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:03:26,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:03:26,409] {logging_mixin.py:115} INFO - [2022-06-05 11:03:26,409] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:03:26,538] {logging_mixin.py:115} INFO - [2022-06-05 11:03:26,535] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:03:26,544] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:03:26,642] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-05 11:03:56,825] {processor.py:153} INFO - Started process (PID=7024) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:03:56,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:03:56,830] {logging_mixin.py:115} INFO - [2022-06-05 11:03:56,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:03:56,956] {logging_mixin.py:115} INFO - [2022-06-05 11:03:56,953] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:03:56,957] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:03:57,063] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 11:04:27,504] {processor.py:153} INFO - Started process (PID=7081) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:04:27,510] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:04:27,513] {logging_mixin.py:115} INFO - [2022-06-05 11:04:27,512] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:04:27,654] {logging_mixin.py:115} INFO - [2022-06-05 11:04:27,652] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:04:27,656] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:04:27,751] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-05 11:04:58,614] {processor.py:153} INFO - Started process (PID=7152) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:04:58,615] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:04:58,616] {logging_mixin.py:115} INFO - [2022-06-05 11:04:58,616] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:04:58,732] {logging_mixin.py:115} INFO - [2022-06-05 11:04:58,731] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:04:58,735] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:04:58,831] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-05 11:05:29,379] {processor.py:153} INFO - Started process (PID=7218) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:05:29,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:05:29,384] {logging_mixin.py:115} INFO - [2022-06-05 11:05:29,384] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:05:29,519] {logging_mixin.py:115} INFO - [2022-06-05 11:05:29,518] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:05:29,521] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:05:29,612] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 11:05:59,869] {processor.py:153} INFO - Started process (PID=7284) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:05:59,871] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:05:59,873] {logging_mixin.py:115} INFO - [2022-06-05 11:05:59,873] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:05:59,999] {logging_mixin.py:115} INFO - [2022-06-05 11:05:59,996] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:06:00,001] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:06:00,092] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 11:06:30,296] {processor.py:153} INFO - Started process (PID=7356) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:06:30,298] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:06:30,299] {logging_mixin.py:115} INFO - [2022-06-05 11:06:30,299] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:06:30,418] {logging_mixin.py:115} INFO - [2022-06-05 11:06:30,416] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:06:30,420] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:06:30,512] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-05 11:07:00,722] {processor.py:153} INFO - Started process (PID=7425) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:07:00,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:07:00,725] {logging_mixin.py:115} INFO - [2022-06-05 11:07:00,725] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:07:00,890] {logging_mixin.py:115} INFO - [2022-06-05 11:07:00,888] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:07:00,892] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:07:01,009] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.290 seconds
[2022-06-05 11:07:31,614] {processor.py:153} INFO - Started process (PID=7483) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:07:31,617] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:07:31,619] {logging_mixin.py:115} INFO - [2022-06-05 11:07:31,619] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:07:31,746] {logging_mixin.py:115} INFO - [2022-06-05 11:07:31,742] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:07:31,747] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:07:31,839] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-05 11:08:02,500] {processor.py:153} INFO - Started process (PID=7556) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:08:02,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:08:02,505] {logging_mixin.py:115} INFO - [2022-06-05 11:08:02,505] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:08:02,665] {logging_mixin.py:115} INFO - [2022-06-05 11:08:02,662] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:08:02,667] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:08:02,766] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.273 seconds
[2022-06-05 11:08:33,088] {processor.py:153} INFO - Started process (PID=7623) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:08:33,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:08:33,090] {logging_mixin.py:115} INFO - [2022-06-05 11:08:33,090] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:08:33,212] {logging_mixin.py:115} INFO - [2022-06-05 11:08:33,210] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:08:33,213] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:08:33,308] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 11:09:03,403] {processor.py:153} INFO - Started process (PID=7691) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:09:03,405] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:09:03,406] {logging_mixin.py:115} INFO - [2022-06-05 11:09:03,406] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:09:03,518] {logging_mixin.py:115} INFO - [2022-06-05 11:09:03,516] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:09:03,520] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:09:03,616] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-05 11:09:33,777] {processor.py:153} INFO - Started process (PID=7756) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:09:33,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:09:33,781] {logging_mixin.py:115} INFO - [2022-06-05 11:09:33,781] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:09:33,942] {logging_mixin.py:115} INFO - [2022-06-05 11:09:33,939] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:09:33,944] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:09:34,130] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.355 seconds
[2022-06-05 11:10:04,431] {processor.py:153} INFO - Started process (PID=7813) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:10:04,432] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:10:04,433] {logging_mixin.py:115} INFO - [2022-06-05 11:10:04,433] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:10:04,550] {logging_mixin.py:115} INFO - [2022-06-05 11:10:04,548] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:10:04,551] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:10:04,645] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-05 11:10:35,323] {processor.py:153} INFO - Started process (PID=7879) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:10:35,326] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:10:35,327] {logging_mixin.py:115} INFO - [2022-06-05 11:10:35,327] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:10:35,451] {logging_mixin.py:115} INFO - [2022-06-05 11:10:35,450] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:10:35,453] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:10:35,552] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 11:11:06,135] {processor.py:153} INFO - Started process (PID=7950) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:11:06,137] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:11:06,138] {logging_mixin.py:115} INFO - [2022-06-05 11:11:06,138] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:11:06,263] {logging_mixin.py:115} INFO - [2022-06-05 11:11:06,261] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:11:06,265] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:11:06,360] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 11:11:37,093] {processor.py:153} INFO - Started process (PID=8018) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:11:37,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:11:37,098] {logging_mixin.py:115} INFO - [2022-06-05 11:11:37,098] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:11:37,224] {logging_mixin.py:115} INFO - [2022-06-05 11:11:37,222] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:11:37,225] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:11:37,322] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 11:12:07,667] {processor.py:153} INFO - Started process (PID=8083) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:12:07,668] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:12:07,669] {logging_mixin.py:115} INFO - [2022-06-05 11:12:07,669] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:12:07,833] {logging_mixin.py:115} INFO - [2022-06-05 11:12:07,831] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:12:07,835] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:12:07,950] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.286 seconds
[2022-06-05 11:12:38,354] {processor.py:153} INFO - Started process (PID=8142) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:12:38,356] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:12:38,357] {logging_mixin.py:115} INFO - [2022-06-05 11:12:38,357] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:12:38,493] {logging_mixin.py:115} INFO - [2022-06-05 11:12:38,490] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:12:38,495] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:12:38,595] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 11:13:09,568] {processor.py:153} INFO - Started process (PID=8211) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:13:09,570] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:13:09,571] {logging_mixin.py:115} INFO - [2022-06-05 11:13:09,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:13:09,693] {logging_mixin.py:115} INFO - [2022-06-05 11:13:09,691] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:13:09,694] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:13:09,786] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-05 11:13:40,575] {processor.py:153} INFO - Started process (PID=8282) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:13:40,578] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:13:40,579] {logging_mixin.py:115} INFO - [2022-06-05 11:13:40,579] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:13:40,717] {logging_mixin.py:115} INFO - [2022-06-05 11:13:40,715] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:13:40,719] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:13:40,814] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 11:14:11,301] {processor.py:153} INFO - Started process (PID=8352) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:14:11,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:14:11,304] {logging_mixin.py:115} INFO - [2022-06-05 11:14:11,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:14:11,427] {logging_mixin.py:115} INFO - [2022-06-05 11:14:11,425] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:14:11,428] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:14:11,520] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-05 11:14:41,809] {processor.py:153} INFO - Started process (PID=8418) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:14:41,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:14:41,812] {logging_mixin.py:115} INFO - [2022-06-05 11:14:41,812] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:14:41,934] {logging_mixin.py:115} INFO - [2022-06-05 11:14:41,933] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:14:41,936] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:14:42,028] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 11:15:12,446] {processor.py:153} INFO - Started process (PID=8476) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:15:12,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:15:12,450] {logging_mixin.py:115} INFO - [2022-06-05 11:15:12,450] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:15:12,601] {logging_mixin.py:115} INFO - [2022-06-05 11:15:12,599] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:15:12,602] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:15:12,704] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.265 seconds
[2022-06-05 11:15:42,964] {processor.py:153} INFO - Started process (PID=8540) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:15:42,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:15:42,968] {logging_mixin.py:115} INFO - [2022-06-05 11:15:42,968] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:15:43,101] {logging_mixin.py:115} INFO - [2022-06-05 11:15:43,098] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:15:43,105] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:15:43,197] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 11:16:13,342] {processor.py:153} INFO - Started process (PID=8609) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:16:13,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:16:13,347] {logging_mixin.py:115} INFO - [2022-06-05 11:16:13,347] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:16:13,478] {logging_mixin.py:115} INFO - [2022-06-05 11:16:13,475] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:16:13,479] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:16:13,570] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 11:16:43,994] {processor.py:153} INFO - Started process (PID=8676) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:16:43,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:16:43,999] {logging_mixin.py:115} INFO - [2022-06-05 11:16:43,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:16:44,341] {logging_mixin.py:115} INFO - [2022-06-05 11:16:44,338] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:16:44,343] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:16:44,504] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.531 seconds
[2022-06-05 11:17:15,032] {processor.py:153} INFO - Started process (PID=8745) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:17:15,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:17:15,035] {logging_mixin.py:115} INFO - [2022-06-05 11:17:15,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:17:15,249] {logging_mixin.py:115} INFO - [2022-06-05 11:17:15,241] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:17:15,250] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:17:15,490] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.460 seconds
[2022-06-05 11:17:46,384] {processor.py:153} INFO - Started process (PID=8804) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:17:46,388] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:17:46,390] {logging_mixin.py:115} INFO - [2022-06-05 11:17:46,390] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:17:46,519] {logging_mixin.py:115} INFO - [2022-06-05 11:17:46,517] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:17:46,520] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:17:46,613] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 11:18:17,437] {processor.py:153} INFO - Started process (PID=8870) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:18:17,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:18:17,441] {logging_mixin.py:115} INFO - [2022-06-05 11:18:17,441] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:18:17,570] {logging_mixin.py:115} INFO - [2022-06-05 11:18:17,568] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:18:17,571] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:18:17,664] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 11:18:48,603] {processor.py:153} INFO - Started process (PID=8938) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:18:48,605] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:18:48,606] {logging_mixin.py:115} INFO - [2022-06-05 11:18:48,606] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:18:48,741] {logging_mixin.py:115} INFO - [2022-06-05 11:18:48,740] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:18:48,742] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:18:48,841] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 11:19:19,204] {processor.py:153} INFO - Started process (PID=9007) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:19:19,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:19:19,207] {logging_mixin.py:115} INFO - [2022-06-05 11:19:19,207] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:19:19,323] {logging_mixin.py:115} INFO - [2022-06-05 11:19:19,321] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:19:19,327] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:19:19,424] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 11:19:50,338] {processor.py:153} INFO - Started process (PID=9076) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:19:50,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:19:50,342] {logging_mixin.py:115} INFO - [2022-06-05 11:19:50,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:19:50,480] {logging_mixin.py:115} INFO - [2022-06-05 11:19:50,478] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:19:50,481] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:19:50,573] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 11:20:20,832] {processor.py:153} INFO - Started process (PID=9135) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:20:20,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:20:20,837] {logging_mixin.py:115} INFO - [2022-06-05 11:20:20,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:20:20,964] {logging_mixin.py:115} INFO - [2022-06-05 11:20:20,961] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:20:20,965] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:20:21,062] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 11:20:51,482] {processor.py:153} INFO - Started process (PID=9202) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:20:51,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:20:51,488] {logging_mixin.py:115} INFO - [2022-06-05 11:20:51,488] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:20:51,628] {logging_mixin.py:115} INFO - [2022-06-05 11:20:51,625] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:20:51,629] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:20:51,727] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.254 seconds
[2022-06-05 11:21:21,810] {processor.py:153} INFO - Started process (PID=9271) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:21:21,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:21:21,813] {logging_mixin.py:115} INFO - [2022-06-05 11:21:21,813] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:21:21,926] {logging_mixin.py:115} INFO - [2022-06-05 11:21:21,923] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:21:21,928] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:21:22,017] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-05 11:21:52,468] {processor.py:153} INFO - Started process (PID=9341) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:21:52,471] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:21:52,473] {logging_mixin.py:115} INFO - [2022-06-05 11:21:52,473] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:21:52,607] {logging_mixin.py:115} INFO - [2022-06-05 11:21:52,605] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:21:52,608] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:21:52,700] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 11:22:22,823] {processor.py:153} INFO - Started process (PID=9407) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:22:22,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:22:22,825] {logging_mixin.py:115} INFO - [2022-06-05 11:22:22,825] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:22:22,953] {logging_mixin.py:115} INFO - [2022-06-05 11:22:22,950] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:22:22,955] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:22:23,054] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 11:22:53,188] {processor.py:153} INFO - Started process (PID=9463) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:22:53,189] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:22:53,192] {logging_mixin.py:115} INFO - [2022-06-05 11:22:53,192] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:22:53,330] {logging_mixin.py:115} INFO - [2022-06-05 11:22:53,328] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:22:53,331] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:22:53,425] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-05 11:23:23,614] {processor.py:153} INFO - Started process (PID=9530) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:23:23,617] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:23:23,619] {logging_mixin.py:115} INFO - [2022-06-05 11:23:23,619] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:23:23,746] {logging_mixin.py:115} INFO - [2022-06-05 11:23:23,742] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:23:23,747] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:23:23,841] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 11:23:54,473] {processor.py:153} INFO - Started process (PID=9597) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:23:54,476] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:23:54,478] {logging_mixin.py:115} INFO - [2022-06-05 11:23:54,478] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:23:54,606] {logging_mixin.py:115} INFO - [2022-06-05 11:23:54,604] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:23:54,607] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:23:54,697] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 11:24:24,970] {processor.py:153} INFO - Started process (PID=9662) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:24:24,972] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:24:24,976] {logging_mixin.py:115} INFO - [2022-06-05 11:24:24,976] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:24:25,105] {logging_mixin.py:115} INFO - [2022-06-05 11:24:25,103] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:24:25,108] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:24:25,198] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 11:24:55,347] {processor.py:153} INFO - Started process (PID=9731) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:24:55,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:24:55,352] {logging_mixin.py:115} INFO - [2022-06-05 11:24:55,352] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:24:55,475] {logging_mixin.py:115} INFO - [2022-06-05 11:24:55,473] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:24:55,476] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:24:55,568] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-05 11:25:25,715] {processor.py:153} INFO - Started process (PID=9789) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:25:25,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:25:25,717] {logging_mixin.py:115} INFO - [2022-06-05 11:25:25,717] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:25:25,857] {logging_mixin.py:115} INFO - [2022-06-05 11:25:25,855] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:25:25,858] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:25:25,959] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-05 11:25:56,267] {processor.py:153} INFO - Started process (PID=9856) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:25:56,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:25:56,270] {logging_mixin.py:115} INFO - [2022-06-05 11:25:56,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:25:56,399] {logging_mixin.py:115} INFO - [2022-06-05 11:25:56,398] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:25:56,401] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:25:56,494] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-05 11:26:26,736] {processor.py:153} INFO - Started process (PID=9924) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:26:26,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:26:26,740] {logging_mixin.py:115} INFO - [2022-06-05 11:26:26,740] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:26:26,861] {logging_mixin.py:115} INFO - [2022-06-05 11:26:26,859] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:26:26,862] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:26:26,955] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 11:26:57,243] {processor.py:153} INFO - Started process (PID=9994) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:26:57,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:26:57,248] {logging_mixin.py:115} INFO - [2022-06-05 11:26:57,248] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:26:57,380] {logging_mixin.py:115} INFO - [2022-06-05 11:26:57,378] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:26:57,382] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:26:57,474] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 11:27:27,996] {processor.py:153} INFO - Started process (PID=10065) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:27:28,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:27:28,002] {logging_mixin.py:115} INFO - [2022-06-05 11:27:28,002] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:27:28,133] {logging_mixin.py:115} INFO - [2022-06-05 11:27:28,131] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:27:28,135] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:27:28,225] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 11:27:58,346] {processor.py:153} INFO - Started process (PID=10132) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:27:58,347] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:27:58,348] {logging_mixin.py:115} INFO - [2022-06-05 11:27:58,348] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:27:58,471] {logging_mixin.py:115} INFO - [2022-06-05 11:27:58,469] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:27:58,473] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:27:58,571] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 11:28:28,653] {processor.py:153} INFO - Started process (PID=10193) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:28:28,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:28:28,655] {logging_mixin.py:115} INFO - [2022-06-05 11:28:28,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:28:28,770] {logging_mixin.py:115} INFO - [2022-06-05 11:28:28,768] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:28:28,771] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:28:28,862] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-05 11:28:59,758] {processor.py:153} INFO - Started process (PID=10259) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:28:59,761] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:28:59,763] {logging_mixin.py:115} INFO - [2022-06-05 11:28:59,763] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:28:59,895] {logging_mixin.py:115} INFO - [2022-06-05 11:28:59,893] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:28:59,897] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:28:59,988] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 11:29:30,163] {processor.py:153} INFO - Started process (PID=10329) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:29:30,164] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:29:30,165] {logging_mixin.py:115} INFO - [2022-06-05 11:29:30,165] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:29:30,280] {logging_mixin.py:115} INFO - [2022-06-05 11:29:30,277] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:29:30,281] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:29:30,371] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-05 11:30:00,583] {processor.py:153} INFO - Started process (PID=10397) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:30:00,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:30:00,588] {logging_mixin.py:115} INFO - [2022-06-05 11:30:00,588] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:30:00,720] {logging_mixin.py:115} INFO - [2022-06-05 11:30:00,717] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:30:00,722] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:30:00,817] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 11:30:31,185] {processor.py:153} INFO - Started process (PID=10464) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:30:31,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:30:31,188] {logging_mixin.py:115} INFO - [2022-06-05 11:30:31,187] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:30:31,307] {logging_mixin.py:115} INFO - [2022-06-05 11:30:31,305] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:30:31,308] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:30:31,417] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 11:31:01,637] {processor.py:153} INFO - Started process (PID=10521) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:31:01,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:31:01,641] {logging_mixin.py:115} INFO - [2022-06-05 11:31:01,641] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:31:01,765] {logging_mixin.py:115} INFO - [2022-06-05 11:31:01,763] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:31:01,766] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:31:01,857] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-05 11:31:32,036] {processor.py:153} INFO - Started process (PID=10588) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:31:32,037] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:31:32,038] {logging_mixin.py:115} INFO - [2022-06-05 11:31:32,038] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:31:32,151] {logging_mixin.py:115} INFO - [2022-06-05 11:31:32,148] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:31:32,152] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:31:32,244] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.210 seconds
[2022-06-05 11:32:02,840] {processor.py:153} INFO - Started process (PID=10658) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:32:02,843] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:32:02,844] {logging_mixin.py:115} INFO - [2022-06-05 11:32:02,844] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:32:02,968] {logging_mixin.py:115} INFO - [2022-06-05 11:32:02,966] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:32:02,970] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:32:03,060] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-05 11:32:33,228] {processor.py:153} INFO - Started process (PID=10724) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:32:33,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:32:33,232] {logging_mixin.py:115} INFO - [2022-06-05 11:32:33,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:32:33,391] {logging_mixin.py:115} INFO - [2022-06-05 11:32:33,389] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:32:33,393] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:32:33,486] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-05 11:33:03,850] {processor.py:153} INFO - Started process (PID=10794) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:33:03,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:33:03,852] {logging_mixin.py:115} INFO - [2022-06-05 11:33:03,852] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:33:03,980] {logging_mixin.py:115} INFO - [2022-06-05 11:33:03,978] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:33:03,981] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:33:04,082] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 11:33:34,126] {processor.py:153} INFO - Started process (PID=10859) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:33:34,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:33:34,129] {logging_mixin.py:115} INFO - [2022-06-05 11:33:34,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:33:34,278] {logging_mixin.py:115} INFO - [2022-06-05 11:33:34,275] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:33:34,279] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:33:34,374] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.250 seconds
[2022-06-05 11:34:04,437] {processor.py:153} INFO - Started process (PID=10919) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:34:04,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:34:04,439] {logging_mixin.py:115} INFO - [2022-06-05 11:34:04,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:34:04,574] {logging_mixin.py:115} INFO - [2022-06-05 11:34:04,571] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:34:04,575] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:34:04,680] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-05 11:34:35,113] {processor.py:153} INFO - Started process (PID=10989) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:34:35,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:34:35,118] {logging_mixin.py:115} INFO - [2022-06-05 11:34:35,118] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:34:35,254] {logging_mixin.py:115} INFO - [2022-06-05 11:34:35,252] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:34:35,256] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:34:35,348] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 11:35:05,637] {processor.py:153} INFO - Started process (PID=11057) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:35:05,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:35:05,640] {logging_mixin.py:115} INFO - [2022-06-05 11:35:05,640] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:35:05,760] {logging_mixin.py:115} INFO - [2022-06-05 11:35:05,757] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:35:05,761] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:35:05,871] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-05 11:35:36,097] {processor.py:153} INFO - Started process (PID=11123) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:35:36,099] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:35:36,101] {logging_mixin.py:115} INFO - [2022-06-05 11:35:36,101] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:35:36,250] {logging_mixin.py:115} INFO - [2022-06-05 11:35:36,248] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:35:36,252] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:35:36,355] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.260 seconds
[2022-06-05 11:36:06,639] {processor.py:153} INFO - Started process (PID=11189) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:36:06,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:36:06,643] {logging_mixin.py:115} INFO - [2022-06-05 11:36:06,643] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:36:06,770] {logging_mixin.py:115} INFO - [2022-06-05 11:36:06,768] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:36:06,772] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:36:06,864] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-05 11:36:37,245] {processor.py:153} INFO - Started process (PID=11246) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:36:37,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:36:37,249] {logging_mixin.py:115} INFO - [2022-06-05 11:36:37,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:36:37,534] {logging_mixin.py:115} INFO - [2022-06-05 11:36:37,525] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:36:37,537] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:36:37,660] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.428 seconds
[2022-06-05 11:37:08,656] {processor.py:153} INFO - Started process (PID=11311) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:37:08,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:37:08,663] {logging_mixin.py:115} INFO - [2022-06-05 11:37:08,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:37:08,809] {logging_mixin.py:115} INFO - [2022-06-05 11:37:08,807] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:37:08,810] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:37:08,911] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.263 seconds
[2022-06-05 11:37:39,321] {processor.py:153} INFO - Started process (PID=11380) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:37:39,323] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:37:39,324] {logging_mixin.py:115} INFO - [2022-06-05 11:37:39,324] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:37:39,438] {logging_mixin.py:115} INFO - [2022-06-05 11:37:39,436] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:37:39,439] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:37:39,531] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-05 11:38:09,670] {processor.py:153} INFO - Started process (PID=11447) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:38:09,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:38:09,673] {logging_mixin.py:115} INFO - [2022-06-05 11:38:09,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:38:09,794] {logging_mixin.py:115} INFO - [2022-06-05 11:38:09,792] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:38:09,795] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:38:09,889] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 11:38:39,964] {processor.py:153} INFO - Started process (PID=11516) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:38:39,966] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:38:39,967] {logging_mixin.py:115} INFO - [2022-06-05 11:38:39,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:38:40,092] {logging_mixin.py:115} INFO - [2022-06-05 11:38:40,088] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:38:40,093] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:38:40,194] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 11:39:10,770] {processor.py:153} INFO - Started process (PID=11585) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:39:10,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:39:10,774] {logging_mixin.py:115} INFO - [2022-06-05 11:39:10,774] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:39:10,899] {logging_mixin.py:115} INFO - [2022-06-05 11:39:10,897] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:39:10,901] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:39:10,992] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-05 11:39:41,471] {processor.py:153} INFO - Started process (PID=11652) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:39:41,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:39:41,474] {logging_mixin.py:115} INFO - [2022-06-05 11:39:41,474] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:39:41,605] {logging_mixin.py:115} INFO - [2022-06-05 11:39:41,601] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:39:41,606] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:39:41,705] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 11:40:12,146] {processor.py:153} INFO - Started process (PID=11710) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:40:12,149] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:40:12,152] {logging_mixin.py:115} INFO - [2022-06-05 11:40:12,152] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:40:12,294] {logging_mixin.py:115} INFO - [2022-06-05 11:40:12,292] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:40:12,297] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:40:12,392] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.251 seconds
[2022-06-05 11:40:42,580] {processor.py:153} INFO - Started process (PID=11778) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:40:42,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:40:42,583] {logging_mixin.py:115} INFO - [2022-06-05 11:40:42,583] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:40:42,713] {logging_mixin.py:115} INFO - [2022-06-05 11:40:42,710] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:40:42,715] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:40:42,809] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 11:41:12,944] {processor.py:153} INFO - Started process (PID=11843) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:41:12,946] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:41:12,947] {logging_mixin.py:115} INFO - [2022-06-05 11:41:12,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:41:13,107] {logging_mixin.py:115} INFO - [2022-06-05 11:41:13,105] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:41:13,109] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:41:13,204] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-05 11:41:43,616] {processor.py:153} INFO - Started process (PID=11910) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:41:43,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:41:43,621] {logging_mixin.py:115} INFO - [2022-06-05 11:41:43,620] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:41:43,751] {logging_mixin.py:115} INFO - [2022-06-05 11:41:43,747] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:41:43,752] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:41:43,840] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-05 11:42:14,034] {processor.py:153} INFO - Started process (PID=11977) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:42:14,037] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:42:14,038] {logging_mixin.py:115} INFO - [2022-06-05 11:42:14,038] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:42:14,164] {logging_mixin.py:115} INFO - [2022-06-05 11:42:14,162] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:42:14,166] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:42:14,260] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 11:42:44,308] {processor.py:153} INFO - Started process (PID=12035) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:42:44,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:42:44,310] {logging_mixin.py:115} INFO - [2022-06-05 11:42:44,310] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:42:44,465] {logging_mixin.py:115} INFO - [2022-06-05 11:42:44,462] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:42:44,466] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:42:44,568] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-05 11:43:15,131] {processor.py:153} INFO - Started process (PID=12102) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:43:15,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:43:15,137] {logging_mixin.py:115} INFO - [2022-06-05 11:43:15,137] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:43:15,270] {logging_mixin.py:115} INFO - [2022-06-05 11:43:15,268] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:43:15,271] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:43:15,363] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 11:43:45,628] {processor.py:153} INFO - Started process (PID=12171) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:43:45,631] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:43:45,632] {logging_mixin.py:115} INFO - [2022-06-05 11:43:45,632] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:43:45,760] {logging_mixin.py:115} INFO - [2022-06-05 11:43:45,758] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:43:45,761] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:43:45,852] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 11:44:16,074] {processor.py:153} INFO - Started process (PID=12239) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:44:16,076] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:44:16,078] {logging_mixin.py:115} INFO - [2022-06-05 11:44:16,078] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:44:16,199] {logging_mixin.py:115} INFO - [2022-06-05 11:44:16,197] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:44:16,201] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:44:16,309] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 11:44:46,680] {processor.py:153} INFO - Started process (PID=12307) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:44:46,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:44:46,686] {logging_mixin.py:115} INFO - [2022-06-05 11:44:46,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:44:46,818] {logging_mixin.py:115} INFO - [2022-06-05 11:44:46,815] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:44:46,820] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:44:46,918] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-05 11:45:17,068] {processor.py:153} INFO - Started process (PID=12375) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:45:17,070] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:45:17,071] {logging_mixin.py:115} INFO - [2022-06-05 11:45:17,071] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:45:17,233] {logging_mixin.py:115} INFO - [2022-06-05 11:45:17,231] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:45:17,235] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:45:17,329] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-05 11:45:47,969] {processor.py:153} INFO - Started process (PID=12432) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:45:47,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:45:47,975] {logging_mixin.py:115} INFO - [2022-06-05 11:45:47,975] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:45:48,105] {logging_mixin.py:115} INFO - [2022-06-05 11:45:48,104] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:45:48,106] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:45:48,199] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 11:46:18,388] {processor.py:153} INFO - Started process (PID=12501) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:46:18,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:46:18,393] {logging_mixin.py:115} INFO - [2022-06-05 11:46:18,393] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:46:18,518] {logging_mixin.py:115} INFO - [2022-06-05 11:46:18,516] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:46:18,526] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:46:18,618] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 11:46:48,934] {processor.py:153} INFO - Started process (PID=12572) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:46:48,936] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:46:48,937] {logging_mixin.py:115} INFO - [2022-06-05 11:46:48,937] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:46:49,062] {logging_mixin.py:115} INFO - [2022-06-05 11:46:49,060] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:46:49,064] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:46:49,163] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 11:47:19,355] {processor.py:153} INFO - Started process (PID=12645) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:47:19,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:47:19,361] {logging_mixin.py:115} INFO - [2022-06-05 11:47:19,361] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:47:19,497] {logging_mixin.py:115} INFO - [2022-06-05 11:47:19,494] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:47:19,498] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:47:19,590] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 11:47:49,741] {processor.py:153} INFO - Started process (PID=12714) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:47:49,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:47:49,745] {logging_mixin.py:115} INFO - [2022-06-05 11:47:49,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:47:49,870] {logging_mixin.py:115} INFO - [2022-06-05 11:47:49,867] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:47:49,872] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:47:49,969] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-05 11:48:20,351] {processor.py:153} INFO - Started process (PID=12774) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:48:20,354] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:48:20,356] {logging_mixin.py:115} INFO - [2022-06-05 11:48:20,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:48:20,517] {logging_mixin.py:115} INFO - [2022-06-05 11:48:20,514] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:48:20,518] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:48:20,623] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.278 seconds
[2022-06-05 11:48:50,893] {processor.py:153} INFO - Started process (PID=12841) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:48:50,895] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:48:50,896] {logging_mixin.py:115} INFO - [2022-06-05 11:48:50,896] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:48:51,025] {logging_mixin.py:115} INFO - [2022-06-05 11:48:51,023] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:48:51,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:48:51,120] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-05 11:49:21,438] {processor.py:153} INFO - Started process (PID=12908) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:49:21,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:49:21,440] {logging_mixin.py:115} INFO - [2022-06-05 11:49:21,440] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:49:21,562] {logging_mixin.py:115} INFO - [2022-06-05 11:49:21,560] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:49:21,563] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:49:21,663] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 11:49:51,900] {processor.py:153} INFO - Started process (PID=12975) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:49:51,902] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:49:51,904] {logging_mixin.py:115} INFO - [2022-06-05 11:49:51,904] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:49:52,026] {logging_mixin.py:115} INFO - [2022-06-05 11:49:52,024] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:49:52,028] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:49:52,119] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-05 11:50:22,382] {processor.py:153} INFO - Started process (PID=13044) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:50:22,401] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:50:22,404] {logging_mixin.py:115} INFO - [2022-06-05 11:50:22,404] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:50:22,569] {logging_mixin.py:115} INFO - [2022-06-05 11:50:22,566] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:50:22,571] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:50:22,675] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.298 seconds
[2022-06-05 11:50:52,760] {processor.py:153} INFO - Started process (PID=13104) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:50:52,762] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:50:52,764] {logging_mixin.py:115} INFO - [2022-06-05 11:50:52,764] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:50:52,897] {logging_mixin.py:115} INFO - [2022-06-05 11:50:52,895] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:50:52,898] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:50:52,989] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 11:51:23,434] {processor.py:153} INFO - Started process (PID=13170) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:51:23,436] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:51:23,437] {logging_mixin.py:115} INFO - [2022-06-05 11:51:23,437] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:51:23,573] {logging_mixin.py:115} INFO - [2022-06-05 11:51:23,571] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:51:23,574] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:51:23,670] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 11:51:53,899] {processor.py:153} INFO - Started process (PID=13240) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:51:53,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:51:53,902] {logging_mixin.py:115} INFO - [2022-06-05 11:51:53,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:51:54,030] {logging_mixin.py:115} INFO - [2022-06-05 11:51:54,028] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:51:54,032] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:51:54,137] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 11:52:24,368] {processor.py:153} INFO - Started process (PID=13311) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:52:24,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:52:24,370] {logging_mixin.py:115} INFO - [2022-06-05 11:52:24,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:52:24,501] {logging_mixin.py:115} INFO - [2022-06-05 11:52:24,499] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:52:24,502] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:52:24,600] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 11:52:54,784] {processor.py:153} INFO - Started process (PID=13381) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:52:54,785] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:52:54,786] {logging_mixin.py:115} INFO - [2022-06-05 11:52:54,786] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:52:54,914] {logging_mixin.py:115} INFO - [2022-06-05 11:52:54,912] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:52:54,915] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:52:55,006] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-05 11:53:25,119] {processor.py:153} INFO - Started process (PID=13438) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:53:25,121] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:53:25,122] {logging_mixin.py:115} INFO - [2022-06-05 11:53:25,122] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:53:25,243] {logging_mixin.py:115} INFO - [2022-06-05 11:53:25,241] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:53:25,245] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:53:25,339] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-05 11:53:55,545] {processor.py:153} INFO - Started process (PID=13507) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:53:55,547] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:53:55,548] {logging_mixin.py:115} INFO - [2022-06-05 11:53:55,548] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:53:55,663] {logging_mixin.py:115} INFO - [2022-06-05 11:53:55,661] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:53:55,664] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:53:55,756] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-05 11:54:26,336] {processor.py:153} INFO - Started process (PID=13579) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:54:26,338] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:54:26,339] {logging_mixin.py:115} INFO - [2022-06-05 11:54:26,339] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:54:26,471] {logging_mixin.py:115} INFO - [2022-06-05 11:54:26,468] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:54:26,473] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:54:26,575] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 11:54:56,981] {processor.py:153} INFO - Started process (PID=13648) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:54:56,984] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:54:56,986] {logging_mixin.py:115} INFO - [2022-06-05 11:54:56,986] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:54:57,122] {logging_mixin.py:115} INFO - [2022-06-05 11:54:57,120] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:54:57,123] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:54:57,216] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.248 seconds
[2022-06-05 11:55:27,948] {processor.py:153} INFO - Started process (PID=13717) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:55:27,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:55:27,956] {logging_mixin.py:115} INFO - [2022-06-05 11:55:27,956] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:55:28,087] {logging_mixin.py:115} INFO - [2022-06-05 11:55:28,084] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:55:28,089] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:55:28,180] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 11:55:58,307] {processor.py:153} INFO - Started process (PID=13782) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:55:58,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:55:58,311] {logging_mixin.py:115} INFO - [2022-06-05 11:55:58,311] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:55:58,460] {logging_mixin.py:115} INFO - [2022-06-05 11:55:58,456] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:55:58,462] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:55:58,583] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.278 seconds
[2022-06-05 11:56:28,708] {processor.py:153} INFO - Started process (PID=13847) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:56:28,710] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:56:28,711] {logging_mixin.py:115} INFO - [2022-06-05 11:56:28,711] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:56:28,834] {logging_mixin.py:115} INFO - [2022-06-05 11:56:28,832] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:56:28,835] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:56:28,934] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-05 11:56:59,134] {processor.py:153} INFO - Started process (PID=13915) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:56:59,136] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:56:59,139] {logging_mixin.py:115} INFO - [2022-06-05 11:56:59,139] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:56:59,264] {logging_mixin.py:115} INFO - [2022-06-05 11:56:59,262] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:56:59,265] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:56:59,357] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-05 11:57:29,780] {processor.py:153} INFO - Started process (PID=13981) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:57:29,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:57:29,784] {logging_mixin.py:115} INFO - [2022-06-05 11:57:29,784] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:57:29,913] {logging_mixin.py:115} INFO - [2022-06-05 11:57:29,911] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:57:29,915] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:57:30,007] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 11:58:00,599] {processor.py:153} INFO - Started process (PID=14046) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:58:00,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:58:00,602] {logging_mixin.py:115} INFO - [2022-06-05 11:58:00,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:58:00,719] {logging_mixin.py:115} INFO - [2022-06-05 11:58:00,717] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:58:00,720] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:58:00,816] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-05 11:58:30,923] {processor.py:153} INFO - Started process (PID=14114) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:58:30,925] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:58:30,926] {logging_mixin.py:115} INFO - [2022-06-05 11:58:30,926] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:58:31,058] {logging_mixin.py:115} INFO - [2022-06-05 11:58:31,053] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:58:31,060] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:58:31,215] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.295 seconds
[2022-06-05 11:59:01,361] {processor.py:153} INFO - Started process (PID=14171) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:59:01,363] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:59:01,365] {logging_mixin.py:115} INFO - [2022-06-05 11:59:01,365] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:59:01,550] {logging_mixin.py:115} INFO - [2022-06-05 11:59:01,548] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:59:01,551] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:59:01,649] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.294 seconds
[2022-06-05 11:59:31,927] {processor.py:153} INFO - Started process (PID=14241) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:59:31,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 11:59:31,931] {logging_mixin.py:115} INFO - [2022-06-05 11:59:31,931] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:59:32,064] {logging_mixin.py:115} INFO - [2022-06-05 11:59:32,062] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 11:59:32,065] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 11:59:32,158] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 12:00:02,408] {processor.py:153} INFO - Started process (PID=14306) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:00:02,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:00:02,412] {logging_mixin.py:115} INFO - [2022-06-05 12:00:02,412] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:00:02,566] {logging_mixin.py:115} INFO - [2022-06-05 12:00:02,564] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:00:02,567] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:00:02,680] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.277 seconds
[2022-06-05 12:00:32,967] {processor.py:153} INFO - Started process (PID=14374) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:00:32,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:00:32,973] {logging_mixin.py:115} INFO - [2022-06-05 12:00:32,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:00:33,100] {logging_mixin.py:115} INFO - [2022-06-05 12:00:33,098] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:00:33,101] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:00:33,193] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-05 12:01:03,386] {processor.py:153} INFO - Started process (PID=14430) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:01:03,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:01:03,394] {logging_mixin.py:115} INFO - [2022-06-05 12:01:03,394] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:01:03,550] {logging_mixin.py:115} INFO - [2022-06-05 12:01:03,547] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:01:03,552] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:01:03,674] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.292 seconds
[2022-06-05 12:01:33,925] {processor.py:153} INFO - Started process (PID=14498) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:01:33,926] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:01:33,927] {logging_mixin.py:115} INFO - [2022-06-05 12:01:33,927] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:01:34,048] {logging_mixin.py:115} INFO - [2022-06-05 12:01:34,047] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:01:34,049] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:01:34,138] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-05 12:02:04,226] {processor.py:153} INFO - Started process (PID=14567) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:02:04,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:02:04,229] {logging_mixin.py:115} INFO - [2022-06-05 12:02:04,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:02:04,346] {logging_mixin.py:115} INFO - [2022-06-05 12:02:04,344] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:02:04,348] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:02:04,440] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-05 12:02:34,936] {processor.py:153} INFO - Started process (PID=14634) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:02:34,938] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:02:34,939] {logging_mixin.py:115} INFO - [2022-06-05 12:02:34,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:02:35,070] {logging_mixin.py:115} INFO - [2022-06-05 12:02:35,068] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:02:35,071] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:02:35,174] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 12:03:05,558] {processor.py:153} INFO - Started process (PID=14701) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:03:05,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:03:05,562] {logging_mixin.py:115} INFO - [2022-06-05 12:03:05,562] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:03:05,683] {logging_mixin.py:115} INFO - [2022-06-05 12:03:05,681] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:03:05,685] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:03:05,777] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-05 12:03:35,845] {processor.py:153} INFO - Started process (PID=14758) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:03:35,847] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:03:35,848] {logging_mixin.py:115} INFO - [2022-06-05 12:03:35,848] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:03:35,975] {logging_mixin.py:115} INFO - [2022-06-05 12:03:35,973] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:03:35,976] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:03:36,080] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 12:04:06,465] {processor.py:153} INFO - Started process (PID=14824) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:04:06,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:04:06,468] {logging_mixin.py:115} INFO - [2022-06-05 12:04:06,468] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:04:06,593] {logging_mixin.py:115} INFO - [2022-06-05 12:04:06,591] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:04:06,595] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:04:06,691] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 12:04:37,109] {processor.py:153} INFO - Started process (PID=14894) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:04:37,112] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:04:37,115] {logging_mixin.py:115} INFO - [2022-06-05 12:04:37,115] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:04:37,252] {logging_mixin.py:115} INFO - [2022-06-05 12:04:37,250] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:04:37,253] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:04:37,346] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-05 12:05:07,743] {processor.py:153} INFO - Started process (PID=14962) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:05:07,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:05:07,745] {logging_mixin.py:115} INFO - [2022-06-05 12:05:07,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:05:07,880] {logging_mixin.py:115} INFO - [2022-06-05 12:05:07,877] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:05:07,881] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:05:07,982] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-05 12:05:38,387] {processor.py:153} INFO - Started process (PID=15034) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:05:38,390] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:05:38,392] {logging_mixin.py:115} INFO - [2022-06-05 12:05:38,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:05:38,525] {logging_mixin.py:115} INFO - [2022-06-05 12:05:38,522] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:05:38,526] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:05:38,618] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-05 12:06:08,813] {processor.py:153} INFO - Started process (PID=15096) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:06:08,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:06:08,820] {logging_mixin.py:115} INFO - [2022-06-05 12:06:08,820] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:06:08,967] {logging_mixin.py:115} INFO - [2022-06-05 12:06:08,966] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:06:08,968] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:06:09,075] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.267 seconds
[2022-06-05 12:06:39,370] {processor.py:153} INFO - Started process (PID=15163) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:06:39,376] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:06:39,378] {logging_mixin.py:115} INFO - [2022-06-05 12:06:39,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:06:39,512] {logging_mixin.py:115} INFO - [2022-06-05 12:06:39,510] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:06:39,514] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:06:39,606] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.242 seconds
[2022-06-05 12:07:09,839] {processor.py:153} INFO - Started process (PID=15231) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:07:09,841] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:07:09,842] {logging_mixin.py:115} INFO - [2022-06-05 12:07:09,842] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:07:09,955] {logging_mixin.py:115} INFO - [2022-06-05 12:07:09,953] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:07:09,956] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:07:10,049] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-05 12:07:40,358] {processor.py:153} INFO - Started process (PID=15301) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:07:40,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:07:40,362] {logging_mixin.py:115} INFO - [2022-06-05 12:07:40,362] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:07:40,480] {logging_mixin.py:115} INFO - [2022-06-05 12:07:40,477] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:07:40,482] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:07:40,592] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 12:08:10,979] {processor.py:153} INFO - Started process (PID=15370) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:08:10,981] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:08:10,984] {logging_mixin.py:115} INFO - [2022-06-05 12:08:10,984] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:08:11,102] {logging_mixin.py:115} INFO - [2022-06-05 12:08:11,100] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:08:11,103] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:08:11,197] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-05 12:08:41,479] {processor.py:153} INFO - Started process (PID=15426) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:08:41,482] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:08:41,484] {logging_mixin.py:115} INFO - [2022-06-05 12:08:41,484] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:08:41,638] {logging_mixin.py:115} INFO - [2022-06-05 12:08:41,636] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:08:41,640] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:08:41,749] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.278 seconds
[2022-06-05 12:09:11,973] {processor.py:153} INFO - Started process (PID=15496) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:09:11,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:09:11,979] {logging_mixin.py:115} INFO - [2022-06-05 12:09:11,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:09:12,107] {logging_mixin.py:115} INFO - [2022-06-05 12:09:12,105] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:09:12,108] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:09:12,200] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 12:09:42,306] {processor.py:153} INFO - Started process (PID=15567) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:09:42,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:09:42,312] {logging_mixin.py:115} INFO - [2022-06-05 12:09:42,312] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:09:42,440] {logging_mixin.py:115} INFO - [2022-06-05 12:09:42,438] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:09:42,442] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:09:42,532] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 12:10:12,842] {processor.py:153} INFO - Started process (PID=15635) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:10:12,845] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:10:12,846] {logging_mixin.py:115} INFO - [2022-06-05 12:10:12,846] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:10:12,976] {logging_mixin.py:115} INFO - [2022-06-05 12:10:12,974] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:10:12,977] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:10:13,070] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-05 12:10:43,487] {processor.py:153} INFO - Started process (PID=15700) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:10:43,490] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:10:43,492] {logging_mixin.py:115} INFO - [2022-06-05 12:10:43,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:10:43,637] {logging_mixin.py:115} INFO - [2022-06-05 12:10:43,632] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:10:43,639] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:10:43,751] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.273 seconds
[2022-06-05 12:11:14,727] {processor.py:153} INFO - Started process (PID=15774) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:11:14,730] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:11:14,731] {logging_mixin.py:115} INFO - [2022-06-05 12:11:14,731] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:11:14,869] {logging_mixin.py:115} INFO - [2022-06-05 12:11:14,866] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:11:14,870] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:11:14,979] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-05 12:11:45,236] {processor.py:153} INFO - Started process (PID=15835) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:11:45,239] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:11:45,241] {logging_mixin.py:115} INFO - [2022-06-05 12:11:45,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:11:45,377] {logging_mixin.py:115} INFO - [2022-06-05 12:11:45,375] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:11:45,380] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:11:45,476] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-05 12:12:15,825] {processor.py:153} INFO - Started process (PID=15906) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:12:15,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:12:15,831] {logging_mixin.py:115} INFO - [2022-06-05 12:12:15,831] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:12:15,988] {logging_mixin.py:115} INFO - [2022-06-05 12:12:15,985] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:12:15,992] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:12:16,086] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.267 seconds
[2022-06-05 12:12:46,752] {processor.py:153} INFO - Started process (PID=15971) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:12:46,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:12:46,759] {logging_mixin.py:115} INFO - [2022-06-05 12:12:46,759] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:12:46,887] {logging_mixin.py:115} INFO - [2022-06-05 12:12:46,885] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:12:46,889] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:12:46,989] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-05 12:13:17,361] {processor.py:153} INFO - Started process (PID=16040) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:13:17,362] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:13:17,364] {logging_mixin.py:115} INFO - [2022-06-05 12:13:17,364] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:13:17,477] {logging_mixin.py:115} INFO - [2022-06-05 12:13:17,475] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:13:17,478] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:13:17,570] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-05 12:13:48,424] {processor.py:153} INFO - Started process (PID=16108) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:13:48,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:13:48,428] {logging_mixin.py:115} INFO - [2022-06-05 12:13:48,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:13:48,547] {logging_mixin.py:115} INFO - [2022-06-05 12:13:48,545] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:13:48,548] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:13:48,639] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-05 12:14:19,082] {processor.py:153} INFO - Started process (PID=16165) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:14:19,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:14:19,087] {logging_mixin.py:115} INFO - [2022-06-05 12:14:19,087] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:14:19,214] {logging_mixin.py:115} INFO - [2022-06-05 12:14:19,212] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:14:19,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:14:19,308] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-05 12:14:49,994] {processor.py:153} INFO - Started process (PID=16238) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:14:49,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:14:49,996] {logging_mixin.py:115} INFO - [2022-06-05 12:14:49,996] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:14:50,115] {logging_mixin.py:115} INFO - [2022-06-05 12:14:50,113] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:14:50,116] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:14:50,210] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-05 12:15:21,073] {processor.py:153} INFO - Started process (PID=16305) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:15:21,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:15:21,077] {logging_mixin.py:115} INFO - [2022-06-05 12:15:21,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:15:21,251] {logging_mixin.py:115} INFO - [2022-06-05 12:15:21,249] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:15:21,253] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:15:21,353] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.284 seconds
[2022-06-05 12:15:51,785] {processor.py:153} INFO - Started process (PID=16370) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:15:51,788] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:15:51,790] {logging_mixin.py:115} INFO - [2022-06-05 12:15:51,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:15:51,933] {logging_mixin.py:115} INFO - [2022-06-05 12:15:51,930] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:15:51,934] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:15:52,030] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-05 12:16:22,465] {processor.py:153} INFO - Started process (PID=16445) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:16:22,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:16:22,468] {logging_mixin.py:115} INFO - [2022-06-05 12:16:22,468] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:16:22,588] {logging_mixin.py:115} INFO - [2022-06-05 12:16:22,585] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:16:22,590] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:16:22,682] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-05 12:16:52,986] {processor.py:153} INFO - Started process (PID=16503) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:16:52,988] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:16:52,989] {logging_mixin.py:115} INFO - [2022-06-05 12:16:52,989] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:16:53,110] {logging_mixin.py:115} INFO - [2022-06-05 12:16:53,107] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:16:53,111] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:16:53,217] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-05 12:17:23,668] {processor.py:153} INFO - Started process (PID=16573) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:17:23,669] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:17:23,672] {logging_mixin.py:115} INFO - [2022-06-05 12:17:23,671] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:17:23,824] {logging_mixin.py:115} INFO - [2022-06-05 12:17:23,822] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:17:23,826] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:17:23,918] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-05 12:17:54,571] {processor.py:153} INFO - Started process (PID=16642) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:17:54,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:17:54,574] {logging_mixin.py:115} INFO - [2022-06-05 12:17:54,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:17:54,694] {logging_mixin.py:115} INFO - [2022-06-05 12:17:54,691] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:17:54,696] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:17:54,789] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-05 12:18:25,609] {processor.py:153} INFO - Started process (PID=16711) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:18:25,611] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:18:25,616] {logging_mixin.py:115} INFO - [2022-06-05 12:18:25,616] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:18:25,762] {logging_mixin.py:115} INFO - [2022-06-05 12:18:25,760] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:18:25,763] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:18:25,853] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-05 12:18:56,252] {processor.py:153} INFO - Started process (PID=16777) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:18:56,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:18:56,255] {logging_mixin.py:115} INFO - [2022-06-05 12:18:56,255] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:18:56,371] {logging_mixin.py:115} INFO - [2022-06-05 12:18:56,370] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:18:56,373] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:18:56,467] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-05 12:19:26,874] {processor.py:153} INFO - Started process (PID=16845) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:19:26,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:19:26,884] {logging_mixin.py:115} INFO - [2022-06-05 12:19:26,884] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:19:27,102] {logging_mixin.py:115} INFO - [2022-06-05 12:19:27,096] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:19:27,107] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:19:27,341] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.472 seconds
[2022-06-05 12:19:57,708] {processor.py:153} INFO - Started process (PID=16903) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:19:57,710] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:19:57,712] {logging_mixin.py:115} INFO - [2022-06-05 12:19:57,712] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:19:57,843] {logging_mixin.py:115} INFO - [2022-06-05 12:19:57,841] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:19:57,844] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:19:57,938] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-05 12:20:28,776] {processor.py:153} INFO - Started process (PID=16968) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:20:28,778] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:20:28,781] {logging_mixin.py:115} INFO - [2022-06-05 12:20:28,780] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:20:28,833] {logging_mixin.py:115} INFO - [2022-06-05 12:20:28,831] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:20:28,834] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:20:28,930] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-05 12:20:58,980] {processor.py:153} INFO - Started process (PID=17037) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:20:58,982] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:20:58,983] {logging_mixin.py:115} INFO - [2022-06-05 12:20:58,983] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:20:59,026] {logging_mixin.py:115} INFO - [2022-06-05 12:20:59,023] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:20:59,028] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:20:59,133] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-05 12:21:29,323] {processor.py:153} INFO - Started process (PID=17103) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:21:29,325] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:21:29,326] {logging_mixin.py:115} INFO - [2022-06-05 12:21:29,326] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:21:29,378] {logging_mixin.py:115} INFO - [2022-06-05 12:21:29,375] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:21:29,379] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:21:29,473] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-05 12:21:59,558] {processor.py:153} INFO - Started process (PID=17172) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:21:59,560] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:21:59,561] {logging_mixin.py:115} INFO - [2022-06-05 12:21:59,561] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:21:59,603] {logging_mixin.py:115} INFO - [2022-06-05 12:21:59,602] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:21:59,605] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:21:59,709] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-05 12:22:29,970] {processor.py:153} INFO - Started process (PID=17230) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:22:29,972] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:22:29,973] {logging_mixin.py:115} INFO - [2022-06-05 12:22:29,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:22:30,017] {logging_mixin.py:115} INFO - [2022-06-05 12:22:30,014] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:22:30,018] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:22:30,113] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-05 12:23:00,192] {processor.py:153} INFO - Started process (PID=17297) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:23:00,194] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:23:00,195] {logging_mixin.py:115} INFO - [2022-06-05 12:23:00,195] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:23:00,238] {logging_mixin.py:115} INFO - [2022-06-05 12:23:00,236] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:23:00,239] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:23:00,332] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.142 seconds
[2022-06-05 12:23:30,738] {processor.py:153} INFO - Started process (PID=17365) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:23:30,741] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:23:30,744] {logging_mixin.py:115} INFO - [2022-06-05 12:23:30,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:23:30,805] {logging_mixin.py:115} INFO - [2022-06-05 12:23:30,803] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:23:30,807] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:23:30,901] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-05 12:24:01,080] {processor.py:153} INFO - Started process (PID=17432) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:24:01,084] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:24:01,088] {logging_mixin.py:115} INFO - [2022-06-05 12:24:01,088] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:24:01,151] {logging_mixin.py:115} INFO - [2022-06-05 12:24:01,149] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:24:01,154] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:24:01,246] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-05 12:24:31,328] {processor.py:153} INFO - Started process (PID=17501) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:24:31,329] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:24:31,331] {logging_mixin.py:115} INFO - [2022-06-05 12:24:31,331] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:24:31,382] {logging_mixin.py:115} INFO - [2022-06-05 12:24:31,377] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:24:31,383] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:24:31,485] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-05 12:25:01,679] {processor.py:153} INFO - Started process (PID=17559) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:25:01,683] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:25:01,685] {logging_mixin.py:115} INFO - [2022-06-05 12:25:01,685] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:25:01,744] {logging_mixin.py:115} INFO - [2022-06-05 12:25:01,742] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:25:01,746] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:25:01,839] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-05 12:25:32,230] {processor.py:153} INFO - Started process (PID=17628) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:25:32,235] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:25:32,237] {logging_mixin.py:115} INFO - [2022-06-05 12:25:32,237] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:25:32,295] {logging_mixin.py:115} INFO - [2022-06-05 12:25:32,293] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:25:32,296] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:25:32,390] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-05 12:26:02,500] {processor.py:153} INFO - Started process (PID=17698) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:26:02,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:26:02,504] {logging_mixin.py:115} INFO - [2022-06-05 12:26:02,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:26:02,568] {logging_mixin.py:115} INFO - [2022-06-05 12:26:02,566] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:26:02,569] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:26:02,663] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-05 12:26:32,877] {processor.py:153} INFO - Started process (PID=17767) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:26:32,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:26:32,879] {logging_mixin.py:115} INFO - [2022-06-05 12:26:32,879] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:26:32,921] {logging_mixin.py:115} INFO - [2022-06-05 12:26:32,919] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:26:32,922] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:26:33,018] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-05 12:27:03,416] {processor.py:153} INFO - Started process (PID=17835) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:27:03,419] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:27:03,421] {logging_mixin.py:115} INFO - [2022-06-05 12:27:03,421] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:27:03,467] {logging_mixin.py:115} INFO - [2022-06-05 12:27:03,465] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:27:03,469] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:27:03,561] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-05 12:27:33,975] {processor.py:153} INFO - Started process (PID=17891) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:27:33,975] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:27:33,977] {logging_mixin.py:115} INFO - [2022-06-05 12:27:33,977] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:27:34,030] {logging_mixin.py:115} INFO - [2022-06-05 12:27:34,028] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:27:34,032] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:27:34,132] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-05 12:28:04,611] {processor.py:153} INFO - Started process (PID=17960) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:28:04,615] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:28:04,617] {logging_mixin.py:115} INFO - [2022-06-05 12:28:04,617] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:28:04,674] {logging_mixin.py:115} INFO - [2022-06-05 12:28:04,672] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:28:04,675] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:28:04,772] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-05 12:28:35,326] {processor.py:153} INFO - Started process (PID=18025) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:28:35,329] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:28:35,331] {logging_mixin.py:115} INFO - [2022-06-05 12:28:35,331] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:28:35,390] {logging_mixin.py:115} INFO - [2022-06-05 12:28:35,387] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:28:35,392] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:28:35,486] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-05 12:29:06,133] {processor.py:153} INFO - Started process (PID=18096) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:29:06,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:29:06,137] {logging_mixin.py:115} INFO - [2022-06-05 12:29:06,137] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:29:06,187] {logging_mixin.py:115} INFO - [2022-06-05 12:29:06,185] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:29:06,188] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:29:06,281] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-05 12:29:37,030] {processor.py:153} INFO - Started process (PID=18168) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:29:37,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:29:37,034] {logging_mixin.py:115} INFO - [2022-06-05 12:29:37,034] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:29:37,085] {logging_mixin.py:115} INFO - [2022-06-05 12:29:37,083] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:29:37,087] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:29:37,181] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-05 12:30:07,790] {processor.py:153} INFO - Started process (PID=18235) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:30:07,793] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:30:07,795] {logging_mixin.py:115} INFO - [2022-06-05 12:30:07,795] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:30:07,851] {logging_mixin.py:115} INFO - [2022-06-05 12:30:07,849] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:30:07,852] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:30:07,945] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-05 12:30:38,498] {processor.py:153} INFO - Started process (PID=18292) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:30:38,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:30:38,504] {logging_mixin.py:115} INFO - [2022-06-05 12:30:38,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:30:38,559] {logging_mixin.py:115} INFO - [2022-06-05 12:30:38,556] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:30:38,561] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:30:38,658] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-05 12:31:09,505] {processor.py:153} INFO - Started process (PID=18360) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:31:09,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:31:09,510] {logging_mixin.py:115} INFO - [2022-06-05 12:31:09,510] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:31:09,566] {logging_mixin.py:115} INFO - [2022-06-05 12:31:09,565] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:31:09,567] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:31:09,672] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-05 12:31:40,522] {processor.py:153} INFO - Started process (PID=18430) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:31:40,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:31:40,528] {logging_mixin.py:115} INFO - [2022-06-05 12:31:40,528] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:31:40,589] {logging_mixin.py:115} INFO - [2022-06-05 12:31:40,587] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:31:40,590] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:31:40,688] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-05 12:32:11,483] {processor.py:153} INFO - Started process (PID=18497) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:32:11,484] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:32:11,485] {logging_mixin.py:115} INFO - [2022-06-05 12:32:11,485] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:32:11,530] {logging_mixin.py:115} INFO - [2022-06-05 12:32:11,529] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:32:11,531] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:32:11,631] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-05 12:32:42,415] {processor.py:153} INFO - Started process (PID=18562) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:32:42,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:32:42,422] {logging_mixin.py:115} INFO - [2022-06-05 12:32:42,422] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:32:42,478] {logging_mixin.py:115} INFO - [2022-06-05 12:32:42,476] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:32:42,479] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:32:42,580] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-05 12:33:13,411] {processor.py:153} INFO - Started process (PID=18634) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:33:13,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:33:13,414] {logging_mixin.py:115} INFO - [2022-06-05 12:33:13,414] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:33:13,467] {logging_mixin.py:115} INFO - [2022-06-05 12:33:13,464] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:33:13,468] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:33:13,561] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-05 12:33:44,311] {processor.py:153} INFO - Started process (PID=18700) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:33:44,314] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:33:44,315] {logging_mixin.py:115} INFO - [2022-06-05 12:33:44,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:33:44,365] {logging_mixin.py:115} INFO - [2022-06-05 12:33:44,363] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:33:44,366] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:33:44,520] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-05 12:34:15,143] {processor.py:153} INFO - Started process (PID=18759) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:34:15,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:34:15,149] {logging_mixin.py:115} INFO - [2022-06-05 12:34:15,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:34:15,209] {logging_mixin.py:115} INFO - [2022-06-05 12:34:15,207] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:34:15,211] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:34:15,306] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-05 12:34:45,395] {processor.py:153} INFO - Started process (PID=18828) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:34:45,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:34:45,400] {logging_mixin.py:115} INFO - [2022-06-05 12:34:45,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:34:45,463] {logging_mixin.py:115} INFO - [2022-06-05 12:34:45,461] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:34:45,464] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:34:45,561] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-05 12:35:15,888] {processor.py:153} INFO - Started process (PID=18896) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:35:15,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:35:15,894] {logging_mixin.py:115} INFO - [2022-06-05 12:35:15,893] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:35:15,951] {logging_mixin.py:115} INFO - [2022-06-05 12:35:15,949] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:35:15,953] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:35:16,053] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-05 12:35:46,922] {processor.py:153} INFO - Started process (PID=18963) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:35:46,925] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:35:46,927] {logging_mixin.py:115} INFO - [2022-06-05 12:35:46,927] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:35:46,988] {logging_mixin.py:115} INFO - [2022-06-05 12:35:46,986] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:35:46,990] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:35:47,083] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-05 12:36:18,074] {processor.py:153} INFO - Started process (PID=19032) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:36:18,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:36:18,076] {logging_mixin.py:115} INFO - [2022-06-05 12:36:18,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:36:18,116] {logging_mixin.py:115} INFO - [2022-06-05 12:36:18,114] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:36:18,118] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:36:18,210] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.140 seconds
[2022-06-05 12:36:48,924] {processor.py:153} INFO - Started process (PID=19089) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:36:48,927] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:36:48,928] {logging_mixin.py:115} INFO - [2022-06-05 12:36:48,928] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:36:49,025] {logging_mixin.py:115} INFO - [2022-06-05 12:36:49,021] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:36:49,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:36:49,176] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.261 seconds
[2022-06-05 12:37:19,943] {processor.py:153} INFO - Started process (PID=19161) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:37:19,945] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:37:19,947] {logging_mixin.py:115} INFO - [2022-06-05 12:37:19,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:37:20,002] {logging_mixin.py:115} INFO - [2022-06-05 12:37:19,999] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:37:20,004] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:37:20,096] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-05 12:37:50,836] {processor.py:153} INFO - Started process (PID=19226) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:37:50,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:37:50,840] {logging_mixin.py:115} INFO - [2022-06-05 12:37:50,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:37:50,893] {logging_mixin.py:115} INFO - [2022-06-05 12:37:50,891] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:37:50,894] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:37:50,989] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-05 12:38:21,746] {processor.py:153} INFO - Started process (PID=19292) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:38:21,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:38:21,752] {logging_mixin.py:115} INFO - [2022-06-05 12:38:21,752] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:38:21,821] {logging_mixin.py:115} INFO - [2022-06-05 12:38:21,818] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:38:21,823] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:38:21,915] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-05 12:38:52,753] {processor.py:153} INFO - Started process (PID=19363) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:38:52,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:38:52,757] {logging_mixin.py:115} INFO - [2022-06-05 12:38:52,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:38:52,800] {logging_mixin.py:115} INFO - [2022-06-05 12:38:52,798] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:38:52,801] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:38:52,894] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-05 12:39:23,376] {processor.py:153} INFO - Started process (PID=19432) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:39:23,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:39:23,379] {logging_mixin.py:115} INFO - [2022-06-05 12:39:23,379] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:39:23,423] {logging_mixin.py:115} INFO - [2022-06-05 12:39:23,421] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:39:23,425] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:39:23,528] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-05 12:39:54,336] {processor.py:153} INFO - Started process (PID=19487) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:39:54,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:39:54,342] {logging_mixin.py:115} INFO - [2022-06-05 12:39:54,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:39:54,398] {logging_mixin.py:115} INFO - [2022-06-05 12:39:54,395] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:39:54,399] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:39:54,492] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-05 12:40:24,721] {processor.py:153} INFO - Started process (PID=19556) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:40:24,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:40:24,726] {logging_mixin.py:115} INFO - [2022-06-05 12:40:24,726] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:40:24,772] {logging_mixin.py:115} INFO - [2022-06-05 12:40:24,769] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:40:24,773] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:40:24,867] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-05 12:40:55,769] {processor.py:153} INFO - Started process (PID=19621) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:40:55,770] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:40:55,771] {logging_mixin.py:115} INFO - [2022-06-05 12:40:55,771] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:40:55,812] {logging_mixin.py:115} INFO - [2022-06-05 12:40:55,810] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:40:55,813] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:40:55,908] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.143 seconds
[2022-06-05 12:41:26,097] {processor.py:153} INFO - Started process (PID=19689) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:41:26,098] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:41:26,099] {logging_mixin.py:115} INFO - [2022-06-05 12:41:26,099] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:41:26,150] {logging_mixin.py:115} INFO - [2022-06-05 12:41:26,147] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:41:26,151] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:41:26,246] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-05 12:41:56,502] {processor.py:153} INFO - Started process (PID=19759) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:41:56,504] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:41:56,505] {logging_mixin.py:115} INFO - [2022-06-05 12:41:56,505] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:41:56,557] {logging_mixin.py:115} INFO - [2022-06-05 12:41:56,555] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:41:56,560] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:41:56,671] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-05 12:42:26,740] {processor.py:153} INFO - Started process (PID=19819) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:42:26,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:42:26,745] {logging_mixin.py:115} INFO - [2022-06-05 12:42:26,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:42:26,791] {logging_mixin.py:115} INFO - [2022-06-05 12:42:26,789] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:42:26,793] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:42:26,885] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-05 12:42:57,067] {processor.py:153} INFO - Started process (PID=19888) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:42:57,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:42:57,072] {logging_mixin.py:115} INFO - [2022-06-05 12:42:57,072] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:42:57,125] {logging_mixin.py:115} INFO - [2022-06-05 12:42:57,124] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:42:57,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:42:57,224] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-05 12:43:27,554] {processor.py:153} INFO - Started process (PID=19956) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:43:27,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:43:27,559] {logging_mixin.py:115} INFO - [2022-06-05 12:43:27,559] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:43:27,614] {logging_mixin.py:115} INFO - [2022-06-05 12:43:27,610] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:43:27,615] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:43:27,709] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-05 12:43:58,208] {processor.py:153} INFO - Started process (PID=20022) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:43:58,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:43:58,212] {logging_mixin.py:115} INFO - [2022-06-05 12:43:58,212] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:43:58,273] {logging_mixin.py:115} INFO - [2022-06-05 12:43:58,270] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:43:58,274] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:43:58,373] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-05 12:44:28,691] {processor.py:153} INFO - Started process (PID=20081) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:44:28,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:44:28,694] {logging_mixin.py:115} INFO - [2022-06-05 12:44:28,694] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:44:28,739] {logging_mixin.py:115} INFO - [2022-06-05 12:44:28,737] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:44:28,741] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:44:28,849] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-05 12:44:59,636] {processor.py:153} INFO - Started process (PID=20150) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:44:59,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:44:59,642] {logging_mixin.py:115} INFO - [2022-06-05 12:44:59,642] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:44:59,700] {logging_mixin.py:115} INFO - [2022-06-05 12:44:59,698] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:44:59,702] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:44:59,794] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-05 12:45:30,038] {processor.py:153} INFO - Started process (PID=20219) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:45:30,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:45:30,040] {logging_mixin.py:115} INFO - [2022-06-05 12:45:30,040] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:45:30,081] {logging_mixin.py:115} INFO - [2022-06-05 12:45:30,080] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:45:30,082] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:45:30,179] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.143 seconds
[2022-06-05 12:46:00,236] {processor.py:153} INFO - Started process (PID=20283) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:46:00,237] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:46:00,239] {logging_mixin.py:115} INFO - [2022-06-05 12:46:00,239] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:46:00,283] {logging_mixin.py:115} INFO - [2022-06-05 12:46:00,281] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:46:00,285] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:46:00,381] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-05 12:46:30,507] {processor.py:153} INFO - Started process (PID=20350) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:46:30,509] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:46:30,511] {logging_mixin.py:115} INFO - [2022-06-05 12:46:30,511] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:46:30,567] {logging_mixin.py:115} INFO - [2022-06-05 12:46:30,565] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:46:30,569] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:46:30,667] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-05 12:47:00,803] {processor.py:153} INFO - Started process (PID=20410) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:47:00,805] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:47:00,806] {logging_mixin.py:115} INFO - [2022-06-05 12:47:00,806] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:47:00,848] {logging_mixin.py:115} INFO - [2022-06-05 12:47:00,846] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:47:00,849] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:47:00,943] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.143 seconds
[2022-06-05 12:47:31,246] {processor.py:153} INFO - Started process (PID=20480) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:47:31,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:47:31,252] {logging_mixin.py:115} INFO - [2022-06-05 12:47:31,252] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:47:31,304] {logging_mixin.py:115} INFO - [2022-06-05 12:47:31,302] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:47:31,305] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:47:31,401] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-05 12:48:01,676] {processor.py:153} INFO - Started process (PID=20546) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:48:01,679] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:48:01,681] {logging_mixin.py:115} INFO - [2022-06-05 12:48:01,681] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:48:01,740] {logging_mixin.py:115} INFO - [2022-06-05 12:48:01,738] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:48:01,741] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:48:01,835] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-05 12:48:31,897] {processor.py:153} INFO - Started process (PID=20613) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:48:31,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:48:31,902] {logging_mixin.py:115} INFO - [2022-06-05 12:48:31,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:48:31,957] {logging_mixin.py:115} INFO - [2022-06-05 12:48:31,955] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:48:31,959] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:48:32,053] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-05 12:49:02,594] {processor.py:153} INFO - Started process (PID=20679) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:49:02,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:49:02,597] {logging_mixin.py:115} INFO - [2022-06-05 12:49:02,597] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:49:02,644] {logging_mixin.py:115} INFO - [2022-06-05 12:49:02,642] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:49:02,645] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:49:02,761] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-05 12:49:32,869] {processor.py:153} INFO - Started process (PID=20739) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:49:32,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:49:32,873] {logging_mixin.py:115} INFO - [2022-06-05 12:49:32,873] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:49:32,938] {logging_mixin.py:115} INFO - [2022-06-05 12:49:32,936] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:49:32,940] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:49:33,035] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-05 12:50:03,286] {processor.py:153} INFO - Started process (PID=20808) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:50:03,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:50:03,290] {logging_mixin.py:115} INFO - [2022-06-05 12:50:03,290] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:50:03,345] {logging_mixin.py:115} INFO - [2022-06-05 12:50:03,343] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:50:03,346] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:50:03,442] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-05 12:50:33,664] {processor.py:153} INFO - Started process (PID=20881) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:50:33,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:50:33,667] {logging_mixin.py:115} INFO - [2022-06-05 12:50:33,667] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:50:33,718] {logging_mixin.py:115} INFO - [2022-06-05 12:50:33,716] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:50:33,720] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:50:33,814] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-05 12:51:04,268] {processor.py:153} INFO - Started process (PID=20946) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:51:04,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:51:04,271] {logging_mixin.py:115} INFO - [2022-06-05 12:51:04,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:51:04,329] {logging_mixin.py:115} INFO - [2022-06-05 12:51:04,327] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:51:04,330] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:51:04,429] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-05 12:51:35,141] {processor.py:153} INFO - Started process (PID=21003) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:51:35,144] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:51:35,146] {logging_mixin.py:115} INFO - [2022-06-05 12:51:35,146] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:51:35,206] {logging_mixin.py:115} INFO - [2022-06-05 12:51:35,204] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:51:35,208] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:51:35,304] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-05 12:52:06,163] {processor.py:153} INFO - Started process (PID=21071) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:52:06,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:52:06,167] {logging_mixin.py:115} INFO - [2022-06-05 12:52:06,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:52:06,224] {logging_mixin.py:115} INFO - [2022-06-05 12:52:06,222] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:52:06,225] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:52:06,319] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-05 12:52:36,721] {processor.py:153} INFO - Started process (PID=21143) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:52:36,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:52:36,727] {logging_mixin.py:115} INFO - [2022-06-05 12:52:36,727] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:52:36,785] {logging_mixin.py:115} INFO - [2022-06-05 12:52:36,783] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:52:36,787] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:52:36,881] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-05 12:53:06,970] {processor.py:153} INFO - Started process (PID=21212) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:53:06,971] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:53:06,973] {logging_mixin.py:115} INFO - [2022-06-05 12:53:06,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:53:07,033] {logging_mixin.py:115} INFO - [2022-06-05 12:53:07,030] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:53:07,034] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:53:07,130] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-05 12:53:37,751] {processor.py:153} INFO - Started process (PID=21282) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:53:37,753] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:53:37,755] {logging_mixin.py:115} INFO - [2022-06-05 12:53:37,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:53:37,819] {logging_mixin.py:115} INFO - [2022-06-05 12:53:37,817] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:53:37,819] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:53:37,912] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-05 12:54:08,572] {processor.py:153} INFO - Started process (PID=21342) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:54:08,575] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:54:08,576] {logging_mixin.py:115} INFO - [2022-06-05 12:54:08,576] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:54:08,630] {logging_mixin.py:115} INFO - [2022-06-05 12:54:08,628] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:54:08,631] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:54:08,725] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-05 12:54:39,453] {processor.py:153} INFO - Started process (PID=21408) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:54:39,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:54:39,458] {logging_mixin.py:115} INFO - [2022-06-05 12:54:39,458] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:54:39,507] {logging_mixin.py:115} INFO - [2022-06-05 12:54:39,505] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:54:39,507] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:54:39,602] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-05 12:55:10,354] {processor.py:153} INFO - Started process (PID=21479) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:55:10,357] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:55:10,358] {logging_mixin.py:115} INFO - [2022-06-05 12:55:10,358] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:55:10,409] {logging_mixin.py:115} INFO - [2022-06-05 12:55:10,407] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:55:10,411] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:55:10,516] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-05 12:55:41,491] {processor.py:153} INFO - Started process (PID=21546) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:55:41,494] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:55:41,495] {logging_mixin.py:115} INFO - [2022-06-05 12:55:41,495] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:55:41,561] {logging_mixin.py:115} INFO - [2022-06-05 12:55:41,559] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:55:41,562] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:55:41,662] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-05 12:56:12,005] {processor.py:153} INFO - Started process (PID=21617) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:56:12,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:56:12,009] {logging_mixin.py:115} INFO - [2022-06-05 12:56:12,009] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:56:12,063] {logging_mixin.py:115} INFO - [2022-06-05 12:56:12,062] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:56:12,065] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:56:12,160] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-05 12:56:42,733] {processor.py:153} INFO - Started process (PID=21675) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:56:42,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:56:42,737] {logging_mixin.py:115} INFO - [2022-06-05 12:56:42,737] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:56:42,789] {logging_mixin.py:115} INFO - [2022-06-05 12:56:42,787] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:56:42,790] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:56:42,914] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-05 12:57:13,203] {processor.py:153} INFO - Started process (PID=21742) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:57:13,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:57:13,208] {logging_mixin.py:115} INFO - [2022-06-05 12:57:13,208] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:57:13,262] {logging_mixin.py:115} INFO - [2022-06-05 12:57:13,260] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:57:13,264] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:57:13,364] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-05 12:57:43,567] {processor.py:153} INFO - Started process (PID=21810) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:57:43,570] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:57:43,572] {logging_mixin.py:115} INFO - [2022-06-05 12:57:43,572] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:57:43,644] {logging_mixin.py:115} INFO - [2022-06-05 12:57:43,643] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:57:43,646] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:57:43,741] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-05 12:58:14,296] {processor.py:153} INFO - Started process (PID=21878) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:58:14,298] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:58:14,300] {logging_mixin.py:115} INFO - [2022-06-05 12:58:14,300] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:58:14,355] {logging_mixin.py:115} INFO - [2022-06-05 12:58:14,352] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:58:14,357] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:58:14,450] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-05 12:58:45,261] {processor.py:153} INFO - Started process (PID=21949) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:58:45,263] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:58:45,266] {logging_mixin.py:115} INFO - [2022-06-05 12:58:45,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:58:45,338] {logging_mixin.py:115} INFO - [2022-06-05 12:58:45,335] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:58:45,339] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:58:45,449] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-05 12:59:15,966] {processor.py:153} INFO - Started process (PID=22005) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:59:15,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:59:15,972] {logging_mixin.py:115} INFO - [2022-06-05 12:59:15,972] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:59:16,029] {logging_mixin.py:115} INFO - [2022-06-05 12:59:16,026] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:59:16,030] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:59:16,123] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-05 12:59:46,183] {processor.py:153} INFO - Started process (PID=22070) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:59:46,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 12:59:46,188] {logging_mixin.py:115} INFO - [2022-06-05 12:59:46,188] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:59:46,250] {logging_mixin.py:115} INFO - [2022-06-05 12:59:46,247] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 12:59:46,251] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 12:59:46,345] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-05 13:00:16,710] {processor.py:153} INFO - Started process (PID=22138) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:00:16,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:00:16,716] {logging_mixin.py:115} INFO - [2022-06-05 13:00:16,716] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:00:16,768] {logging_mixin.py:115} INFO - [2022-06-05 13:00:16,765] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:00:16,769] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:00:16,865] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-05 13:00:47,174] {processor.py:153} INFO - Started process (PID=22205) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:00:47,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:00:47,179] {logging_mixin.py:115} INFO - [2022-06-05 13:00:47,179] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:00:47,241] {logging_mixin.py:115} INFO - [2022-06-05 13:00:47,239] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:00:47,242] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:00:47,336] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-05 13:01:18,230] {processor.py:153} INFO - Started process (PID=22272) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:01:18,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:01:18,235] {logging_mixin.py:115} INFO - [2022-06-05 13:01:18,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:01:18,347] {logging_mixin.py:115} INFO - [2022-06-05 13:01:18,335] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:01:18,350] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:01:18,496] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.270 seconds
[2022-06-05 13:01:49,219] {processor.py:153} INFO - Started process (PID=22332) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:01:49,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:01:49,224] {logging_mixin.py:115} INFO - [2022-06-05 13:01:49,224] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:01:49,286] {logging_mixin.py:115} INFO - [2022-06-05 13:01:49,284] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:01:49,287] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:01:49,381] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-05 13:02:20,068] {processor.py:153} INFO - Started process (PID=22398) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:02:20,070] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:02:20,071] {logging_mixin.py:115} INFO - [2022-06-05 13:02:20,071] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:02:20,113] {logging_mixin.py:115} INFO - [2022-06-05 13:02:20,110] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:02:20,114] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:02:20,207] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.141 seconds
[2022-06-05 13:02:50,813] {processor.py:153} INFO - Started process (PID=22466) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:02:50,815] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:02:50,816] {logging_mixin.py:115} INFO - [2022-06-05 13:02:50,816] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:02:50,862] {logging_mixin.py:115} INFO - [2022-06-05 13:02:50,860] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:02:50,864] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:02:50,966] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-05 13:03:21,776] {processor.py:153} INFO - Started process (PID=22529) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:03:21,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:03:21,780] {logging_mixin.py:115} INFO - [2022-06-05 13:03:21,780] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:03:21,843] {logging_mixin.py:115} INFO - [2022-06-05 13:03:21,840] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:03:21,844] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:03:21,938] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-05 13:03:52,664] {processor.py:153} INFO - Started process (PID=22596) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:03:52,667] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:03:52,670] {logging_mixin.py:115} INFO - [2022-06-05 13:03:52,669] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:03:52,724] {logging_mixin.py:115} INFO - [2022-06-05 13:03:52,722] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:03:52,726] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:03:52,820] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-05 13:04:23,006] {processor.py:153} INFO - Started process (PID=22652) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:04:23,009] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:04:23,011] {logging_mixin.py:115} INFO - [2022-06-05 13:04:23,011] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:04:23,074] {logging_mixin.py:115} INFO - [2022-06-05 13:04:23,071] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:04:23,075] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:04:23,172] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-05 13:04:53,229] {processor.py:153} INFO - Started process (PID=22722) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:04:53,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:04:53,233] {logging_mixin.py:115} INFO - [2022-06-05 13:04:53,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:04:53,279] {logging_mixin.py:115} INFO - [2022-06-05 13:04:53,277] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:04:53,280] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:04:53,375] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-05 13:05:23,447] {processor.py:153} INFO - Started process (PID=22792) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:05:23,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:05:23,452] {logging_mixin.py:115} INFO - [2022-06-05 13:05:23,452] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:05:23,505] {logging_mixin.py:115} INFO - [2022-06-05 13:05:23,502] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:05:23,506] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:05:23,603] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-05 13:05:53,777] {processor.py:153} INFO - Started process (PID=22861) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:05:53,781] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:05:53,783] {logging_mixin.py:115} INFO - [2022-06-05 13:05:53,783] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:05:53,843] {logging_mixin.py:115} INFO - [2022-06-05 13:05:53,841] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:05:53,845] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:05:53,939] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-05 13:06:24,253] {processor.py:153} INFO - Started process (PID=22918) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:06:24,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:06:24,260] {logging_mixin.py:115} INFO - [2022-06-05 13:06:24,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:06:24,370] {logging_mixin.py:115} INFO - [2022-06-05 13:06:24,367] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:06:24,371] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:06:24,488] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-05 13:06:54,612] {processor.py:153} INFO - Started process (PID=22986) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:06:54,616] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:06:54,618] {logging_mixin.py:115} INFO - [2022-06-05 13:06:54,617] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:06:54,675] {logging_mixin.py:115} INFO - [2022-06-05 13:06:54,673] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:06:54,677] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:06:54,775] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-05 13:07:24,923] {processor.py:153} INFO - Started process (PID=23054) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:07:24,926] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:07:24,929] {logging_mixin.py:115} INFO - [2022-06-05 13:07:24,928] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:07:24,985] {logging_mixin.py:115} INFO - [2022-06-05 13:07:24,983] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:07:24,986] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:07:25,083] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-05 13:07:55,811] {processor.py:153} INFO - Started process (PID=23120) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:07:55,813] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:07:55,815] {logging_mixin.py:115} INFO - [2022-06-05 13:07:55,815] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:07:55,867] {logging_mixin.py:115} INFO - [2022-06-05 13:07:55,865] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:07:55,868] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:07:55,970] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-05 13:08:26,301] {processor.py:153} INFO - Started process (PID=23183) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:08:26,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:08:26,304] {logging_mixin.py:115} INFO - [2022-06-05 13:08:26,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:08:26,345] {logging_mixin.py:115} INFO - [2022-06-05 13:08:26,343] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:08:26,346] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:08:26,439] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.142 seconds
[2022-06-05 13:08:57,260] {processor.py:153} INFO - Started process (PID=23239) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:08:57,264] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:08:57,266] {logging_mixin.py:115} INFO - [2022-06-05 13:08:57,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:08:57,322] {logging_mixin.py:115} INFO - [2022-06-05 13:08:57,320] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:08:57,323] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:08:57,419] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-05 13:09:27,494] {processor.py:153} INFO - Started process (PID=23313) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:09:27,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:09:27,498] {logging_mixin.py:115} INFO - [2022-06-05 13:09:27,498] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:09:27,552] {logging_mixin.py:115} INFO - [2022-06-05 13:09:27,550] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:09:27,554] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:09:27,648] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-05 13:09:58,571] {processor.py:153} INFO - Started process (PID=23385) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:09:58,572] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:09:58,574] {logging_mixin.py:115} INFO - [2022-06-05 13:09:58,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:09:58,619] {logging_mixin.py:115} INFO - [2022-06-05 13:09:58,617] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:09:58,620] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:09:58,726] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-05 13:10:29,441] {processor.py:153} INFO - Started process (PID=23453) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:10:29,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:10:29,445] {logging_mixin.py:115} INFO - [2022-06-05 13:10:29,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:10:29,496] {logging_mixin.py:115} INFO - [2022-06-05 13:10:29,494] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:10:29,498] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:10:29,607] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-05 13:10:59,977] {processor.py:153} INFO - Started process (PID=23523) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:10:59,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:10:59,979] {logging_mixin.py:115} INFO - [2022-06-05 13:10:59,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:11:00,025] {logging_mixin.py:115} INFO - [2022-06-05 13:11:00,022] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:11:00,027] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:11:00,124] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-05 13:11:30,908] {processor.py:153} INFO - Started process (PID=23582) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:11:30,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:11:30,913] {logging_mixin.py:115} INFO - [2022-06-05 13:11:30,913] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:11:30,962] {logging_mixin.py:115} INFO - [2022-06-05 13:11:30,960] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:11:30,964] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:11:31,062] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-05 13:12:01,404] {processor.py:153} INFO - Started process (PID=23646) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:12:01,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:12:01,408] {logging_mixin.py:115} INFO - [2022-06-05 13:12:01,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:12:01,466] {logging_mixin.py:115} INFO - [2022-06-05 13:12:01,464] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:12:01,467] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:12:01,567] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-05 13:12:32,025] {processor.py:153} INFO - Started process (PID=23713) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:12:32,027] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:12:32,029] {logging_mixin.py:115} INFO - [2022-06-05 13:12:32,028] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:12:32,083] {logging_mixin.py:115} INFO - [2022-06-05 13:12:32,080] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:12:32,087] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:12:32,180] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-05 13:13:02,649] {processor.py:153} INFO - Started process (PID=23780) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:13:02,652] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:13:02,655] {logging_mixin.py:115} INFO - [2022-06-05 13:13:02,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:13:02,715] {logging_mixin.py:115} INFO - [2022-06-05 13:13:02,711] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:13:02,716] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:13:02,811] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-05 13:13:33,214] {processor.py:153} INFO - Started process (PID=23849) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:13:33,216] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:13:33,218] {logging_mixin.py:115} INFO - [2022-06-05 13:13:33,218] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:13:33,262] {logging_mixin.py:115} INFO - [2022-06-05 13:13:33,260] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:13:33,264] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:13:33,357] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-05 13:14:04,039] {processor.py:153} INFO - Started process (PID=23906) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:14:04,041] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:14:04,042] {logging_mixin.py:115} INFO - [2022-06-05 13:14:04,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:14:04,105] {logging_mixin.py:115} INFO - [2022-06-05 13:14:04,103] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:14:04,106] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:14:04,225] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-05 13:14:34,930] {processor.py:153} INFO - Started process (PID=23974) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:14:34,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:14:34,934] {logging_mixin.py:115} INFO - [2022-06-05 13:14:34,933] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:14:34,985] {logging_mixin.py:115} INFO - [2022-06-05 13:14:34,982] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:14:34,986] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:14:35,093] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-05 13:15:05,925] {processor.py:153} INFO - Started process (PID=24042) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:15:05,928] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:15:05,930] {logging_mixin.py:115} INFO - [2022-06-05 13:15:05,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:15:05,980] {logging_mixin.py:115} INFO - [2022-06-05 13:15:05,978] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:15:05,981] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:15:06,076] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-05 13:15:37,065] {processor.py:153} INFO - Started process (PID=24110) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:15:37,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:15:37,069] {logging_mixin.py:115} INFO - [2022-06-05 13:15:37,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:15:37,117] {logging_mixin.py:115} INFO - [2022-06-05 13:15:37,116] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:15:37,119] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:15:37,214] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-05 13:16:08,253] {processor.py:153} INFO - Started process (PID=24176) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:16:08,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:16:08,259] {logging_mixin.py:115} INFO - [2022-06-05 13:16:08,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:16:08,311] {logging_mixin.py:115} INFO - [2022-06-05 13:16:08,309] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:16:08,315] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:16:08,407] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-05 13:16:39,207] {processor.py:153} INFO - Started process (PID=24244) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:16:39,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:16:39,211] {logging_mixin.py:115} INFO - [2022-06-05 13:16:39,211] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:16:39,258] {logging_mixin.py:115} INFO - [2022-06-05 13:16:39,255] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:16:39,259] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:16:39,356] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-05 13:17:10,016] {processor.py:153} INFO - Started process (PID=24300) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:17:10,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:17:10,020] {logging_mixin.py:115} INFO - [2022-06-05 13:17:10,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:17:10,077] {logging_mixin.py:115} INFO - [2022-06-05 13:17:10,074] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:17:10,078] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:17:10,172] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-05 13:17:40,352] {processor.py:153} INFO - Started process (PID=24369) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:17:40,354] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:17:40,356] {logging_mixin.py:115} INFO - [2022-06-05 13:17:40,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:17:40,408] {logging_mixin.py:115} INFO - [2022-06-05 13:17:40,406] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:17:40,409] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:17:40,504] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-05 13:18:10,628] {processor.py:153} INFO - Started process (PID=24443) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:18:10,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:18:10,634] {logging_mixin.py:115} INFO - [2022-06-05 13:18:10,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:18:10,694] {logging_mixin.py:115} INFO - [2022-06-05 13:18:10,692] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:18:10,696] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:18:10,790] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-05 13:18:41,738] {processor.py:153} INFO - Started process (PID=24511) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:18:41,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:18:41,741] {logging_mixin.py:115} INFO - [2022-06-05 13:18:41,741] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:18:41,786] {logging_mixin.py:115} INFO - [2022-06-05 13:18:41,783] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:18:41,787] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:18:41,882] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-05 13:19:11,999] {processor.py:153} INFO - Started process (PID=24580) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:19:12,001] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:19:12,002] {logging_mixin.py:115} INFO - [2022-06-05 13:19:12,002] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:19:12,112] {logging_mixin.py:115} INFO - [2022-06-05 13:19:12,107] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:19:12,114] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:19:12,305] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.311 seconds
[2022-06-05 13:19:42,361] {processor.py:153} INFO - Started process (PID=24638) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:19:42,362] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:19:42,363] {logging_mixin.py:115} INFO - [2022-06-05 13:19:42,363] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:19:42,407] {logging_mixin.py:115} INFO - [2022-06-05 13:19:42,405] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:19:42,408] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:19:42,504] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-05 13:20:12,567] {processor.py:153} INFO - Started process (PID=24704) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:20:12,570] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:20:12,571] {logging_mixin.py:115} INFO - [2022-06-05 13:20:12,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:20:12,628] {logging_mixin.py:115} INFO - [2022-06-05 13:20:12,626] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:20:12,630] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:20:12,725] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-05 13:20:43,351] {processor.py:153} INFO - Started process (PID=24774) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:20:43,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:20:43,353] {logging_mixin.py:115} INFO - [2022-06-05 13:20:43,353] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:20:43,405] {logging_mixin.py:115} INFO - [2022-06-05 13:20:43,403] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:20:43,406] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:20:43,503] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-05 13:21:14,551] {processor.py:153} INFO - Started process (PID=24842) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:21:14,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:21:14,564] {logging_mixin.py:115} INFO - [2022-06-05 13:21:14,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:21:14,629] {logging_mixin.py:115} INFO - [2022-06-05 13:21:14,627] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:21:14,630] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:21:14,722] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-05 13:21:45,022] {processor.py:153} INFO - Started process (PID=24908) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:21:45,028] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:21:45,032] {logging_mixin.py:115} INFO - [2022-06-05 13:21:45,032] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:21:45,147] {logging_mixin.py:115} INFO - [2022-06-05 13:21:45,144] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:21:45,149] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:21:45,427] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.407 seconds
[2022-06-05 13:22:15,619] {processor.py:153} INFO - Started process (PID=24969) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:22:15,621] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:22:15,622] {logging_mixin.py:115} INFO - [2022-06-05 13:22:15,622] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:22:15,668] {logging_mixin.py:115} INFO - [2022-06-05 13:22:15,665] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:22:15,669] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:22:15,769] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-05 13:22:45,810] {processor.py:153} INFO - Started process (PID=25040) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:22:45,812] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:22:45,813] {logging_mixin.py:115} INFO - [2022-06-05 13:22:45,813] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:22:45,854] {logging_mixin.py:115} INFO - [2022-06-05 13:22:45,852] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:22:45,855] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:22:45,961] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-05 13:23:16,160] {processor.py:153} INFO - Started process (PID=25109) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:23:16,162] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:23:16,163] {logging_mixin.py:115} INFO - [2022-06-05 13:23:16,163] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:23:16,209] {logging_mixin.py:115} INFO - [2022-06-05 13:23:16,207] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:23:16,211] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:23:16,313] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-05 13:23:47,020] {processor.py:153} INFO - Started process (PID=25180) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:23:47,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:23:47,023] {logging_mixin.py:115} INFO - [2022-06-05 13:23:47,023] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:23:47,068] {logging_mixin.py:115} INFO - [2022-06-05 13:23:47,066] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:23:47,070] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:23:47,165] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-05 13:24:17,630] {processor.py:153} INFO - Started process (PID=25239) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:24:17,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:24:17,633] {logging_mixin.py:115} INFO - [2022-06-05 13:24:17,633] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:24:17,692] {logging_mixin.py:115} INFO - [2022-06-05 13:24:17,690] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:24:17,694] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:24:17,816] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-05 13:24:48,036] {processor.py:153} INFO - Started process (PID=25305) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:24:48,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:24:48,041] {logging_mixin.py:115} INFO - [2022-06-05 13:24:48,040] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:24:48,093] {logging_mixin.py:115} INFO - [2022-06-05 13:24:48,091] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:24:48,098] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:24:48,193] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-05 13:25:18,314] {processor.py:153} INFO - Started process (PID=25370) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:25:18,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:25:18,319] {logging_mixin.py:115} INFO - [2022-06-05 13:25:18,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:25:18,370] {logging_mixin.py:115} INFO - [2022-06-05 13:25:18,368] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:25:18,371] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:25:18,470] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-05 13:25:48,657] {processor.py:153} INFO - Started process (PID=25438) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:25:48,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:25:48,661] {logging_mixin.py:115} INFO - [2022-06-05 13:25:48,661] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:25:48,715] {logging_mixin.py:115} INFO - [2022-06-05 13:25:48,712] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:25:48,716] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:25:48,808] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-05 13:26:18,872] {processor.py:153} INFO - Started process (PID=25507) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:26:18,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:26:18,876] {logging_mixin.py:115} INFO - [2022-06-05 13:26:18,875] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:26:18,924] {logging_mixin.py:115} INFO - [2022-06-05 13:26:18,922] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:26:18,925] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:26:19,019] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-05 13:26:49,422] {processor.py:153} INFO - Started process (PID=25563) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:26:49,424] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:26:49,424] {logging_mixin.py:115} INFO - [2022-06-05 13:26:49,424] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:26:49,476] {logging_mixin.py:115} INFO - [2022-06-05 13:26:49,473] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:26:49,478] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:26:49,595] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-05 13:27:19,927] {processor.py:153} INFO - Started process (PID=25630) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:27:19,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:27:19,931] {logging_mixin.py:115} INFO - [2022-06-05 13:27:19,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:27:19,982] {logging_mixin.py:115} INFO - [2022-06-05 13:27:19,980] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:27:19,983] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:27:20,076] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-05 13:27:51,049] {processor.py:153} INFO - Started process (PID=25697) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:27:51,052] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:27:51,055] {logging_mixin.py:115} INFO - [2022-06-05 13:27:51,055] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:27:51,111] {logging_mixin.py:115} INFO - [2022-06-05 13:27:51,109] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:27:51,113] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:27:51,207] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-05 13:28:21,331] {processor.py:153} INFO - Started process (PID=25764) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:28:21,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-05 13:28:21,334] {logging_mixin.py:115} INFO - [2022-06-05 13:28:21,334] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:28:21,384] {logging_mixin.py:115} INFO - [2022-06-05 13:28:21,382] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-05 13:28:21,386] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-05 13:28:21,477] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
