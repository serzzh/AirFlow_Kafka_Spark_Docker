[2022-06-06 03:40:52,715] {processor.py:153} INFO - Started process (PID=25808) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:40:52,722] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:40:52,726] {logging_mixin.py:115} INFO - [2022-06-06 03:40:52,726] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:40:53,037] {logging_mixin.py:115} INFO - [2022-06-06 03:40:53,018] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:40:53,038] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:40:53,457] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.750 seconds
[2022-06-06 03:41:24,383] {processor.py:153} INFO - Started process (PID=25865) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:41:24,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:41:24,385] {logging_mixin.py:115} INFO - [2022-06-06 03:41:24,385] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:41:24,426] {logging_mixin.py:115} INFO - [2022-06-06 03:41:24,425] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:41:24,428] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:41:24,524] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.143 seconds
[2022-06-06 03:41:55,091] {processor.py:153} INFO - Started process (PID=25931) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:41:55,093] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:41:55,095] {logging_mixin.py:115} INFO - [2022-06-06 03:41:55,095] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:41:55,176] {logging_mixin.py:115} INFO - [2022-06-06 03:41:55,173] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:41:55,177] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:41:55,282] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-06 03:42:25,439] {processor.py:153} INFO - Started process (PID=25995) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:42:25,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:42:25,444] {logging_mixin.py:115} INFO - [2022-06-06 03:42:25,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:42:25,521] {logging_mixin.py:115} INFO - [2022-06-06 03:42:25,515] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:42:25,526] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:42:25,728] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.292 seconds
[2022-06-06 03:42:56,431] {processor.py:153} INFO - Started process (PID=26064) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:42:56,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:42:56,437] {logging_mixin.py:115} INFO - [2022-06-06 03:42:56,437] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:42:56,512] {logging_mixin.py:115} INFO - [2022-06-06 03:42:56,509] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:42:56,515] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:42:56,640] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-06 03:43:26,787] {processor.py:153} INFO - Started process (PID=26121) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:43:26,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:43:26,792] {logging_mixin.py:115} INFO - [2022-06-06 03:43:26,792] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:43:26,848] {logging_mixin.py:115} INFO - [2022-06-06 03:43:26,844] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:43:26,851] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:43:26,946] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 03:43:57,363] {processor.py:153} INFO - Started process (PID=26187) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:43:57,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:43:57,367] {logging_mixin.py:115} INFO - [2022-06-06 03:43:57,367] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:43:57,426] {logging_mixin.py:115} INFO - [2022-06-06 03:43:57,423] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:43:57,427] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:43:57,523] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 03:44:27,678] {processor.py:153} INFO - Started process (PID=26254) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:44:27,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:44:27,683] {logging_mixin.py:115} INFO - [2022-06-06 03:44:27,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:44:27,741] {logging_mixin.py:115} INFO - [2022-06-06 03:44:27,739] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:44:27,743] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:44:27,853] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 03:44:58,669] {processor.py:153} INFO - Started process (PID=26318) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:44:58,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:44:58,672] {logging_mixin.py:115} INFO - [2022-06-06 03:44:58,672] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:44:58,732] {logging_mixin.py:115} INFO - [2022-06-06 03:44:58,730] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:44:58,733] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:44:58,827] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 03:45:29,197] {processor.py:153} INFO - Started process (PID=26386) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:45:29,199] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:45:29,200] {logging_mixin.py:115} INFO - [2022-06-06 03:45:29,200] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:45:29,253] {logging_mixin.py:115} INFO - [2022-06-06 03:45:29,250] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:45:29,256] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:45:29,368] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 03:45:59,414] {processor.py:153} INFO - Started process (PID=26444) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:45:59,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:45:59,419] {logging_mixin.py:115} INFO - [2022-06-06 03:45:59,418] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:45:59,485] {logging_mixin.py:115} INFO - [2022-06-06 03:45:59,482] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:45:59,487] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:45:59,595] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 03:46:29,711] {processor.py:153} INFO - Started process (PID=26510) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:46:29,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:46:29,714] {logging_mixin.py:115} INFO - [2022-06-06 03:46:29,714] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:46:29,770] {logging_mixin.py:115} INFO - [2022-06-06 03:46:29,768] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:46:29,772] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:46:29,867] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 03:47:00,567] {processor.py:153} INFO - Started process (PID=26579) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:47:00,570] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:47:00,571] {logging_mixin.py:115} INFO - [2022-06-06 03:47:00,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:47:00,624] {logging_mixin.py:115} INFO - [2022-06-06 03:47:00,622] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:47:00,625] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:47:00,731] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 03:47:31,142] {processor.py:153} INFO - Started process (PID=26647) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:47:31,144] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:47:31,145] {logging_mixin.py:115} INFO - [2022-06-06 03:47:31,145] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:47:31,187] {logging_mixin.py:115} INFO - [2022-06-06 03:47:31,185] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:47:31,187] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:47:31,280] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.140 seconds
[2022-06-06 03:48:01,464] {processor.py:153} INFO - Started process (PID=26714) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:48:01,465] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:48:01,467] {logging_mixin.py:115} INFO - [2022-06-06 03:48:01,467] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:48:01,513] {logging_mixin.py:115} INFO - [2022-06-06 03:48:01,511] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:48:01,514] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:48:01,621] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 03:48:32,086] {processor.py:153} INFO - Started process (PID=26772) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:48:32,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:48:32,089] {logging_mixin.py:115} INFO - [2022-06-06 03:48:32,089] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:48:32,170] {logging_mixin.py:115} INFO - [2022-06-06 03:48:32,166] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:48:32,171] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:48:32,304] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-06 03:49:02,432] {processor.py:153} INFO - Started process (PID=26841) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:49:02,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:49:02,436] {logging_mixin.py:115} INFO - [2022-06-06 03:49:02,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:49:02,488] {logging_mixin.py:115} INFO - [2022-06-06 03:49:02,486] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:49:02,489] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:49:02,584] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 03:49:32,620] {processor.py:153} INFO - Started process (PID=26908) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:49:32,621] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:49:32,622] {logging_mixin.py:115} INFO - [2022-06-06 03:49:32,622] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:49:32,677] {logging_mixin.py:115} INFO - [2022-06-06 03:49:32,674] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:49:32,678] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:49:32,776] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 03:50:03,064] {processor.py:153} INFO - Started process (PID=26975) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:50:03,065] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:50:03,066] {logging_mixin.py:115} INFO - [2022-06-06 03:50:03,066] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:50:03,122] {logging_mixin.py:115} INFO - [2022-06-06 03:50:03,120] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:50:03,124] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:50:03,223] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 03:50:33,637] {processor.py:153} INFO - Started process (PID=27043) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:50:33,638] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:50:33,640] {logging_mixin.py:115} INFO - [2022-06-06 03:50:33,639] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:50:33,680] {logging_mixin.py:115} INFO - [2022-06-06 03:50:33,678] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:50:33,681] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:50:33,778] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-06 03:51:03,818] {processor.py:153} INFO - Started process (PID=27100) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:51:03,820] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:51:03,821] {logging_mixin.py:115} INFO - [2022-06-06 03:51:03,821] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:51:03,868] {logging_mixin.py:115} INFO - [2022-06-06 03:51:03,865] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:51:03,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:51:03,971] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 03:51:34,085] {processor.py:153} INFO - Started process (PID=27168) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:51:34,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:51:34,091] {logging_mixin.py:115} INFO - [2022-06-06 03:51:34,091] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:51:34,152] {logging_mixin.py:115} INFO - [2022-06-06 03:51:34,149] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:51:34,153] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:51:34,254] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 03:52:04,341] {processor.py:153} INFO - Started process (PID=27235) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:52:04,343] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:52:04,344] {logging_mixin.py:115} INFO - [2022-06-06 03:52:04,344] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:52:04,404] {logging_mixin.py:115} INFO - [2022-06-06 03:52:04,401] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:52:04,405] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:52:04,501] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 03:52:34,559] {processor.py:153} INFO - Started process (PID=27302) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:52:34,562] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:52:34,564] {logging_mixin.py:115} INFO - [2022-06-06 03:52:34,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:52:34,674] {logging_mixin.py:115} INFO - [2022-06-06 03:52:34,667] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:52:34,676] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:52:34,784] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-06 03:53:05,598] {processor.py:153} INFO - Started process (PID=27370) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:53:05,599] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:53:05,602] {logging_mixin.py:115} INFO - [2022-06-06 03:53:05,602] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:53:05,649] {logging_mixin.py:115} INFO - [2022-06-06 03:53:05,645] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:53:05,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:53:05,765] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 03:53:36,313] {processor.py:153} INFO - Started process (PID=27438) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:53:36,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:53:36,319] {logging_mixin.py:115} INFO - [2022-06-06 03:53:36,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:53:36,453] {logging_mixin.py:115} INFO - [2022-06-06 03:53:36,445] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:53:36,458] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:53:36,643] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.338 seconds
[2022-06-06 03:54:07,562] {processor.py:153} INFO - Started process (PID=27498) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:54:07,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:54:07,568] {logging_mixin.py:115} INFO - [2022-06-06 03:54:07,568] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:54:07,700] {logging_mixin.py:115} INFO - [2022-06-06 03:54:07,695] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:54:07,703] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:54:07,844] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.289 seconds
[2022-06-06 03:54:38,319] {processor.py:153} INFO - Started process (PID=27566) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:54:38,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:54:38,323] {logging_mixin.py:115} INFO - [2022-06-06 03:54:38,323] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:54:38,372] {logging_mixin.py:115} INFO - [2022-06-06 03:54:38,368] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:54:38,373] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:54:38,479] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 03:55:09,423] {processor.py:153} INFO - Started process (PID=27631) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:55:09,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:55:09,427] {logging_mixin.py:115} INFO - [2022-06-06 03:55:09,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:55:09,506] {logging_mixin.py:115} INFO - [2022-06-06 03:55:09,502] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:55:09,507] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:55:09,608] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-06 03:55:39,952] {processor.py:153} INFO - Started process (PID=27697) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:55:39,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:55:39,955] {logging_mixin.py:115} INFO - [2022-06-06 03:55:39,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:55:40,015] {logging_mixin.py:115} INFO - [2022-06-06 03:55:40,012] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:55:40,017] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:55:40,144] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-06 03:56:10,330] {processor.py:153} INFO - Started process (PID=27766) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:56:10,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:56:10,333] {logging_mixin.py:115} INFO - [2022-06-06 03:56:10,333] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:56:10,396] {logging_mixin.py:115} INFO - [2022-06-06 03:56:10,387] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:56:10,397] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:56:10,525] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-06 03:56:41,056] {processor.py:153} INFO - Started process (PID=27825) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:56:41,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:56:41,060] {logging_mixin.py:115} INFO - [2022-06-06 03:56:41,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:56:41,119] {logging_mixin.py:115} INFO - [2022-06-06 03:56:41,117] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:56:41,121] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:56:41,225] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 03:57:11,291] {processor.py:153} INFO - Started process (PID=27894) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:57:11,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:57:11,294] {logging_mixin.py:115} INFO - [2022-06-06 03:57:11,294] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:57:11,338] {logging_mixin.py:115} INFO - [2022-06-06 03:57:11,336] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:57:11,339] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:57:11,436] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 03:57:41,952] {processor.py:153} INFO - Started process (PID=27966) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:57:41,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:57:41,956] {logging_mixin.py:115} INFO - [2022-06-06 03:57:41,956] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:57:42,001] {logging_mixin.py:115} INFO - [2022-06-06 03:57:41,998] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:57:42,002] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:57:42,095] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 03:58:12,371] {processor.py:153} INFO - Started process (PID=28038) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:58:12,376] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:58:12,377] {logging_mixin.py:115} INFO - [2022-06-06 03:58:12,377] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:58:12,442] {logging_mixin.py:115} INFO - [2022-06-06 03:58:12,439] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:58:12,443] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:58:12,570] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-06 03:58:42,629] {processor.py:153} INFO - Started process (PID=28098) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:58:42,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:58:42,636] {logging_mixin.py:115} INFO - [2022-06-06 03:58:42,636] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:58:42,689] {logging_mixin.py:115} INFO - [2022-06-06 03:58:42,687] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:58:42,692] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:58:42,821] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-06 03:59:13,108] {processor.py:153} INFO - Started process (PID=28171) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:59:13,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:59:13,111] {logging_mixin.py:115} INFO - [2022-06-06 03:59:13,111] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:59:13,152] {logging_mixin.py:115} INFO - [2022-06-06 03:59:13,150] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:59:13,153] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:59:13,249] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-06 03:59:43,759] {processor.py:153} INFO - Started process (PID=28239) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:59:43,762] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 03:59:43,763] {logging_mixin.py:115} INFO - [2022-06-06 03:59:43,763] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:59:43,837] {logging_mixin.py:115} INFO - [2022-06-06 03:59:43,828] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 03:59:43,842] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 03:59:43,951] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 04:00:14,768] {processor.py:153} INFO - Started process (PID=28306) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:00:14,771] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:00:14,773] {logging_mixin.py:115} INFO - [2022-06-06 04:00:14,773] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:00:14,836] {logging_mixin.py:115} INFO - [2022-06-06 04:00:14,833] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:00:14,837] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:00:14,932] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 04:00:45,439] {processor.py:153} INFO - Started process (PID=28373) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:00:45,440] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:00:45,442] {logging_mixin.py:115} INFO - [2022-06-06 04:00:45,442] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:00:45,486] {logging_mixin.py:115} INFO - [2022-06-06 04:00:45,485] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:00:45,487] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:00:45,591] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 04:01:16,309] {processor.py:153} INFO - Started process (PID=28441) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:01:16,311] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:01:16,312] {logging_mixin.py:115} INFO - [2022-06-06 04:01:16,312] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:01:16,365] {logging_mixin.py:115} INFO - [2022-06-06 04:01:16,362] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:01:16,366] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:01:16,474] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 04:01:47,238] {processor.py:153} INFO - Started process (PID=28503) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:01:47,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:01:47,241] {logging_mixin.py:115} INFO - [2022-06-06 04:01:47,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:01:47,286] {logging_mixin.py:115} INFO - [2022-06-06 04:01:47,284] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:01:47,287] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:01:47,380] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-06 04:02:18,075] {processor.py:153} INFO - Started process (PID=28575) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:02:18,077] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:02:18,078] {logging_mixin.py:115} INFO - [2022-06-06 04:02:18,078] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:02:18,129] {logging_mixin.py:115} INFO - [2022-06-06 04:02:18,126] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:02:18,131] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:02:18,229] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 04:02:49,059] {processor.py:153} INFO - Started process (PID=28639) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:02:49,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:02:49,064] {logging_mixin.py:115} INFO - [2022-06-06 04:02:49,064] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:02:49,127] {logging_mixin.py:115} INFO - [2022-06-06 04:02:49,124] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:02:49,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:02:49,223] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 04:03:19,939] {processor.py:153} INFO - Started process (PID=28710) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:03:19,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:03:19,946] {logging_mixin.py:115} INFO - [2022-06-06 04:03:19,945] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:03:20,007] {logging_mixin.py:115} INFO - [2022-06-06 04:03:20,005] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:03:20,009] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:03:20,105] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 04:03:50,759] {processor.py:153} INFO - Started process (PID=28781) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:03:50,760] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:03:50,761] {logging_mixin.py:115} INFO - [2022-06-06 04:03:50,761] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:03:50,824] {logging_mixin.py:115} INFO - [2022-06-06 04:03:50,820] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:03:50,825] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:03:50,942] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 04:04:21,734] {processor.py:153} INFO - Started process (PID=28839) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:04:21,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:04:21,740] {logging_mixin.py:115} INFO - [2022-06-06 04:04:21,740] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:04:21,797] {logging_mixin.py:115} INFO - [2022-06-06 04:04:21,795] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:04:21,799] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:04:21,894] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 04:04:52,259] {processor.py:153} INFO - Started process (PID=28905) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:04:52,260] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:04:52,261] {logging_mixin.py:115} INFO - [2022-06-06 04:04:52,261] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:04:52,301] {logging_mixin.py:115} INFO - [2022-06-06 04:04:52,300] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:04:52,303] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:04:52,396] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.139 seconds
[2022-06-06 04:05:23,192] {processor.py:153} INFO - Started process (PID=28975) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:05:23,195] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:05:23,197] {logging_mixin.py:115} INFO - [2022-06-06 04:05:23,197] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:05:23,249] {logging_mixin.py:115} INFO - [2022-06-06 04:05:23,246] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:05:23,251] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:05:23,345] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 04:05:54,127] {processor.py:153} INFO - Started process (PID=29043) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:05:54,130] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:05:54,133] {logging_mixin.py:115} INFO - [2022-06-06 04:05:54,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:05:54,208] {logging_mixin.py:115} INFO - [2022-06-06 04:05:54,206] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:05:54,209] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:05:54,307] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-06 04:06:24,394] {processor.py:153} INFO - Started process (PID=29112) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:06:24,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:06:24,396] {logging_mixin.py:115} INFO - [2022-06-06 04:06:24,396] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:06:24,440] {logging_mixin.py:115} INFO - [2022-06-06 04:06:24,438] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:06:24,442] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:06:24,541] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-06 04:06:54,752] {processor.py:153} INFO - Started process (PID=29168) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:06:54,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:06:54,755] {logging_mixin.py:115} INFO - [2022-06-06 04:06:54,755] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:06:54,830] {logging_mixin.py:115} INFO - [2022-06-06 04:06:54,818] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:06:54,831] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:06:54,947] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-06 04:07:25,018] {processor.py:153} INFO - Started process (PID=29235) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:07:25,021] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:07:25,023] {logging_mixin.py:115} INFO - [2022-06-06 04:07:25,023] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:07:25,079] {logging_mixin.py:115} INFO - [2022-06-06 04:07:25,077] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:07:25,080] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:07:25,175] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 04:07:55,315] {processor.py:153} INFO - Started process (PID=29302) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:07:55,318] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:07:55,320] {logging_mixin.py:115} INFO - [2022-06-06 04:07:55,320] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:07:55,384] {logging_mixin.py:115} INFO - [2022-06-06 04:07:55,382] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:07:55,385] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:07:55,481] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 04:08:26,460] {processor.py:153} INFO - Started process (PID=29370) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:08:26,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:08:26,466] {logging_mixin.py:115} INFO - [2022-06-06 04:08:26,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:08:26,521] {logging_mixin.py:115} INFO - [2022-06-06 04:08:26,519] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:08:26,523] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:08:26,632] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 04:08:57,639] {processor.py:153} INFO - Started process (PID=29446) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:08:57,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:08:57,644] {logging_mixin.py:115} INFO - [2022-06-06 04:08:57,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:08:57,698] {logging_mixin.py:115} INFO - [2022-06-06 04:08:57,695] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:08:57,700] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:08:57,793] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 04:09:28,428] {processor.py:153} INFO - Started process (PID=29515) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:09:28,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:09:28,432] {logging_mixin.py:115} INFO - [2022-06-06 04:09:28,432] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:09:28,541] {logging_mixin.py:115} INFO - [2022-06-06 04:09:28,532] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:09:28,553] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:09:28,730] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.310 seconds
[2022-06-06 04:09:59,598] {processor.py:153} INFO - Started process (PID=29575) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:09:59,601] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:09:59,603] {logging_mixin.py:115} INFO - [2022-06-06 04:09:59,603] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:09:59,691] {logging_mixin.py:115} INFO - [2022-06-06 04:09:59,689] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:09:59,693] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:09:59,807] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-06 04:10:30,306] {processor.py:153} INFO - Started process (PID=29643) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:10:30,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:10:30,311] {logging_mixin.py:115} INFO - [2022-06-06 04:10:30,311] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:10:30,367] {logging_mixin.py:115} INFO - [2022-06-06 04:10:30,365] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:10:30,375] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:10:30,474] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 04:11:01,253] {processor.py:153} INFO - Started process (PID=29711) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:11:01,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:11:01,259] {logging_mixin.py:115} INFO - [2022-06-06 04:11:01,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:11:01,317] {logging_mixin.py:115} INFO - [2022-06-06 04:11:01,315] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:11:01,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:11:01,415] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 04:11:32,204] {processor.py:153} INFO - Started process (PID=29782) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:11:32,207] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:11:32,210] {logging_mixin.py:115} INFO - [2022-06-06 04:11:32,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:11:32,264] {logging_mixin.py:115} INFO - [2022-06-06 04:11:32,263] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:11:32,266] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:11:32,362] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 04:12:03,034] {processor.py:153} INFO - Started process (PID=29851) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:12:03,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:12:03,037] {logging_mixin.py:115} INFO - [2022-06-06 04:12:03,037] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:12:03,119] {logging_mixin.py:115} INFO - [2022-06-06 04:12:03,115] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:12:03,121] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:12:03,235] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.205 seconds
[2022-06-06 04:12:33,392] {processor.py:153} INFO - Started process (PID=29909) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:12:33,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:12:33,400] {logging_mixin.py:115} INFO - [2022-06-06 04:12:33,400] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:12:33,470] {logging_mixin.py:115} INFO - [2022-06-06 04:12:33,468] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:12:33,472] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:12:33,621] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.236 seconds
[2022-06-06 04:13:04,276] {processor.py:153} INFO - Started process (PID=29975) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:13:04,278] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:13:04,280] {logging_mixin.py:115} INFO - [2022-06-06 04:13:04,280] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:13:04,345] {logging_mixin.py:115} INFO - [2022-06-06 04:13:04,342] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:13:04,350] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:13:04,456] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 04:13:35,367] {processor.py:153} INFO - Started process (PID=30047) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:13:35,369] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:13:35,371] {logging_mixin.py:115} INFO - [2022-06-06 04:13:35,371] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:13:35,416] {logging_mixin.py:115} INFO - [2022-06-06 04:13:35,414] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:13:35,417] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:13:35,515] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 04:14:05,685] {processor.py:153} INFO - Started process (PID=30119) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:14:05,687] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:14:05,691] {logging_mixin.py:115} INFO - [2022-06-06 04:14:05,691] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:14:05,811] {logging_mixin.py:115} INFO - [2022-06-06 04:14:05,807] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:14:05,815] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:14:05,956] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.278 seconds
[2022-06-06 04:14:36,016] {processor.py:153} INFO - Started process (PID=30177) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:14:36,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:14:36,018] {logging_mixin.py:115} INFO - [2022-06-06 04:14:36,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:14:36,067] {logging_mixin.py:115} INFO - [2022-06-06 04:14:36,064] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:14:36,068] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:14:36,162] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 04:15:06,686] {processor.py:153} INFO - Started process (PID=30247) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:15:06,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:15:06,690] {logging_mixin.py:115} INFO - [2022-06-06 04:15:06,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:15:06,739] {logging_mixin.py:115} INFO - [2022-06-06 04:15:06,736] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:15:06,740] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:15:06,838] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 04:15:37,263] {processor.py:153} INFO - Started process (PID=30314) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:15:37,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:15:37,268] {logging_mixin.py:115} INFO - [2022-06-06 04:15:37,268] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:15:37,323] {logging_mixin.py:115} INFO - [2022-06-06 04:15:37,320] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:15:37,326] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:15:37,425] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 04:16:07,894] {processor.py:153} INFO - Started process (PID=30383) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:16:07,896] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:16:07,897] {logging_mixin.py:115} INFO - [2022-06-06 04:16:07,897] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:16:07,952] {logging_mixin.py:115} INFO - [2022-06-06 04:16:07,950] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:16:07,954] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:16:08,063] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 04:16:38,900] {processor.py:153} INFO - Started process (PID=30442) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:16:38,901] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:16:38,902] {logging_mixin.py:115} INFO - [2022-06-06 04:16:38,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:16:38,945] {logging_mixin.py:115} INFO - [2022-06-06 04:16:38,942] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:16:38,946] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:16:39,045] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 04:17:09,851] {processor.py:153} INFO - Started process (PID=30509) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:17:09,852] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:17:09,854] {logging_mixin.py:115} INFO - [2022-06-06 04:17:09,854] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:17:09,898] {logging_mixin.py:115} INFO - [2022-06-06 04:17:09,895] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:17:09,899] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:17:10,000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 04:17:41,032] {processor.py:153} INFO - Started process (PID=30579) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:17:41,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:17:41,036] {logging_mixin.py:115} INFO - [2022-06-06 04:17:41,036] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:17:41,084] {logging_mixin.py:115} INFO - [2022-06-06 04:17:41,082] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:17:41,086] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:17:41,182] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 04:18:12,164] {processor.py:153} INFO - Started process (PID=30647) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:18:12,167] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:18:12,168] {logging_mixin.py:115} INFO - [2022-06-06 04:18:12,168] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:18:12,229] {logging_mixin.py:115} INFO - [2022-06-06 04:18:12,225] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:18:12,236] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:18:12,342] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 04:18:42,645] {processor.py:153} INFO - Started process (PID=30718) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:18:42,647] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:18:42,649] {logging_mixin.py:115} INFO - [2022-06-06 04:18:42,649] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:18:42,712] {logging_mixin.py:115} INFO - [2022-06-06 04:18:42,709] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:18:42,713] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:18:42,810] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 04:19:13,230] {processor.py:153} INFO - Started process (PID=30782) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:19:13,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:19:13,235] {logging_mixin.py:115} INFO - [2022-06-06 04:19:13,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:19:13,304] {logging_mixin.py:115} INFO - [2022-06-06 04:19:13,301] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:19:13,305] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:19:13,450] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-06 04:19:43,661] {processor.py:153} INFO - Started process (PID=30840) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:19:43,665] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:19:43,667] {logging_mixin.py:115} INFO - [2022-06-06 04:19:43,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:19:43,727] {logging_mixin.py:115} INFO - [2022-06-06 04:19:43,724] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:19:43,729] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:19:43,824] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 04:20:14,760] {processor.py:153} INFO - Started process (PID=30917) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:20:14,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:20:14,765] {logging_mixin.py:115} INFO - [2022-06-06 04:20:14,765] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:20:14,835] {logging_mixin.py:115} INFO - [2022-06-06 04:20:14,833] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:20:14,836] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:20:14,961] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-06 04:20:45,296] {processor.py:153} INFO - Started process (PID=30985) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:20:45,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:20:45,301] {logging_mixin.py:115} INFO - [2022-06-06 04:20:45,300] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:20:45,349] {logging_mixin.py:115} INFO - [2022-06-06 04:20:45,347] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:20:45,351] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:20:45,443] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 04:21:15,749] {processor.py:153} INFO - Started process (PID=31052) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:21:15,752] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:21:15,753] {logging_mixin.py:115} INFO - [2022-06-06 04:21:15,753] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:21:15,817] {logging_mixin.py:115} INFO - [2022-06-06 04:21:15,814] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:21:15,819] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:21:15,915] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 04:21:46,145] {processor.py:153} INFO - Started process (PID=31111) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:21:46,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:21:46,150] {logging_mixin.py:115} INFO - [2022-06-06 04:21:46,150] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:21:46,211] {logging_mixin.py:115} INFO - [2022-06-06 04:21:46,207] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:21:46,212] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:21:46,315] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 04:22:16,465] {processor.py:153} INFO - Started process (PID=31179) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:22:16,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:22:16,469] {logging_mixin.py:115} INFO - [2022-06-06 04:22:16,469] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:22:16,536] {logging_mixin.py:115} INFO - [2022-06-06 04:22:16,534] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:22:16,538] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:22:16,640] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 04:22:47,075] {processor.py:153} INFO - Started process (PID=31246) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:22:47,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:22:47,080] {logging_mixin.py:115} INFO - [2022-06-06 04:22:47,080] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:22:47,137] {logging_mixin.py:115} INFO - [2022-06-06 04:22:47,134] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:22:47,138] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:22:47,237] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 04:23:17,415] {processor.py:153} INFO - Started process (PID=31313) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:23:17,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:23:17,420] {logging_mixin.py:115} INFO - [2022-06-06 04:23:17,420] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:23:17,479] {logging_mixin.py:115} INFO - [2022-06-06 04:23:17,475] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:23:17,482] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:23:17,573] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 04:23:47,755] {processor.py:153} INFO - Started process (PID=31371) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:23:47,758] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:23:47,759] {logging_mixin.py:115} INFO - [2022-06-06 04:23:47,759] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:23:47,816] {logging_mixin.py:115} INFO - [2022-06-06 04:23:47,814] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:23:47,818] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:23:47,924] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 04:24:18,059] {processor.py:153} INFO - Started process (PID=31436) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:24:18,063] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:24:18,066] {logging_mixin.py:115} INFO - [2022-06-06 04:24:18,066] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:24:18,123] {logging_mixin.py:115} INFO - [2022-06-06 04:24:18,120] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:24:18,124] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:24:18,222] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 04:24:48,890] {processor.py:153} INFO - Started process (PID=31502) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:24:48,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:24:48,893] {logging_mixin.py:115} INFO - [2022-06-06 04:24:48,892] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:24:48,956] {logging_mixin.py:115} INFO - [2022-06-06 04:24:48,953] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:24:48,957] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:24:49,051] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 04:25:19,729] {processor.py:153} INFO - Started process (PID=31570) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:25:19,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:25:19,732] {logging_mixin.py:115} INFO - [2022-06-06 04:25:19,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:25:19,784] {logging_mixin.py:115} INFO - [2022-06-06 04:25:19,782] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:25:19,788] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:25:19,882] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 04:25:50,664] {processor.py:153} INFO - Started process (PID=31637) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:25:50,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:25:50,667] {logging_mixin.py:115} INFO - [2022-06-06 04:25:50,667] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:25:50,724] {logging_mixin.py:115} INFO - [2022-06-06 04:25:50,721] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:25:50,725] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:25:50,821] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 04:26:21,437] {processor.py:153} INFO - Started process (PID=31705) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:26:21,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:26:21,442] {logging_mixin.py:115} INFO - [2022-06-06 04:26:21,442] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:26:21,490] {logging_mixin.py:115} INFO - [2022-06-06 04:26:21,488] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:26:21,493] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:26:21,602] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 04:26:52,581] {processor.py:153} INFO - Started process (PID=31763) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:26:52,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:26:52,583] {logging_mixin.py:115} INFO - [2022-06-06 04:26:52,583] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:26:52,627] {logging_mixin.py:115} INFO - [2022-06-06 04:26:52,625] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:26:52,628] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:26:52,726] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 04:27:22,882] {processor.py:153} INFO - Started process (PID=31835) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:27:22,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:27:22,887] {logging_mixin.py:115} INFO - [2022-06-06 04:27:22,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:27:22,941] {logging_mixin.py:115} INFO - [2022-06-06 04:27:22,938] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:27:22,943] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:27:23,053] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 04:27:53,125] {processor.py:153} INFO - Started process (PID=31903) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:27:53,128] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:27:53,129] {logging_mixin.py:115} INFO - [2022-06-06 04:27:53,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:27:53,200] {logging_mixin.py:115} INFO - [2022-06-06 04:27:53,196] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:27:53,201] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:27:53,324] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-06 04:28:23,726] {processor.py:153} INFO - Started process (PID=31970) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:28:23,728] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:28:23,729] {logging_mixin.py:115} INFO - [2022-06-06 04:28:23,729] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:28:23,771] {logging_mixin.py:115} INFO - [2022-06-06 04:28:23,768] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:28:23,772] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:28:23,867] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-06 04:28:53,935] {processor.py:153} INFO - Started process (PID=32035) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:28:53,936] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:28:53,937] {logging_mixin.py:115} INFO - [2022-06-06 04:28:53,937] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:28:53,989] {logging_mixin.py:115} INFO - [2022-06-06 04:28:53,987] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:28:53,991] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:28:54,100] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 04:29:24,300] {processor.py:153} INFO - Started process (PID=32093) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:29:24,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:29:24,303] {logging_mixin.py:115} INFO - [2022-06-06 04:29:24,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:29:24,357] {logging_mixin.py:115} INFO - [2022-06-06 04:29:24,354] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:29:24,358] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:29:24,461] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 04:29:55,301] {processor.py:153} INFO - Started process (PID=32161) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:29:55,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:29:55,306] {logging_mixin.py:115} INFO - [2022-06-06 04:29:55,306] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:29:55,369] {logging_mixin.py:115} INFO - [2022-06-06 04:29:55,366] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:29:55,372] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:29:55,492] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-06 04:30:25,590] {processor.py:153} INFO - Started process (PID=32227) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:30:25,592] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:30:25,593] {logging_mixin.py:115} INFO - [2022-06-06 04:30:25,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:30:25,638] {logging_mixin.py:115} INFO - [2022-06-06 04:30:25,635] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:30:25,640] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:30:25,736] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-06 04:30:56,490] {processor.py:153} INFO - Started process (PID=32295) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:30:56,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:30:56,496] {logging_mixin.py:115} INFO - [2022-06-06 04:30:56,495] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:30:56,561] {logging_mixin.py:115} INFO - [2022-06-06 04:30:56,559] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:30:56,563] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:30:56,659] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 04:31:27,292] {processor.py:153} INFO - Started process (PID=32362) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:31:27,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:31:27,296] {logging_mixin.py:115} INFO - [2022-06-06 04:31:27,296] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:31:27,360] {logging_mixin.py:115} INFO - [2022-06-06 04:31:27,357] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:31:27,362] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:31:27,478] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 04:31:57,628] {processor.py:153} INFO - Started process (PID=32418) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:31:57,631] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:31:57,634] {logging_mixin.py:115} INFO - [2022-06-06 04:31:57,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:31:57,689] {logging_mixin.py:115} INFO - [2022-06-06 04:31:57,687] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:31:57,691] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:31:57,785] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 04:32:27,938] {processor.py:153} INFO - Started process (PID=32486) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:32:27,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:32:27,941] {logging_mixin.py:115} INFO - [2022-06-06 04:32:27,941] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:32:27,992] {logging_mixin.py:115} INFO - [2022-06-06 04:32:27,990] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:32:27,993] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:32:28,087] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 04:32:58,232] {processor.py:153} INFO - Started process (PID=32552) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:32:58,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:32:58,235] {logging_mixin.py:115} INFO - [2022-06-06 04:32:58,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:32:58,297] {logging_mixin.py:115} INFO - [2022-06-06 04:32:58,294] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:32:58,301] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:32:58,442] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-06 04:33:28,790] {processor.py:153} INFO - Started process (PID=32620) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:33:28,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:33:28,792] {logging_mixin.py:115} INFO - [2022-06-06 04:33:28,792] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:33:28,836] {logging_mixin.py:115} INFO - [2022-06-06 04:33:28,834] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:33:28,837] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:33:28,932] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-06 04:33:59,634] {processor.py:153} INFO - Started process (PID=32692) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:33:59,636] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:33:59,638] {logging_mixin.py:115} INFO - [2022-06-06 04:33:59,638] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:33:59,710] {logging_mixin.py:115} INFO - [2022-06-06 04:33:59,707] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:33:59,715] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:33:59,829] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-06 04:34:30,293] {processor.py:153} INFO - Started process (PID=32749) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:34:30,295] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:34:30,297] {logging_mixin.py:115} INFO - [2022-06-06 04:34:30,297] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:34:30,368] {logging_mixin.py:115} INFO - [2022-06-06 04:34:30,366] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:34:30,369] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:34:30,480] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 04:35:01,059] {processor.py:153} INFO - Started process (PID=32820) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:35:01,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:35:01,064] {logging_mixin.py:115} INFO - [2022-06-06 04:35:01,064] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:35:01,115] {logging_mixin.py:115} INFO - [2022-06-06 04:35:01,112] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:35:01,117] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:35:01,222] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 04:35:31,407] {processor.py:153} INFO - Started process (PID=32890) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:35:31,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:35:31,410] {logging_mixin.py:115} INFO - [2022-06-06 04:35:31,410] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:35:31,464] {logging_mixin.py:115} INFO - [2022-06-06 04:35:31,461] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:35:31,464] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:35:31,559] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 04:36:01,762] {processor.py:153} INFO - Started process (PID=32957) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:36:01,764] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:36:01,765] {logging_mixin.py:115} INFO - [2022-06-06 04:36:01,765] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:36:01,823] {logging_mixin.py:115} INFO - [2022-06-06 04:36:01,821] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:36:01,825] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:36:01,926] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 04:36:32,533] {processor.py:153} INFO - Started process (PID=33025) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:36:32,535] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:36:32,537] {logging_mixin.py:115} INFO - [2022-06-06 04:36:32,537] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:36:32,592] {logging_mixin.py:115} INFO - [2022-06-06 04:36:32,589] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:36:32,593] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:36:32,708] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 04:37:02,773] {processor.py:153} INFO - Started process (PID=33087) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:37:02,775] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:37:02,777] {logging_mixin.py:115} INFO - [2022-06-06 04:37:02,777] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:37:02,857] {logging_mixin.py:115} INFO - [2022-06-06 04:37:02,854] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:37:02,860] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:37:03,009] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-06 04:37:33,700] {processor.py:153} INFO - Started process (PID=33155) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:37:33,703] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:37:33,705] {logging_mixin.py:115} INFO - [2022-06-06 04:37:33,704] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:37:33,762] {logging_mixin.py:115} INFO - [2022-06-06 04:37:33,760] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:37:33,764] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:37:33,858] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 04:38:04,412] {processor.py:153} INFO - Started process (PID=33221) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:38:04,414] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:38:04,415] {logging_mixin.py:115} INFO - [2022-06-06 04:38:04,415] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:38:04,467] {logging_mixin.py:115} INFO - [2022-06-06 04:38:04,465] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:38:04,468] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:38:04,562] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 04:38:35,335] {processor.py:153} INFO - Started process (PID=33290) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:38:35,336] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:38:35,337] {logging_mixin.py:115} INFO - [2022-06-06 04:38:35,337] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:38:35,379] {logging_mixin.py:115} INFO - [2022-06-06 04:38:35,377] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:38:35,381] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:38:35,480] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 04:39:05,885] {processor.py:153} INFO - Started process (PID=33358) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:39:05,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:39:05,888] {logging_mixin.py:115} INFO - [2022-06-06 04:39:05,888] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:39:05,938] {logging_mixin.py:115} INFO - [2022-06-06 04:39:05,936] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:39:05,939] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:39:06,034] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 04:39:36,740] {processor.py:153} INFO - Started process (PID=33429) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:39:36,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:39:36,745] {logging_mixin.py:115} INFO - [2022-06-06 04:39:36,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:39:36,806] {logging_mixin.py:115} INFO - [2022-06-06 04:39:36,804] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:39:36,808] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:39:36,905] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 04:40:07,682] {processor.py:153} INFO - Started process (PID=33496) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:40:07,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:40:07,685] {logging_mixin.py:115} INFO - [2022-06-06 04:40:07,685] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:40:07,729] {logging_mixin.py:115} INFO - [2022-06-06 04:40:07,726] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:40:07,730] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:40:07,824] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-06 04:40:38,599] {processor.py:153} INFO - Started process (PID=33553) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:40:38,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:40:38,601] {logging_mixin.py:115} INFO - [2022-06-06 04:40:38,601] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:40:38,646] {logging_mixin.py:115} INFO - [2022-06-06 04:40:38,644] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:40:38,649] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:40:38,750] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 04:41:09,268] {processor.py:153} INFO - Started process (PID=33622) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:41:09,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:41:09,271] {logging_mixin.py:115} INFO - [2022-06-06 04:41:09,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:41:09,315] {logging_mixin.py:115} INFO - [2022-06-06 04:41:09,312] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:41:09,316] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:41:09,408] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.143 seconds
[2022-06-06 04:41:40,101] {processor.py:153} INFO - Started process (PID=33691) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:41:40,104] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:41:40,106] {logging_mixin.py:115} INFO - [2022-06-06 04:41:40,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:41:40,162] {logging_mixin.py:115} INFO - [2022-06-06 04:41:40,160] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:41:40,164] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:41:40,262] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 04:42:10,866] {processor.py:153} INFO - Started process (PID=33757) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:42:10,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:42:10,869] {logging_mixin.py:115} INFO - [2022-06-06 04:42:10,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:42:10,909] {logging_mixin.py:115} INFO - [2022-06-06 04:42:10,907] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:42:10,911] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:42:11,005] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.142 seconds
[2022-06-06 04:42:41,525] {processor.py:153} INFO - Started process (PID=33823) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:42:41,527] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:42:41,529] {logging_mixin.py:115} INFO - [2022-06-06 04:42:41,529] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:42:41,577] {logging_mixin.py:115} INFO - [2022-06-06 04:42:41,575] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:42:41,578] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:42:41,675] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 04:43:12,331] {processor.py:153} INFO - Started process (PID=33890) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:43:12,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:43:12,333] {logging_mixin.py:115} INFO - [2022-06-06 04:43:12,333] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:43:12,376] {logging_mixin.py:115} INFO - [2022-06-06 04:43:12,374] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:43:12,377] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:43:12,470] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.141 seconds
[2022-06-06 04:43:42,977] {processor.py:153} INFO - Started process (PID=33949) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:43:42,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:43:42,980] {logging_mixin.py:115} INFO - [2022-06-06 04:43:42,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:43:43,031] {logging_mixin.py:115} INFO - [2022-06-06 04:43:43,029] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:43:43,033] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:43:43,135] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 04:44:13,753] {processor.py:153} INFO - Started process (PID=34016) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:44:13,757] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:44:13,759] {logging_mixin.py:115} INFO - [2022-06-06 04:44:13,759] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:44:13,825] {logging_mixin.py:115} INFO - [2022-06-06 04:44:13,822] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:44:13,827] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:44:13,923] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 04:44:44,498] {processor.py:153} INFO - Started process (PID=34085) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:44:44,500] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:44:44,501] {logging_mixin.py:115} INFO - [2022-06-06 04:44:44,501] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:44:44,543] {logging_mixin.py:115} INFO - [2022-06-06 04:44:44,540] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:44:44,544] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:44:44,637] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.141 seconds
[2022-06-06 04:45:15,435] {processor.py:153} INFO - Started process (PID=34153) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:45:15,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:45:15,440] {logging_mixin.py:115} INFO - [2022-06-06 04:45:15,440] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:45:15,498] {logging_mixin.py:115} INFO - [2022-06-06 04:45:15,494] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:45:15,500] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:45:15,610] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 04:45:46,490] {processor.py:153} INFO - Started process (PID=34222) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:45:46,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:45:46,495] {logging_mixin.py:115} INFO - [2022-06-06 04:45:46,495] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:45:46,552] {logging_mixin.py:115} INFO - [2022-06-06 04:45:46,550] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:45:46,553] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:45:46,646] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 04:46:17,346] {processor.py:153} INFO - Started process (PID=34290) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:46:17,349] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:46:17,350] {logging_mixin.py:115} INFO - [2022-06-06 04:46:17,350] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:46:17,395] {logging_mixin.py:115} INFO - [2022-06-06 04:46:17,392] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:46:17,396] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:46:17,490] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 04:46:48,419] {processor.py:153} INFO - Started process (PID=34358) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:46:48,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:46:48,425] {logging_mixin.py:115} INFO - [2022-06-06 04:46:48,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:46:48,477] {logging_mixin.py:115} INFO - [2022-06-06 04:46:48,475] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:46:48,479] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:46:48,571] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 04:47:18,770] {processor.py:153} INFO - Started process (PID=34414) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:47:18,771] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:47:18,772] {logging_mixin.py:115} INFO - [2022-06-06 04:47:18,771] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:47:18,815] {logging_mixin.py:115} INFO - [2022-06-06 04:47:18,813] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:47:18,817] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:47:18,919] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 04:47:48,962] {processor.py:153} INFO - Started process (PID=34479) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:47:48,964] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:47:48,966] {logging_mixin.py:115} INFO - [2022-06-06 04:47:48,966] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:47:49,017] {logging_mixin.py:115} INFO - [2022-06-06 04:47:49,013] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:47:49,019] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:47:49,125] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 04:48:19,307] {processor.py:153} INFO - Started process (PID=34546) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:48:19,310] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:48:19,312] {logging_mixin.py:115} INFO - [2022-06-06 04:48:19,311] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:48:19,368] {logging_mixin.py:115} INFO - [2022-06-06 04:48:19,366] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:48:19,370] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:48:19,465] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 04:48:49,693] {processor.py:153} INFO - Started process (PID=34617) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:48:49,694] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:48:49,696] {logging_mixin.py:115} INFO - [2022-06-06 04:48:49,695] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:48:49,736] {logging_mixin.py:115} INFO - [2022-06-06 04:48:49,734] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:48:49,737] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:48:49,834] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-06 04:49:19,909] {processor.py:153} INFO - Started process (PID=34686) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:49:19,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:49:19,914] {logging_mixin.py:115} INFO - [2022-06-06 04:49:19,914] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:49:19,967] {logging_mixin.py:115} INFO - [2022-06-06 04:49:19,965] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:49:19,968] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:49:20,061] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 04:49:50,340] {processor.py:153} INFO - Started process (PID=34746) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:49:50,343] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:49:50,345] {logging_mixin.py:115} INFO - [2022-06-06 04:49:50,345] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:49:50,398] {logging_mixin.py:115} INFO - [2022-06-06 04:49:50,396] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:49:50,399] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:49:50,493] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 04:50:20,665] {processor.py:153} INFO - Started process (PID=34817) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:50:20,667] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:50:20,668] {logging_mixin.py:115} INFO - [2022-06-06 04:50:20,668] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:50:20,711] {logging_mixin.py:115} INFO - [2022-06-06 04:50:20,709] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:50:20,712] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:50:20,808] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-06 04:50:50,891] {processor.py:153} INFO - Started process (PID=34884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:50:50,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:50:50,894] {logging_mixin.py:115} INFO - [2022-06-06 04:50:50,894] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:50:50,942] {logging_mixin.py:115} INFO - [2022-06-06 04:50:50,940] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:50:50,944] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:50:51,041] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 04:51:21,522] {processor.py:153} INFO - Started process (PID=34952) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:51:21,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:51:21,527] {logging_mixin.py:115} INFO - [2022-06-06 04:51:21,527] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:51:21,584] {logging_mixin.py:115} INFO - [2022-06-06 04:51:21,582] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:51:21,585] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:51:21,683] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 04:51:52,302] {processor.py:153} INFO - Started process (PID=35020) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:51:52,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:51:52,307] {logging_mixin.py:115} INFO - [2022-06-06 04:51:52,307] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:51:52,360] {logging_mixin.py:115} INFO - [2022-06-06 04:51:52,358] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:51:52,362] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:51:52,455] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 04:52:23,343] {processor.py:153} INFO - Started process (PID=35089) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:52:23,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:52:23,346] {logging_mixin.py:115} INFO - [2022-06-06 04:52:23,346] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:52:23,390] {logging_mixin.py:115} INFO - [2022-06-06 04:52:23,388] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:52:23,391] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:52:23,487] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 04:52:54,405] {processor.py:153} INFO - Started process (PID=35148) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:52:54,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:52:54,407] {logging_mixin.py:115} INFO - [2022-06-06 04:52:54,407] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:52:54,448] {logging_mixin.py:115} INFO - [2022-06-06 04:52:54,446] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:52:54,450] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:52:54,543] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.140 seconds
[2022-06-06 04:53:25,430] {processor.py:153} INFO - Started process (PID=35218) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:53:25,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:53:25,432] {logging_mixin.py:115} INFO - [2022-06-06 04:53:25,432] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:53:25,480] {logging_mixin.py:115} INFO - [2022-06-06 04:53:25,478] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:53:25,481] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:53:25,583] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 04:53:56,458] {processor.py:153} INFO - Started process (PID=35285) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:53:56,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:53:56,461] {logging_mixin.py:115} INFO - [2022-06-06 04:53:56,461] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:53:56,514] {logging_mixin.py:115} INFO - [2022-06-06 04:53:56,512] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:53:56,516] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:53:56,613] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 04:54:27,214] {processor.py:153} INFO - Started process (PID=35357) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:54:27,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:54:27,223] {logging_mixin.py:115} INFO - [2022-06-06 04:54:27,223] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:54:27,276] {logging_mixin.py:115} INFO - [2022-06-06 04:54:27,274] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:54:27,277] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:54:27,374] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 04:54:57,862] {processor.py:153} INFO - Started process (PID=35426) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:54:57,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:54:57,865] {logging_mixin.py:115} INFO - [2022-06-06 04:54:57,865] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:54:57,917] {logging_mixin.py:115} INFO - [2022-06-06 04:54:57,914] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:54:57,919] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:54:58,019] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 04:55:28,701] {processor.py:153} INFO - Started process (PID=35492) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:55:28,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:55:28,708] {logging_mixin.py:115} INFO - [2022-06-06 04:55:28,708] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:55:28,763] {logging_mixin.py:115} INFO - [2022-06-06 04:55:28,760] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:55:28,764] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:55:28,857] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 04:55:59,525] {processor.py:153} INFO - Started process (PID=35558) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:55:59,527] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:55:59,528] {logging_mixin.py:115} INFO - [2022-06-06 04:55:59,527] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:55:59,568] {logging_mixin.py:115} INFO - [2022-06-06 04:55:59,566] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:55:59,569] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:55:59,661] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.138 seconds
[2022-06-06 04:56:30,703] {processor.py:153} INFO - Started process (PID=35617) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:56:30,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:56:30,710] {logging_mixin.py:115} INFO - [2022-06-06 04:56:30,710] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:56:30,768] {logging_mixin.py:115} INFO - [2022-06-06 04:56:30,765] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:56:30,769] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:56:30,863] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 04:57:01,032] {processor.py:153} INFO - Started process (PID=35692) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:57:01,037] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:57:01,039] {logging_mixin.py:115} INFO - [2022-06-06 04:57:01,039] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:57:01,093] {logging_mixin.py:115} INFO - [2022-06-06 04:57:01,091] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:57:01,094] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:57:01,191] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 04:57:31,450] {processor.py:153} INFO - Started process (PID=35761) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:57:31,453] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:57:31,455] {logging_mixin.py:115} INFO - [2022-06-06 04:57:31,455] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:57:31,506] {logging_mixin.py:115} INFO - [2022-06-06 04:57:31,505] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:57:31,508] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:57:31,605] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 04:58:01,906] {processor.py:153} INFO - Started process (PID=35835) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:58:01,909] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:58:01,911] {logging_mixin.py:115} INFO - [2022-06-06 04:58:01,911] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:58:01,965] {logging_mixin.py:115} INFO - [2022-06-06 04:58:01,963] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:58:01,966] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:58:02,060] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 04:58:32,274] {processor.py:153} INFO - Started process (PID=35902) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:58:32,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:58:32,276] {logging_mixin.py:115} INFO - [2022-06-06 04:58:32,276] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:58:32,317] {logging_mixin.py:115} INFO - [2022-06-06 04:58:32,315] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:58:32,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:58:32,413] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.142 seconds
[2022-06-06 04:59:03,375] {processor.py:153} INFO - Started process (PID=35961) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:59:03,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:59:03,381] {logging_mixin.py:115} INFO - [2022-06-06 04:59:03,381] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:59:03,440] {logging_mixin.py:115} INFO - [2022-06-06 04:59:03,438] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:59:03,441] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:59:03,541] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 04:59:34,070] {processor.py:153} INFO - Started process (PID=36030) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:59:34,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 04:59:34,072] {logging_mixin.py:115} INFO - [2022-06-06 04:59:34,072] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:59:34,112] {logging_mixin.py:115} INFO - [2022-06-06 04:59:34,110] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 04:59:34,114] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 04:59:34,208] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.139 seconds
[2022-06-06 05:00:04,634] {processor.py:153} INFO - Started process (PID=36099) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:00:04,637] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:00:04,639] {logging_mixin.py:115} INFO - [2022-06-06 05:00:04,639] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:00:04,698] {logging_mixin.py:115} INFO - [2022-06-06 05:00:04,695] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:00:04,699] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:00:04,795] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 05:00:35,567] {processor.py:153} INFO - Started process (PID=36167) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:00:35,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:00:35,571] {logging_mixin.py:115} INFO - [2022-06-06 05:00:35,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:00:35,618] {logging_mixin.py:115} INFO - [2022-06-06 05:00:35,616] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:00:35,620] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:00:35,719] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 05:01:06,353] {processor.py:153} INFO - Started process (PID=36234) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:01:06,355] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:01:06,356] {logging_mixin.py:115} INFO - [2022-06-06 05:01:06,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:01:06,397] {logging_mixin.py:115} INFO - [2022-06-06 05:01:06,395] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:01:06,398] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:01:06,491] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.140 seconds
[2022-06-06 05:01:37,224] {processor.py:153} INFO - Started process (PID=36302) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:01:37,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:01:37,229] {logging_mixin.py:115} INFO - [2022-06-06 05:01:37,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:01:37,273] {logging_mixin.py:115} INFO - [2022-06-06 05:01:37,271] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:01:37,275] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:01:37,367] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 05:02:08,081] {processor.py:153} INFO - Started process (PID=36359) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:02:08,084] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:02:08,084] {logging_mixin.py:115} INFO - [2022-06-06 05:02:08,084] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:02:08,130] {logging_mixin.py:115} INFO - [2022-06-06 05:02:08,128] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:02:08,131] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:02:08,226] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 05:02:38,949] {processor.py:153} INFO - Started process (PID=36429) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:02:38,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:02:38,954] {logging_mixin.py:115} INFO - [2022-06-06 05:02:38,954] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:02:39,010] {logging_mixin.py:115} INFO - [2022-06-06 05:02:39,007] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:02:39,012] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:02:39,107] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 05:03:09,853] {processor.py:153} INFO - Started process (PID=36496) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:03:09,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:03:09,856] {logging_mixin.py:115} INFO - [2022-06-06 05:03:09,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:03:09,907] {logging_mixin.py:115} INFO - [2022-06-06 05:03:09,903] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:03:09,908] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:03:10,011] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 05:03:40,814] {processor.py:153} INFO - Started process (PID=36565) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:03:40,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:03:40,818] {logging_mixin.py:115} INFO - [2022-06-06 05:03:40,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:03:40,860] {logging_mixin.py:115} INFO - [2022-06-06 05:03:40,858] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:03:40,861] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:03:40,964] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 05:04:11,700] {processor.py:153} INFO - Started process (PID=36633) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:04:11,703] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:04:11,705] {logging_mixin.py:115} INFO - [2022-06-06 05:04:11,705] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:04:11,759] {logging_mixin.py:115} INFO - [2022-06-06 05:04:11,758] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:04:11,762] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:04:11,868] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 05:04:42,538] {processor.py:153} INFO - Started process (PID=36702) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:04:42,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:04:42,543] {logging_mixin.py:115} INFO - [2022-06-06 05:04:42,543] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:04:42,599] {logging_mixin.py:115} INFO - [2022-06-06 05:04:42,598] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:04:42,600] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:04:42,695] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 05:05:13,256] {processor.py:153} INFO - Started process (PID=36771) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:05:13,258] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:05:13,259] {logging_mixin.py:115} INFO - [2022-06-06 05:05:13,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:05:13,310] {logging_mixin.py:115} INFO - [2022-06-06 05:05:13,307] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:05:13,312] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:05:13,420] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 05:05:43,985] {processor.py:153} INFO - Started process (PID=36827) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:05:43,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:05:43,988] {logging_mixin.py:115} INFO - [2022-06-06 05:05:43,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:05:44,035] {logging_mixin.py:115} INFO - [2022-06-06 05:05:44,032] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:05:44,036] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:05:44,133] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 05:06:15,135] {processor.py:153} INFO - Started process (PID=36895) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:06:15,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:06:15,141] {logging_mixin.py:115} INFO - [2022-06-06 05:06:15,141] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:06:15,193] {logging_mixin.py:115} INFO - [2022-06-06 05:06:15,191] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:06:15,195] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:06:15,287] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 05:06:45,424] {processor.py:153} INFO - Started process (PID=36965) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:06:45,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:06:45,427] {logging_mixin.py:115} INFO - [2022-06-06 05:06:45,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:06:45,478] {logging_mixin.py:115} INFO - [2022-06-06 05:06:45,474] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:06:45,479] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:06:45,585] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 05:07:15,689] {processor.py:153} INFO - Started process (PID=37033) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:07:15,691] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:07:15,692] {logging_mixin.py:115} INFO - [2022-06-06 05:07:15,692] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:07:15,733] {logging_mixin.py:115} INFO - [2022-06-06 05:07:15,730] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:07:15,735] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:07:15,826] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.139 seconds
[2022-06-06 05:07:45,892] {processor.py:153} INFO - Started process (PID=37099) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:07:45,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:07:45,894] {logging_mixin.py:115} INFO - [2022-06-06 05:07:45,894] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:07:45,944] {logging_mixin.py:115} INFO - [2022-06-06 05:07:45,941] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:07:45,945] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:07:46,054] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 05:08:16,253] {processor.py:153} INFO - Started process (PID=37157) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:08:16,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:08:16,258] {logging_mixin.py:115} INFO - [2022-06-06 05:08:16,258] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:08:16,316] {logging_mixin.py:115} INFO - [2022-06-06 05:08:16,313] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:08:16,320] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:08:16,437] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 05:08:46,544] {processor.py:153} INFO - Started process (PID=37225) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:08:46,548] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:08:46,550] {logging_mixin.py:115} INFO - [2022-06-06 05:08:46,550] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:08:46,607] {logging_mixin.py:115} INFO - [2022-06-06 05:08:46,604] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:08:46,608] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:08:46,701] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 05:09:17,655] {processor.py:153} INFO - Started process (PID=37293) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:09:17,656] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:09:17,657] {logging_mixin.py:115} INFO - [2022-06-06 05:09:17,657] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:09:17,700] {logging_mixin.py:115} INFO - [2022-06-06 05:09:17,697] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:09:17,702] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:09:17,794] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.141 seconds
[2022-06-06 05:09:48,452] {processor.py:153} INFO - Started process (PID=37360) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:09:48,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:09:48,458] {logging_mixin.py:115} INFO - [2022-06-06 05:09:48,457] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:09:48,515] {logging_mixin.py:115} INFO - [2022-06-06 05:09:48,512] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:09:48,516] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:09:48,614] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 05:10:19,444] {processor.py:153} INFO - Started process (PID=37427) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:10:19,448] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:10:19,452] {logging_mixin.py:115} INFO - [2022-06-06 05:10:19,452] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:10:19,512] {logging_mixin.py:115} INFO - [2022-06-06 05:10:19,510] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:10:19,513] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:10:19,616] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 05:10:50,375] {processor.py:153} INFO - Started process (PID=37494) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:10:50,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:10:50,379] {logging_mixin.py:115} INFO - [2022-06-06 05:10:50,379] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:10:50,427] {logging_mixin.py:115} INFO - [2022-06-06 05:10:50,425] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:10:50,429] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:10:50,534] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 05:11:20,790] {processor.py:153} INFO - Started process (PID=37563) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:11:20,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:11:20,793] {logging_mixin.py:115} INFO - [2022-06-06 05:11:20,793] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:11:20,839] {logging_mixin.py:115} INFO - [2022-06-06 05:11:20,837] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:11:20,840] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:11:20,947] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 05:11:51,212] {processor.py:153} INFO - Started process (PID=37621) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:11:51,214] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:11:51,217] {logging_mixin.py:115} INFO - [2022-06-06 05:11:51,216] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:11:51,277] {logging_mixin.py:115} INFO - [2022-06-06 05:11:51,275] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:11:51,279] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:11:51,374] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 05:12:21,525] {processor.py:153} INFO - Started process (PID=37689) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:12:21,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:12:21,527] {logging_mixin.py:115} INFO - [2022-06-06 05:12:21,527] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:12:21,567] {logging_mixin.py:115} INFO - [2022-06-06 05:12:21,565] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:12:21,569] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:12:21,662] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.139 seconds
[2022-06-06 05:12:51,864] {processor.py:153} INFO - Started process (PID=37756) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:12:51,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:12:51,868] {logging_mixin.py:115} INFO - [2022-06-06 05:12:51,868] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:12:51,922] {logging_mixin.py:115} INFO - [2022-06-06 05:12:51,920] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:12:51,923] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:12:52,017] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 05:13:22,175] {processor.py:153} INFO - Started process (PID=37826) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:13:22,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:13:22,178] {logging_mixin.py:115} INFO - [2022-06-06 05:13:22,178] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:13:22,223] {logging_mixin.py:115} INFO - [2022-06-06 05:13:22,220] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:13:22,225] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:13:22,331] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 05:13:52,430] {processor.py:153} INFO - Started process (PID=37893) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:13:52,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:13:52,432] {logging_mixin.py:115} INFO - [2022-06-06 05:13:52,432] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:13:52,474] {logging_mixin.py:115} INFO - [2022-06-06 05:13:52,470] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:13:52,475] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:13:52,567] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.139 seconds
[2022-06-06 05:14:22,680] {processor.py:153} INFO - Started process (PID=37951) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:14:22,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:14:22,683] {logging_mixin.py:115} INFO - [2022-06-06 05:14:22,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:14:22,734] {logging_mixin.py:115} INFO - [2022-06-06 05:14:22,731] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:14:22,735] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:14:22,829] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 05:14:52,943] {processor.py:153} INFO - Started process (PID=38017) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:14:52,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:14:52,950] {logging_mixin.py:115} INFO - [2022-06-06 05:14:52,949] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:14:53,012] {logging_mixin.py:115} INFO - [2022-06-06 05:14:53,010] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:14:53,014] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:14:53,121] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 05:15:23,422] {processor.py:153} INFO - Started process (PID=38088) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:15:23,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:15:23,424] {logging_mixin.py:115} INFO - [2022-06-06 05:15:23,424] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:15:23,465] {logging_mixin.py:115} INFO - [2022-06-06 05:15:23,463] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:15:23,466] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:15:23,557] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.138 seconds
[2022-06-06 05:15:53,712] {processor.py:153} INFO - Started process (PID=38156) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:15:53,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:15:53,715] {logging_mixin.py:115} INFO - [2022-06-06 05:15:53,715] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:15:53,765] {logging_mixin.py:115} INFO - [2022-06-06 05:15:53,761] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:15:53,767] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:15:53,863] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 05:16:23,958] {processor.py:153} INFO - Started process (PID=38224) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:16:23,960] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:16:23,961] {logging_mixin.py:115} INFO - [2022-06-06 05:16:23,961] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:16:24,008] {logging_mixin.py:115} INFO - [2022-06-06 05:16:24,006] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:16:24,009] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:16:24,116] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 05:16:54,831] {processor.py:153} INFO - Started process (PID=38282) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:16:54,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:16:54,835] {logging_mixin.py:115} INFO - [2022-06-06 05:16:54,835] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:16:54,879] {logging_mixin.py:115} INFO - [2022-06-06 05:16:54,877] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:16:54,880] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:16:54,975] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 05:17:25,864] {processor.py:153} INFO - Started process (PID=38349) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:17:25,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:17:25,869] {logging_mixin.py:115} INFO - [2022-06-06 05:17:25,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:17:25,914] {logging_mixin.py:115} INFO - [2022-06-06 05:17:25,912] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:17:25,915] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:17:26,010] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-06 05:17:56,483] {processor.py:153} INFO - Started process (PID=38418) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:17:56,485] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:17:56,486] {logging_mixin.py:115} INFO - [2022-06-06 05:17:56,486] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:17:56,544] {logging_mixin.py:115} INFO - [2022-06-06 05:17:56,541] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:17:56,545] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:17:56,639] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 05:18:26,799] {processor.py:153} INFO - Started process (PID=38486) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:18:26,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:18:26,802] {logging_mixin.py:115} INFO - [2022-06-06 05:18:26,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:18:26,856] {logging_mixin.py:115} INFO - [2022-06-06 05:18:26,854] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:18:26,863] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:18:26,965] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 05:18:57,981] {processor.py:153} INFO - Started process (PID=38555) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:18:57,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:18:57,985] {logging_mixin.py:115} INFO - [2022-06-06 05:18:57,985] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:18:58,042] {logging_mixin.py:115} INFO - [2022-06-06 05:18:58,040] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:18:58,043] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:18:58,138] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 05:19:28,389] {processor.py:153} INFO - Started process (PID=38620) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:19:28,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:19:28,394] {logging_mixin.py:115} INFO - [2022-06-06 05:19:28,394] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:19:28,446] {logging_mixin.py:115} INFO - [2022-06-06 05:19:28,444] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:19:28,447] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:19:28,541] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 05:19:58,719] {processor.py:153} INFO - Started process (PID=38678) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:19:58,723] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:19:58,725] {logging_mixin.py:115} INFO - [2022-06-06 05:19:58,725] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:19:58,788] {logging_mixin.py:115} INFO - [2022-06-06 05:19:58,783] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:19:58,789] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:19:58,892] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 05:20:28,978] {processor.py:153} INFO - Started process (PID=38745) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:20:28,980] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:20:28,982] {logging_mixin.py:115} INFO - [2022-06-06 05:20:28,982] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:20:29,036] {logging_mixin.py:115} INFO - [2022-06-06 05:20:29,034] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:20:29,038] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:20:29,133] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 05:20:59,944] {processor.py:153} INFO - Started process (PID=38812) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:20:59,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:20:59,950] {logging_mixin.py:115} INFO - [2022-06-06 05:20:59,950] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:21:00,007] {logging_mixin.py:115} INFO - [2022-06-06 05:21:00,005] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:21:00,008] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:21:00,103] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 05:21:30,843] {processor.py:153} INFO - Started process (PID=38882) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:21:30,846] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:21:30,848] {logging_mixin.py:115} INFO - [2022-06-06 05:21:30,848] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:21:30,904] {logging_mixin.py:115} INFO - [2022-06-06 05:21:30,902] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:21:30,906] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:21:31,006] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 05:22:01,730] {processor.py:153} INFO - Started process (PID=38948) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:22:01,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:22:01,735] {logging_mixin.py:115} INFO - [2022-06-06 05:22:01,735] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:22:01,789] {logging_mixin.py:115} INFO - [2022-06-06 05:22:01,787] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:22:01,791] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:22:01,887] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 05:22:32,739] {processor.py:153} INFO - Started process (PID=39013) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:22:32,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:22:32,744] {logging_mixin.py:115} INFO - [2022-06-06 05:22:32,743] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:22:32,803] {logging_mixin.py:115} INFO - [2022-06-06 05:22:32,801] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:22:32,805] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:22:32,904] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 05:23:03,494] {processor.py:153} INFO - Started process (PID=39082) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:23:03,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:23:03,497] {logging_mixin.py:115} INFO - [2022-06-06 05:23:03,497] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:23:03,548] {logging_mixin.py:115} INFO - [2022-06-06 05:23:03,545] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:23:03,549] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:23:03,644] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 05:23:34,605] {processor.py:153} INFO - Started process (PID=39140) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:23:34,607] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:23:34,608] {logging_mixin.py:115} INFO - [2022-06-06 05:23:34,608] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:23:34,652] {logging_mixin.py:115} INFO - [2022-06-06 05:23:34,649] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:23:34,653] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:23:34,749] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-06 05:24:05,529] {processor.py:153} INFO - Started process (PID=39209) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:24:05,531] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:24:05,532] {logging_mixin.py:115} INFO - [2022-06-06 05:24:05,532] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:24:05,577] {logging_mixin.py:115} INFO - [2022-06-06 05:24:05,575] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:24:05,578] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:24:05,672] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 05:24:36,378] {processor.py:153} INFO - Started process (PID=39278) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:24:36,380] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:24:36,382] {logging_mixin.py:115} INFO - [2022-06-06 05:24:36,381] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:24:36,424] {logging_mixin.py:115} INFO - [2022-06-06 05:24:36,422] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:24:36,425] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:24:36,537] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 05:25:07,303] {processor.py:153} INFO - Started process (PID=39346) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:25:07,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:25:07,306] {logging_mixin.py:115} INFO - [2022-06-06 05:25:07,306] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:25:07,350] {logging_mixin.py:115} INFO - [2022-06-06 05:25:07,348] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:25:07,351] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:25:07,444] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-06 05:25:38,320] {processor.py:153} INFO - Started process (PID=39415) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:25:38,323] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:25:38,324] {logging_mixin.py:115} INFO - [2022-06-06 05:25:38,324] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:25:38,386] {logging_mixin.py:115} INFO - [2022-06-06 05:25:38,384] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:25:38,388] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:25:38,490] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 05:26:09,242] {processor.py:153} INFO - Started process (PID=39483) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:26:09,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:26:09,246] {logging_mixin.py:115} INFO - [2022-06-06 05:26:09,246] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:26:09,300] {logging_mixin.py:115} INFO - [2022-06-06 05:26:09,296] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:26:09,302] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:26:09,404] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 05:26:39,820] {processor.py:153} INFO - Started process (PID=39551) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:26:39,822] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:26:39,823] {logging_mixin.py:115} INFO - [2022-06-06 05:26:39,823] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:26:39,876] {logging_mixin.py:115} INFO - [2022-06-06 05:26:39,873] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:26:39,877] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:26:39,985] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 05:27:10,655] {processor.py:153} INFO - Started process (PID=39610) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:27:10,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:27:10,659] {logging_mixin.py:115} INFO - [2022-06-06 05:27:10,659] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:27:10,828] {logging_mixin.py:115} INFO - [2022-06-06 05:27:10,824] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:27:10,831] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:27:10,958] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.315 seconds
[2022-06-06 05:27:41,718] {processor.py:153} INFO - Started process (PID=39680) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:27:41,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:27:41,724] {logging_mixin.py:115} INFO - [2022-06-06 05:27:41,724] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:27:41,826] {logging_mixin.py:115} INFO - [2022-06-06 05:27:41,823] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:27:41,828] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:27:41,940] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-06 05:28:12,225] {processor.py:153} INFO - Started process (PID=39747) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:28:12,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:28:12,230] {logging_mixin.py:115} INFO - [2022-06-06 05:28:12,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:28:12,286] {logging_mixin.py:115} INFO - [2022-06-06 05:28:12,284] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:28:12,288] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:28:12,402] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-06 05:28:42,935] {processor.py:153} INFO - Started process (PID=39816) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:28:42,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:28:42,939] {logging_mixin.py:115} INFO - [2022-06-06 05:28:42,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:28:42,996] {logging_mixin.py:115} INFO - [2022-06-06 05:28:42,994] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:28:42,997] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:28:43,106] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 05:29:13,511] {processor.py:153} INFO - Started process (PID=39882) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:29:13,512] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:29:13,514] {logging_mixin.py:115} INFO - [2022-06-06 05:29:13,514] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:29:13,574] {logging_mixin.py:115} INFO - [2022-06-06 05:29:13,572] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:29:13,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:29:13,681] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 05:29:43,728] {processor.py:153} INFO - Started process (PID=39941) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:29:43,730] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:29:43,734] {logging_mixin.py:115} INFO - [2022-06-06 05:29:43,733] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:29:43,840] {logging_mixin.py:115} INFO - [2022-06-06 05:29:43,837] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:29:43,842] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:29:44,048] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.325 seconds
[2022-06-06 05:30:14,247] {processor.py:153} INFO - Started process (PID=40009) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:30:14,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:30:14,252] {logging_mixin.py:115} INFO - [2022-06-06 05:30:14,252] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:30:14,328] {logging_mixin.py:115} INFO - [2022-06-06 05:30:14,326] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:30:14,330] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:30:14,436] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 05:30:44,944] {processor.py:153} INFO - Started process (PID=40079) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:30:44,946] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:30:44,947] {logging_mixin.py:115} INFO - [2022-06-06 05:30:44,947] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:30:45,019] {logging_mixin.py:115} INFO - [2022-06-06 05:30:45,013] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:30:45,021] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:30:45,125] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 05:31:15,594] {processor.py:153} INFO - Started process (PID=40145) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:31:15,598] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:31:15,601] {logging_mixin.py:115} INFO - [2022-06-06 05:31:15,601] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:31:15,654] {logging_mixin.py:115} INFO - [2022-06-06 05:31:15,652] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:31:15,655] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:31:15,748] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 05:31:46,725] {processor.py:153} INFO - Started process (PID=40212) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:31:46,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:31:46,727] {logging_mixin.py:115} INFO - [2022-06-06 05:31:46,727] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:31:46,787] {logging_mixin.py:115} INFO - [2022-06-06 05:31:46,785] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:31:46,788] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:31:46,906] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 05:32:17,095] {processor.py:153} INFO - Started process (PID=40269) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:32:17,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:32:17,097] {logging_mixin.py:115} INFO - [2022-06-06 05:32:17,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:32:17,142] {logging_mixin.py:115} INFO - [2022-06-06 05:32:17,140] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:32:17,144] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:32:17,247] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 05:32:47,442] {processor.py:153} INFO - Started process (PID=40334) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:32:47,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:32:47,445] {logging_mixin.py:115} INFO - [2022-06-06 05:32:47,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:32:47,502] {logging_mixin.py:115} INFO - [2022-06-06 05:32:47,499] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:32:47,504] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:32:47,599] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 05:33:17,738] {processor.py:153} INFO - Started process (PID=40403) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:33:17,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:33:17,744] {logging_mixin.py:115} INFO - [2022-06-06 05:33:17,743] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:33:17,803] {logging_mixin.py:115} INFO - [2022-06-06 05:33:17,801] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:33:17,804] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:33:17,900] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 05:33:48,205] {processor.py:153} INFO - Started process (PID=40471) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:33:48,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:33:48,210] {logging_mixin.py:115} INFO - [2022-06-06 05:33:48,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:33:48,260] {logging_mixin.py:115} INFO - [2022-06-06 05:33:48,258] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:33:48,262] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:33:48,354] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 05:34:18,687] {processor.py:153} INFO - Started process (PID=40540) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:34:18,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:34:18,690] {logging_mixin.py:115} INFO - [2022-06-06 05:34:18,690] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:34:18,736] {logging_mixin.py:115} INFO - [2022-06-06 05:34:18,734] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:34:18,737] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:34:18,972] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.287 seconds
[2022-06-06 05:34:49,862] {processor.py:153} INFO - Started process (PID=40596) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:34:49,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:34:49,866] {logging_mixin.py:115} INFO - [2022-06-06 05:34:49,866] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:34:49,925] {logging_mixin.py:115} INFO - [2022-06-06 05:34:49,923] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:34:49,927] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:34:50,023] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 05:35:20,978] {processor.py:153} INFO - Started process (PID=40664) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:35:20,979] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:35:20,980] {logging_mixin.py:115} INFO - [2022-06-06 05:35:20,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:35:21,025] {logging_mixin.py:115} INFO - [2022-06-06 05:35:21,023] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:35:21,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:35:21,126] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 05:35:51,261] {processor.py:153} INFO - Started process (PID=40730) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:35:51,264] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:35:51,268] {logging_mixin.py:115} INFO - [2022-06-06 05:35:51,268] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:35:51,329] {logging_mixin.py:115} INFO - [2022-06-06 05:35:51,325] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:35:51,332] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:35:51,433] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 05:36:22,408] {processor.py:153} INFO - Started process (PID=40799) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:36:22,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:36:22,411] {logging_mixin.py:115} INFO - [2022-06-06 05:36:22,411] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:36:22,455] {logging_mixin.py:115} INFO - [2022-06-06 05:36:22,453] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:36:22,456] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:36:22,548] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-06 05:36:52,686] {processor.py:153} INFO - Started process (PID=40866) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:36:52,689] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:36:52,692] {logging_mixin.py:115} INFO - [2022-06-06 05:36:52,691] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:36:52,749] {logging_mixin.py:115} INFO - [2022-06-06 05:36:52,746] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:36:52,751] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:36:52,842] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 05:37:23,727] {processor.py:153} INFO - Started process (PID=40933) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:37:23,728] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:37:23,729] {logging_mixin.py:115} INFO - [2022-06-06 05:37:23,729] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:37:23,783] {logging_mixin.py:115} INFO - [2022-06-06 05:37:23,777] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:37:23,786] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:37:23,942] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-06 05:37:54,789] {processor.py:153} INFO - Started process (PID=40990) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:37:54,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:37:54,794] {logging_mixin.py:115} INFO - [2022-06-06 05:37:54,794] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:37:54,844] {logging_mixin.py:115} INFO - [2022-06-06 05:37:54,843] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:37:54,846] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:37:54,941] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 05:38:25,090] {processor.py:153} INFO - Started process (PID=41060) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:38:25,092] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:38:25,093] {logging_mixin.py:115} INFO - [2022-06-06 05:38:25,093] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:38:25,147] {logging_mixin.py:115} INFO - [2022-06-06 05:38:25,144] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:38:25,149] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:38:25,253] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 05:38:55,396] {processor.py:153} INFO - Started process (PID=41130) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:38:55,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:38:55,399] {logging_mixin.py:115} INFO - [2022-06-06 05:38:55,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:38:55,445] {logging_mixin.py:115} INFO - [2022-06-06 05:38:55,442] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:38:55,447] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:38:55,539] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-06 05:39:25,641] {processor.py:153} INFO - Started process (PID=41199) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:39:25,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:39:25,643] {logging_mixin.py:115} INFO - [2022-06-06 05:39:25,643] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:39:25,684] {logging_mixin.py:115} INFO - [2022-06-06 05:39:25,682] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:39:25,686] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:39:25,779] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.141 seconds
[2022-06-06 05:39:55,867] {processor.py:153} INFO - Started process (PID=41269) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:39:55,869] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:39:55,870] {logging_mixin.py:115} INFO - [2022-06-06 05:39:55,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:39:55,930] {logging_mixin.py:115} INFO - [2022-06-06 05:39:55,927] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:39:55,932] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:39:56,036] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 05:40:26,393] {processor.py:153} INFO - Started process (PID=41328) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:40:26,395] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:40:26,397] {logging_mixin.py:115} INFO - [2022-06-06 05:40:26,397] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:40:26,463] {logging_mixin.py:115} INFO - [2022-06-06 05:40:26,461] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:40:26,465] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:40:26,561] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 05:40:56,863] {processor.py:153} INFO - Started process (PID=41399) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:40:56,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:40:56,866] {logging_mixin.py:115} INFO - [2022-06-06 05:40:56,866] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:40:56,910] {logging_mixin.py:115} INFO - [2022-06-06 05:40:56,907] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:40:56,911] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:40:57,007] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 05:41:27,419] {processor.py:153} INFO - Started process (PID=41465) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:41:27,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:41:27,428] {logging_mixin.py:115} INFO - [2022-06-06 05:41:27,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:41:27,501] {logging_mixin.py:115} INFO - [2022-06-06 05:41:27,499] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:41:27,504] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:41:27,604] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 05:41:58,060] {processor.py:153} INFO - Started process (PID=41532) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:41:58,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:41:58,065] {logging_mixin.py:115} INFO - [2022-06-06 05:41:58,064] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:41:58,143] {logging_mixin.py:115} INFO - [2022-06-06 05:41:58,140] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:41:58,144] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:41:58,257] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-06 05:42:28,410] {processor.py:153} INFO - Started process (PID=41589) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:42:28,412] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:42:28,414] {logging_mixin.py:115} INFO - [2022-06-06 05:42:28,414] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:42:28,502] {logging_mixin.py:115} INFO - [2022-06-06 05:42:28,500] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:42:28,504] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:42:28,600] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-06 05:42:58,680] {processor.py:153} INFO - Started process (PID=41656) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:42:58,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:42:58,683] {logging_mixin.py:115} INFO - [2022-06-06 05:42:58,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:42:58,759] {logging_mixin.py:115} INFO - [2022-06-06 05:42:58,757] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:42:58,760] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:42:58,859] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 05:43:29,080] {processor.py:153} INFO - Started process (PID=41723) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:43:29,082] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:43:29,083] {logging_mixin.py:115} INFO - [2022-06-06 05:43:29,083] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:43:29,195] {logging_mixin.py:115} INFO - [2022-06-06 05:43:29,191] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:43:29,199] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:43:29,395] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.325 seconds
[2022-06-06 05:43:59,662] {processor.py:153} INFO - Started process (PID=41792) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:43:59,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:43:59,669] {logging_mixin.py:115} INFO - [2022-06-06 05:43:59,669] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:43:59,784] {logging_mixin.py:115} INFO - [2022-06-06 05:43:59,782] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:43:59,786] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:43:59,885] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-06 05:44:30,252] {processor.py:153} INFO - Started process (PID=41859) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:44:30,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:44:30,255] {logging_mixin.py:115} INFO - [2022-06-06 05:44:30,255] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:44:30,320] {logging_mixin.py:115} INFO - [2022-06-06 05:44:30,318] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:44:30,321] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:44:30,450] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-06 05:45:01,416] {processor.py:153} INFO - Started process (PID=41916) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:45:01,419] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:45:01,420] {logging_mixin.py:115} INFO - [2022-06-06 05:45:01,420] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:45:01,502] {logging_mixin.py:115} INFO - [2022-06-06 05:45:01,500] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:45:01,504] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:45:01,619] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-06 05:45:31,993] {processor.py:153} INFO - Started process (PID=41982) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:45:31,996] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:45:31,998] {logging_mixin.py:115} INFO - [2022-06-06 05:45:31,998] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:45:32,067] {logging_mixin.py:115} INFO - [2022-06-06 05:45:32,065] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:45:32,069] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:45:32,171] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 05:46:02,719] {processor.py:153} INFO - Started process (PID=42048) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:46:02,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:46:02,722] {logging_mixin.py:115} INFO - [2022-06-06 05:46:02,722] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:46:02,801] {logging_mixin.py:115} INFO - [2022-06-06 05:46:02,798] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:46:02,804] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:46:02,916] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 05:46:32,995] {processor.py:153} INFO - Started process (PID=42117) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:46:32,997] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:46:32,999] {logging_mixin.py:115} INFO - [2022-06-06 05:46:32,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:46:33,074] {logging_mixin.py:115} INFO - [2022-06-06 05:46:33,070] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:46:33,076] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:46:33,197] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-06 05:47:03,518] {processor.py:153} INFO - Started process (PID=42183) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:47:03,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:47:03,521] {logging_mixin.py:115} INFO - [2022-06-06 05:47:03,521] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:47:03,602] {logging_mixin.py:115} INFO - [2022-06-06 05:47:03,600] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:47:03,605] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:47:03,750] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-06 05:47:34,159] {processor.py:153} INFO - Started process (PID=42243) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:47:34,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:47:34,172] {logging_mixin.py:115} INFO - [2022-06-06 05:47:34,172] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:47:34,333] {logging_mixin.py:115} INFO - [2022-06-06 05:47:34,328] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:47:34,335] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:47:34,484] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.340 seconds
[2022-06-06 05:48:04,756] {processor.py:153} INFO - Started process (PID=42313) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:48:04,757] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:48:04,759] {logging_mixin.py:115} INFO - [2022-06-06 05:48:04,759] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:48:04,822] {logging_mixin.py:115} INFO - [2022-06-06 05:48:04,820] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:48:04,824] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:48:04,920] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 05:48:35,745] {processor.py:153} INFO - Started process (PID=42381) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:48:35,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:48:35,749] {logging_mixin.py:115} INFO - [2022-06-06 05:48:35,749] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:48:35,885] {logging_mixin.py:115} INFO - [2022-06-06 05:48:35,882] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:48:35,886] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:48:35,993] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.254 seconds
[2022-06-06 05:49:06,064] {processor.py:153} INFO - Started process (PID=42448) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:49:06,066] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:49:06,074] {logging_mixin.py:115} INFO - [2022-06-06 05:49:06,074] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:49:06,156] {logging_mixin.py:115} INFO - [2022-06-06 05:49:06,153] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:49:06,158] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:49:06,282] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-06 05:49:36,675] {processor.py:153} INFO - Started process (PID=42504) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:49:36,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:49:36,678] {logging_mixin.py:115} INFO - [2022-06-06 05:49:36,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:49:36,762] {logging_mixin.py:115} INFO - [2022-06-06 05:49:36,760] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:49:36,763] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:49:36,891] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-06 05:50:07,230] {processor.py:153} INFO - Started process (PID=42573) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:50:07,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:50:07,235] {logging_mixin.py:115} INFO - [2022-06-06 05:50:07,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:50:07,313] {logging_mixin.py:115} INFO - [2022-06-06 05:50:07,311] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:50:07,316] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:50:07,415] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-06 05:50:37,714] {processor.py:153} INFO - Started process (PID=42642) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:50:37,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:50:37,719] {logging_mixin.py:115} INFO - [2022-06-06 05:50:37,719] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:50:37,792] {logging_mixin.py:115} INFO - [2022-06-06 05:50:37,789] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:50:37,793] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:50:37,895] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 05:51:08,332] {processor.py:153} INFO - Started process (PID=42709) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:51:08,334] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:51:08,337] {logging_mixin.py:115} INFO - [2022-06-06 05:51:08,337] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:51:08,419] {logging_mixin.py:115} INFO - [2022-06-06 05:51:08,414] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:51:08,420] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:51:08,534] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.205 seconds
[2022-06-06 05:51:39,546] {processor.py:153} INFO - Started process (PID=42777) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:51:39,548] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:51:39,550] {logging_mixin.py:115} INFO - [2022-06-06 05:51:39,550] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:51:39,647] {logging_mixin.py:115} INFO - [2022-06-06 05:51:39,645] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:51:39,649] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:51:39,855] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.323 seconds
[2022-06-06 05:52:10,579] {processor.py:153} INFO - Started process (PID=42834) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:52:10,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:52:10,584] {logging_mixin.py:115} INFO - [2022-06-06 05:52:10,584] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:52:10,691] {logging_mixin.py:115} INFO - [2022-06-06 05:52:10,688] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:52:10,695] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:52:10,842] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.270 seconds
[2022-06-06 05:52:41,014] {processor.py:153} INFO - Started process (PID=42902) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:52:41,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:52:41,021] {logging_mixin.py:115} INFO - [2022-06-06 05:52:41,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:52:41,193] {logging_mixin.py:115} INFO - [2022-06-06 05:52:41,189] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:52:41,206] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:52:41,361] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.351 seconds
[2022-06-06 05:53:11,896] {processor.py:153} INFO - Started process (PID=42974) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:53:11,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:53:11,901] {logging_mixin.py:115} INFO - [2022-06-06 05:53:11,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:53:11,969] {logging_mixin.py:115} INFO - [2022-06-06 05:53:11,967] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:53:11,970] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:53:12,081] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 05:53:42,431] {processor.py:153} INFO - Started process (PID=43044) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:53:42,433] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:53:42,434] {logging_mixin.py:115} INFO - [2022-06-06 05:53:42,434] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:53:42,535] {logging_mixin.py:115} INFO - [2022-06-06 05:53:42,528] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:53:42,539] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:53:42,664] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-06 05:54:12,740] {processor.py:153} INFO - Started process (PID=43112) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:54:12,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:54:12,744] {logging_mixin.py:115} INFO - [2022-06-06 05:54:12,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:54:12,826] {logging_mixin.py:115} INFO - [2022-06-06 05:54:12,822] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:54:12,828] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:54:12,939] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-06 05:54:43,773] {processor.py:153} INFO - Started process (PID=43170) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:54:43,776] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:54:43,784] {logging_mixin.py:115} INFO - [2022-06-06 05:54:43,784] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:54:43,871] {logging_mixin.py:115} INFO - [2022-06-06 05:54:43,868] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:54:43,873] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:54:43,999] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-06 05:55:14,561] {processor.py:153} INFO - Started process (PID=43237) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:55:14,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:55:14,565] {logging_mixin.py:115} INFO - [2022-06-06 05:55:14,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:55:14,649] {logging_mixin.py:115} INFO - [2022-06-06 05:55:14,646] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:55:14,650] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:55:14,765] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-06 05:55:45,486] {processor.py:153} INFO - Started process (PID=43305) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:55:45,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:55:45,491] {logging_mixin.py:115} INFO - [2022-06-06 05:55:45,490] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:55:45,600] {logging_mixin.py:115} INFO - [2022-06-06 05:55:45,596] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:55:45,606] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:55:45,724] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-06 05:56:16,738] {processor.py:153} INFO - Started process (PID=43372) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:56:16,741] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:56:16,742] {logging_mixin.py:115} INFO - [2022-06-06 05:56:16,742] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:56:16,796] {logging_mixin.py:115} INFO - [2022-06-06 05:56:16,794] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:56:16,797] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:56:16,901] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 05:56:46,971] {processor.py:153} INFO - Started process (PID=43440) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:56:46,972] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:56:46,973] {logging_mixin.py:115} INFO - [2022-06-06 05:56:46,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:56:47,066] {logging_mixin.py:115} INFO - [2022-06-06 05:56:47,062] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:56:47,068] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:56:47,182] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-06 05:57:17,509] {processor.py:153} INFO - Started process (PID=43497) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:57:17,512] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:57:17,519] {logging_mixin.py:115} INFO - [2022-06-06 05:57:17,519] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:57:17,609] {logging_mixin.py:115} INFO - [2022-06-06 05:57:17,607] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:57:17,611] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:57:17,748] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-06 05:57:48,470] {processor.py:153} INFO - Started process (PID=43564) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:57:48,472] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:57:48,473] {logging_mixin.py:115} INFO - [2022-06-06 05:57:48,473] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:57:48,536] {logging_mixin.py:115} INFO - [2022-06-06 05:57:48,534] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:57:48,538] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:57:48,660] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-06 05:58:18,850] {processor.py:153} INFO - Started process (PID=43633) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:58:18,852] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:58:18,853] {logging_mixin.py:115} INFO - [2022-06-06 05:58:18,853] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:58:18,899] {logging_mixin.py:115} INFO - [2022-06-06 05:58:18,897] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:58:18,900] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:58:19,029] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 05:58:49,109] {processor.py:153} INFO - Started process (PID=43699) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:58:49,112] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:58:49,113] {logging_mixin.py:115} INFO - [2022-06-06 05:58:49,113] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:58:49,166] {logging_mixin.py:115} INFO - [2022-06-06 05:58:49,162] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:58:49,168] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:58:49,303] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 05:59:19,439] {processor.py:153} INFO - Started process (PID=43763) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:59:19,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:59:19,444] {logging_mixin.py:115} INFO - [2022-06-06 05:59:19,443] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:59:19,519] {logging_mixin.py:115} INFO - [2022-06-06 05:59:19,515] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:59:19,520] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:59:19,642] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-06 05:59:49,756] {processor.py:153} INFO - Started process (PID=43822) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:59:49,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 05:59:49,761] {logging_mixin.py:115} INFO - [2022-06-06 05:59:49,761] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:59:49,808] {logging_mixin.py:115} INFO - [2022-06-06 05:59:49,806] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 05:59:49,809] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 05:59:49,921] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 06:00:20,832] {processor.py:153} INFO - Started process (PID=43890) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:00:20,834] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:00:20,835] {logging_mixin.py:115} INFO - [2022-06-06 06:00:20,835] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:00:20,903] {logging_mixin.py:115} INFO - [2022-06-06 06:00:20,901] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:00:20,905] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:00:21,025] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-06 06:00:51,427] {processor.py:153} INFO - Started process (PID=43959) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:00:51,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:00:51,432] {logging_mixin.py:115} INFO - [2022-06-06 06:00:51,432] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:00:51,510] {logging_mixin.py:115} INFO - [2022-06-06 06:00:51,508] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:00:51,511] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:00:51,638] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-06 06:01:21,892] {processor.py:153} INFO - Started process (PID=44027) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:01:21,895] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:01:21,897] {logging_mixin.py:115} INFO - [2022-06-06 06:01:21,897] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:01:21,974] {logging_mixin.py:115} INFO - [2022-06-06 06:01:21,971] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:01:21,975] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:01:22,072] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 06:01:53,051] {processor.py:153} INFO - Started process (PID=44094) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:01:53,054] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:01:53,057] {logging_mixin.py:115} INFO - [2022-06-06 06:01:53,056] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:01:53,141] {logging_mixin.py:115} INFO - [2022-06-06 06:01:53,138] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:01:53,142] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:01:53,275] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-06 06:02:23,317] {processor.py:153} INFO - Started process (PID=44154) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:02:23,321] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:02:23,323] {logging_mixin.py:115} INFO - [2022-06-06 06:02:23,323] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:02:23,395] {logging_mixin.py:115} INFO - [2022-06-06 06:02:23,392] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:02:23,399] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:02:23,563] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-06 06:02:53,715] {processor.py:153} INFO - Started process (PID=44222) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:02:53,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:02:53,719] {logging_mixin.py:115} INFO - [2022-06-06 06:02:53,719] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:02:53,816] {logging_mixin.py:115} INFO - [2022-06-06 06:02:53,812] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:02:53,818] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:02:53,968] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-06 06:03:24,221] {processor.py:153} INFO - Started process (PID=44288) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:03:24,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:03:24,224] {logging_mixin.py:115} INFO - [2022-06-06 06:03:24,224] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:03:24,289] {logging_mixin.py:115} INFO - [2022-06-06 06:03:24,287] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:03:24,291] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:03:24,388] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 06:03:54,698] {processor.py:153} INFO - Started process (PID=44354) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:03:54,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:03:54,701] {logging_mixin.py:115} INFO - [2022-06-06 06:03:54,701] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:03:54,763] {logging_mixin.py:115} INFO - [2022-06-06 06:03:54,760] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:03:54,765] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:03:54,888] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-06 06:04:25,248] {processor.py:153} INFO - Started process (PID=44412) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:04:25,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:04:25,251] {logging_mixin.py:115} INFO - [2022-06-06 06:04:25,251] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:04:25,354] {logging_mixin.py:115} INFO - [2022-06-06 06:04:25,350] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:04:25,357] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:04:25,590] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.347 seconds
[2022-06-06 06:04:56,581] {processor.py:153} INFO - Started process (PID=44480) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:04:56,584] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:04:56,586] {logging_mixin.py:115} INFO - [2022-06-06 06:04:56,586] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:04:56,670] {logging_mixin.py:115} INFO - [2022-06-06 06:04:56,666] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:04:56,672] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:04:56,775] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-06 06:05:26,958] {processor.py:153} INFO - Started process (PID=44549) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:05:26,960] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:05:26,962] {logging_mixin.py:115} INFO - [2022-06-06 06:05:26,962] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:05:27,006] {logging_mixin.py:115} INFO - [2022-06-06 06:05:27,004] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:05:27,007] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:05:27,110] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 06:05:57,286] {processor.py:153} INFO - Started process (PID=44619) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:05:57,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:05:57,291] {logging_mixin.py:115} INFO - [2022-06-06 06:05:57,291] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:05:57,369] {logging_mixin.py:115} INFO - [2022-06-06 06:05:57,366] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:05:57,371] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:05:57,477] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-06 06:06:27,832] {processor.py:153} INFO - Started process (PID=44687) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:06:27,835] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:06:27,836] {logging_mixin.py:115} INFO - [2022-06-06 06:06:27,836] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:06:27,960] {logging_mixin.py:115} INFO - [2022-06-06 06:06:27,952] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:06:27,962] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:06:28,123] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.303 seconds
[2022-06-06 06:06:58,783] {processor.py:153} INFO - Started process (PID=44747) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:06:58,785] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:06:58,787] {logging_mixin.py:115} INFO - [2022-06-06 06:06:58,786] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:06:58,864] {logging_mixin.py:115} INFO - [2022-06-06 06:06:58,862] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:06:58,868] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:06:58,968] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 06:07:29,503] {processor.py:153} INFO - Started process (PID=44814) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:07:29,509] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:07:29,510] {logging_mixin.py:115} INFO - [2022-06-06 06:07:29,510] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:07:29,584] {logging_mixin.py:115} INFO - [2022-06-06 06:07:29,582] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:07:29,585] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:07:29,690] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 06:08:00,111] {processor.py:153} INFO - Started process (PID=44882) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:08:00,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:08:00,117] {logging_mixin.py:115} INFO - [2022-06-06 06:08:00,117] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:08:00,194] {logging_mixin.py:115} INFO - [2022-06-06 06:08:00,191] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:08:00,196] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:08:00,329] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-06 06:08:30,610] {processor.py:153} INFO - Started process (PID=44949) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:08:30,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:08:30,613] {logging_mixin.py:115} INFO - [2022-06-06 06:08:30,613] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:08:30,671] {logging_mixin.py:115} INFO - [2022-06-06 06:08:30,669] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:08:30,673] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:08:30,771] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 06:09:00,907] {processor.py:153} INFO - Started process (PID=45007) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:09:00,910] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:09:00,912] {logging_mixin.py:115} INFO - [2022-06-06 06:09:00,912] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:09:00,989] {logging_mixin.py:115} INFO - [2022-06-06 06:09:00,987] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:09:00,991] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:09:01,090] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 06:09:31,243] {processor.py:153} INFO - Started process (PID=45076) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:09:31,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:09:31,249] {logging_mixin.py:115} INFO - [2022-06-06 06:09:31,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:09:31,344] {logging_mixin.py:115} INFO - [2022-06-06 06:09:31,340] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:09:31,346] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:09:31,456] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-06 06:10:01,979] {processor.py:153} INFO - Started process (PID=45145) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:10:01,982] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:10:01,983] {logging_mixin.py:115} INFO - [2022-06-06 06:10:01,983] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:10:02,030] {logging_mixin.py:115} INFO - [2022-06-06 06:10:02,027] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:10:02,032] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:10:02,125] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 06:10:32,820] {processor.py:153} INFO - Started process (PID=45212) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:10:32,823] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:10:32,827] {logging_mixin.py:115} INFO - [2022-06-06 06:10:32,827] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:10:32,950] {logging_mixin.py:115} INFO - [2022-06-06 06:10:32,940] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:10:32,952] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:10:33,108] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.297 seconds
[2022-06-06 06:11:03,575] {processor.py:153} INFO - Started process (PID=45278) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:11:03,577] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:11:03,579] {logging_mixin.py:115} INFO - [2022-06-06 06:11:03,579] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:11:03,662] {logging_mixin.py:115} INFO - [2022-06-06 06:11:03,659] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:11:03,664] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:11:03,783] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-06 06:11:33,862] {processor.py:153} INFO - Started process (PID=45336) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:11:33,865] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:11:33,867] {logging_mixin.py:115} INFO - [2022-06-06 06:11:33,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:11:33,934] {logging_mixin.py:115} INFO - [2022-06-06 06:11:33,932] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:11:33,935] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:11:34,036] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 06:12:04,807] {processor.py:153} INFO - Started process (PID=45402) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:12:04,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:12:04,810] {logging_mixin.py:115} INFO - [2022-06-06 06:12:04,810] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:12:04,870] {logging_mixin.py:115} INFO - [2022-06-06 06:12:04,867] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:12:04,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:12:04,972] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 06:12:35,268] {processor.py:153} INFO - Started process (PID=45471) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:12:35,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:12:35,271] {logging_mixin.py:115} INFO - [2022-06-06 06:12:35,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:12:35,342] {logging_mixin.py:115} INFO - [2022-06-06 06:12:35,338] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:12:35,344] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:12:35,460] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-06 06:13:06,047] {processor.py:153} INFO - Started process (PID=45539) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:13:06,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:13:06,060] {logging_mixin.py:115} INFO - [2022-06-06 06:13:06,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:13:06,126] {logging_mixin.py:115} INFO - [2022-06-06 06:13:06,124] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:13:06,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:13:06,230] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-06 06:13:36,481] {processor.py:153} INFO - Started process (PID=45605) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:13:36,483] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:13:36,484] {logging_mixin.py:115} INFO - [2022-06-06 06:13:36,484] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:13:36,548] {logging_mixin.py:115} INFO - [2022-06-06 06:13:36,545] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:13:36,550] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:13:36,668] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 06:14:07,377] {processor.py:153} INFO - Started process (PID=45661) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:14:07,380] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:14:07,382] {logging_mixin.py:115} INFO - [2022-06-06 06:14:07,382] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:14:07,434] {logging_mixin.py:115} INFO - [2022-06-06 06:14:07,432] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:14:07,435] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:14:07,532] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 06:14:38,263] {processor.py:153} INFO - Started process (PID=45728) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:14:38,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:14:38,267] {logging_mixin.py:115} INFO - [2022-06-06 06:14:38,267] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:14:38,321] {logging_mixin.py:115} INFO - [2022-06-06 06:14:38,319] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:14:38,323] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:14:38,422] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 06:15:08,865] {processor.py:153} INFO - Started process (PID=45797) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:15:08,867] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:15:08,869] {logging_mixin.py:115} INFO - [2022-06-06 06:15:08,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:15:08,931] {logging_mixin.py:115} INFO - [2022-06-06 06:15:08,929] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:15:08,932] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:15:09,027] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 06:15:39,250] {processor.py:153} INFO - Started process (PID=45863) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:15:39,251] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:15:39,252] {logging_mixin.py:115} INFO - [2022-06-06 06:15:39,252] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:15:39,293] {logging_mixin.py:115} INFO - [2022-06-06 06:15:39,291] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:15:39,294] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:15:39,390] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.143 seconds
[2022-06-06 06:16:09,609] {processor.py:153} INFO - Started process (PID=45930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:16:09,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:16:09,613] {logging_mixin.py:115} INFO - [2022-06-06 06:16:09,613] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:16:09,664] {logging_mixin.py:115} INFO - [2022-06-06 06:16:09,661] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:16:09,666] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:16:09,779] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 06:16:40,796] {processor.py:153} INFO - Started process (PID=45988) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:16:40,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:16:40,801] {logging_mixin.py:115} INFO - [2022-06-06 06:16:40,801] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:16:40,854] {logging_mixin.py:115} INFO - [2022-06-06 06:16:40,853] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:16:40,856] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:16:40,969] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 06:17:11,391] {processor.py:153} INFO - Started process (PID=46056) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:17:11,393] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:17:11,395] {logging_mixin.py:115} INFO - [2022-06-06 06:17:11,395] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:17:11,456] {logging_mixin.py:115} INFO - [2022-06-06 06:17:11,454] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:17:11,457] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:17:11,555] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 06:17:41,771] {processor.py:153} INFO - Started process (PID=46124) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:17:41,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:17:41,774] {logging_mixin.py:115} INFO - [2022-06-06 06:17:41,774] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:17:41,845] {logging_mixin.py:115} INFO - [2022-06-06 06:17:41,842] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:17:41,848] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:17:41,958] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 06:18:12,506] {processor.py:153} INFO - Started process (PID=46191) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:18:12,509] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:18:12,510] {logging_mixin.py:115} INFO - [2022-06-06 06:18:12,510] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:18:12,563] {logging_mixin.py:115} INFO - [2022-06-06 06:18:12,561] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:18:12,564] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:18:12,660] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 06:18:43,302] {processor.py:153} INFO - Started process (PID=46261) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:18:43,305] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:18:43,308] {logging_mixin.py:115} INFO - [2022-06-06 06:18:43,308] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:18:43,423] {logging_mixin.py:115} INFO - [2022-06-06 06:18:43,420] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:18:43,424] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:18:43,554] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.258 seconds
[2022-06-06 06:19:13,698] {processor.py:153} INFO - Started process (PID=46321) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:19:13,701] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:19:13,702] {logging_mixin.py:115} INFO - [2022-06-06 06:19:13,702] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:19:13,795] {logging_mixin.py:115} INFO - [2022-06-06 06:19:13,792] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:19:13,796] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:19:13,910] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-06 06:19:43,995] {processor.py:153} INFO - Started process (PID=46389) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:19:43,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:19:44,001] {logging_mixin.py:115} INFO - [2022-06-06 06:19:44,001] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:19:44,086] {logging_mixin.py:115} INFO - [2022-06-06 06:19:44,084] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:19:44,087] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:19:44,254] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.271 seconds
[2022-06-06 06:20:14,682] {processor.py:153} INFO - Started process (PID=46456) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:20:14,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:20:14,686] {logging_mixin.py:115} INFO - [2022-06-06 06:20:14,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:20:14,770] {logging_mixin.py:115} INFO - [2022-06-06 06:20:14,768] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:20:14,773] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:20:14,878] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 06:20:45,683] {processor.py:153} INFO - Started process (PID=46526) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:20:45,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:20:45,687] {logging_mixin.py:115} INFO - [2022-06-06 06:20:45,686] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:20:45,753] {logging_mixin.py:115} INFO - [2022-06-06 06:20:45,751] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:20:45,754] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:20:45,853] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 06:21:16,783] {processor.py:153} INFO - Started process (PID=46594) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:21:16,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:21:16,790] {logging_mixin.py:115} INFO - [2022-06-06 06:21:16,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:21:16,846] {logging_mixin.py:115} INFO - [2022-06-06 06:21:16,841] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:21:16,848] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:21:16,973] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 06:21:47,042] {processor.py:153} INFO - Started process (PID=46651) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:21:47,044] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:21:47,048] {logging_mixin.py:115} INFO - [2022-06-06 06:21:47,048] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:21:47,128] {logging_mixin.py:115} INFO - [2022-06-06 06:21:47,125] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:21:47,129] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:21:47,270] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-06 06:22:17,942] {processor.py:153} INFO - Started process (PID=46718) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:22:17,944] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:22:17,946] {logging_mixin.py:115} INFO - [2022-06-06 06:22:17,946] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:22:18,016] {logging_mixin.py:115} INFO - [2022-06-06 06:22:18,014] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:22:18,018] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:22:18,116] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 06:22:48,923] {processor.py:153} INFO - Started process (PID=46785) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:22:48,927] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:22:48,930] {logging_mixin.py:115} INFO - [2022-06-06 06:22:48,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:22:49,065] {logging_mixin.py:115} INFO - [2022-06-06 06:22:49,062] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:22:49,066] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:22:49,181] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.267 seconds
[2022-06-06 06:23:19,234] {processor.py:153} INFO - Started process (PID=46851) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:23:19,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:23:19,237] {logging_mixin.py:115} INFO - [2022-06-06 06:23:19,237] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:23:19,322] {logging_mixin.py:115} INFO - [2022-06-06 06:23:19,320] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:23:19,324] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:23:19,431] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 06:23:49,623] {processor.py:153} INFO - Started process (PID=46917) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:23:49,624] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:23:49,626] {logging_mixin.py:115} INFO - [2022-06-06 06:23:49,626] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:23:49,721] {logging_mixin.py:115} INFO - [2022-06-06 06:23:49,719] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:23:49,722] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:23:49,838] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-06 06:24:20,083] {processor.py:153} INFO - Started process (PID=46983) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:24:20,086] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:24:20,088] {logging_mixin.py:115} INFO - [2022-06-06 06:24:20,088] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:24:20,161] {logging_mixin.py:115} INFO - [2022-06-06 06:24:20,157] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:24:20,163] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:24:20,311] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-06 06:24:50,398] {processor.py:153} INFO - Started process (PID=47043) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:24:50,400] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:24:50,401] {logging_mixin.py:115} INFO - [2022-06-06 06:24:50,401] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:24:50,470] {logging_mixin.py:115} INFO - [2022-06-06 06:24:50,467] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:24:50,471] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:24:50,580] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 06:25:21,091] {processor.py:153} INFO - Started process (PID=47111) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:25:21,093] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:25:21,096] {logging_mixin.py:115} INFO - [2022-06-06 06:25:21,096] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:25:21,190] {logging_mixin.py:115} INFO - [2022-06-06 06:25:21,188] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:25:21,192] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:25:21,303] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-06 06:25:52,200] {processor.py:153} INFO - Started process (PID=47179) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:25:52,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:25:52,202] {logging_mixin.py:115} INFO - [2022-06-06 06:25:52,202] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:25:52,317] {logging_mixin.py:115} INFO - [2022-06-06 06:25:52,315] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:25:52,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:25:52,438] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.242 seconds
[2022-06-06 06:26:22,653] {processor.py:153} INFO - Started process (PID=47247) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:26:22,656] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:26:22,658] {logging_mixin.py:115} INFO - [2022-06-06 06:26:22,657] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:26:22,732] {logging_mixin.py:115} INFO - [2022-06-06 06:26:22,730] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:26:22,734] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:26:22,845] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-06 06:26:53,880] {processor.py:153} INFO - Started process (PID=47314) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:26:53,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:26:53,886] {logging_mixin.py:115} INFO - [2022-06-06 06:26:53,886] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:26:54,018] {logging_mixin.py:115} INFO - [2022-06-06 06:26:54,014] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:26:54,020] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:26:54,156] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.281 seconds
[2022-06-06 06:27:24,669] {processor.py:153} INFO - Started process (PID=47372) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:27:24,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:27:24,673] {logging_mixin.py:115} INFO - [2022-06-06 06:27:24,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:27:24,754] {logging_mixin.py:115} INFO - [2022-06-06 06:27:24,752] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:27:24,755] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:27:24,858] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 06:27:54,989] {processor.py:153} INFO - Started process (PID=47439) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:27:54,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:27:54,992] {logging_mixin.py:115} INFO - [2022-06-06 06:27:54,992] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:27:55,053] {logging_mixin.py:115} INFO - [2022-06-06 06:27:55,051] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:27:55,056] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:27:55,184] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-06 06:28:25,322] {processor.py:153} INFO - Started process (PID=47506) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:28:25,324] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:28:25,325] {logging_mixin.py:115} INFO - [2022-06-06 06:28:25,325] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:28:25,434] {logging_mixin.py:115} INFO - [2022-06-06 06:28:25,430] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:28:25,439] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:28:25,581] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.268 seconds
[2022-06-06 06:28:56,092] {processor.py:153} INFO - Started process (PID=47575) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:28:56,095] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:28:56,097] {logging_mixin.py:115} INFO - [2022-06-06 06:28:56,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:28:56,171] {logging_mixin.py:115} INFO - [2022-06-06 06:28:56,169] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:28:56,173] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:28:56,275] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 06:29:26,553] {processor.py:153} INFO - Started process (PID=47645) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:29:26,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:29:26,572] {logging_mixin.py:115} INFO - [2022-06-06 06:29:26,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:29:26,691] {logging_mixin.py:115} INFO - [2022-06-06 06:29:26,680] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:29:26,695] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:29:26,931] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.392 seconds
[2022-06-06 06:29:57,423] {processor.py:153} INFO - Started process (PID=47702) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:29:57,427] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:29:57,433] {logging_mixin.py:115} INFO - [2022-06-06 06:29:57,433] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:29:57,542] {logging_mixin.py:115} INFO - [2022-06-06 06:29:57,536] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:29:57,545] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:29:57,674] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.258 seconds
[2022-06-06 06:30:27,762] {processor.py:153} INFO - Started process (PID=47773) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:30:27,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:30:27,767] {logging_mixin.py:115} INFO - [2022-06-06 06:30:27,767] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:30:27,876] {logging_mixin.py:115} INFO - [2022-06-06 06:30:27,874] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:30:27,878] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:30:27,998] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-06 06:30:58,054] {processor.py:153} INFO - Started process (PID=47840) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:30:58,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:30:58,059] {logging_mixin.py:115} INFO - [2022-06-06 06:30:58,058] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:30:58,125] {logging_mixin.py:115} INFO - [2022-06-06 06:30:58,123] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:30:58,127] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:30:58,226] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 06:31:28,712] {processor.py:153} INFO - Started process (PID=47907) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:31:28,730] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:31:28,731] {logging_mixin.py:115} INFO - [2022-06-06 06:31:28,731] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:31:28,793] {logging_mixin.py:115} INFO - [2022-06-06 06:31:28,791] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:31:28,795] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:31:28,907] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-06 06:31:59,496] {processor.py:153} INFO - Started process (PID=47964) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:31:59,498] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:31:59,500] {logging_mixin.py:115} INFO - [2022-06-06 06:31:59,500] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:31:59,594] {logging_mixin.py:115} INFO - [2022-06-06 06:31:59,591] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:31:59,597] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:31:59,705] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-06 06:32:30,049] {processor.py:153} INFO - Started process (PID=48032) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:32:30,052] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:32:30,056] {logging_mixin.py:115} INFO - [2022-06-06 06:32:30,056] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:32:30,128] {logging_mixin.py:115} INFO - [2022-06-06 06:32:30,125] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:32:30,134] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:32:30,235] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 06:33:01,250] {processor.py:153} INFO - Started process (PID=48103) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:33:01,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:33:01,253] {logging_mixin.py:115} INFO - [2022-06-06 06:33:01,253] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:33:01,309] {logging_mixin.py:115} INFO - [2022-06-06 06:33:01,306] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:33:01,310] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:33:01,452] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.205 seconds
[2022-06-06 06:33:31,661] {processor.py:153} INFO - Started process (PID=48173) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:33:31,664] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:33:31,665] {logging_mixin.py:115} INFO - [2022-06-06 06:33:31,665] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:33:31,745] {logging_mixin.py:115} INFO - [2022-06-06 06:33:31,742] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:33:31,757] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:33:31,895] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-06 06:34:02,878] {processor.py:153} INFO - Started process (PID=48238) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:34:02,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:34:02,883] {logging_mixin.py:115} INFO - [2022-06-06 06:34:02,883] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:34:03,005] {logging_mixin.py:115} INFO - [2022-06-06 06:34:03,002] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:34:03,007] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:34:03,132] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.260 seconds
[2022-06-06 06:34:33,321] {processor.py:153} INFO - Started process (PID=48294) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:34:33,324] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:34:33,326] {logging_mixin.py:115} INFO - [2022-06-06 06:34:33,325] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:34:33,398] {logging_mixin.py:115} INFO - [2022-06-06 06:34:33,395] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:34:33,400] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:34:33,500] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 06:35:03,640] {processor.py:153} INFO - Started process (PID=48362) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:35:03,643] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:35:03,644] {logging_mixin.py:115} INFO - [2022-06-06 06:35:03,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:35:03,710] {logging_mixin.py:115} INFO - [2022-06-06 06:35:03,707] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:35:03,712] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:35:03,816] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 06:35:34,116] {processor.py:153} INFO - Started process (PID=48428) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:35:34,119] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:35:34,121] {logging_mixin.py:115} INFO - [2022-06-06 06:35:34,121] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:35:34,193] {logging_mixin.py:115} INFO - [2022-06-06 06:35:34,190] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:35:34,195] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:35:34,298] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-06 06:36:04,342] {processor.py:153} INFO - Started process (PID=48497) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:36:04,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:36:04,347] {logging_mixin.py:115} INFO - [2022-06-06 06:36:04,347] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:36:04,396] {logging_mixin.py:115} INFO - [2022-06-06 06:36:04,393] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:36:04,397] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:36:04,493] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 06:36:34,921] {processor.py:153} INFO - Started process (PID=48564) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:36:34,923] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:36:34,925] {logging_mixin.py:115} INFO - [2022-06-06 06:36:34,925] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:36:34,985] {logging_mixin.py:115} INFO - [2022-06-06 06:36:34,982] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:36:34,987] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:36:35,082] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 06:37:05,370] {processor.py:153} INFO - Started process (PID=48622) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:37:05,372] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:37:05,374] {logging_mixin.py:115} INFO - [2022-06-06 06:37:05,374] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:37:05,433] {logging_mixin.py:115} INFO - [2022-06-06 06:37:05,431] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:37:05,435] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:37:05,527] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 06:37:36,301] {processor.py:153} INFO - Started process (PID=48692) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:37:36,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:37:36,303] {logging_mixin.py:115} INFO - [2022-06-06 06:37:36,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:37:36,347] {logging_mixin.py:115} INFO - [2022-06-06 06:37:36,345] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:37:36,349] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:37:36,446] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 06:38:07,186] {processor.py:153} INFO - Started process (PID=48759) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:38:07,188] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:38:07,189] {logging_mixin.py:115} INFO - [2022-06-06 06:38:07,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:38:07,243] {logging_mixin.py:115} INFO - [2022-06-06 06:38:07,240] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:38:07,245] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:38:07,355] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 06:38:38,055] {processor.py:153} INFO - Started process (PID=48828) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:38:38,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:38:38,060] {logging_mixin.py:115} INFO - [2022-06-06 06:38:38,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:38:38,115] {logging_mixin.py:115} INFO - [2022-06-06 06:38:38,113] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:38:38,117] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:38:38,210] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 06:39:09,131] {processor.py:153} INFO - Started process (PID=48897) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:39:09,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:39:09,137] {logging_mixin.py:115} INFO - [2022-06-06 06:39:09,137] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:39:09,205] {logging_mixin.py:115} INFO - [2022-06-06 06:39:09,203] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:39:09,207] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:39:09,302] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 06:39:39,335] {processor.py:153} INFO - Started process (PID=48955) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:39:39,337] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:39:39,338] {logging_mixin.py:115} INFO - [2022-06-06 06:39:39,338] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:39:39,395] {logging_mixin.py:115} INFO - [2022-06-06 06:39:39,393] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:39:39,397] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:39:39,536] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.204 seconds
[2022-06-06 06:40:09,606] {processor.py:153} INFO - Started process (PID=49023) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:40:09,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:40:09,610] {logging_mixin.py:115} INFO - [2022-06-06 06:40:09,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:40:09,668] {logging_mixin.py:115} INFO - [2022-06-06 06:40:09,666] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:40:09,670] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:40:09,775] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 06:40:40,245] {processor.py:153} INFO - Started process (PID=49094) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:40:40,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:40:40,248] {logging_mixin.py:115} INFO - [2022-06-06 06:40:40,248] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:40:40,305] {logging_mixin.py:115} INFO - [2022-06-06 06:40:40,303] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:40:40,306] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:40:40,414] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 06:41:10,816] {processor.py:153} INFO - Started process (PID=49164) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:41:10,819] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:41:10,820] {logging_mixin.py:115} INFO - [2022-06-06 06:41:10,820] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:41:10,883] {logging_mixin.py:115} INFO - [2022-06-06 06:41:10,880] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:41:10,884] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:41:10,980] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 06:41:41,063] {processor.py:153} INFO - Started process (PID=49235) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:41:41,064] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:41:41,065] {logging_mixin.py:115} INFO - [2022-06-06 06:41:41,065] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:41:41,145] {logging_mixin.py:115} INFO - [2022-06-06 06:41:41,141] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:41:41,146] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:41:41,268] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.210 seconds
[2022-06-06 06:42:11,461] {processor.py:153} INFO - Started process (PID=49292) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:42:11,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:42:11,466] {logging_mixin.py:115} INFO - [2022-06-06 06:42:11,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:42:11,541] {logging_mixin.py:115} INFO - [2022-06-06 06:42:11,539] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:42:11,543] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:42:11,639] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 06:42:41,971] {processor.py:153} INFO - Started process (PID=49364) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:42:41,975] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:42:41,977] {logging_mixin.py:115} INFO - [2022-06-06 06:42:41,977] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:42:42,036] {logging_mixin.py:115} INFO - [2022-06-06 06:42:42,034] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:42:42,038] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:42:42,133] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 06:43:12,200] {processor.py:153} INFO - Started process (PID=49436) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:43:12,202] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:43:12,203] {logging_mixin.py:115} INFO - [2022-06-06 06:43:12,203] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:43:12,251] {logging_mixin.py:115} INFO - [2022-06-06 06:43:12,249] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:43:12,253] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:43:12,357] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 06:43:43,361] {processor.py:153} INFO - Started process (PID=49502) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:43:43,363] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:43:43,365] {logging_mixin.py:115} INFO - [2022-06-06 06:43:43,365] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:43:43,421] {logging_mixin.py:115} INFO - [2022-06-06 06:43:43,419] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:43:43,423] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:43:43,523] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 06:44:14,383] {processor.py:153} INFO - Started process (PID=49569) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:44:14,385] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:44:14,386] {logging_mixin.py:115} INFO - [2022-06-06 06:44:14,386] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:44:14,447] {logging_mixin.py:115} INFO - [2022-06-06 06:44:14,445] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:44:14,449] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:44:14,548] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 06:44:45,337] {processor.py:153} INFO - Started process (PID=49625) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:44:45,340] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:44:45,343] {logging_mixin.py:115} INFO - [2022-06-06 06:44:45,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:44:45,401] {logging_mixin.py:115} INFO - [2022-06-06 06:44:45,399] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:44:45,402] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:44:45,499] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 06:45:15,759] {processor.py:153} INFO - Started process (PID=49693) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:45:15,762] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:45:15,764] {logging_mixin.py:115} INFO - [2022-06-06 06:45:15,764] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:45:15,824] {logging_mixin.py:115} INFO - [2022-06-06 06:45:15,821] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:45:15,826] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:45:15,926] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 06:45:46,112] {processor.py:153} INFO - Started process (PID=49762) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:45:46,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:45:46,117] {logging_mixin.py:115} INFO - [2022-06-06 06:45:46,117] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:45:46,176] {logging_mixin.py:115} INFO - [2022-06-06 06:45:46,173] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:45:46,177] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:45:46,279] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 06:46:16,379] {processor.py:153} INFO - Started process (PID=49835) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:46:16,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:46:16,384] {logging_mixin.py:115} INFO - [2022-06-06 06:46:16,384] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:46:16,446] {logging_mixin.py:115} INFO - [2022-06-06 06:46:16,444] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:46:16,447] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:46:16,543] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 06:46:46,715] {processor.py:153} INFO - Started process (PID=49903) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:46:46,718] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:46:46,720] {logging_mixin.py:115} INFO - [2022-06-06 06:46:46,720] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:46:46,834] {logging_mixin.py:115} INFO - [2022-06-06 06:46:46,829] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:46:46,837] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:46:47,029] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.322 seconds
[2022-06-06 06:47:17,138] {processor.py:153} INFO - Started process (PID=49963) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:47:17,139] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:47:17,142] {logging_mixin.py:115} INFO - [2022-06-06 06:47:17,142] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:47:17,195] {logging_mixin.py:115} INFO - [2022-06-06 06:47:17,193] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:47:17,197] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:47:17,297] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 06:47:48,072] {processor.py:153} INFO - Started process (PID=50031) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:47:48,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:47:48,075] {logging_mixin.py:115} INFO - [2022-06-06 06:47:48,075] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:47:48,123] {logging_mixin.py:115} INFO - [2022-06-06 06:47:48,121] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:47:48,124] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:47:48,224] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 06:48:18,874] {processor.py:153} INFO - Started process (PID=50098) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:48:18,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:48:18,879] {logging_mixin.py:115} INFO - [2022-06-06 06:48:18,879] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:48:18,991] {logging_mixin.py:115} INFO - [2022-06-06 06:48:18,989] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:48:18,992] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:48:19,091] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-06 06:48:49,280] {processor.py:153} INFO - Started process (PID=50164) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:48:49,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:48:49,282] {logging_mixin.py:115} INFO - [2022-06-06 06:48:49,282] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:48:49,361] {logging_mixin.py:115} INFO - [2022-06-06 06:48:49,358] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:48:49,364] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:48:49,471] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 06:49:19,707] {processor.py:153} INFO - Started process (PID=50223) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:49:19,711] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:49:19,713] {logging_mixin.py:115} INFO - [2022-06-06 06:49:19,713] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:49:19,801] {logging_mixin.py:115} INFO - [2022-06-06 06:49:19,798] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:49:19,802] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:49:19,910] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-06 06:49:50,783] {processor.py:153} INFO - Started process (PID=50288) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:49:50,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:49:50,788] {logging_mixin.py:115} INFO - [2022-06-06 06:49:50,788] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:49:50,868] {logging_mixin.py:115} INFO - [2022-06-06 06:49:50,865] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:49:50,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:49:51,000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-06 06:50:21,454] {processor.py:153} INFO - Started process (PID=50360) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:50:21,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:50:21,457] {logging_mixin.py:115} INFO - [2022-06-06 06:50:21,457] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:50:21,539] {logging_mixin.py:115} INFO - [2022-06-06 06:50:21,535] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:50:21,540] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:50:21,638] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 06:50:52,543] {processor.py:153} INFO - Started process (PID=50428) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:50:52,545] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:50:52,547] {logging_mixin.py:115} INFO - [2022-06-06 06:50:52,547] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:50:52,592] {logging_mixin.py:115} INFO - [2022-06-06 06:50:52,590] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:50:52,593] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:50:52,697] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 06:51:23,158] {processor.py:153} INFO - Started process (PID=50488) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:51:23,160] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:51:23,162] {logging_mixin.py:115} INFO - [2022-06-06 06:51:23,162] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:51:23,231] {logging_mixin.py:115} INFO - [2022-06-06 06:51:23,227] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:51:23,234] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:51:23,358] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.205 seconds
[2022-06-06 06:51:54,093] {processor.py:153} INFO - Started process (PID=50554) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:51:54,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:51:54,097] {logging_mixin.py:115} INFO - [2022-06-06 06:51:54,097] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:51:54,148] {logging_mixin.py:115} INFO - [2022-06-06 06:51:54,146] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:51:54,150] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:51:54,247] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 06:52:24,846] {processor.py:153} INFO - Started process (PID=50622) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:52:24,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:52:24,851] {logging_mixin.py:115} INFO - [2022-06-06 06:52:24,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:52:24,928] {logging_mixin.py:115} INFO - [2022-06-06 06:52:24,926] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:52:24,929] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:52:25,038] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 06:52:55,938] {processor.py:153} INFO - Started process (PID=50689) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:52:55,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:52:55,943] {logging_mixin.py:115} INFO - [2022-06-06 06:52:55,943] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:52:56,001] {logging_mixin.py:115} INFO - [2022-06-06 06:52:55,998] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:52:56,002] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:52:56,104] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 06:53:26,172] {processor.py:153} INFO - Started process (PID=50757) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:53:26,174] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:53:26,175] {logging_mixin.py:115} INFO - [2022-06-06 06:53:26,175] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:53:26,224] {logging_mixin.py:115} INFO - [2022-06-06 06:53:26,221] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:53:26,225] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:53:26,327] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 06:53:56,371] {processor.py:153} INFO - Started process (PID=50827) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:53:56,373] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:53:56,374] {logging_mixin.py:115} INFO - [2022-06-06 06:53:56,374] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:53:56,438] {logging_mixin.py:115} INFO - [2022-06-06 06:53:56,436] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:53:56,439] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:53:56,586] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-06 06:54:26,756] {processor.py:153} INFO - Started process (PID=50882) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:54:26,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:54:26,761] {logging_mixin.py:115} INFO - [2022-06-06 06:54:26,761] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:54:26,822] {logging_mixin.py:115} INFO - [2022-06-06 06:54:26,819] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:54:26,823] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:54:26,919] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 06:54:57,394] {processor.py:153} INFO - Started process (PID=50953) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:54:57,397] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:54:57,399] {logging_mixin.py:115} INFO - [2022-06-06 06:54:57,399] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:54:57,456] {logging_mixin.py:115} INFO - [2022-06-06 06:54:57,454] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:54:57,457] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:54:57,564] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 06:55:27,694] {processor.py:153} INFO - Started process (PID=51022) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:55:27,697] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:55:27,699] {logging_mixin.py:115} INFO - [2022-06-06 06:55:27,699] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:55:27,756] {logging_mixin.py:115} INFO - [2022-06-06 06:55:27,754] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:55:27,759] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:55:27,856] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 06:55:58,072] {processor.py:153} INFO - Started process (PID=51089) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:55:58,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:55:58,075] {logging_mixin.py:115} INFO - [2022-06-06 06:55:58,075] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:55:58,136] {logging_mixin.py:115} INFO - [2022-06-06 06:55:58,134] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:55:58,138] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:55:58,249] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 06:56:28,292] {processor.py:153} INFO - Started process (PID=51149) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:56:28,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:56:28,296] {logging_mixin.py:115} INFO - [2022-06-06 06:56:28,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:56:28,345] {logging_mixin.py:115} INFO - [2022-06-06 06:56:28,343] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:56:28,347] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:56:28,440] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 06:56:58,551] {processor.py:153} INFO - Started process (PID=51217) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:56:58,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:56:58,557] {logging_mixin.py:115} INFO - [2022-06-06 06:56:58,557] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:56:58,616] {logging_mixin.py:115} INFO - [2022-06-06 06:56:58,613] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:56:58,617] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:56:58,716] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 06:57:28,998] {processor.py:153} INFO - Started process (PID=51284) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:57:29,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:57:29,001] {logging_mixin.py:115} INFO - [2022-06-06 06:57:29,001] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:57:29,059] {logging_mixin.py:115} INFO - [2022-06-06 06:57:29,056] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:57:29,061] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:57:29,169] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 06:57:59,849] {processor.py:153} INFO - Started process (PID=51354) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:57:59,852] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:57:59,854] {logging_mixin.py:115} INFO - [2022-06-06 06:57:59,853] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:57:59,917] {logging_mixin.py:115} INFO - [2022-06-06 06:57:59,914] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:57:59,918] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:58:00,024] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 06:58:30,889] {processor.py:153} INFO - Started process (PID=51421) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:58:30,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:58:30,892] {logging_mixin.py:115} INFO - [2022-06-06 06:58:30,892] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:58:30,939] {logging_mixin.py:115} INFO - [2022-06-06 06:58:30,936] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:58:30,941] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:58:31,037] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 06:59:01,593] {processor.py:153} INFO - Started process (PID=51478) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:59:01,594] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:59:01,596] {logging_mixin.py:115} INFO - [2022-06-06 06:59:01,595] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:59:01,648] {logging_mixin.py:115} INFO - [2022-06-06 06:59:01,646] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:59:01,649] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:59:01,744] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 06:59:32,386] {processor.py:153} INFO - Started process (PID=51549) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:59:32,388] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 06:59:32,389] {logging_mixin.py:115} INFO - [2022-06-06 06:59:32,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:59:32,433] {logging_mixin.py:115} INFO - [2022-06-06 06:59:32,430] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 06:59:32,434] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 06:59:32,530] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-06 07:00:03,055] {processor.py:153} INFO - Started process (PID=51619) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:00:03,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:00:03,060] {logging_mixin.py:115} INFO - [2022-06-06 07:00:03,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:00:03,124] {logging_mixin.py:115} INFO - [2022-06-06 07:00:03,122] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:00:03,125] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:00:03,228] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 07:00:33,846] {processor.py:153} INFO - Started process (PID=51687) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:00:33,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:00:33,852] {logging_mixin.py:115} INFO - [2022-06-06 07:00:33,852] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:00:33,945] {logging_mixin.py:115} INFO - [2022-06-06 07:00:33,942] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:00:33,946] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:00:34,050] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-06 07:01:04,204] {processor.py:153} INFO - Started process (PID=51752) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:01:04,206] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:01:04,207] {logging_mixin.py:115} INFO - [2022-06-06 07:01:04,207] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:01:04,266] {logging_mixin.py:115} INFO - [2022-06-06 07:01:04,263] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:01:04,267] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:01:04,410] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-06 07:01:35,443] {processor.py:153} INFO - Started process (PID=51818) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:01:35,446] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:01:35,447] {logging_mixin.py:115} INFO - [2022-06-06 07:01:35,447] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:01:35,491] {logging_mixin.py:115} INFO - [2022-06-06 07:01:35,488] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:01:35,492] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:01:35,586] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 07:02:06,090] {processor.py:153} INFO - Started process (PID=51884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:02:06,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:02:06,096] {logging_mixin.py:115} INFO - [2022-06-06 07:02:06,096] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:02:06,167] {logging_mixin.py:115} INFO - [2022-06-06 07:02:06,165] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:02:06,169] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:02:06,264] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 07:02:36,620] {processor.py:153} INFO - Started process (PID=51953) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:02:36,624] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:02:36,625] {logging_mixin.py:115} INFO - [2022-06-06 07:02:36,625] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:02:36,683] {logging_mixin.py:115} INFO - [2022-06-06 07:02:36,680] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:02:36,684] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:02:36,779] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 07:03:07,798] {processor.py:153} INFO - Started process (PID=52020) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:03:07,800] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:03:07,802] {logging_mixin.py:115} INFO - [2022-06-06 07:03:07,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:03:07,866] {logging_mixin.py:115} INFO - [2022-06-06 07:03:07,863] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:03:07,868] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:03:07,961] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 07:03:38,222] {processor.py:153} INFO - Started process (PID=52086) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:03:38,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:03:38,225] {logging_mixin.py:115} INFO - [2022-06-06 07:03:38,225] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:03:38,295] {logging_mixin.py:115} INFO - [2022-06-06 07:03:38,288] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:03:38,297] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:03:38,420] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 07:04:09,207] {processor.py:153} INFO - Started process (PID=52145) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:04:09,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:04:09,210] {logging_mixin.py:115} INFO - [2022-06-06 07:04:09,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:04:09,262] {logging_mixin.py:115} INFO - [2022-06-06 07:04:09,259] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:04:09,264] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:04:09,366] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 07:04:39,974] {processor.py:153} INFO - Started process (PID=52212) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:04:39,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:04:39,978] {logging_mixin.py:115} INFO - [2022-06-06 07:04:39,978] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:04:40,034] {logging_mixin.py:115} INFO - [2022-06-06 07:04:40,032] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:04:40,035] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:04:40,132] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 07:05:10,966] {processor.py:153} INFO - Started process (PID=52283) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:05:10,968] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:05:10,969] {logging_mixin.py:115} INFO - [2022-06-06 07:05:10,969] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:05:11,044] {logging_mixin.py:115} INFO - [2022-06-06 07:05:11,041] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:05:11,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:05:11,142] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 07:05:41,872] {processor.py:153} INFO - Started process (PID=52350) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:05:41,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:05:41,874] {logging_mixin.py:115} INFO - [2022-06-06 07:05:41,874] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:05:41,919] {logging_mixin.py:115} INFO - [2022-06-06 07:05:41,917] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:05:41,921] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:05:42,018] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 07:06:12,260] {processor.py:153} INFO - Started process (PID=52418) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:06:12,263] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:06:12,265] {logging_mixin.py:115} INFO - [2022-06-06 07:06:12,265] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:06:12,324] {logging_mixin.py:115} INFO - [2022-06-06 07:06:12,322] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:06:12,326] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:06:12,428] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 07:06:42,494] {processor.py:153} INFO - Started process (PID=52484) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:06:42,496] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:06:42,496] {logging_mixin.py:115} INFO - [2022-06-06 07:06:42,496] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:06:42,558] {logging_mixin.py:115} INFO - [2022-06-06 07:06:42,555] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:06:42,560] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:06:42,672] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 07:07:13,644] {processor.py:153} INFO - Started process (PID=52542) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:07:13,648] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:07:13,650] {logging_mixin.py:115} INFO - [2022-06-06 07:07:13,649] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:07:13,720] {logging_mixin.py:115} INFO - [2022-06-06 07:07:13,707] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:07:13,723] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:07:13,845] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-06 07:07:44,407] {processor.py:153} INFO - Started process (PID=52611) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:07:44,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:07:44,411] {logging_mixin.py:115} INFO - [2022-06-06 07:07:44,411] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:07:44,467] {logging_mixin.py:115} INFO - [2022-06-06 07:07:44,465] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:07:44,469] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:07:44,569] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 07:08:15,106] {processor.py:153} INFO - Started process (PID=52678) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:08:15,108] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:08:15,109] {logging_mixin.py:115} INFO - [2022-06-06 07:08:15,109] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:08:15,152] {logging_mixin.py:115} INFO - [2022-06-06 07:08:15,150] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:08:15,153] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:08:15,247] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-06 07:08:45,644] {processor.py:153} INFO - Started process (PID=52748) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:08:45,647] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:08:45,650] {logging_mixin.py:115} INFO - [2022-06-06 07:08:45,650] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:08:45,709] {logging_mixin.py:115} INFO - [2022-06-06 07:08:45,706] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:08:45,710] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:08:45,806] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 07:09:16,585] {processor.py:153} INFO - Started process (PID=52815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:09:16,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:09:16,589] {logging_mixin.py:115} INFO - [2022-06-06 07:09:16,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:09:16,636] {logging_mixin.py:115} INFO - [2022-06-06 07:09:16,634] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:09:16,637] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:09:16,729] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 07:09:47,384] {processor.py:153} INFO - Started process (PID=52884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:09:47,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:09:47,387] {logging_mixin.py:115} INFO - [2022-06-06 07:09:47,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:09:47,444] {logging_mixin.py:115} INFO - [2022-06-06 07:09:47,442] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:09:47,447] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:09:47,548] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 07:10:18,207] {processor.py:153} INFO - Started process (PID=52941) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:10:18,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:10:18,210] {logging_mixin.py:115} INFO - [2022-06-06 07:10:18,210] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:10:18,261] {logging_mixin.py:115} INFO - [2022-06-06 07:10:18,258] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:10:18,262] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:10:18,371] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 07:10:48,959] {processor.py:153} INFO - Started process (PID=53008) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:10:48,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:10:48,964] {logging_mixin.py:115} INFO - [2022-06-06 07:10:48,964] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:10:49,021] {logging_mixin.py:115} INFO - [2022-06-06 07:10:49,019] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:10:49,023] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:10:49,135] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 07:11:19,989] {processor.py:153} INFO - Started process (PID=53071) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:11:19,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:11:19,996] {logging_mixin.py:115} INFO - [2022-06-06 07:11:19,996] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:11:20,056] {logging_mixin.py:115} INFO - [2022-06-06 07:11:20,054] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:11:20,058] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:11:20,154] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 07:11:50,376] {processor.py:153} INFO - Started process (PID=53138) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:11:50,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:11:50,379] {logging_mixin.py:115} INFO - [2022-06-06 07:11:50,379] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:11:50,435] {logging_mixin.py:115} INFO - [2022-06-06 07:11:50,432] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:11:50,437] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:11:50,540] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 07:12:20,726] {processor.py:153} INFO - Started process (PID=53205) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:12:20,728] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:12:20,729] {logging_mixin.py:115} INFO - [2022-06-06 07:12:20,729] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:12:20,775] {logging_mixin.py:115} INFO - [2022-06-06 07:12:20,773] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:12:20,777] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:12:20,880] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 07:12:51,576] {processor.py:153} INFO - Started process (PID=53273) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:12:51,579] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:12:51,582] {logging_mixin.py:115} INFO - [2022-06-06 07:12:51,582] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:12:51,642] {logging_mixin.py:115} INFO - [2022-06-06 07:12:51,640] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:12:51,644] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:12:51,735] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 07:13:22,638] {processor.py:153} INFO - Started process (PID=53328) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:13:22,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:13:22,642] {logging_mixin.py:115} INFO - [2022-06-06 07:13:22,642] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:13:22,695] {logging_mixin.py:115} INFO - [2022-06-06 07:13:22,693] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:13:22,696] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:13:22,812] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 07:13:52,990] {processor.py:153} INFO - Started process (PID=53398) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:13:52,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:13:52,992] {logging_mixin.py:115} INFO - [2022-06-06 07:13:52,992] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:13:53,039] {logging_mixin.py:115} INFO - [2022-06-06 07:13:53,036] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:13:53,041] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:13:53,140] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 07:14:23,353] {processor.py:153} INFO - Started process (PID=53465) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:14:23,355] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:14:23,357] {logging_mixin.py:115} INFO - [2022-06-06 07:14:23,357] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:14:23,411] {logging_mixin.py:115} INFO - [2022-06-06 07:14:23,409] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:14:23,412] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:14:23,508] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 07:14:53,707] {processor.py:153} INFO - Started process (PID=53534) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:14:53,709] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:14:53,712] {logging_mixin.py:115} INFO - [2022-06-06 07:14:53,711] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:14:53,853] {logging_mixin.py:115} INFO - [2022-06-06 07:14:53,849] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:14:53,855] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:14:53,966] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-06 07:15:24,771] {processor.py:153} INFO - Started process (PID=53604) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:15:24,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:15:24,774] {logging_mixin.py:115} INFO - [2022-06-06 07:15:24,774] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:15:24,839] {logging_mixin.py:115} INFO - [2022-06-06 07:15:24,837] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:15:24,840] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:15:24,943] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 07:15:55,956] {processor.py:153} INFO - Started process (PID=53660) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:15:55,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:15:55,964] {logging_mixin.py:115} INFO - [2022-06-06 07:15:55,964] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:15:56,079] {logging_mixin.py:115} INFO - [2022-06-06 07:15:56,076] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:15:56,081] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:15:56,249] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.304 seconds
[2022-06-06 07:16:26,515] {processor.py:153} INFO - Started process (PID=53726) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:16:26,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:16:26,520] {logging_mixin.py:115} INFO - [2022-06-06 07:16:26,519] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:16:26,611] {logging_mixin.py:115} INFO - [2022-06-06 07:16:26,608] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:16:26,613] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:16:26,733] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-06 07:16:57,201] {processor.py:153} INFO - Started process (PID=53798) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:16:57,203] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:16:57,205] {logging_mixin.py:115} INFO - [2022-06-06 07:16:57,205] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:16:57,295] {logging_mixin.py:115} INFO - [2022-06-06 07:16:57,292] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:16:57,296] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:16:57,428] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-06 07:17:27,697] {processor.py:153} INFO - Started process (PID=53864) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:17:27,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:17:27,703] {logging_mixin.py:115} INFO - [2022-06-06 07:17:27,703] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:17:27,789] {logging_mixin.py:115} INFO - [2022-06-06 07:17:27,786] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:17:27,792] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:17:27,919] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-06 07:17:58,701] {processor.py:153} INFO - Started process (PID=53921) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:17:58,703] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:17:58,704] {logging_mixin.py:115} INFO - [2022-06-06 07:17:58,704] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:17:58,788] {logging_mixin.py:115} INFO - [2022-06-06 07:17:58,786] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:17:58,790] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:17:58,893] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-06 07:18:29,913] {processor.py:153} INFO - Started process (PID=53988) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:18:29,914] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:18:29,915] {logging_mixin.py:115} INFO - [2022-06-06 07:18:29,915] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:18:29,997] {logging_mixin.py:115} INFO - [2022-06-06 07:18:29,993] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:18:29,999] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:18:30,130] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-06 07:19:00,730] {processor.py:153} INFO - Started process (PID=54054) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:19:00,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:19:00,732] {logging_mixin.py:115} INFO - [2022-06-06 07:19:00,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:19:00,795] {logging_mixin.py:115} INFO - [2022-06-06 07:19:00,793] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:19:00,796] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:19:00,900] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 07:19:31,351] {processor.py:153} INFO - Started process (PID=54121) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:19:31,354] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:19:31,357] {logging_mixin.py:115} INFO - [2022-06-06 07:19:31,357] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:19:31,456] {logging_mixin.py:115} INFO - [2022-06-06 07:19:31,454] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:19:31,458] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:19:31,562] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.224 seconds
[2022-06-06 07:20:02,234] {processor.py:153} INFO - Started process (PID=54181) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:20:02,238] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:20:02,240] {logging_mixin.py:115} INFO - [2022-06-06 07:20:02,240] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:20:02,416] {logging_mixin.py:115} INFO - [2022-06-06 07:20:02,406] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:20:02,418] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:20:02,605] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.384 seconds
[2022-06-06 07:20:32,717] {processor.py:153} INFO - Started process (PID=54250) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:20:32,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:20:32,725] {logging_mixin.py:115} INFO - [2022-06-06 07:20:32,725] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:20:32,850] {logging_mixin.py:115} INFO - [2022-06-06 07:20:32,843] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:20:32,855] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:20:33,021] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.310 seconds
[2022-06-06 07:21:03,914] {processor.py:153} INFO - Started process (PID=54317) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:21:03,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:21:03,918] {logging_mixin.py:115} INFO - [2022-06-06 07:21:03,918] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:21:04,022] {logging_mixin.py:115} INFO - [2022-06-06 07:21:04,016] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:21:04,023] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:21:04,139] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-06 07:21:34,285] {processor.py:153} INFO - Started process (PID=54383) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:21:34,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:21:34,290] {logging_mixin.py:115} INFO - [2022-06-06 07:21:34,290] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:21:34,370] {logging_mixin.py:115} INFO - [2022-06-06 07:21:34,368] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:21:34,371] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:21:34,482] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-06 07:22:05,115] {processor.py:153} INFO - Started process (PID=54448) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:22:05,123] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:22:05,129] {logging_mixin.py:115} INFO - [2022-06-06 07:22:05,128] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:22:05,367] {logging_mixin.py:115} INFO - [2022-06-06 07:22:05,361] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:22:05,370] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:22:05,520] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.415 seconds
[2022-06-06 07:22:35,609] {processor.py:153} INFO - Started process (PID=54506) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:22:35,619] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:22:35,621] {logging_mixin.py:115} INFO - [2022-06-06 07:22:35,621] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:22:35,705] {logging_mixin.py:115} INFO - [2022-06-06 07:22:35,702] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:22:35,706] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:22:35,824] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-06 07:23:06,574] {processor.py:153} INFO - Started process (PID=54573) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:23:06,575] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:23:06,577] {logging_mixin.py:115} INFO - [2022-06-06 07:23:06,576] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:23:06,663] {logging_mixin.py:115} INFO - [2022-06-06 07:23:06,660] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:23:06,665] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:23:06,796] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-06 07:23:36,881] {processor.py:153} INFO - Started process (PID=54640) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:23:36,885] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:23:36,888] {logging_mixin.py:115} INFO - [2022-06-06 07:23:36,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:23:37,119] {logging_mixin.py:115} INFO - [2022-06-06 07:23:37,109] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:23:37,123] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:23:37,344] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.467 seconds
[2022-06-06 07:24:07,608] {processor.py:153} INFO - Started process (PID=54699) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:24:07,611] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:24:07,612] {logging_mixin.py:115} INFO - [2022-06-06 07:24:07,612] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:24:07,700] {logging_mixin.py:115} INFO - [2022-06-06 07:24:07,696] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:24:07,702] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:24:07,818] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-06 07:24:38,591] {processor.py:153} INFO - Started process (PID=54771) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:24:38,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:24:38,599] {logging_mixin.py:115} INFO - [2022-06-06 07:24:38,598] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:24:38,747] {logging_mixin.py:115} INFO - [2022-06-06 07:24:38,738] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:24:38,758] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:24:38,933] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.357 seconds
[2022-06-06 07:25:09,420] {processor.py:153} INFO - Started process (PID=54838) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:25:09,428] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:25:09,435] {logging_mixin.py:115} INFO - [2022-06-06 07:25:09,435] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:25:09,526] {logging_mixin.py:115} INFO - [2022-06-06 07:25:09,518] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:25:09,528] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:25:09,631] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-06 07:25:40,375] {processor.py:153} INFO - Started process (PID=54909) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:25:40,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:25:40,378] {logging_mixin.py:115} INFO - [2022-06-06 07:25:40,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:25:40,536] {logging_mixin.py:115} INFO - [2022-06-06 07:25:40,532] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:25:40,538] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:25:40,682] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.323 seconds
[2022-06-06 07:26:10,749] {processor.py:153} INFO - Started process (PID=54964) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:26:10,752] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:26:10,753] {logging_mixin.py:115} INFO - [2022-06-06 07:26:10,753] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:26:10,889] {logging_mixin.py:115} INFO - [2022-06-06 07:26:10,886] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:26:10,890] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:26:10,987] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-06 07:26:41,157] {processor.py:153} INFO - Started process (PID=55030) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:26:41,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:26:41,170] {logging_mixin.py:115} INFO - [2022-06-06 07:26:41,170] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:26:41,349] {logging_mixin.py:115} INFO - [2022-06-06 07:26:41,345] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:26:41,350] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:26:41,484] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.348 seconds
[2022-06-06 07:27:11,837] {processor.py:153} INFO - Started process (PID=55099) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:27:11,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:27:11,841] {logging_mixin.py:115} INFO - [2022-06-06 07:27:11,840] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:27:11,925] {logging_mixin.py:115} INFO - [2022-06-06 07:27:11,922] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:27:11,929] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:27:12,048] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-06 07:27:42,652] {processor.py:153} INFO - Started process (PID=55167) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:27:42,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:27:42,656] {logging_mixin.py:115} INFO - [2022-06-06 07:27:42,656] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:27:42,754] {logging_mixin.py:115} INFO - [2022-06-06 07:27:42,752] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:27:42,760] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:27:42,905] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-06 07:28:13,066] {processor.py:153} INFO - Started process (PID=55226) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:28:13,069] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:28:13,071] {logging_mixin.py:115} INFO - [2022-06-06 07:28:13,071] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:28:13,149] {logging_mixin.py:115} INFO - [2022-06-06 07:28:13,146] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:28:13,150] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:28:13,270] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-06 07:28:43,618] {processor.py:153} INFO - Started process (PID=55297) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:28:43,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:28:43,622] {logging_mixin.py:115} INFO - [2022-06-06 07:28:43,622] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:28:43,713] {logging_mixin.py:115} INFO - [2022-06-06 07:28:43,710] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:28:43,721] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:28:43,823] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.210 seconds
[2022-06-06 07:29:14,553] {processor.py:153} INFO - Started process (PID=55368) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:29:14,556] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:29:14,557] {logging_mixin.py:115} INFO - [2022-06-06 07:29:14,557] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:29:14,637] {logging_mixin.py:115} INFO - [2022-06-06 07:29:14,635] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:29:14,639] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:29:14,753] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-06 07:29:45,373] {processor.py:153} INFO - Started process (PID=55424) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:29:45,376] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:29:45,378] {logging_mixin.py:115} INFO - [2022-06-06 07:29:45,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:29:45,458] {logging_mixin.py:115} INFO - [2022-06-06 07:29:45,455] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:29:45,459] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:29:45,603] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-06 07:30:16,151] {processor.py:153} INFO - Started process (PID=55489) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:30:16,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:30:16,155] {logging_mixin.py:115} INFO - [2022-06-06 07:30:16,155] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:30:16,259] {logging_mixin.py:115} INFO - [2022-06-06 07:30:16,255] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:30:16,261] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:30:16,392] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-06 07:30:46,826] {processor.py:153} INFO - Started process (PID=55556) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:30:46,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:30:46,830] {logging_mixin.py:115} INFO - [2022-06-06 07:30:46,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:30:46,917] {logging_mixin.py:115} INFO - [2022-06-06 07:30:46,915] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:30:46,930] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:30:47,077] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-06 07:31:17,197] {processor.py:153} INFO - Started process (PID=55623) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:31:17,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:31:17,201] {logging_mixin.py:115} INFO - [2022-06-06 07:31:17,201] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:31:17,274] {logging_mixin.py:115} INFO - [2022-06-06 07:31:17,271] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:31:17,275] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:31:17,370] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 07:31:48,423] {processor.py:153} INFO - Started process (PID=55688) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:31:48,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:31:48,431] {logging_mixin.py:115} INFO - [2022-06-06 07:31:48,431] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:31:48,684] {logging_mixin.py:115} INFO - [2022-06-06 07:31:48,676] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:31:48,691] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:31:48,987] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.580 seconds
[2022-06-06 07:32:19,957] {processor.py:153} INFO - Started process (PID=55747) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:32:19,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:32:19,960] {logging_mixin.py:115} INFO - [2022-06-06 07:32:19,960] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:32:20,042] {logging_mixin.py:115} INFO - [2022-06-06 07:32:20,038] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:32:20,043] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:32:20,174] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-06 07:32:50,505] {processor.py:153} INFO - Started process (PID=55817) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:32:50,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:32:50,510] {logging_mixin.py:115} INFO - [2022-06-06 07:32:50,510] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:32:50,589] {logging_mixin.py:115} INFO - [2022-06-06 07:32:50,585] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:32:50,591] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:32:50,706] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-06 07:33:21,094] {processor.py:153} INFO - Started process (PID=55884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:33:21,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:33:21,099] {logging_mixin.py:115} INFO - [2022-06-06 07:33:21,099] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:33:21,187] {logging_mixin.py:115} INFO - [2022-06-06 07:33:21,185] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:33:21,189] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:33:21,305] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-06 07:33:51,381] {processor.py:153} INFO - Started process (PID=55954) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:33:51,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:33:51,391] {logging_mixin.py:115} INFO - [2022-06-06 07:33:51,391] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:33:51,544] {logging_mixin.py:115} INFO - [2022-06-06 07:33:51,541] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:33:51,547] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:33:51,669] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.302 seconds
[2022-06-06 07:34:21,729] {processor.py:153} INFO - Started process (PID=56013) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:34:21,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:34:21,732] {logging_mixin.py:115} INFO - [2022-06-06 07:34:21,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:34:21,799] {logging_mixin.py:115} INFO - [2022-06-06 07:34:21,795] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:34:21,801] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:34:21,910] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 07:34:52,874] {processor.py:153} INFO - Started process (PID=56082) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:34:52,877] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:34:52,879] {logging_mixin.py:115} INFO - [2022-06-06 07:34:52,878] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:34:52,935] {logging_mixin.py:115} INFO - [2022-06-06 07:34:52,934] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:34:52,939] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:34:53,032] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 07:35:23,381] {processor.py:153} INFO - Started process (PID=56148) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:35:23,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:35:23,387] {logging_mixin.py:115} INFO - [2022-06-06 07:35:23,387] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:35:23,477] {logging_mixin.py:115} INFO - [2022-06-06 07:35:23,473] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:35:23,478] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:35:23,592] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-06 07:35:54,132] {processor.py:153} INFO - Started process (PID=56214) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:35:54,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:35:54,148] {logging_mixin.py:115} INFO - [2022-06-06 07:35:54,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:35:54,374] {logging_mixin.py:115} INFO - [2022-06-06 07:35:54,372] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:35:54,376] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:35:54,533] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.426 seconds
[2022-06-06 07:36:24,584] {processor.py:153} INFO - Started process (PID=56272) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:36:24,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:36:24,588] {logging_mixin.py:115} INFO - [2022-06-06 07:36:24,588] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:36:24,673] {logging_mixin.py:115} INFO - [2022-06-06 07:36:24,665] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:36:24,675] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:36:24,797] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-06 07:36:55,298] {processor.py:153} INFO - Started process (PID=56341) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:36:55,301] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:36:55,303] {logging_mixin.py:115} INFO - [2022-06-06 07:36:55,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:36:55,379] {logging_mixin.py:115} INFO - [2022-06-06 07:36:55,377] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:36:55,380] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:36:55,476] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-06 07:37:25,836] {processor.py:153} INFO - Started process (PID=56411) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:37:25,838] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:37:25,839] {logging_mixin.py:115} INFO - [2022-06-06 07:37:25,839] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:37:25,915] {logging_mixin.py:115} INFO - [2022-06-06 07:37:25,912] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:37:25,917] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:37:26,020] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-06 07:37:56,482] {processor.py:153} INFO - Started process (PID=56478) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:37:56,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:37:56,508] {logging_mixin.py:115} INFO - [2022-06-06 07:37:56,508] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:37:56,832] {logging_mixin.py:115} INFO - [2022-06-06 07:37:56,827] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:37:56,834] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:37:57,145] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.674 seconds
[2022-06-06 07:38:27,306] {processor.py:153} INFO - Started process (PID=56534) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:38:27,307] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:38:27,308] {logging_mixin.py:115} INFO - [2022-06-06 07:38:27,308] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:38:27,391] {logging_mixin.py:115} INFO - [2022-06-06 07:38:27,389] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:38:27,393] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:38:27,498] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 07:38:57,562] {processor.py:153} INFO - Started process (PID=56598) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:38:57,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:38:57,565] {logging_mixin.py:115} INFO - [2022-06-06 07:38:57,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:38:57,684] {logging_mixin.py:115} INFO - [2022-06-06 07:38:57,677] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:38:57,687] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:38:57,832] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.274 seconds
[2022-06-06 07:39:28,815] {processor.py:153} INFO - Started process (PID=56662) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:39:28,817] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:39:28,819] {logging_mixin.py:115} INFO - [2022-06-06 07:39:28,819] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:39:28,892] {logging_mixin.py:115} INFO - [2022-06-06 07:39:28,889] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:39:28,894] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:39:28,998] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 07:39:59,317] {processor.py:153} INFO - Started process (PID=56720) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:39:59,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:39:59,322] {logging_mixin.py:115} INFO - [2022-06-06 07:39:59,322] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:39:59,394] {logging_mixin.py:115} INFO - [2022-06-06 07:39:59,391] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:39:59,396] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:39:59,489] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 07:40:29,647] {processor.py:153} INFO - Started process (PID=56792) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:40:29,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:40:29,651] {logging_mixin.py:115} INFO - [2022-06-06 07:40:29,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:40:29,718] {logging_mixin.py:115} INFO - [2022-06-06 07:40:29,715] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:40:29,724] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:40:29,826] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 07:41:00,410] {processor.py:153} INFO - Started process (PID=56862) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:41:00,411] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:41:00,412] {logging_mixin.py:115} INFO - [2022-06-06 07:41:00,412] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:41:00,487] {logging_mixin.py:115} INFO - [2022-06-06 07:41:00,484] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:41:00,488] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:41:00,592] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-06 07:41:30,759] {processor.py:153} INFO - Started process (PID=56918) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:41:30,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:41:30,767] {logging_mixin.py:115} INFO - [2022-06-06 07:41:30,767] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:41:30,866] {logging_mixin.py:115} INFO - [2022-06-06 07:41:30,863] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:41:30,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:41:31,020] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.270 seconds
[2022-06-06 07:42:01,790] {processor.py:153} INFO - Started process (PID=56983) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:42:01,794] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:42:01,796] {logging_mixin.py:115} INFO - [2022-06-06 07:42:01,796] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:42:01,908] {logging_mixin.py:115} INFO - [2022-06-06 07:42:01,904] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:42:01,910] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:42:02,042] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-06 07:42:32,103] {processor.py:153} INFO - Started process (PID=57049) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:42:32,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:42:32,110] {logging_mixin.py:115} INFO - [2022-06-06 07:42:32,110] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:42:32,211] {logging_mixin.py:115} INFO - [2022-06-06 07:42:32,208] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:42:32,212] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:42:32,313] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-06 07:43:02,886] {processor.py:153} INFO - Started process (PID=57115) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:43:02,888] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:43:02,889] {logging_mixin.py:115} INFO - [2022-06-06 07:43:02,889] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:43:02,983] {logging_mixin.py:115} INFO - [2022-06-06 07:43:02,980] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:43:02,985] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:43:03,191] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.315 seconds
[2022-06-06 07:43:33,370] {processor.py:153} INFO - Started process (PID=57170) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:43:33,372] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:43:33,374] {logging_mixin.py:115} INFO - [2022-06-06 07:43:33,374] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:43:33,477] {logging_mixin.py:115} INFO - [2022-06-06 07:43:33,471] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:43:33,478] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:43:33,588] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-06 07:44:04,084] {processor.py:153} INFO - Started process (PID=57240) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:44:04,086] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:44:04,088] {logging_mixin.py:115} INFO - [2022-06-06 07:44:04,088] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:44:04,213] {logging_mixin.py:115} INFO - [2022-06-06 07:44:04,209] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:44:04,215] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:44:04,345] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.265 seconds
[2022-06-06 07:44:34,410] {processor.py:153} INFO - Started process (PID=57310) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:44:34,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:44:34,415] {logging_mixin.py:115} INFO - [2022-06-06 07:44:34,415] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:44:34,492] {logging_mixin.py:115} INFO - [2022-06-06 07:44:34,489] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:44:34,493] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:44:34,598] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 07:45:05,591] {processor.py:153} INFO - Started process (PID=57371) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:45:05,594] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:45:05,596] {logging_mixin.py:115} INFO - [2022-06-06 07:45:05,595] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:45:05,694] {logging_mixin.py:115} INFO - [2022-06-06 07:45:05,692] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:45:05,696] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:45:05,795] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-06 07:45:36,185] {processor.py:153} INFO - Started process (PID=57441) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:45:36,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:45:36,189] {logging_mixin.py:115} INFO - [2022-06-06 07:45:36,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:45:36,297] {logging_mixin.py:115} INFO - [2022-06-06 07:45:36,294] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:45:36,298] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:45:36,420] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.255 seconds
[2022-06-06 07:46:06,642] {processor.py:153} INFO - Started process (PID=57507) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:46:06,644] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:46:06,645] {logging_mixin.py:115} INFO - [2022-06-06 07:46:06,645] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:46:06,758] {logging_mixin.py:115} INFO - [2022-06-06 07:46:06,752] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:46:06,760] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:46:06,872] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-06 07:46:37,340] {processor.py:153} INFO - Started process (PID=57563) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:46:37,346] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:46:37,351] {logging_mixin.py:115} INFO - [2022-06-06 07:46:37,351] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:46:37,554] {logging_mixin.py:115} INFO - [2022-06-06 07:46:37,545] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:46:37,557] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:46:37,820] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.494 seconds
[2022-06-06 07:47:08,306] {processor.py:153} INFO - Started process (PID=57633) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:47:08,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:47:08,311] {logging_mixin.py:115} INFO - [2022-06-06 07:47:08,310] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:47:08,402] {logging_mixin.py:115} INFO - [2022-06-06 07:47:08,400] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:47:08,405] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:47:08,538] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.241 seconds
[2022-06-06 07:47:38,722] {processor.py:153} INFO - Started process (PID=57701) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:47:38,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:47:38,728] {logging_mixin.py:115} INFO - [2022-06-06 07:47:38,728] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:47:38,804] {logging_mixin.py:115} INFO - [2022-06-06 07:47:38,802] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:47:38,819] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:47:38,933] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-06 07:48:09,012] {processor.py:153} INFO - Started process (PID=57770) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:48:09,014] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:48:09,016] {logging_mixin.py:115} INFO - [2022-06-06 07:48:09,016] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:48:09,132] {logging_mixin.py:115} INFO - [2022-06-06 07:48:09,128] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:48:09,134] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:48:09,245] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-06 07:48:39,502] {processor.py:153} INFO - Started process (PID=57830) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:48:39,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:48:39,517] {logging_mixin.py:115} INFO - [2022-06-06 07:48:39,517] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:48:39,612] {logging_mixin.py:115} INFO - [2022-06-06 07:48:39,609] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:48:39,613] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:48:39,736] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-06 07:49:10,143] {processor.py:153} INFO - Started process (PID=57899) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:49:10,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:49:10,149] {logging_mixin.py:115} INFO - [2022-06-06 07:49:10,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:49:10,228] {logging_mixin.py:115} INFO - [2022-06-06 07:49:10,226] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:49:10,230] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:49:10,356] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-06 07:49:41,345] {processor.py:153} INFO - Started process (PID=57967) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:49:41,348] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:49:41,350] {logging_mixin.py:115} INFO - [2022-06-06 07:49:41,350] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:49:41,434] {logging_mixin.py:115} INFO - [2022-06-06 07:49:41,432] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:49:41,436] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:49:41,544] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-06 07:50:11,686] {processor.py:153} INFO - Started process (PID=58036) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:50:11,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:50:11,691] {logging_mixin.py:115} INFO - [2022-06-06 07:50:11,691] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:50:11,771] {logging_mixin.py:115} INFO - [2022-06-06 07:50:11,768] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:50:11,772] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:50:11,898] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-06 07:50:42,062] {processor.py:153} INFO - Started process (PID=58094) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:50:42,064] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:50:42,069] {logging_mixin.py:115} INFO - [2022-06-06 07:50:42,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:50:42,166] {logging_mixin.py:115} INFO - [2022-06-06 07:50:42,163] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:50:42,168] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:50:42,287] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-06 07:51:12,428] {processor.py:153} INFO - Started process (PID=58162) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:51:12,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:51:12,432] {logging_mixin.py:115} INFO - [2022-06-06 07:51:12,432] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:51:12,514] {logging_mixin.py:115} INFO - [2022-06-06 07:51:12,512] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:51:12,515] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:51:12,635] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-06 07:51:43,284] {processor.py:153} INFO - Started process (PID=58232) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:51:43,287] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:51:43,289] {logging_mixin.py:115} INFO - [2022-06-06 07:51:43,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:51:43,369] {logging_mixin.py:115} INFO - [2022-06-06 07:51:43,367] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:51:43,371] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:51:43,485] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-06 07:52:14,327] {processor.py:153} INFO - Started process (PID=58298) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:52:14,330] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:52:14,339] {logging_mixin.py:115} INFO - [2022-06-06 07:52:14,338] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:52:14,458] {logging_mixin.py:115} INFO - [2022-06-06 07:52:14,453] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:52:14,460] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:52:14,602] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.278 seconds
[2022-06-06 07:52:44,957] {processor.py:153} INFO - Started process (PID=58354) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:52:44,960] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:52:44,961] {logging_mixin.py:115} INFO - [2022-06-06 07:52:44,961] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:52:45,035] {logging_mixin.py:115} INFO - [2022-06-06 07:52:45,033] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:52:45,039] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:52:45,147] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-06 07:53:15,807] {processor.py:153} INFO - Started process (PID=58421) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:53:15,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:53:15,812] {logging_mixin.py:115} INFO - [2022-06-06 07:53:15,812] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:53:15,870] {logging_mixin.py:115} INFO - [2022-06-06 07:53:15,867] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:53:15,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:53:15,970] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 07:53:46,279] {processor.py:153} INFO - Started process (PID=58487) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:53:46,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:53:46,282] {logging_mixin.py:115} INFO - [2022-06-06 07:53:46,282] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:53:46,341] {logging_mixin.py:115} INFO - [2022-06-06 07:53:46,339] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:53:46,343] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:53:46,437] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 07:54:16,613] {processor.py:153} INFO - Started process (PID=58555) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:54:16,615] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:54:16,617] {logging_mixin.py:115} INFO - [2022-06-06 07:54:16,617] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:54:16,700] {logging_mixin.py:115} INFO - [2022-06-06 07:54:16,698] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:54:16,701] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:54:16,797] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 07:54:47,103] {processor.py:153} INFO - Started process (PID=58611) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:54:47,110] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:54:47,113] {logging_mixin.py:115} INFO - [2022-06-06 07:54:47,112] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:54:47,318] {logging_mixin.py:115} INFO - [2022-06-06 07:54:47,310] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:54:47,324] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:54:47,512] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.417 seconds
[2022-06-06 07:55:18,441] {processor.py:153} INFO - Started process (PID=58683) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:55:18,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:55:18,445] {logging_mixin.py:115} INFO - [2022-06-06 07:55:18,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:55:18,531] {logging_mixin.py:115} INFO - [2022-06-06 07:55:18,529] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:55:18,532] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:55:18,646] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-06 07:55:49,431] {processor.py:153} INFO - Started process (PID=58752) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:55:49,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:55:49,436] {logging_mixin.py:115} INFO - [2022-06-06 07:55:49,436] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:55:49,513] {logging_mixin.py:115} INFO - [2022-06-06 07:55:49,509] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:55:49,514] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:55:49,629] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.209 seconds
[2022-06-06 07:56:20,256] {processor.py:153} INFO - Started process (PID=58821) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:56:20,258] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:56:20,259] {logging_mixin.py:115} INFO - [2022-06-06 07:56:20,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:56:20,312] {logging_mixin.py:115} INFO - [2022-06-06 07:56:20,310] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:56:20,313] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:56:20,406] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 07:56:51,303] {processor.py:153} INFO - Started process (PID=58892) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:56:51,305] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:56:51,308] {logging_mixin.py:115} INFO - [2022-06-06 07:56:51,307] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:56:51,426] {logging_mixin.py:115} INFO - [2022-06-06 07:56:51,421] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:56:51,433] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:56:51,587] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.289 seconds
[2022-06-06 07:57:22,254] {processor.py:153} INFO - Started process (PID=58948) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:57:22,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:57:22,259] {logging_mixin.py:115} INFO - [2022-06-06 07:57:22,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:57:22,327] {logging_mixin.py:115} INFO - [2022-06-06 07:57:22,325] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:57:22,328] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:57:22,423] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 07:57:52,680] {processor.py:153} INFO - Started process (PID=59013) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:57:52,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:57:52,683] {logging_mixin.py:115} INFO - [2022-06-06 07:57:52,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:57:52,741] {logging_mixin.py:115} INFO - [2022-06-06 07:57:52,738] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:57:52,742] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:57:52,856] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 07:58:22,922] {processor.py:153} INFO - Started process (PID=59079) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:58:22,923] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:58:22,924] {logging_mixin.py:115} INFO - [2022-06-06 07:58:22,924] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:58:22,970] {logging_mixin.py:115} INFO - [2022-06-06 07:58:22,968] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:58:22,972] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:58:23,072] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 07:58:53,166] {processor.py:153} INFO - Started process (PID=59145) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:58:53,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:58:53,170] {logging_mixin.py:115} INFO - [2022-06-06 07:58:53,170] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:58:53,227] {logging_mixin.py:115} INFO - [2022-06-06 07:58:53,225] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:58:53,228] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:58:53,322] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 07:59:23,960] {processor.py:153} INFO - Started process (PID=59201) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:59:23,963] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:59:23,965] {logging_mixin.py:115} INFO - [2022-06-06 07:59:23,964] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:59:24,041] {logging_mixin.py:115} INFO - [2022-06-06 07:59:24,039] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:59:24,044] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:59:24,136] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 07:59:54,222] {processor.py:153} INFO - Started process (PID=59267) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:59:54,225] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 07:59:54,226] {logging_mixin.py:115} INFO - [2022-06-06 07:59:54,226] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:59:54,298] {logging_mixin.py:115} INFO - [2022-06-06 07:59:54,296] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 07:59:54,300] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 07:59:54,410] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 08:00:25,290] {processor.py:153} INFO - Started process (PID=59335) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:00:25,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:00:25,295] {logging_mixin.py:115} INFO - [2022-06-06 08:00:25,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:00:25,359] {logging_mixin.py:115} INFO - [2022-06-06 08:00:25,355] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:00:25,361] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:00:25,466] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 08:00:55,683] {processor.py:153} INFO - Started process (PID=59394) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:00:55,685] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:00:55,689] {logging_mixin.py:115} INFO - [2022-06-06 08:00:55,689] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:00:55,761] {logging_mixin.py:115} INFO - [2022-06-06 08:00:55,757] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:00:55,762] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:00:55,866] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 08:01:26,909] {processor.py:153} INFO - Started process (PID=59463) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:01:26,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:01:26,915] {logging_mixin.py:115} INFO - [2022-06-06 08:01:26,914] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:01:26,994] {logging_mixin.py:115} INFO - [2022-06-06 08:01:26,990] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:01:26,998] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:01:27,132] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-06 08:01:57,349] {processor.py:153} INFO - Started process (PID=59530) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:01:57,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:01:57,354] {logging_mixin.py:115} INFO - [2022-06-06 08:01:57,354] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:01:57,478] {logging_mixin.py:115} INFO - [2022-06-06 08:01:57,475] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:01:57,483] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:01:57,682] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.344 seconds
[2022-06-06 08:02:28,666] {processor.py:153} INFO - Started process (PID=59597) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:02:28,668] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:02:28,669] {logging_mixin.py:115} INFO - [2022-06-06 08:02:28,669] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:02:28,762] {logging_mixin.py:115} INFO - [2022-06-06 08:02:28,755] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:02:28,765] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:02:28,886] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-06 08:02:59,237] {processor.py:153} INFO - Started process (PID=59665) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:02:59,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:02:59,241] {logging_mixin.py:115} INFO - [2022-06-06 08:02:59,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:02:59,355] {logging_mixin.py:115} INFO - [2022-06-06 08:02:59,352] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:02:59,356] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:02:59,510] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.283 seconds
[2022-06-06 08:03:29,869] {processor.py:153} INFO - Started process (PID=59722) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:03:29,874] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:03:29,884] {logging_mixin.py:115} INFO - [2022-06-06 08:03:29,884] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:03:30,013] {logging_mixin.py:115} INFO - [2022-06-06 08:03:30,000] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:03:30,017] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:03:30,240] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.384 seconds
[2022-06-06 08:04:00,356] {processor.py:153} INFO - Started process (PID=59789) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:04:00,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:04:00,361] {logging_mixin.py:115} INFO - [2022-06-06 08:04:00,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:04:00,440] {logging_mixin.py:115} INFO - [2022-06-06 08:04:00,438] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:04:00,442] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:04:00,546] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-06 08:04:30,686] {processor.py:153} INFO - Started process (PID=59857) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:04:30,687] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:04:30,688] {logging_mixin.py:115} INFO - [2022-06-06 08:04:30,688] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:04:30,743] {logging_mixin.py:115} INFO - [2022-06-06 08:04:30,741] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:04:30,744] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:04:30,879] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-06 08:05:01,270] {processor.py:153} INFO - Started process (PID=59918) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:05:01,273] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:05:01,276] {logging_mixin.py:115} INFO - [2022-06-06 08:05:01,276] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:05:01,383] {logging_mixin.py:115} INFO - [2022-06-06 08:05:01,379] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:05:01,390] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:05:01,514] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-06 08:05:31,781] {processor.py:153} INFO - Started process (PID=59984) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:05:31,788] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:05:31,797] {logging_mixin.py:115} INFO - [2022-06-06 08:05:31,797] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:05:31,898] {logging_mixin.py:115} INFO - [2022-06-06 08:05:31,892] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:05:31,899] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:05:32,008] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-06 08:06:02,390] {processor.py:153} INFO - Started process (PID=60050) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:06:02,394] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:06:02,398] {logging_mixin.py:115} INFO - [2022-06-06 08:06:02,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:06:02,570] {logging_mixin.py:115} INFO - [2022-06-06 08:06:02,562] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:06:02,574] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:06:02,773] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.394 seconds
[2022-06-06 08:06:33,509] {processor.py:153} INFO - Started process (PID=60118) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:06:33,512] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:06:33,513] {logging_mixin.py:115} INFO - [2022-06-06 08:06:33,513] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:06:33,609] {logging_mixin.py:115} INFO - [2022-06-06 08:06:33,605] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:06:33,610] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:06:33,716] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-06 08:07:03,927] {processor.py:153} INFO - Started process (PID=60175) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:07:03,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:07:03,933] {logging_mixin.py:115} INFO - [2022-06-06 08:07:03,933] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:07:04,097] {logging_mixin.py:115} INFO - [2022-06-06 08:07:04,084] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:07:04,102] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:07:04,289] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.376 seconds
[2022-06-06 08:07:34,419] {processor.py:153} INFO - Started process (PID=60240) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:07:34,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:07:34,424] {logging_mixin.py:115} INFO - [2022-06-06 08:07:34,424] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:07:34,514] {logging_mixin.py:115} INFO - [2022-06-06 08:07:34,511] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:07:34,516] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:07:34,630] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-06 08:08:05,050] {processor.py:153} INFO - Started process (PID=60307) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:08:05,052] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:08:05,054] {logging_mixin.py:115} INFO - [2022-06-06 08:08:05,054] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:08:05,126] {logging_mixin.py:115} INFO - [2022-06-06 08:08:05,124] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:08:05,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:08:05,232] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 08:08:35,500] {processor.py:153} INFO - Started process (PID=60374) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:08:35,502] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:08:35,503] {logging_mixin.py:115} INFO - [2022-06-06 08:08:35,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:08:35,613] {logging_mixin.py:115} INFO - [2022-06-06 08:08:35,609] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:08:35,615] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:08:35,766] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.271 seconds
[2022-06-06 08:09:06,246] {processor.py:153} INFO - Started process (PID=60441) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:09:06,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:09:06,249] {logging_mixin.py:115} INFO - [2022-06-06 08:09:06,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:09:06,313] {logging_mixin.py:115} INFO - [2022-06-06 08:09:06,310] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:09:06,314] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:09:06,431] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-06 08:09:36,901] {processor.py:153} INFO - Started process (PID=60499) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:09:36,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:09:36,904] {logging_mixin.py:115} INFO - [2022-06-06 08:09:36,904] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:09:36,953] {logging_mixin.py:115} INFO - [2022-06-06 08:09:36,951] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:09:36,954] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:09:37,050] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 08:10:07,931] {processor.py:153} INFO - Started process (PID=60569) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:10:07,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:10:07,935] {logging_mixin.py:115} INFO - [2022-06-06 08:10:07,935] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:10:08,067] {logging_mixin.py:115} INFO - [2022-06-06 08:10:08,061] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:10:08,068] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:10:08,248] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.327 seconds
[2022-06-06 08:10:38,450] {processor.py:153} INFO - Started process (PID=60641) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:10:38,452] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:10:38,454] {logging_mixin.py:115} INFO - [2022-06-06 08:10:38,454] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:10:38,513] {logging_mixin.py:115} INFO - [2022-06-06 08:10:38,511] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:10:38,514] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:10:38,616] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 08:11:09,139] {processor.py:153} INFO - Started process (PID=60708) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:11:09,142] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:11:09,145] {logging_mixin.py:115} INFO - [2022-06-06 08:11:09,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:11:09,213] {logging_mixin.py:115} INFO - [2022-06-06 08:11:09,210] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:11:09,214] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:11:09,309] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 08:11:39,997] {processor.py:153} INFO - Started process (PID=60775) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:11:39,999] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:11:40,000] {logging_mixin.py:115} INFO - [2022-06-06 08:11:40,000] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:11:40,051] {logging_mixin.py:115} INFO - [2022-06-06 08:11:40,048] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:11:40,053] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:11:40,148] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 08:12:10,798] {processor.py:153} INFO - Started process (PID=60834) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:12:10,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:12:10,804] {logging_mixin.py:115} INFO - [2022-06-06 08:12:10,804] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:12:10,878] {logging_mixin.py:115} INFO - [2022-06-06 08:12:10,875] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:12:10,879] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:12:10,977] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 08:12:41,672] {processor.py:153} INFO - Started process (PID=60899) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:12:41,674] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:12:41,676] {logging_mixin.py:115} INFO - [2022-06-06 08:12:41,675] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:12:41,772] {logging_mixin.py:115} INFO - [2022-06-06 08:12:41,768] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:12:41,774] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:12:41,888] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-06 08:13:12,032] {processor.py:153} INFO - Started process (PID=60968) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:13:12,037] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:13:12,042] {logging_mixin.py:115} INFO - [2022-06-06 08:13:12,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:13:12,110] {logging_mixin.py:115} INFO - [2022-06-06 08:13:12,108] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:13:12,111] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:13:12,212] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 08:13:42,811] {processor.py:153} INFO - Started process (PID=61035) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:13:42,813] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:13:42,814] {logging_mixin.py:115} INFO - [2022-06-06 08:13:42,814] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:13:42,871] {logging_mixin.py:115} INFO - [2022-06-06 08:13:42,868] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:13:42,874] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:13:42,992] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 08:14:13,082] {processor.py:153} INFO - Started process (PID=61103) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:14:13,084] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:14:13,085] {logging_mixin.py:115} INFO - [2022-06-06 08:14:13,085] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:14:13,160] {logging_mixin.py:115} INFO - [2022-06-06 08:14:13,158] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:14:13,161] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:14:13,266] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 08:14:43,365] {processor.py:153} INFO - Started process (PID=61159) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:14:43,367] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:14:43,368] {logging_mixin.py:115} INFO - [2022-06-06 08:14:43,368] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:14:43,432] {logging_mixin.py:115} INFO - [2022-06-06 08:14:43,429] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:14:43,434] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:14:43,553] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 08:15:14,009] {processor.py:153} INFO - Started process (PID=61227) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:15:14,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:15:14,014] {logging_mixin.py:115} INFO - [2022-06-06 08:15:14,014] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:15:14,166] {logging_mixin.py:115} INFO - [2022-06-06 08:15:14,162] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:15:14,169] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:15:14,328] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.324 seconds
[2022-06-06 08:15:44,952] {processor.py:153} INFO - Started process (PID=61297) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:15:44,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:15:44,956] {logging_mixin.py:115} INFO - [2022-06-06 08:15:44,956] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:15:45,051] {logging_mixin.py:115} INFO - [2022-06-06 08:15:45,048] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:15:45,052] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:15:45,152] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-06 08:16:15,532] {processor.py:153} INFO - Started process (PID=61367) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:16:15,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:16:15,550] {logging_mixin.py:115} INFO - [2022-06-06 08:16:15,550] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:16:15,783] {logging_mixin.py:115} INFO - [2022-06-06 08:16:15,771] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:16:15,790] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:16:16,145] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.620 seconds
[2022-06-06 08:16:46,937] {processor.py:153} INFO - Started process (PID=61424) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:16:46,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:16:46,941] {logging_mixin.py:115} INFO - [2022-06-06 08:16:46,940] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:16:47,011] {logging_mixin.py:115} INFO - [2022-06-06 08:16:47,009] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:16:47,012] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:16:47,113] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 08:17:18,011] {processor.py:153} INFO - Started process (PID=61491) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:17:18,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:17:18,021] {logging_mixin.py:115} INFO - [2022-06-06 08:17:18,021] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:17:18,144] {logging_mixin.py:115} INFO - [2022-06-06 08:17:18,140] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:17:18,146] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:17:18,281] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.291 seconds
[2022-06-06 08:17:48,425] {processor.py:153} INFO - Started process (PID=61560) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:17:48,428] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:17:48,429] {logging_mixin.py:115} INFO - [2022-06-06 08:17:48,429] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:17:48,544] {logging_mixin.py:115} INFO - [2022-06-06 08:17:48,541] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:17:48,546] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:17:48,673] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.256 seconds
[2022-06-06 08:18:19,231] {processor.py:153} INFO - Started process (PID=61629) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:18:19,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:18:19,235] {logging_mixin.py:115} INFO - [2022-06-06 08:18:19,235] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:18:19,324] {logging_mixin.py:115} INFO - [2022-06-06 08:18:19,321] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:18:19,324] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:18:19,451] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.224 seconds
[2022-06-06 08:18:49,729] {processor.py:153} INFO - Started process (PID=61686) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:18:49,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:18:49,738] {logging_mixin.py:115} INFO - [2022-06-06 08:18:49,738] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:18:49,836] {logging_mixin.py:115} INFO - [2022-06-06 08:18:49,833] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:18:49,837] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:18:49,987] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.263 seconds
[2022-06-06 08:19:20,567] {processor.py:153} INFO - Started process (PID=61758) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:19:20,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:19:20,571] {logging_mixin.py:115} INFO - [2022-06-06 08:19:20,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:19:20,654] {logging_mixin.py:115} INFO - [2022-06-06 08:19:20,651] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:19:20,656] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:19:20,757] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 08:19:51,018] {processor.py:153} INFO - Started process (PID=61830) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:19:51,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:19:51,022] {logging_mixin.py:115} INFO - [2022-06-06 08:19:51,022] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:19:51,120] {logging_mixin.py:115} INFO - [2022-06-06 08:19:51,118] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:19:51,122] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:19:51,246] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-06 08:20:21,782] {processor.py:153} INFO - Started process (PID=61897) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:20:21,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:20:21,785] {logging_mixin.py:115} INFO - [2022-06-06 08:20:21,785] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:20:21,883] {logging_mixin.py:115} INFO - [2022-06-06 08:20:21,880] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:20:21,885] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:20:22,043] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.272 seconds
[2022-06-06 08:20:52,176] {processor.py:153} INFO - Started process (PID=61956) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:20:52,180] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:20:52,181] {logging_mixin.py:115} INFO - [2022-06-06 08:20:52,181] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:20:52,253] {logging_mixin.py:115} INFO - [2022-06-06 08:20:52,251] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:20:52,255] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:20:52,365] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 08:21:22,982] {processor.py:153} INFO - Started process (PID=62021) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:21:22,985] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:21:22,988] {logging_mixin.py:115} INFO - [2022-06-06 08:21:22,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:21:23,155] {logging_mixin.py:115} INFO - [2022-06-06 08:21:23,149] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:21:23,158] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:21:23,310] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.333 seconds
[2022-06-06 08:21:54,189] {processor.py:153} INFO - Started process (PID=62091) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:21:54,191] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:21:54,193] {logging_mixin.py:115} INFO - [2022-06-06 08:21:54,193] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:21:54,280] {logging_mixin.py:115} INFO - [2022-06-06 08:21:54,278] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:21:54,281] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:21:54,390] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-06 08:22:24,439] {processor.py:153} INFO - Started process (PID=62160) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:22:24,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:22:24,444] {logging_mixin.py:115} INFO - [2022-06-06 08:22:24,443] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:22:24,513] {logging_mixin.py:115} INFO - [2022-06-06 08:22:24,510] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:22:24,515] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:22:24,639] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-06 08:22:54,769] {processor.py:153} INFO - Started process (PID=62216) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:22:54,771] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:22:54,773] {logging_mixin.py:115} INFO - [2022-06-06 08:22:54,773] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:22:54,863] {logging_mixin.py:115} INFO - [2022-06-06 08:22:54,860] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:22:54,865] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:22:54,986] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-06 08:23:25,058] {processor.py:153} INFO - Started process (PID=62284) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:23:25,065] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:23:25,069] {logging_mixin.py:115} INFO - [2022-06-06 08:23:25,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:23:25,219] {logging_mixin.py:115} INFO - [2022-06-06 08:23:25,215] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:23:25,222] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:23:25,342] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.292 seconds
[2022-06-06 08:23:55,806] {processor.py:153} INFO - Started process (PID=62351) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:23:55,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:23:55,820] {logging_mixin.py:115} INFO - [2022-06-06 08:23:55,820] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:23:56,017] {logging_mixin.py:115} INFO - [2022-06-06 08:23:56,006] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:23:56,024] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:23:56,397] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.619 seconds
[2022-06-06 08:24:27,251] {processor.py:153} INFO - Started process (PID=62419) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:24:27,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:24:27,257] {logging_mixin.py:115} INFO - [2022-06-06 08:24:27,256] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:24:27,323] {logging_mixin.py:115} INFO - [2022-06-06 08:24:27,321] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:24:27,325] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:24:27,434] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 08:24:58,228] {processor.py:153} INFO - Started process (PID=62488) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:24:58,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:24:58,233] {logging_mixin.py:115} INFO - [2022-06-06 08:24:58,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:24:58,295] {logging_mixin.py:115} INFO - [2022-06-06 08:24:58,293] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:24:58,297] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:24:58,397] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 08:25:29,114] {processor.py:153} INFO - Started process (PID=62555) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:25:29,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:25:29,117] {logging_mixin.py:115} INFO - [2022-06-06 08:25:29,117] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:25:29,177] {logging_mixin.py:115} INFO - [2022-06-06 08:25:29,171] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:25:29,179] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:25:29,275] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 08:26:00,097] {processor.py:153} INFO - Started process (PID=62614) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:26:00,100] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:26:00,103] {logging_mixin.py:115} INFO - [2022-06-06 08:26:00,102] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:26:00,167] {logging_mixin.py:115} INFO - [2022-06-06 08:26:00,163] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:26:00,169] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:26:00,264] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 08:26:30,692] {processor.py:153} INFO - Started process (PID=62683) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:26:30,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:26:30,694] {logging_mixin.py:115} INFO - [2022-06-06 08:26:30,694] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:26:30,746] {logging_mixin.py:115} INFO - [2022-06-06 08:26:30,744] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:26:30,747] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:26:30,840] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 08:27:01,472] {processor.py:153} INFO - Started process (PID=62750) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:27:01,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:27:01,475] {logging_mixin.py:115} INFO - [2022-06-06 08:27:01,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:27:01,524] {logging_mixin.py:115} INFO - [2022-06-06 08:27:01,522] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:27:01,525] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:27:01,634] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 08:27:32,243] {processor.py:153} INFO - Started process (PID=62818) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:27:32,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:27:32,249] {logging_mixin.py:115} INFO - [2022-06-06 08:27:32,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:27:32,303] {logging_mixin.py:115} INFO - [2022-06-06 08:27:32,300] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:27:32,305] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:27:32,410] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 08:28:03,172] {processor.py:153} INFO - Started process (PID=62884) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:28:03,174] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:28:03,175] {logging_mixin.py:115} INFO - [2022-06-06 08:28:03,175] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:28:03,228] {logging_mixin.py:115} INFO - [2022-06-06 08:28:03,226] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:28:03,230] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:28:03,327] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 08:28:33,985] {processor.py:153} INFO - Started process (PID=62952) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:28:33,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:28:33,991] {logging_mixin.py:115} INFO - [2022-06-06 08:28:33,991] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:28:34,045] {logging_mixin.py:115} INFO - [2022-06-06 08:28:34,042] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:28:34,046] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:28:34,140] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 08:29:04,696] {processor.py:153} INFO - Started process (PID=63020) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:29:04,698] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:29:04,699] {logging_mixin.py:115} INFO - [2022-06-06 08:29:04,699] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:29:04,755] {logging_mixin.py:115} INFO - [2022-06-06 08:29:04,752] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:29:04,757] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:29:04,878] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 08:29:35,121] {processor.py:153} INFO - Started process (PID=63079) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:29:35,123] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:29:35,124] {logging_mixin.py:115} INFO - [2022-06-06 08:29:35,124] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:29:35,187] {logging_mixin.py:115} INFO - [2022-06-06 08:29:35,184] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:29:35,189] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:29:35,314] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-06 08:30:05,942] {processor.py:153} INFO - Started process (PID=63146) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:30:05,944] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:30:05,946] {logging_mixin.py:115} INFO - [2022-06-06 08:30:05,946] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:30:06,024] {logging_mixin.py:115} INFO - [2022-06-06 08:30:06,019] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:30:06,031] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:30:06,218] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.279 seconds
[2022-06-06 08:30:36,502] {processor.py:153} INFO - Started process (PID=63217) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:30:36,505] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:30:36,508] {logging_mixin.py:115} INFO - [2022-06-06 08:30:36,508] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:30:36,596] {logging_mixin.py:115} INFO - [2022-06-06 08:30:36,590] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:30:36,598] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:30:36,758] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-06 08:31:07,169] {processor.py:153} INFO - Started process (PID=63277) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:31:07,172] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:31:07,178] {logging_mixin.py:115} INFO - [2022-06-06 08:31:07,178] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:31:07,304] {logging_mixin.py:115} INFO - [2022-06-06 08:31:07,299] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:31:07,306] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:31:07,639] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.476 seconds
[2022-06-06 08:31:38,418] {processor.py:153} INFO - Started process (PID=63344) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:31:38,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:31:38,424] {logging_mixin.py:115} INFO - [2022-06-06 08:31:38,424] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:31:38,514] {logging_mixin.py:115} INFO - [2022-06-06 08:31:38,511] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:31:38,518] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:31:38,721] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.307 seconds
[2022-06-06 08:32:08,949] {processor.py:153} INFO - Started process (PID=63411) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:32:08,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:32:08,952] {logging_mixin.py:115} INFO - [2022-06-06 08:32:08,952] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:32:08,994] {logging_mixin.py:115} INFO - [2022-06-06 08:32:08,992] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:32:08,995] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:32:09,089] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.142 seconds
[2022-06-06 08:32:39,172] {processor.py:153} INFO - Started process (PID=63469) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:32:39,175] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:32:39,176] {logging_mixin.py:115} INFO - [2022-06-06 08:32:39,176] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:32:39,229] {logging_mixin.py:115} INFO - [2022-06-06 08:32:39,226] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:32:39,232] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:32:39,354] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 08:33:10,048] {processor.py:153} INFO - Started process (PID=63535) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:33:10,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:33:10,055] {logging_mixin.py:115} INFO - [2022-06-06 08:33:10,055] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:33:10,125] {logging_mixin.py:115} INFO - [2022-06-06 08:33:10,123] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:33:10,127] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:33:10,239] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 08:33:40,754] {processor.py:153} INFO - Started process (PID=63601) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:33:40,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:33:40,761] {logging_mixin.py:115} INFO - [2022-06-06 08:33:40,761] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:33:40,840] {logging_mixin.py:115} INFO - [2022-06-06 08:33:40,837] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:33:40,844] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:33:40,958] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.208 seconds
[2022-06-06 08:34:11,051] {processor.py:153} INFO - Started process (PID=63671) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:34:11,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:34:11,055] {logging_mixin.py:115} INFO - [2022-06-06 08:34:11,055] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:34:11,106] {logging_mixin.py:115} INFO - [2022-06-06 08:34:11,104] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:34:11,107] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:34:11,195] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 08:34:41,648] {processor.py:153} INFO - Started process (PID=63728) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:34:41,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:34:41,650] {logging_mixin.py:115} INFO - [2022-06-06 08:34:41,650] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:34:41,696] {logging_mixin.py:115} INFO - [2022-06-06 08:34:41,694] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:34:41,698] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:34:41,807] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 08:35:12,217] {processor.py:153} INFO - Started process (PID=63795) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:35:12,219] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:35:12,220] {logging_mixin.py:115} INFO - [2022-06-06 08:35:12,220] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:35:12,297] {logging_mixin.py:115} INFO - [2022-06-06 08:35:12,295] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:35:12,298] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:35:12,414] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-06 08:35:42,864] {processor.py:153} INFO - Started process (PID=63863) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:35:42,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:35:42,867] {logging_mixin.py:115} INFO - [2022-06-06 08:35:42,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:35:42,915] {logging_mixin.py:115} INFO - [2022-06-06 08:35:42,912] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:35:42,916] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:35:43,009] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 08:36:13,549] {processor.py:153} INFO - Started process (PID=63932) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:36:13,550] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:36:13,552] {logging_mixin.py:115} INFO - [2022-06-06 08:36:13,552] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:36:13,607] {logging_mixin.py:115} INFO - [2022-06-06 08:36:13,605] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:36:13,608] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:36:13,721] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 08:36:44,062] {processor.py:153} INFO - Started process (PID=64000) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:36:44,066] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:36:44,068] {logging_mixin.py:115} INFO - [2022-06-06 08:36:44,068] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:36:44,134] {logging_mixin.py:115} INFO - [2022-06-06 08:36:44,132] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:36:44,136] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:36:44,253] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 08:37:14,816] {processor.py:153} INFO - Started process (PID=64057) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:37:14,818] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:37:14,822] {logging_mixin.py:115} INFO - [2022-06-06 08:37:14,822] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:37:14,870] {logging_mixin.py:115} INFO - [2022-06-06 08:37:14,868] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:37:14,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:37:14,969] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 08:37:45,337] {processor.py:153} INFO - Started process (PID=64124) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:37:45,338] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:37:45,342] {logging_mixin.py:115} INFO - [2022-06-06 08:37:45,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:37:45,387] {logging_mixin.py:115} INFO - [2022-06-06 08:37:45,384] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:37:45,388] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:37:45,480] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-06 08:38:15,992] {processor.py:153} INFO - Started process (PID=64193) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:38:15,994] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:38:15,995] {logging_mixin.py:115} INFO - [2022-06-06 08:38:15,995] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:38:16,048] {logging_mixin.py:115} INFO - [2022-06-06 08:38:16,045] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:38:16,049] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:38:16,144] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 08:38:46,590] {processor.py:153} INFO - Started process (PID=64262) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:38:46,593] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:38:46,594] {logging_mixin.py:115} INFO - [2022-06-06 08:38:46,594] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:38:46,639] {logging_mixin.py:115} INFO - [2022-06-06 08:38:46,637] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:38:46,641] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:38:46,741] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 08:39:16,978] {processor.py:153} INFO - Started process (PID=64330) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:39:16,980] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:39:16,981] {logging_mixin.py:115} INFO - [2022-06-06 08:39:16,981] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:39:17,029] {logging_mixin.py:115} INFO - [2022-06-06 08:39:17,026] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:39:17,030] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:39:17,132] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 08:39:47,761] {processor.py:153} INFO - Started process (PID=64389) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:39:47,764] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:39:47,766] {logging_mixin.py:115} INFO - [2022-06-06 08:39:47,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:39:47,850] {logging_mixin.py:115} INFO - [2022-06-06 08:39:47,846] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:39:47,852] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:39:48,008] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-06 08:40:18,377] {processor.py:153} INFO - Started process (PID=64458) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:40:18,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:40:18,380] {logging_mixin.py:115} INFO - [2022-06-06 08:40:18,380] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:40:18,427] {logging_mixin.py:115} INFO - [2022-06-06 08:40:18,424] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:40:18,429] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:40:18,522] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 08:40:49,213] {processor.py:153} INFO - Started process (PID=64527) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:40:49,215] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:40:49,216] {logging_mixin.py:115} INFO - [2022-06-06 08:40:49,216] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:40:49,272] {logging_mixin.py:115} INFO - [2022-06-06 08:40:49,270] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:40:49,273] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:40:49,375] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 08:41:20,057] {processor.py:153} INFO - Started process (PID=64597) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:41:20,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:41:20,060] {logging_mixin.py:115} INFO - [2022-06-06 08:41:20,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:41:20,104] {logging_mixin.py:115} INFO - [2022-06-06 08:41:20,101] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:41:20,105] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:41:20,201] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 08:41:50,863] {processor.py:153} INFO - Started process (PID=64667) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:41:50,866] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:41:50,868] {logging_mixin.py:115} INFO - [2022-06-06 08:41:50,867] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:41:50,921] {logging_mixin.py:115} INFO - [2022-06-06 08:41:50,918] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:41:50,923] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:41:51,020] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 08:42:21,387] {processor.py:153} INFO - Started process (PID=64736) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:42:21,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:42:21,390] {logging_mixin.py:115} INFO - [2022-06-06 08:42:21,390] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:42:21,458] {logging_mixin.py:115} INFO - [2022-06-06 08:42:21,455] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:42:21,461] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:42:21,568] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 08:42:52,317] {processor.py:153} INFO - Started process (PID=64791) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:42:52,319] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:42:52,319] {logging_mixin.py:115} INFO - [2022-06-06 08:42:52,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:42:52,367] {logging_mixin.py:115} INFO - [2022-06-06 08:42:52,365] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:42:52,368] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:42:52,464] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-06 08:43:23,295] {processor.py:153} INFO - Started process (PID=64857) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:43:23,297] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:43:23,298] {logging_mixin.py:115} INFO - [2022-06-06 08:43:23,298] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:43:23,354] {logging_mixin.py:115} INFO - [2022-06-06 08:43:23,352] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:43:23,356] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:43:23,468] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 08:43:53,896] {processor.py:153} INFO - Started process (PID=64926) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:43:53,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:43:53,901] {logging_mixin.py:115} INFO - [2022-06-06 08:43:53,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:43:53,963] {logging_mixin.py:115} INFO - [2022-06-06 08:43:53,961] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:43:53,964] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:43:54,062] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 08:44:24,775] {processor.py:153} INFO - Started process (PID=64994) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:44:24,778] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:44:24,779] {logging_mixin.py:115} INFO - [2022-06-06 08:44:24,779] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:44:24,833] {logging_mixin.py:115} INFO - [2022-06-06 08:44:24,831] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:44:24,834] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:44:24,932] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 08:44:55,532] {processor.py:153} INFO - Started process (PID=65065) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:44:55,534] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:44:55,535] {logging_mixin.py:115} INFO - [2022-06-06 08:44:55,535] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:44:55,589] {logging_mixin.py:115} INFO - [2022-06-06 08:44:55,587] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:44:55,590] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:44:55,689] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 08:45:26,366] {processor.py:153} INFO - Started process (PID=65136) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:45:26,371] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:45:26,373] {logging_mixin.py:115} INFO - [2022-06-06 08:45:26,373] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:45:26,444] {logging_mixin.py:115} INFO - [2022-06-06 08:45:26,441] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:45:26,445] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:45:26,542] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 08:45:57,078] {processor.py:153} INFO - Started process (PID=65201) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:45:57,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:45:57,080] {logging_mixin.py:115} INFO - [2022-06-06 08:45:57,080] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:45:57,130] {logging_mixin.py:115} INFO - [2022-06-06 08:45:57,127] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:45:57,132] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:45:57,237] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 08:46:28,072] {processor.py:153} INFO - Started process (PID=65257) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:46:28,074] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:46:28,075] {logging_mixin.py:115} INFO - [2022-06-06 08:46:28,075] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:46:28,131] {logging_mixin.py:115} INFO - [2022-06-06 08:46:28,129] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:46:28,132] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:46:28,227] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 08:46:58,887] {processor.py:153} INFO - Started process (PID=65324) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:46:58,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:46:58,892] {logging_mixin.py:115} INFO - [2022-06-06 08:46:58,892] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:46:58,951] {logging_mixin.py:115} INFO - [2022-06-06 08:46:58,949] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:46:58,953] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:46:59,062] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 08:47:29,494] {processor.py:153} INFO - Started process (PID=65392) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:47:29,498] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:47:29,500] {logging_mixin.py:115} INFO - [2022-06-06 08:47:29,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:47:29,557] {logging_mixin.py:115} INFO - [2022-06-06 08:47:29,555] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:47:29,559] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:47:29,692] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-06 08:48:00,408] {processor.py:153} INFO - Started process (PID=65459) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:48:00,411] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:48:00,413] {logging_mixin.py:115} INFO - [2022-06-06 08:48:00,413] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:48:00,467] {logging_mixin.py:115} INFO - [2022-06-06 08:48:00,465] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:48:00,468] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:48:00,566] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 08:48:31,325] {processor.py:153} INFO - Started process (PID=65530) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:48:31,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:48:31,330] {logging_mixin.py:115} INFO - [2022-06-06 08:48:31,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:48:31,387] {logging_mixin.py:115} INFO - [2022-06-06 08:48:31,385] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:48:31,388] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:48:31,482] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 08:49:02,437] {processor.py:153} INFO - Started process (PID=65602) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:49:02,440] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:49:02,441] {logging_mixin.py:115} INFO - [2022-06-06 08:49:02,441] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:49:02,492] {logging_mixin.py:115} INFO - [2022-06-06 08:49:02,489] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:49:02,494] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:49:02,588] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 08:49:32,803] {processor.py:153} INFO - Started process (PID=65661) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:49:32,806] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:49:32,810] {logging_mixin.py:115} INFO - [2022-06-06 08:49:32,809] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:49:32,875] {logging_mixin.py:115} INFO - [2022-06-06 08:49:32,873] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:49:32,877] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:49:32,977] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 08:50:03,840] {processor.py:153} INFO - Started process (PID=65729) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:50:03,842] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:50:03,843] {logging_mixin.py:115} INFO - [2022-06-06 08:50:03,843] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:50:03,892] {logging_mixin.py:115} INFO - [2022-06-06 08:50:03,889] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:50:03,894] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:50:04,008] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 08:50:34,696] {processor.py:153} INFO - Started process (PID=65799) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:50:34,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:50:34,702] {logging_mixin.py:115} INFO - [2022-06-06 08:50:34,702] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:50:34,761] {logging_mixin.py:115} INFO - [2022-06-06 08:50:34,759] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:50:34,762] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:50:34,858] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 08:51:05,121] {processor.py:153} INFO - Started process (PID=65870) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:51:05,122] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:51:05,123] {logging_mixin.py:115} INFO - [2022-06-06 08:51:05,123] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:51:05,165] {logging_mixin.py:115} INFO - [2022-06-06 08:51:05,163] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:51:05,167] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:51:05,262] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-06 08:51:35,790] {processor.py:153} INFO - Started process (PID=65941) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:51:35,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:51:35,793] {logging_mixin.py:115} INFO - [2022-06-06 08:51:35,793] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:51:35,841] {logging_mixin.py:115} INFO - [2022-06-06 08:51:35,839] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:51:35,843] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:51:35,944] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 08:52:06,346] {processor.py:153} INFO - Started process (PID=66009) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:52:06,348] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:52:06,350] {logging_mixin.py:115} INFO - [2022-06-06 08:52:06,350] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:52:06,404] {logging_mixin.py:115} INFO - [2022-06-06 08:52:06,402] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:52:06,405] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:52:06,501] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 08:52:37,272] {processor.py:153} INFO - Started process (PID=66067) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:52:37,274] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:52:37,275] {logging_mixin.py:115} INFO - [2022-06-06 08:52:37,275] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:52:37,327] {logging_mixin.py:115} INFO - [2022-06-06 08:52:37,325] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:52:37,328] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:52:37,426] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 08:53:08,164] {processor.py:153} INFO - Started process (PID=66133) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:53:08,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:53:08,167] {logging_mixin.py:115} INFO - [2022-06-06 08:53:08,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:53:08,223] {logging_mixin.py:115} INFO - [2022-06-06 08:53:08,221] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:53:08,225] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:53:08,330] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 08:53:39,116] {processor.py:153} INFO - Started process (PID=66199) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:53:39,117] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:53:39,118] {logging_mixin.py:115} INFO - [2022-06-06 08:53:39,118] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:53:39,165] {logging_mixin.py:115} INFO - [2022-06-06 08:53:39,162] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:53:39,167] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:53:39,264] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 08:54:09,728] {processor.py:153} INFO - Started process (PID=66268) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:54:09,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:54:09,732] {logging_mixin.py:115} INFO - [2022-06-06 08:54:09,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:54:09,778] {logging_mixin.py:115} INFO - [2022-06-06 08:54:09,775] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:54:09,779] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:54:09,882] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 08:54:40,501] {processor.py:153} INFO - Started process (PID=66336) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:54:40,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:54:40,504] {logging_mixin.py:115} INFO - [2022-06-06 08:54:40,504] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:54:40,573] {logging_mixin.py:115} INFO - [2022-06-06 08:54:40,571] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:54:40,575] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:54:40,672] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 08:55:11,471] {processor.py:153} INFO - Started process (PID=66400) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:55:11,475] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:55:11,478] {logging_mixin.py:115} INFO - [2022-06-06 08:55:11,478] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:55:11,539] {logging_mixin.py:115} INFO - [2022-06-06 08:55:11,536] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:55:11,540] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:55:11,638] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 08:55:42,290] {processor.py:153} INFO - Started process (PID=66465) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:55:42,291] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:55:42,292] {logging_mixin.py:115} INFO - [2022-06-06 08:55:42,292] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:55:42,348] {logging_mixin.py:115} INFO - [2022-06-06 08:55:42,346] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:55:42,351] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:55:42,471] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 08:56:13,143] {processor.py:153} INFO - Started process (PID=66524) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:56:13,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:56:13,148] {logging_mixin.py:115} INFO - [2022-06-06 08:56:13,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:56:13,208] {logging_mixin.py:115} INFO - [2022-06-06 08:56:13,205] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:56:13,209] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:56:13,317] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 08:56:43,442] {processor.py:153} INFO - Started process (PID=66591) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:56:43,445] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:56:43,448] {logging_mixin.py:115} INFO - [2022-06-06 08:56:43,447] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:56:43,541] {logging_mixin.py:115} INFO - [2022-06-06 08:56:43,536] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:56:43,544] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:56:43,656] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-06 08:57:14,568] {processor.py:153} INFO - Started process (PID=66659) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:57:14,570] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:57:14,571] {logging_mixin.py:115} INFO - [2022-06-06 08:57:14,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:57:14,621] {logging_mixin.py:115} INFO - [2022-06-06 08:57:14,619] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:57:14,622] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:57:14,727] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 08:57:45,100] {processor.py:153} INFO - Started process (PID=66725) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:57:45,102] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:57:45,103] {logging_mixin.py:115} INFO - [2022-06-06 08:57:45,103] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:57:45,157] {logging_mixin.py:115} INFO - [2022-06-06 08:57:45,155] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:57:45,159] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:57:45,253] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 08:58:15,351] {processor.py:153} INFO - Started process (PID=66793) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:58:15,354] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:58:15,356] {logging_mixin.py:115} INFO - [2022-06-06 08:58:15,356] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:58:15,416] {logging_mixin.py:115} INFO - [2022-06-06 08:58:15,414] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:58:15,417] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:58:15,516] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 08:58:45,592] {processor.py:153} INFO - Started process (PID=66850) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:58:45,594] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:58:45,596] {logging_mixin.py:115} INFO - [2022-06-06 08:58:45,596] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:58:45,655] {logging_mixin.py:115} INFO - [2022-06-06 08:58:45,653] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:58:45,656] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:58:45,750] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 08:59:16,024] {processor.py:153} INFO - Started process (PID=66921) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:59:16,027] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:59:16,028] {logging_mixin.py:115} INFO - [2022-06-06 08:59:16,028] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:59:16,092] {logging_mixin.py:115} INFO - [2022-06-06 08:59:16,090] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:59:16,093] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:59:16,198] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 08:59:47,206] {processor.py:153} INFO - Started process (PID=66989) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:59:47,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 08:59:47,209] {logging_mixin.py:115} INFO - [2022-06-06 08:59:47,209] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:59:47,256] {logging_mixin.py:115} INFO - [2022-06-06 08:59:47,254] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 08:59:47,257] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 08:59:47,365] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 09:00:17,676] {processor.py:153} INFO - Started process (PID=67059) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:00:17,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:00:17,684] {logging_mixin.py:115} INFO - [2022-06-06 09:00:17,684] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:00:17,749] {logging_mixin.py:115} INFO - [2022-06-06 09:00:17,747] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:00:17,752] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:00:17,855] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 09:00:48,077] {processor.py:153} INFO - Started process (PID=67129) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:00:48,079] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:00:48,081] {logging_mixin.py:115} INFO - [2022-06-06 09:00:48,081] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:00:48,139] {logging_mixin.py:115} INFO - [2022-06-06 09:00:48,137] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:00:48,140] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:00:48,235] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 09:01:18,340] {processor.py:153} INFO - Started process (PID=67188) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:01:18,342] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:01:18,343] {logging_mixin.py:115} INFO - [2022-06-06 09:01:18,343] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:01:18,395] {logging_mixin.py:115} INFO - [2022-06-06 09:01:18,392] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:01:18,397] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:01:18,499] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 09:01:48,889] {processor.py:153} INFO - Started process (PID=67256) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:01:48,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:01:48,892] {logging_mixin.py:115} INFO - [2022-06-06 09:01:48,892] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:01:48,938] {logging_mixin.py:115} INFO - [2022-06-06 09:01:48,936] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:01:48,939] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:01:49,035] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 09:02:19,775] {processor.py:153} INFO - Started process (PID=67322) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:02:19,777] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:02:19,778] {logging_mixin.py:115} INFO - [2022-06-06 09:02:19,778] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:02:19,826] {logging_mixin.py:115} INFO - [2022-06-06 09:02:19,824] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:02:19,828] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:02:19,933] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 09:02:50,602] {processor.py:153} INFO - Started process (PID=67389) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:02:50,606] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:02:50,608] {logging_mixin.py:115} INFO - [2022-06-06 09:02:50,608] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:02:50,670] {logging_mixin.py:115} INFO - [2022-06-06 09:02:50,668] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:02:50,671] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:02:50,769] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 09:03:21,363] {processor.py:153} INFO - Started process (PID=67457) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:03:21,367] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:03:21,370] {logging_mixin.py:115} INFO - [2022-06-06 09:03:21,370] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:03:21,438] {logging_mixin.py:115} INFO - [2022-06-06 09:03:21,436] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:03:21,440] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:03:21,545] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 09:03:52,400] {processor.py:153} INFO - Started process (PID=67525) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:03:52,403] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:03:52,405] {logging_mixin.py:115} INFO - [2022-06-06 09:03:52,405] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:03:52,462] {logging_mixin.py:115} INFO - [2022-06-06 09:03:52,460] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:03:52,463] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:03:52,562] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 09:04:23,441] {processor.py:153} INFO - Started process (PID=67594) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:04:23,443] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:04:23,444] {logging_mixin.py:115} INFO - [2022-06-06 09:04:23,444] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:04:23,490] {logging_mixin.py:115} INFO - [2022-06-06 09:04:23,488] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:04:23,492] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:04:23,588] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 09:04:53,704] {processor.py:153} INFO - Started process (PID=67650) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:04:53,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:04:53,708] {logging_mixin.py:115} INFO - [2022-06-06 09:04:53,708] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:04:53,760] {logging_mixin.py:115} INFO - [2022-06-06 09:04:53,757] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:04:53,761] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:04:53,875] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 09:05:24,507] {processor.py:153} INFO - Started process (PID=67719) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:05:24,509] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:05:24,510] {logging_mixin.py:115} INFO - [2022-06-06 09:05:24,510] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:05:24,559] {logging_mixin.py:115} INFO - [2022-06-06 09:05:24,557] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:05:24,560] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:05:24,664] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 09:05:55,287] {processor.py:153} INFO - Started process (PID=67788) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:05:55,291] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:05:55,293] {logging_mixin.py:115} INFO - [2022-06-06 09:05:55,293] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:05:55,354] {logging_mixin.py:115} INFO - [2022-06-06 09:05:55,352] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:05:55,354] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:05:55,451] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 09:06:26,400] {processor.py:153} INFO - Started process (PID=67854) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:06:26,404] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:06:26,406] {logging_mixin.py:115} INFO - [2022-06-06 09:06:26,406] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:06:26,459] {logging_mixin.py:115} INFO - [2022-06-06 09:06:26,457] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:06:26,461] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:06:26,557] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 09:06:56,861] {processor.py:153} INFO - Started process (PID=67922) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:06:56,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:06:56,868] {logging_mixin.py:115} INFO - [2022-06-06 09:06:56,868] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:06:56,935] {logging_mixin.py:115} INFO - [2022-06-06 09:06:56,933] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:06:56,936] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:06:57,035] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 09:07:27,213] {processor.py:153} INFO - Started process (PID=67993) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:07:27,215] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:07:27,216] {logging_mixin.py:115} INFO - [2022-06-06 09:07:27,216] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:07:27,267] {logging_mixin.py:115} INFO - [2022-06-06 09:07:27,264] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:07:27,269] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:07:27,383] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 09:07:57,508] {processor.py:153} INFO - Started process (PID=68051) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:07:57,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:07:57,514] {logging_mixin.py:115} INFO - [2022-06-06 09:07:57,514] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:07:57,577] {logging_mixin.py:115} INFO - [2022-06-06 09:07:57,574] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:07:57,579] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:07:57,684] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 09:08:27,793] {processor.py:153} INFO - Started process (PID=68121) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:08:27,795] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:08:27,797] {logging_mixin.py:115} INFO - [2022-06-06 09:08:27,797] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:08:27,851] {logging_mixin.py:115} INFO - [2022-06-06 09:08:27,849] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:08:27,852] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:08:27,947] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 09:08:58,141] {processor.py:153} INFO - Started process (PID=68188) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:08:58,143] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:08:58,144] {logging_mixin.py:115} INFO - [2022-06-06 09:08:58,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:08:58,195] {logging_mixin.py:115} INFO - [2022-06-06 09:08:58,193] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:08:58,197] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:08:58,304] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 09:09:28,606] {processor.py:153} INFO - Started process (PID=68256) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:09:28,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:09:28,610] {logging_mixin.py:115} INFO - [2022-06-06 09:09:28,610] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:09:28,663] {logging_mixin.py:115} INFO - [2022-06-06 09:09:28,661] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:09:28,664] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:09:28,766] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 09:09:59,339] {processor.py:153} INFO - Started process (PID=68321) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:09:59,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:09:59,342] {logging_mixin.py:115} INFO - [2022-06-06 09:09:59,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:09:59,392] {logging_mixin.py:115} INFO - [2022-06-06 09:09:59,390] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:09:59,394] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:09:59,503] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 09:10:29,855] {processor.py:153} INFO - Started process (PID=68382) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:10:29,857] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:10:29,858] {logging_mixin.py:115} INFO - [2022-06-06 09:10:29,858] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:10:29,908] {logging_mixin.py:115} INFO - [2022-06-06 09:10:29,906] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:10:29,909] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:10:30,013] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 09:11:00,161] {processor.py:153} INFO - Started process (PID=68450) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:11:00,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:11:00,167] {logging_mixin.py:115} INFO - [2022-06-06 09:11:00,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:11:00,238] {logging_mixin.py:115} INFO - [2022-06-06 09:11:00,235] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:11:00,239] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:11:00,335] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 09:11:30,666] {processor.py:153} INFO - Started process (PID=68518) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:11:30,669] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:11:30,671] {logging_mixin.py:115} INFO - [2022-06-06 09:11:30,671] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:11:30,729] {logging_mixin.py:115} INFO - [2022-06-06 09:11:30,727] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:11:30,730] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:11:30,825] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 09:12:01,037] {processor.py:153} INFO - Started process (PID=68587) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:12:01,039] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:12:01,041] {logging_mixin.py:115} INFO - [2022-06-06 09:12:01,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:12:01,091] {logging_mixin.py:115} INFO - [2022-06-06 09:12:01,089] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:12:01,093] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:12:01,188] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 09:12:31,521] {processor.py:153} INFO - Started process (PID=68655) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:12:31,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:12:31,525] {logging_mixin.py:115} INFO - [2022-06-06 09:12:31,525] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:12:31,576] {logging_mixin.py:115} INFO - [2022-06-06 09:12:31,573] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:12:31,578] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:12:31,693] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 09:13:02,036] {processor.py:153} INFO - Started process (PID=68713) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:13:02,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:13:02,040] {logging_mixin.py:115} INFO - [2022-06-06 09:13:02,040] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:13:02,092] {logging_mixin.py:115} INFO - [2022-06-06 09:13:02,089] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:13:02,094] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:13:02,201] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 09:13:32,765] {processor.py:153} INFO - Started process (PID=68780) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:13:32,768] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:13:32,769] {logging_mixin.py:115} INFO - [2022-06-06 09:13:32,769] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:13:32,822] {logging_mixin.py:115} INFO - [2022-06-06 09:13:32,820] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:13:32,823] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:13:32,917] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 09:14:03,002] {processor.py:153} INFO - Started process (PID=68848) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:14:03,006] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:14:03,024] {logging_mixin.py:115} INFO - [2022-06-06 09:14:03,024] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:14:03,089] {logging_mixin.py:115} INFO - [2022-06-06 09:14:03,087] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:14:03,091] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:14:03,197] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-06 09:14:33,641] {processor.py:153} INFO - Started process (PID=68914) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:14:33,643] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:14:33,644] {logging_mixin.py:115} INFO - [2022-06-06 09:14:33,644] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:14:33,703] {logging_mixin.py:115} INFO - [2022-06-06 09:14:33,701] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:14:33,706] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:14:33,805] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 09:15:04,201] {processor.py:153} INFO - Started process (PID=68972) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:15:04,204] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:15:04,206] {logging_mixin.py:115} INFO - [2022-06-06 09:15:04,206] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:15:04,266] {logging_mixin.py:115} INFO - [2022-06-06 09:15:04,263] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:15:04,267] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:15:04,371] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 09:15:35,274] {processor.py:153} INFO - Started process (PID=69042) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:15:35,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:15:35,276] {logging_mixin.py:115} INFO - [2022-06-06 09:15:35,276] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:15:35,328] {logging_mixin.py:115} INFO - [2022-06-06 09:15:35,326] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:15:35,329] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:15:35,425] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 09:16:05,998] {processor.py:153} INFO - Started process (PID=69110) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:16:06,003] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:16:06,005] {logging_mixin.py:115} INFO - [2022-06-06 09:16:06,005] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:16:06,087] {logging_mixin.py:115} INFO - [2022-06-06 09:16:06,084] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:16:06,087] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:16:06,185] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-06 09:16:36,874] {processor.py:153} INFO - Started process (PID=69178) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:16:36,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:16:36,877] {logging_mixin.py:115} INFO - [2022-06-06 09:16:36,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:16:36,923] {logging_mixin.py:115} INFO - [2022-06-06 09:16:36,920] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:16:36,925] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:16:37,020] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 09:17:07,863] {processor.py:153} INFO - Started process (PID=69249) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:17:07,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:17:07,870] {logging_mixin.py:115} INFO - [2022-06-06 09:17:07,870] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:17:07,927] {logging_mixin.py:115} INFO - [2022-06-06 09:17:07,925] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:17:07,929] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:17:08,026] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 09:17:38,131] {processor.py:153} INFO - Started process (PID=69317) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:17:38,132] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:17:38,135] {logging_mixin.py:115} INFO - [2022-06-06 09:17:38,135] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:17:38,192] {logging_mixin.py:115} INFO - [2022-06-06 09:17:38,189] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:17:38,194] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:17:38,314] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 09:18:09,213] {processor.py:153} INFO - Started process (PID=69373) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:18:09,216] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:18:09,218] {logging_mixin.py:115} INFO - [2022-06-06 09:18:09,218] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:18:09,280] {logging_mixin.py:115} INFO - [2022-06-06 09:18:09,278] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:18:09,281] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:18:09,381] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 09:18:40,008] {processor.py:153} INFO - Started process (PID=69440) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:18:40,009] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:18:40,010] {logging_mixin.py:115} INFO - [2022-06-06 09:18:40,010] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:18:40,055] {logging_mixin.py:115} INFO - [2022-06-06 09:18:40,053] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:18:40,056] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:18:40,155] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 09:19:10,724] {processor.py:153} INFO - Started process (PID=69510) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:19:10,727] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:19:10,729] {logging_mixin.py:115} INFO - [2022-06-06 09:19:10,729] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:19:10,786] {logging_mixin.py:115} INFO - [2022-06-06 09:19:10,784] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:19:10,789] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:19:10,888] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 09:19:40,981] {processor.py:153} INFO - Started process (PID=69579) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:19:40,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:19:40,986] {logging_mixin.py:115} INFO - [2022-06-06 09:19:40,986] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:19:41,044] {logging_mixin.py:115} INFO - [2022-06-06 09:19:41,042] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:19:41,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:19:41,157] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 09:20:11,236] {processor.py:153} INFO - Started process (PID=69645) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:20:11,238] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:20:11,239] {logging_mixin.py:115} INFO - [2022-06-06 09:20:11,239] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:20:11,283] {logging_mixin.py:115} INFO - [2022-06-06 09:20:11,281] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:20:11,285] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:20:11,380] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 09:20:41,489] {processor.py:153} INFO - Started process (PID=69714) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:20:41,492] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:20:41,493] {logging_mixin.py:115} INFO - [2022-06-06 09:20:41,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:20:41,545] {logging_mixin.py:115} INFO - [2022-06-06 09:20:41,543] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:20:41,547] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:20:41,665] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 09:21:11,718] {processor.py:153} INFO - Started process (PID=69774) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:21:11,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:21:11,721] {logging_mixin.py:115} INFO - [2022-06-06 09:21:11,721] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:21:11,777] {logging_mixin.py:115} INFO - [2022-06-06 09:21:11,774] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:21:11,779] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:21:11,873] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 09:21:42,413] {processor.py:153} INFO - Started process (PID=69840) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:21:42,416] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:21:42,417] {logging_mixin.py:115} INFO - [2022-06-06 09:21:42,417] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:21:42,471] {logging_mixin.py:115} INFO - [2022-06-06 09:21:42,468] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:21:42,472] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:21:42,567] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 09:22:12,840] {processor.py:153} INFO - Started process (PID=69909) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:22:12,842] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:22:12,844] {logging_mixin.py:115} INFO - [2022-06-06 09:22:12,844] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:22:12,901] {logging_mixin.py:115} INFO - [2022-06-06 09:22:12,898] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:22:12,903] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:22:12,999] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 09:22:43,378] {processor.py:153} INFO - Started process (PID=69976) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:22:43,380] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:22:43,381] {logging_mixin.py:115} INFO - [2022-06-06 09:22:43,381] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:22:43,430] {logging_mixin.py:115} INFO - [2022-06-06 09:22:43,427] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:22:43,433] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:22:43,567] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 09:23:13,785] {processor.py:153} INFO - Started process (PID=70035) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:23:13,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:23:13,795] {logging_mixin.py:115} INFO - [2022-06-06 09:23:13,795] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:23:13,897] {logging_mixin.py:115} INFO - [2022-06-06 09:23:13,892] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:23:13,904] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:23:14,042] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.261 seconds
[2022-06-06 09:23:44,147] {processor.py:153} INFO - Started process (PID=70102) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:23:44,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:23:44,150] {logging_mixin.py:115} INFO - [2022-06-06 09:23:44,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:23:44,197] {logging_mixin.py:115} INFO - [2022-06-06 09:23:44,195] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:23:44,199] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:23:44,300] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 09:24:14,652] {processor.py:153} INFO - Started process (PID=70169) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:24:14,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:24:14,657] {logging_mixin.py:115} INFO - [2022-06-06 09:24:14,657] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:24:14,767] {logging_mixin.py:115} INFO - [2022-06-06 09:24:14,764] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:24:14,771] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:24:14,896] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.250 seconds
[2022-06-06 09:24:44,972] {processor.py:153} INFO - Started process (PID=70237) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:24:44,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:24:44,974] {logging_mixin.py:115} INFO - [2022-06-06 09:24:44,974] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:24:45,021] {logging_mixin.py:115} INFO - [2022-06-06 09:24:45,018] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:24:45,022] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:24:45,119] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 09:25:15,987] {processor.py:153} INFO - Started process (PID=70304) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:25:15,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:25:15,990] {logging_mixin.py:115} INFO - [2022-06-06 09:25:15,990] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:25:16,051] {logging_mixin.py:115} INFO - [2022-06-06 09:25:16,048] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:25:16,054] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:25:16,173] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-06 09:25:47,067] {processor.py:153} INFO - Started process (PID=70362) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:25:47,087] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:25:47,121] {logging_mixin.py:115} INFO - [2022-06-06 09:25:47,121] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:25:47,187] {logging_mixin.py:115} INFO - [2022-06-06 09:25:47,185] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:25:47,188] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:25:47,281] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-06 09:26:17,639] {processor.py:153} INFO - Started process (PID=70431) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:26:17,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:26:17,641] {logging_mixin.py:115} INFO - [2022-06-06 09:26:17,641] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:26:17,686] {logging_mixin.py:115} INFO - [2022-06-06 09:26:17,685] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:26:17,688] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:26:17,790] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 09:26:47,875] {processor.py:153} INFO - Started process (PID=70501) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:26:47,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:26:47,877] {logging_mixin.py:115} INFO - [2022-06-06 09:26:47,877] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:26:47,920] {logging_mixin.py:115} INFO - [2022-06-06 09:26:47,918] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:26:47,921] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:26:48,014] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.142 seconds
[2022-06-06 09:27:18,644] {processor.py:153} INFO - Started process (PID=70570) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:27:18,648] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:27:18,649] {logging_mixin.py:115} INFO - [2022-06-06 09:27:18,649] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:27:18,700] {logging_mixin.py:115} INFO - [2022-06-06 09:27:18,698] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:27:18,701] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:27:18,795] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 09:27:49,381] {processor.py:153} INFO - Started process (PID=70639) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:27:49,388] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:27:49,392] {logging_mixin.py:115} INFO - [2022-06-06 09:27:49,391] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:27:49,457] {logging_mixin.py:115} INFO - [2022-06-06 09:27:49,454] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:27:49,459] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:27:49,560] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 09:28:20,561] {processor.py:153} INFO - Started process (PID=70706) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:28:20,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:28:20,564] {logging_mixin.py:115} INFO - [2022-06-06 09:28:20,563] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:28:20,620] {logging_mixin.py:115} INFO - [2022-06-06 09:28:20,618] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:28:20,621] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:28:20,723] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 09:28:50,877] {processor.py:153} INFO - Started process (PID=70763) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:28:50,879] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:28:50,880] {logging_mixin.py:115} INFO - [2022-06-06 09:28:50,880] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:28:50,923] {logging_mixin.py:115} INFO - [2022-06-06 09:28:50,921] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:28:50,925] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:28:51,020] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-06 09:29:21,092] {processor.py:153} INFO - Started process (PID=70831) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:29:21,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:29:21,095] {logging_mixin.py:115} INFO - [2022-06-06 09:29:21,095] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:29:21,155] {logging_mixin.py:115} INFO - [2022-06-06 09:29:21,151] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:29:21,158] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:29:21,280] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-06 09:29:51,390] {processor.py:153} INFO - Started process (PID=70898) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:29:51,395] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:29:51,398] {logging_mixin.py:115} INFO - [2022-06-06 09:29:51,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:29:51,476] {logging_mixin.py:115} INFO - [2022-06-06 09:29:51,472] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:29:51,478] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:29:51,585] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-06 09:30:22,228] {processor.py:153} INFO - Started process (PID=70966) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:30:22,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:30:22,230] {logging_mixin.py:115} INFO - [2022-06-06 09:30:22,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:30:22,300] {logging_mixin.py:115} INFO - [2022-06-06 09:30:22,296] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:30:22,303] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:30:22,464] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-06 09:30:53,186] {processor.py:153} INFO - Started process (PID=71032) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:30:53,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:30:53,189] {logging_mixin.py:115} INFO - [2022-06-06 09:30:53,189] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:30:53,249] {logging_mixin.py:115} INFO - [2022-06-06 09:30:53,246] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:30:53,251] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:30:53,361] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 09:31:23,511] {processor.py:153} INFO - Started process (PID=71091) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:31:23,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:31:23,516] {logging_mixin.py:115} INFO - [2022-06-06 09:31:23,516] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:31:23,578] {logging_mixin.py:115} INFO - [2022-06-06 09:31:23,576] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:31:23,579] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:31:23,673] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 09:31:54,426] {processor.py:153} INFO - Started process (PID=71158) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:31:54,428] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:31:54,429] {logging_mixin.py:115} INFO - [2022-06-06 09:31:54,429] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:31:54,472] {logging_mixin.py:115} INFO - [2022-06-06 09:31:54,470] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:31:54,474] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:31:54,568] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-06 09:32:25,479] {processor.py:153} INFO - Started process (PID=71226) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:32:25,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:32:25,482] {logging_mixin.py:115} INFO - [2022-06-06 09:32:25,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:32:25,573] {logging_mixin.py:115} INFO - [2022-06-06 09:32:25,570] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:32:25,574] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:32:25,678] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 09:32:56,465] {processor.py:153} INFO - Started process (PID=71294) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:32:56,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:32:56,468] {logging_mixin.py:115} INFO - [2022-06-06 09:32:56,468] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:32:56,527] {logging_mixin.py:115} INFO - [2022-06-06 09:32:56,525] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:32:56,528] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:32:56,622] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 09:33:27,154] {processor.py:153} INFO - Started process (PID=71362) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:33:27,157] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:33:27,159] {logging_mixin.py:115} INFO - [2022-06-06 09:33:27,159] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:33:27,212] {logging_mixin.py:115} INFO - [2022-06-06 09:33:27,209] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:33:27,214] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:33:27,306] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 09:33:57,777] {processor.py:153} INFO - Started process (PID=71431) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:33:57,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:33:57,779] {logging_mixin.py:115} INFO - [2022-06-06 09:33:57,779] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:33:57,826] {logging_mixin.py:115} INFO - [2022-06-06 09:33:57,824] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:33:57,827] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:33:57,930] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 09:34:28,667] {processor.py:153} INFO - Started process (PID=71488) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:34:28,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:34:28,672] {logging_mixin.py:115} INFO - [2022-06-06 09:34:28,672] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:34:28,729] {logging_mixin.py:115} INFO - [2022-06-06 09:34:28,727] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:34:28,731] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:34:28,827] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 09:34:59,300] {processor.py:153} INFO - Started process (PID=71556) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:34:59,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:34:59,303] {logging_mixin.py:115} INFO - [2022-06-06 09:34:59,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:34:59,350] {logging_mixin.py:115} INFO - [2022-06-06 09:34:59,348] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:34:59,352] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:34:59,473] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 09:35:29,926] {processor.py:153} INFO - Started process (PID=71626) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:35:29,928] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:35:29,929] {logging_mixin.py:115} INFO - [2022-06-06 09:35:29,929] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:35:29,976] {logging_mixin.py:115} INFO - [2022-06-06 09:35:29,974] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:35:29,978] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:35:30,084] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 09:36:00,592] {processor.py:153} INFO - Started process (PID=71694) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:36:00,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:36:00,597] {logging_mixin.py:115} INFO - [2022-06-06 09:36:00,597] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:36:00,665] {logging_mixin.py:115} INFO - [2022-06-06 09:36:00,663] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:36:00,666] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:36:00,762] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 09:36:31,025] {processor.py:153} INFO - Started process (PID=71763) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:36:31,027] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:36:31,030] {logging_mixin.py:115} INFO - [2022-06-06 09:36:31,030] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:36:31,153] {logging_mixin.py:115} INFO - [2022-06-06 09:36:31,148] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:36:31,156] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:36:31,294] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.273 seconds
[2022-06-06 09:37:01,692] {processor.py:153} INFO - Started process (PID=71821) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:37:01,694] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:37:01,695] {logging_mixin.py:115} INFO - [2022-06-06 09:37:01,695] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:37:01,760] {logging_mixin.py:115} INFO - [2022-06-06 09:37:01,758] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:37:01,761] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:37:01,860] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 09:37:32,143] {processor.py:153} INFO - Started process (PID=71891) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:37:32,145] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:37:32,146] {logging_mixin.py:115} INFO - [2022-06-06 09:37:32,146] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:37:32,199] {logging_mixin.py:115} INFO - [2022-06-06 09:37:32,196] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:37:32,201] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:37:32,311] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 09:38:02,389] {processor.py:153} INFO - Started process (PID=71959) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:38:02,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:38:02,398] {logging_mixin.py:115} INFO - [2022-06-06 09:38:02,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:38:02,451] {logging_mixin.py:115} INFO - [2022-06-06 09:38:02,449] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:38:02,452] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:38:02,551] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 09:38:32,815] {processor.py:153} INFO - Started process (PID=72027) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:38:32,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:38:32,817] {logging_mixin.py:115} INFO - [2022-06-06 09:38:32,817] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:38:32,871] {logging_mixin.py:115} INFO - [2022-06-06 09:38:32,869] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:38:32,873] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:38:32,975] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 09:39:03,272] {processor.py:153} INFO - Started process (PID=72097) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:39:03,274] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:39:03,276] {logging_mixin.py:115} INFO - [2022-06-06 09:39:03,276] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:39:03,335] {logging_mixin.py:115} INFO - [2022-06-06 09:39:03,331] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:39:03,336] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:39:03,432] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 09:39:33,502] {processor.py:153} INFO - Started process (PID=72154) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:39:33,504] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:39:33,507] {logging_mixin.py:115} INFO - [2022-06-06 09:39:33,506] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:39:33,604] {logging_mixin.py:115} INFO - [2022-06-06 09:39:33,602] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:39:33,607] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:39:33,738] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-06 09:40:03,865] {processor.py:153} INFO - Started process (PID=72223) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:40:03,867] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:40:03,869] {logging_mixin.py:115} INFO - [2022-06-06 09:40:03,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:40:03,943] {logging_mixin.py:115} INFO - [2022-06-06 09:40:03,941] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:40:03,944] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:40:04,041] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 09:40:34,447] {processor.py:153} INFO - Started process (PID=72292) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:40:34,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:40:34,451] {logging_mixin.py:115} INFO - [2022-06-06 09:40:34,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:40:34,501] {logging_mixin.py:115} INFO - [2022-06-06 09:40:34,498] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:40:34,502] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:40:34,602] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 09:41:04,924] {processor.py:153} INFO - Started process (PID=72359) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:41:04,927] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:41:04,931] {logging_mixin.py:115} INFO - [2022-06-06 09:41:04,931] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:41:04,979] {logging_mixin.py:115} INFO - [2022-06-06 09:41:04,977] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:41:04,980] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:41:05,075] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 09:41:35,506] {processor.py:153} INFO - Started process (PID=72425) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:41:35,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:41:35,509] {logging_mixin.py:115} INFO - [2022-06-06 09:41:35,509] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:41:35,557] {logging_mixin.py:115} INFO - [2022-06-06 09:41:35,555] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:41:35,559] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:41:35,665] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 09:42:05,990] {processor.py:153} INFO - Started process (PID=72482) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:42:05,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:42:05,992] {logging_mixin.py:115} INFO - [2022-06-06 09:42:05,992] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:42:06,084] {logging_mixin.py:115} INFO - [2022-06-06 09:42:06,079] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:42:06,086] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:42:06,205] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-06 09:42:36,975] {processor.py:153} INFO - Started process (PID=72549) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:42:36,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:42:36,978] {logging_mixin.py:115} INFO - [2022-06-06 09:42:36,978] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:42:37,037] {logging_mixin.py:115} INFO - [2022-06-06 09:42:37,034] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:42:37,038] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:42:37,134] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 09:43:07,457] {processor.py:153} INFO - Started process (PID=72617) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:43:07,460] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:43:07,462] {logging_mixin.py:115} INFO - [2022-06-06 09:43:07,462] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:43:07,530] {logging_mixin.py:115} INFO - [2022-06-06 09:43:07,528] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:43:07,533] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:43:07,630] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 09:43:38,148] {processor.py:153} INFO - Started process (PID=72686) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:43:38,152] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:43:38,154] {logging_mixin.py:115} INFO - [2022-06-06 09:43:38,154] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:43:38,217] {logging_mixin.py:115} INFO - [2022-06-06 09:43:38,215] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:43:38,218] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:43:38,312] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 09:44:09,169] {processor.py:153} INFO - Started process (PID=72753) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:44:09,172] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:44:09,174] {logging_mixin.py:115} INFO - [2022-06-06 09:44:09,174] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:44:09,238] {logging_mixin.py:115} INFO - [2022-06-06 09:44:09,236] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:44:09,239] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:44:09,334] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 09:44:39,543] {processor.py:153} INFO - Started process (PID=72812) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:44:39,545] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:44:39,546] {logging_mixin.py:115} INFO - [2022-06-06 09:44:39,546] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:44:39,619] {logging_mixin.py:115} INFO - [2022-06-06 09:44:39,616] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:44:39,621] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:44:39,728] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 09:45:10,057] {processor.py:153} INFO - Started process (PID=72880) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:45:10,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:45:10,060] {logging_mixin.py:115} INFO - [2022-06-06 09:45:10,060] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:45:10,127] {logging_mixin.py:115} INFO - [2022-06-06 09:45:10,124] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:45:10,129] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:45:10,226] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 09:45:40,312] {processor.py:153} INFO - Started process (PID=72947) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:45:40,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:45:40,324] {logging_mixin.py:115} INFO - [2022-06-06 09:45:40,324] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:45:40,410] {logging_mixin.py:115} INFO - [2022-06-06 09:45:40,406] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:45:40,411] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:45:40,517] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-06 09:46:10,569] {processor.py:153} INFO - Started process (PID=73012) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:46:10,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:46:10,573] {logging_mixin.py:115} INFO - [2022-06-06 09:46:10,573] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:46:10,630] {logging_mixin.py:115} INFO - [2022-06-06 09:46:10,626] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:46:10,632] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:46:10,728] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 09:46:41,062] {processor.py:153} INFO - Started process (PID=73080) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:46:41,065] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:46:41,066] {logging_mixin.py:115} INFO - [2022-06-06 09:46:41,066] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:46:41,122] {logging_mixin.py:115} INFO - [2022-06-06 09:46:41,120] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:46:41,123] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:46:41,220] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 09:47:11,664] {processor.py:153} INFO - Started process (PID=73135) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:47:11,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:47:11,668] {logging_mixin.py:115} INFO - [2022-06-06 09:47:11,668] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:47:11,746] {logging_mixin.py:115} INFO - [2022-06-06 09:47:11,744] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:47:11,747] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:47:11,847] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 09:47:41,910] {processor.py:153} INFO - Started process (PID=73203) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:47:41,914] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:47:41,916] {logging_mixin.py:115} INFO - [2022-06-06 09:47:41,916] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:47:41,982] {logging_mixin.py:115} INFO - [2022-06-06 09:47:41,979] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:47:41,983] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:47:42,077] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 09:48:12,929] {processor.py:153} INFO - Started process (PID=73271) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:48:12,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:48:12,934] {logging_mixin.py:115} INFO - [2022-06-06 09:48:12,934] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:48:12,989] {logging_mixin.py:115} INFO - [2022-06-06 09:48:12,987] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:48:12,990] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:48:13,083] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 09:48:43,348] {processor.py:153} INFO - Started process (PID=73338) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:48:43,350] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:48:43,351] {logging_mixin.py:115} INFO - [2022-06-06 09:48:43,351] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:48:43,399] {logging_mixin.py:115} INFO - [2022-06-06 09:48:43,396] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:48:43,401] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:48:43,494] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 09:49:14,087] {processor.py:153} INFO - Started process (PID=73405) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:49:14,090] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:49:14,092] {logging_mixin.py:115} INFO - [2022-06-06 09:49:14,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:49:14,154] {logging_mixin.py:115} INFO - [2022-06-06 09:49:14,152] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:49:14,155] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:49:14,250] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 09:49:44,525] {processor.py:153} INFO - Started process (PID=73464) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:49:44,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:49:44,536] {logging_mixin.py:115} INFO - [2022-06-06 09:49:44,536] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:49:44,602] {logging_mixin.py:115} INFO - [2022-06-06 09:49:44,600] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:49:44,604] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:49:44,705] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 09:50:15,513] {processor.py:153} INFO - Started process (PID=73531) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:50:15,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:50:15,516] {logging_mixin.py:115} INFO - [2022-06-06 09:50:15,516] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:50:15,571] {logging_mixin.py:115} INFO - [2022-06-06 09:50:15,568] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:50:15,573] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:50:15,684] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 09:50:46,153] {processor.py:153} INFO - Started process (PID=73599) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:50:46,156] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:50:46,157] {logging_mixin.py:115} INFO - [2022-06-06 09:50:46,157] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:50:46,221] {logging_mixin.py:115} INFO - [2022-06-06 09:50:46,219] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:50:46,223] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:50:46,315] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 09:51:16,749] {processor.py:153} INFO - Started process (PID=73665) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:51:16,752] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:51:16,753] {logging_mixin.py:115} INFO - [2022-06-06 09:51:16,753] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:51:16,805] {logging_mixin.py:115} INFO - [2022-06-06 09:51:16,803] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:51:16,806] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:51:16,900] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 09:51:47,430] {processor.py:153} INFO - Started process (PID=73735) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:51:47,432] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:51:47,434] {logging_mixin.py:115} INFO - [2022-06-06 09:51:47,434] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:51:47,495] {logging_mixin.py:115} INFO - [2022-06-06 09:51:47,491] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:51:47,497] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:51:47,603] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 09:52:18,082] {processor.py:153} INFO - Started process (PID=73805) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:52:18,084] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:52:18,085] {logging_mixin.py:115} INFO - [2022-06-06 09:52:18,085] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:52:18,136] {logging_mixin.py:115} INFO - [2022-06-06 09:52:18,134] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:52:18,137] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:52:18,244] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 09:52:48,882] {processor.py:153} INFO - Started process (PID=73863) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:52:48,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:52:48,895] {logging_mixin.py:115} INFO - [2022-06-06 09:52:48,895] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:52:48,972] {logging_mixin.py:115} INFO - [2022-06-06 09:52:48,970] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:52:48,974] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:52:49,123] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-06 09:53:19,709] {processor.py:153} INFO - Started process (PID=73930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:53:19,711] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:53:19,712] {logging_mixin.py:115} INFO - [2022-06-06 09:53:19,712] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:53:19,766] {logging_mixin.py:115} INFO - [2022-06-06 09:53:19,764] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:53:19,767] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:53:19,871] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 09:53:50,496] {processor.py:153} INFO - Started process (PID=73996) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:53:50,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:53:50,500] {logging_mixin.py:115} INFO - [2022-06-06 09:53:50,500] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:53:50,568] {logging_mixin.py:115} INFO - [2022-06-06 09:53:50,565] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:53:50,569] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:53:50,669] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 09:54:21,666] {processor.py:153} INFO - Started process (PID=74063) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:54:21,667] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:54:21,668] {logging_mixin.py:115} INFO - [2022-06-06 09:54:21,668] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:54:21,713] {logging_mixin.py:115} INFO - [2022-06-06 09:54:21,710] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:54:21,714] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:54:21,815] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 09:54:52,626] {processor.py:153} INFO - Started process (PID=74130) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:54:52,629] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:54:52,631] {logging_mixin.py:115} INFO - [2022-06-06 09:54:52,631] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:54:52,686] {logging_mixin.py:115} INFO - [2022-06-06 09:54:52,684] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:54:52,687] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:54:52,786] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 09:55:23,136] {processor.py:153} INFO - Started process (PID=74196) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:55:23,139] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:55:23,141] {logging_mixin.py:115} INFO - [2022-06-06 09:55:23,141] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:55:23,218] {logging_mixin.py:115} INFO - [2022-06-06 09:55:23,216] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:55:23,219] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:55:23,320] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 09:55:53,985] {processor.py:153} INFO - Started process (PID=74262) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:55:53,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:55:53,988] {logging_mixin.py:115} INFO - [2022-06-06 09:55:53,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:55:54,042] {logging_mixin.py:115} INFO - [2022-06-06 09:55:54,040] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:55:54,043] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:55:54,176] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-06 09:56:24,607] {processor.py:153} INFO - Started process (PID=74321) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:56:24,609] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:56:24,611] {logging_mixin.py:115} INFO - [2022-06-06 09:56:24,611] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:56:24,675] {logging_mixin.py:115} INFO - [2022-06-06 09:56:24,671] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:56:24,681] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:56:24,805] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 09:56:55,563] {processor.py:153} INFO - Started process (PID=74388) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:56:55,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:56:55,568] {logging_mixin.py:115} INFO - [2022-06-06 09:56:55,568] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:56:55,632] {logging_mixin.py:115} INFO - [2022-06-06 09:56:55,630] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:56:55,633] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:56:55,725] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 09:57:26,125] {processor.py:153} INFO - Started process (PID=74456) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:57:26,136] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:57:26,137] {logging_mixin.py:115} INFO - [2022-06-06 09:57:26,137] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:57:26,194] {logging_mixin.py:115} INFO - [2022-06-06 09:57:26,191] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:57:26,196] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:57:26,307] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 09:57:56,896] {processor.py:153} INFO - Started process (PID=74524) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:57:56,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:57:56,903] {logging_mixin.py:115} INFO - [2022-06-06 09:57:56,903] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:57:56,973] {logging_mixin.py:115} INFO - [2022-06-06 09:57:56,971] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:57:56,974] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:57:57,068] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 09:58:27,656] {processor.py:153} INFO - Started process (PID=74592) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:58:27,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:58:27,663] {logging_mixin.py:115} INFO - [2022-06-06 09:58:27,663] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:58:27,716] {logging_mixin.py:115} INFO - [2022-06-06 09:58:27,714] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:58:27,718] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:58:27,815] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 09:58:58,243] {processor.py:153} INFO - Started process (PID=74660) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:58:58,245] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:58:58,246] {logging_mixin.py:115} INFO - [2022-06-06 09:58:58,246] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:58:58,293] {logging_mixin.py:115} INFO - [2022-06-06 09:58:58,291] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:58:58,295] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:58:58,396] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 09:59:28,774] {processor.py:153} INFO - Started process (PID=74719) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:59:28,776] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:59:28,777] {logging_mixin.py:115} INFO - [2022-06-06 09:59:28,777] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:59:28,838] {logging_mixin.py:115} INFO - [2022-06-06 09:59:28,835] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:59:28,840] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:59:28,942] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 09:59:59,572] {processor.py:153} INFO - Started process (PID=74785) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:59:59,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 09:59:59,575] {logging_mixin.py:115} INFO - [2022-06-06 09:59:59,574] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:59:59,624] {logging_mixin.py:115} INFO - [2022-06-06 09:59:59,623] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 09:59:59,626] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 09:59:59,720] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 10:00:30,166] {processor.py:153} INFO - Started process (PID=74855) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:00:30,170] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:00:30,171] {logging_mixin.py:115} INFO - [2022-06-06 10:00:30,171] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:00:30,216] {logging_mixin.py:115} INFO - [2022-06-06 10:00:30,214] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:00:30,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:00:30,310] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 10:01:01,049] {processor.py:153} INFO - Started process (PID=74923) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:01:01,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:01:01,058] {logging_mixin.py:115} INFO - [2022-06-06 10:01:01,058] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:01:01,115] {logging_mixin.py:115} INFO - [2022-06-06 10:01:01,113] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:01:01,116] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:01:01,211] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 10:01:31,737] {processor.py:153} INFO - Started process (PID=74991) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:01:31,739] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:01:31,743] {logging_mixin.py:115} INFO - [2022-06-06 10:01:31,743] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:01:31,803] {logging_mixin.py:115} INFO - [2022-06-06 10:01:31,801] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:01:31,804] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:01:31,899] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 10:02:02,447] {processor.py:153} INFO - Started process (PID=75059) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:02:02,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:02:02,451] {logging_mixin.py:115} INFO - [2022-06-06 10:02:02,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:02:02,527] {logging_mixin.py:115} INFO - [2022-06-06 10:02:02,525] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:02:02,529] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:02:02,657] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-06 10:02:33,198] {processor.py:153} INFO - Started process (PID=75116) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:02:33,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:02:33,202] {logging_mixin.py:115} INFO - [2022-06-06 10:02:33,202] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:02:33,275] {logging_mixin.py:115} INFO - [2022-06-06 10:02:33,271] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:02:33,276] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:02:33,394] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-06 10:03:04,020] {processor.py:153} INFO - Started process (PID=75185) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:03:04,023] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:03:04,024] {logging_mixin.py:115} INFO - [2022-06-06 10:03:04,024] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:03:04,075] {logging_mixin.py:115} INFO - [2022-06-06 10:03:04,071] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:03:04,077] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:03:04,184] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 10:03:34,456] {processor.py:153} INFO - Started process (PID=75251) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:03:34,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:03:34,461] {logging_mixin.py:115} INFO - [2022-06-06 10:03:34,461] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:03:34,510] {logging_mixin.py:115} INFO - [2022-06-06 10:03:34,508] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:03:34,511] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:03:34,606] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 10:04:04,796] {processor.py:153} INFO - Started process (PID=75319) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:04:04,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:04:04,800] {logging_mixin.py:115} INFO - [2022-06-06 10:04:04,800] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:04:04,862] {logging_mixin.py:115} INFO - [2022-06-06 10:04:04,860] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:04:04,864] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:04:04,958] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 10:04:35,714] {processor.py:153} INFO - Started process (PID=75385) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:04:35,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:04:35,719] {logging_mixin.py:115} INFO - [2022-06-06 10:04:35,719] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:04:35,781] {logging_mixin.py:115} INFO - [2022-06-06 10:04:35,779] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:04:35,782] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:04:35,877] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 10:05:06,514] {processor.py:153} INFO - Started process (PID=75448) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:05:06,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:05:06,517] {logging_mixin.py:115} INFO - [2022-06-06 10:05:06,517] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:05:06,568] {logging_mixin.py:115} INFO - [2022-06-06 10:05:06,565] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:05:06,571] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:05:06,676] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 10:05:36,963] {processor.py:153} INFO - Started process (PID=75508) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:05:36,965] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:05:36,966] {logging_mixin.py:115} INFO - [2022-06-06 10:05:36,966] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:05:37,015] {logging_mixin.py:115} INFO - [2022-06-06 10:05:37,013] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:05:37,016] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:05:37,133] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 10:06:07,808] {processor.py:153} INFO - Started process (PID=75576) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:06:07,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:06:07,814] {logging_mixin.py:115} INFO - [2022-06-06 10:06:07,814] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:06:07,871] {logging_mixin.py:115} INFO - [2022-06-06 10:06:07,869] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:06:07,873] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:06:07,973] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 10:06:38,053] {processor.py:153} INFO - Started process (PID=75645) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:06:38,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:06:38,057] {logging_mixin.py:115} INFO - [2022-06-06 10:06:38,056] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:06:38,120] {logging_mixin.py:115} INFO - [2022-06-06 10:06:38,116] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:06:38,121] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:06:38,221] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 10:07:08,730] {processor.py:153} INFO - Started process (PID=75714) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:07:08,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:07:08,734] {logging_mixin.py:115} INFO - [2022-06-06 10:07:08,734] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:07:08,784] {logging_mixin.py:115} INFO - [2022-06-06 10:07:08,782] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:07:08,786] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:07:08,880] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 10:07:39,389] {processor.py:153} INFO - Started process (PID=75783) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:07:39,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:07:39,392] {logging_mixin.py:115} INFO - [2022-06-06 10:07:39,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:07:39,463] {logging_mixin.py:115} INFO - [2022-06-06 10:07:39,460] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:07:39,466] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:07:39,629] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-06 10:08:10,432] {processor.py:153} INFO - Started process (PID=75843) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:08:10,433] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:08:10,436] {logging_mixin.py:115} INFO - [2022-06-06 10:08:10,435] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:08:10,575] {logging_mixin.py:115} INFO - [2022-06-06 10:08:10,570] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:08:10,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:08:10,825] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.401 seconds
[2022-06-06 10:08:41,692] {processor.py:153} INFO - Started process (PID=75908) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:08:41,695] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:08:41,696] {logging_mixin.py:115} INFO - [2022-06-06 10:08:41,696] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:08:41,745] {logging_mixin.py:115} INFO - [2022-06-06 10:08:41,743] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:08:41,746] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:08:41,842] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 10:09:12,289] {processor.py:153} INFO - Started process (PID=75978) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:09:12,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:09:12,295] {logging_mixin.py:115} INFO - [2022-06-06 10:09:12,295] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:09:12,369] {logging_mixin.py:115} INFO - [2022-06-06 10:09:12,366] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:09:12,371] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:09:12,464] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 10:09:43,001] {processor.py:153} INFO - Started process (PID=76049) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:09:43,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:09:43,006] {logging_mixin.py:115} INFO - [2022-06-06 10:09:43,005] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:09:43,099] {logging_mixin.py:115} INFO - [2022-06-06 10:09:43,092] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:09:43,104] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:09:43,280] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.285 seconds
[2022-06-06 10:10:13,834] {processor.py:153} INFO - Started process (PID=76116) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:10:13,837] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:10:13,839] {logging_mixin.py:115} INFO - [2022-06-06 10:10:13,839] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:10:13,921] {logging_mixin.py:115} INFO - [2022-06-06 10:10:13,918] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:10:13,923] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:10:14,034] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.206 seconds
[2022-06-06 10:10:44,802] {processor.py:153} INFO - Started process (PID=76172) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:10:44,806] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:10:44,808] {logging_mixin.py:115} INFO - [2022-06-06 10:10:44,808] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:10:44,868] {logging_mixin.py:115} INFO - [2022-06-06 10:10:44,866] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:10:44,870] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:10:44,966] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 10:11:15,533] {processor.py:153} INFO - Started process (PID=76239) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:11:15,536] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:11:15,538] {logging_mixin.py:115} INFO - [2022-06-06 10:11:15,537] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:11:15,585] {logging_mixin.py:115} INFO - [2022-06-06 10:11:15,583] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:11:15,586] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:11:15,681] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 10:11:46,245] {processor.py:153} INFO - Started process (PID=76306) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:11:46,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:11:46,248] {logging_mixin.py:115} INFO - [2022-06-06 10:11:46,248] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:11:46,296] {logging_mixin.py:115} INFO - [2022-06-06 10:11:46,294] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:11:46,298] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:11:46,390] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 10:12:16,825] {processor.py:153} INFO - Started process (PID=76374) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:12:16,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:12:16,830] {logging_mixin.py:115} INFO - [2022-06-06 10:12:16,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:12:16,898] {logging_mixin.py:115} INFO - [2022-06-06 10:12:16,895] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:12:16,899] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:12:17,001] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 10:12:47,688] {processor.py:153} INFO - Started process (PID=76441) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:12:47,690] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:12:47,692] {logging_mixin.py:115} INFO - [2022-06-06 10:12:47,691] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:12:47,746] {logging_mixin.py:115} INFO - [2022-06-06 10:12:47,744] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:12:47,748] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:12:47,843] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 10:13:18,326] {processor.py:153} INFO - Started process (PID=76512) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:13:18,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:13:18,329] {logging_mixin.py:115} INFO - [2022-06-06 10:13:18,329] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:13:18,378] {logging_mixin.py:115} INFO - [2022-06-06 10:13:18,375] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:13:18,379] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:13:18,484] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 10:13:48,969] {processor.py:153} INFO - Started process (PID=76569) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:13:48,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:13:48,975] {logging_mixin.py:115} INFO - [2022-06-06 10:13:48,975] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:13:49,035] {logging_mixin.py:115} INFO - [2022-06-06 10:13:49,032] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:13:49,041] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:13:49,140] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 10:14:19,895] {processor.py:153} INFO - Started process (PID=76636) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:14:19,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:14:19,902] {logging_mixin.py:115} INFO - [2022-06-06 10:14:19,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:14:19,974] {logging_mixin.py:115} INFO - [2022-06-06 10:14:19,971] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:14:19,975] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:14:20,077] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 10:14:50,813] {processor.py:153} INFO - Started process (PID=76705) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:14:50,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:14:50,818] {logging_mixin.py:115} INFO - [2022-06-06 10:14:50,818] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:14:50,915] {logging_mixin.py:115} INFO - [2022-06-06 10:14:50,910] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:14:50,917] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:14:51,053] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.253 seconds
[2022-06-06 10:15:22,028] {processor.py:153} INFO - Started process (PID=76772) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:15:22,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:15:22,033] {logging_mixin.py:115} INFO - [2022-06-06 10:15:22,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:15:22,091] {logging_mixin.py:115} INFO - [2022-06-06 10:15:22,088] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:15:22,092] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:15:22,190] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 10:15:52,807] {processor.py:153} INFO - Started process (PID=76841) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:15:52,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:15:52,814] {logging_mixin.py:115} INFO - [2022-06-06 10:15:52,814] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:15:52,892] {logging_mixin.py:115} INFO - [2022-06-06 10:15:52,890] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:15:52,893] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:15:52,993] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 10:16:23,763] {processor.py:153} INFO - Started process (PID=76910) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:16:23,764] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:16:23,765] {logging_mixin.py:115} INFO - [2022-06-06 10:16:23,765] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:16:23,811] {logging_mixin.py:115} INFO - [2022-06-06 10:16:23,808] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:16:23,813] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:16:23,939] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 10:16:54,445] {processor.py:153} INFO - Started process (PID=76966) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:16:54,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:16:54,457] {logging_mixin.py:115} INFO - [2022-06-06 10:16:54,457] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:16:54,508] {logging_mixin.py:115} INFO - [2022-06-06 10:16:54,505] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:16:54,509] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:16:54,627] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 10:17:25,131] {processor.py:153} INFO - Started process (PID=77033) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:17:25,132] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:17:25,133] {logging_mixin.py:115} INFO - [2022-06-06 10:17:25,133] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:17:25,192] {logging_mixin.py:115} INFO - [2022-06-06 10:17:25,189] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:17:25,194] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:17:25,297] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 10:17:55,999] {processor.py:153} INFO - Started process (PID=77098) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:17:56,001] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:17:56,003] {logging_mixin.py:115} INFO - [2022-06-06 10:17:56,003] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:17:56,072] {logging_mixin.py:115} INFO - [2022-06-06 10:17:56,066] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:17:56,073] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:17:56,192] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-06 10:18:26,934] {processor.py:153} INFO - Started process (PID=77169) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:18:26,938] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:18:26,939] {logging_mixin.py:115} INFO - [2022-06-06 10:18:26,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:18:27,005] {logging_mixin.py:115} INFO - [2022-06-06 10:18:27,001] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:18:27,007] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:18:27,100] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 10:18:57,690] {processor.py:153} INFO - Started process (PID=77238) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:18:57,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:18:57,695] {logging_mixin.py:115} INFO - [2022-06-06 10:18:57,695] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:18:57,753] {logging_mixin.py:115} INFO - [2022-06-06 10:18:57,751] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:18:57,754] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:18:57,849] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 10:19:28,630] {processor.py:153} INFO - Started process (PID=77307) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:19:28,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:19:28,637] {logging_mixin.py:115} INFO - [2022-06-06 10:19:28,637] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:19:28,694] {logging_mixin.py:115} INFO - [2022-06-06 10:19:28,692] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:19:28,695] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:19:28,800] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 10:19:59,352] {processor.py:153} INFO - Started process (PID=77373) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:19:59,354] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:19:59,355] {logging_mixin.py:115} INFO - [2022-06-06 10:19:59,355] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:19:59,401] {logging_mixin.py:115} INFO - [2022-06-06 10:19:59,399] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:19:59,402] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:19:59,514] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 10:20:30,099] {processor.py:153} INFO - Started process (PID=77432) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:20:30,100] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:20:30,104] {logging_mixin.py:115} INFO - [2022-06-06 10:20:30,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:20:30,157] {logging_mixin.py:115} INFO - [2022-06-06 10:20:30,155] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:20:30,159] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:20:30,251] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 10:21:00,853] {processor.py:153} INFO - Started process (PID=77499) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:21:00,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:21:00,857] {logging_mixin.py:115} INFO - [2022-06-06 10:21:00,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:21:00,909] {logging_mixin.py:115} INFO - [2022-06-06 10:21:00,907] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:21:00,910] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:21:01,019] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 10:21:31,827] {processor.py:153} INFO - Started process (PID=77567) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:21:31,830] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:21:31,832] {logging_mixin.py:115} INFO - [2022-06-06 10:21:31,832] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:21:31,886] {logging_mixin.py:115} INFO - [2022-06-06 10:21:31,885] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:21:31,887] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:21:31,985] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 10:22:02,425] {processor.py:153} INFO - Started process (PID=77638) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:22:02,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:22:02,427] {logging_mixin.py:115} INFO - [2022-06-06 10:22:02,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:22:02,480] {logging_mixin.py:115} INFO - [2022-06-06 10:22:02,477] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:22:02,481] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:22:02,578] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 10:22:33,142] {processor.py:153} INFO - Started process (PID=77706) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:22:33,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:22:33,149] {logging_mixin.py:115} INFO - [2022-06-06 10:22:33,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:22:33,198] {logging_mixin.py:115} INFO - [2022-06-06 10:22:33,195] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:22:33,200] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:22:33,316] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 10:23:04,198] {processor.py:153} INFO - Started process (PID=77776) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:23:04,203] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:23:04,205] {logging_mixin.py:115} INFO - [2022-06-06 10:23:04,205] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:23:04,270] {logging_mixin.py:115} INFO - [2022-06-06 10:23:04,266] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:23:04,271] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:23:04,385] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-06 10:23:34,855] {processor.py:153} INFO - Started process (PID=77836) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:23:34,858] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:23:34,859] {logging_mixin.py:115} INFO - [2022-06-06 10:23:34,859] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:23:34,965] {logging_mixin.py:115} INFO - [2022-06-06 10:23:34,962] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:23:34,966] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:23:35,068] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-06 10:24:05,126] {processor.py:153} INFO - Started process (PID=77902) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:24:05,127] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:24:05,129] {logging_mixin.py:115} INFO - [2022-06-06 10:24:05,129] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:24:05,192] {logging_mixin.py:115} INFO - [2022-06-06 10:24:05,190] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:24:05,194] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:24:05,296] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 10:24:35,327] {processor.py:153} INFO - Started process (PID=77970) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:24:35,329] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:24:35,330] {logging_mixin.py:115} INFO - [2022-06-06 10:24:35,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:24:35,397] {logging_mixin.py:115} INFO - [2022-06-06 10:24:35,394] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:24:35,398] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:24:35,511] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-06 10:25:05,670] {processor.py:153} INFO - Started process (PID=78038) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:25:05,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:25:05,673] {logging_mixin.py:115} INFO - [2022-06-06 10:25:05,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:25:05,729] {logging_mixin.py:115} INFO - [2022-06-06 10:25:05,725] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:25:05,731] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:25:05,830] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 10:25:36,564] {processor.py:153} INFO - Started process (PID=78095) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:25:36,567] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:25:36,569] {logging_mixin.py:115} INFO - [2022-06-06 10:25:36,569] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:25:36,638] {logging_mixin.py:115} INFO - [2022-06-06 10:25:36,636] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:25:36,640] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:25:36,739] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 10:26:06,993] {processor.py:153} INFO - Started process (PID=78165) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:26:06,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:26:06,996] {logging_mixin.py:115} INFO - [2022-06-06 10:26:06,996] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:26:07,089] {logging_mixin.py:115} INFO - [2022-06-06 10:26:07,084] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:26:07,093] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:26:07,206] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-06 10:26:37,488] {processor.py:153} INFO - Started process (PID=78235) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:26:37,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:26:37,491] {logging_mixin.py:115} INFO - [2022-06-06 10:26:37,491] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:26:37,572] {logging_mixin.py:115} INFO - [2022-06-06 10:26:37,570] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:26:37,574] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:26:37,685] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 10:27:08,509] {processor.py:153} INFO - Started process (PID=78303) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:27:08,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:27:08,513] {logging_mixin.py:115} INFO - [2022-06-06 10:27:08,513] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:27:08,618] {logging_mixin.py:115} INFO - [2022-06-06 10:27:08,611] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:27:08,622] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:27:08,763] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-06 10:27:39,390] {processor.py:153} INFO - Started process (PID=78367) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:27:39,391] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:27:39,393] {logging_mixin.py:115} INFO - [2022-06-06 10:27:39,393] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:27:39,452] {logging_mixin.py:115} INFO - [2022-06-06 10:27:39,449] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:27:39,454] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:27:39,553] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 10:28:09,697] {processor.py:153} INFO - Started process (PID=78425) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:28:09,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:28:09,702] {logging_mixin.py:115} INFO - [2022-06-06 10:28:09,702] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:28:09,788] {logging_mixin.py:115} INFO - [2022-06-06 10:28:09,785] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:28:09,791] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:28:09,914] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-06 10:28:40,063] {processor.py:153} INFO - Started process (PID=78492) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:28:40,065] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:28:40,067] {logging_mixin.py:115} INFO - [2022-06-06 10:28:40,066] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:28:40,129] {logging_mixin.py:115} INFO - [2022-06-06 10:28:40,127] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:28:40,131] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:28:40,235] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 10:29:10,477] {processor.py:153} INFO - Started process (PID=78560) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:29:10,480] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:29:10,482] {logging_mixin.py:115} INFO - [2022-06-06 10:29:10,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:29:10,560] {logging_mixin.py:115} INFO - [2022-06-06 10:29:10,558] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:29:10,561] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:29:10,668] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-06 10:29:40,765] {processor.py:153} INFO - Started process (PID=78628) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:29:40,768] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:29:40,773] {logging_mixin.py:115} INFO - [2022-06-06 10:29:40,773] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:29:40,936] {logging_mixin.py:115} INFO - [2022-06-06 10:29:40,927] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:29:40,939] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:29:41,216] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.463 seconds
[2022-06-06 10:30:12,112] {processor.py:153} INFO - Started process (PID=78697) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:30:12,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:30:12,116] {logging_mixin.py:115} INFO - [2022-06-06 10:30:12,116] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:30:12,188] {logging_mixin.py:115} INFO - [2022-06-06 10:30:12,184] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:30:12,189] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:30:12,311] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 10:30:42,760] {processor.py:153} INFO - Started process (PID=78755) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:30:42,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:30:42,764] {logging_mixin.py:115} INFO - [2022-06-06 10:30:42,764] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:30:42,851] {logging_mixin.py:115} INFO - [2022-06-06 10:30:42,848] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:30:42,853] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:30:42,960] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-06 10:31:13,984] {processor.py:153} INFO - Started process (PID=78823) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:31:13,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:31:13,989] {logging_mixin.py:115} INFO - [2022-06-06 10:31:13,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:31:14,083] {logging_mixin.py:115} INFO - [2022-06-06 10:31:14,080] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:31:14,085] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:31:14,231] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.249 seconds
[2022-06-06 10:31:45,126] {processor.py:153} INFO - Started process (PID=78890) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:31:45,130] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:31:45,132] {logging_mixin.py:115} INFO - [2022-06-06 10:31:45,132] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:31:45,199] {logging_mixin.py:115} INFO - [2022-06-06 10:31:45,196] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:31:45,200] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:31:45,293] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 10:32:15,975] {processor.py:153} INFO - Started process (PID=78959) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:32:15,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:32:15,979] {logging_mixin.py:115} INFO - [2022-06-06 10:32:15,979] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:32:16,078] {logging_mixin.py:115} INFO - [2022-06-06 10:32:16,075] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:32:16,080] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:32:16,189] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-06 10:32:46,479] {processor.py:153} INFO - Started process (PID=79027) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:32:46,483] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:32:46,485] {logging_mixin.py:115} INFO - [2022-06-06 10:32:46,485] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:32:46,554] {logging_mixin.py:115} INFO - [2022-06-06 10:32:46,551] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:32:46,557] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:32:46,655] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 10:33:16,786] {processor.py:153} INFO - Started process (PID=79085) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:33:16,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:33:16,788] {logging_mixin.py:115} INFO - [2022-06-06 10:33:16,788] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:33:16,881] {logging_mixin.py:115} INFO - [2022-06-06 10:33:16,871] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:33:16,883] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:33:17,009] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.228 seconds
[2022-06-06 10:33:47,298] {processor.py:153} INFO - Started process (PID=79154) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:33:47,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:33:47,305] {logging_mixin.py:115} INFO - [2022-06-06 10:33:47,305] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:33:47,386] {logging_mixin.py:115} INFO - [2022-06-06 10:33:47,383] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:33:47,389] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:33:47,522] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-06 10:34:18,008] {processor.py:153} INFO - Started process (PID=79220) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:34:18,011] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:34:18,014] {logging_mixin.py:115} INFO - [2022-06-06 10:34:18,014] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:34:18,082] {logging_mixin.py:115} INFO - [2022-06-06 10:34:18,080] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:34:18,084] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:34:18,182] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 10:34:49,134] {processor.py:153} INFO - Started process (PID=79287) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:34:49,136] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:34:49,138] {logging_mixin.py:115} INFO - [2022-06-06 10:34:49,138] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:34:49,268] {logging_mixin.py:115} INFO - [2022-06-06 10:34:49,264] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:34:49,271] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:34:49,392] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.263 seconds
[2022-06-06 10:35:20,205] {processor.py:153} INFO - Started process (PID=79354) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:35:20,207] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:35:20,209] {logging_mixin.py:115} INFO - [2022-06-06 10:35:20,209] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:35:20,287] {logging_mixin.py:115} INFO - [2022-06-06 10:35:20,284] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:35:20,288] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:35:20,391] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 10:35:50,565] {processor.py:153} INFO - Started process (PID=79410) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:35:50,572] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:35:50,575] {logging_mixin.py:115} INFO - [2022-06-06 10:35:50,575] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:35:50,684] {logging_mixin.py:115} INFO - [2022-06-06 10:35:50,680] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:35:50,687] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:35:50,859] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.298 seconds
[2022-06-06 10:36:20,932] {processor.py:153} INFO - Started process (PID=79482) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:36:20,938] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:36:20,939] {logging_mixin.py:115} INFO - [2022-06-06 10:36:20,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:36:21,029] {logging_mixin.py:115} INFO - [2022-06-06 10:36:21,027] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:36:21,031] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:36:21,176] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.250 seconds
[2022-06-06 10:36:51,319] {processor.py:153} INFO - Started process (PID=79553) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:36:51,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:36:51,324] {logging_mixin.py:115} INFO - [2022-06-06 10:36:51,324] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:36:51,415] {logging_mixin.py:115} INFO - [2022-06-06 10:36:51,412] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:36:51,417] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:36:51,539] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-06 10:37:22,077] {processor.py:153} INFO - Started process (PID=79611) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:37:22,079] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:37:22,081] {logging_mixin.py:115} INFO - [2022-06-06 10:37:22,081] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:37:22,174] {logging_mixin.py:115} INFO - [2022-06-06 10:37:22,170] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:37:22,177] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:37:22,299] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-06 10:37:52,385] {processor.py:153} INFO - Started process (PID=79679) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:37:52,387] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:37:52,389] {logging_mixin.py:115} INFO - [2022-06-06 10:37:52,388] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:37:52,469] {logging_mixin.py:115} INFO - [2022-06-06 10:37:52,466] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:37:52,472] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:37:52,592] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-06 10:38:23,386] {processor.py:153} INFO - Started process (PID=79747) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:38:23,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:38:23,391] {logging_mixin.py:115} INFO - [2022-06-06 10:38:23,390] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:38:23,488] {logging_mixin.py:115} INFO - [2022-06-06 10:38:23,485] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:38:23,490] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:38:23,601] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-06 10:38:54,247] {processor.py:153} INFO - Started process (PID=79814) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:38:54,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:38:54,251] {logging_mixin.py:115} INFO - [2022-06-06 10:38:54,250] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:38:54,319] {logging_mixin.py:115} INFO - [2022-06-06 10:38:54,316] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:38:54,320] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:38:54,450] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-06 10:39:24,601] {processor.py:153} INFO - Started process (PID=79873) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:39:24,604] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:39:24,605] {logging_mixin.py:115} INFO - [2022-06-06 10:39:24,605] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:39:24,705] {logging_mixin.py:115} INFO - [2022-06-06 10:39:24,703] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:39:24,708] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:39:24,838] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.245 seconds
[2022-06-06 10:39:54,984] {processor.py:153} INFO - Started process (PID=79940) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:39:54,991] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:39:54,993] {logging_mixin.py:115} INFO - [2022-06-06 10:39:54,993] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:39:55,066] {logging_mixin.py:115} INFO - [2022-06-06 10:39:55,064] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:39:55,067] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:39:55,169] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-06 10:40:25,676] {processor.py:153} INFO - Started process (PID=80008) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:40:25,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:40:25,692] {logging_mixin.py:115} INFO - [2022-06-06 10:40:25,692] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:40:25,785] {logging_mixin.py:115} INFO - [2022-06-06 10:40:25,781] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:40:25,789] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:40:25,915] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.258 seconds
[2022-06-06 10:40:56,034] {processor.py:153} INFO - Started process (PID=80078) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:40:56,036] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:40:56,037] {logging_mixin.py:115} INFO - [2022-06-06 10:40:56,037] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:40:56,124] {logging_mixin.py:115} INFO - [2022-06-06 10:40:56,120] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:40:56,125] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:40:56,284] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-06 10:41:26,585] {processor.py:153} INFO - Started process (PID=80136) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:41:26,587] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:41:26,589] {logging_mixin.py:115} INFO - [2022-06-06 10:41:26,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:41:26,669] {logging_mixin.py:115} INFO - [2022-06-06 10:41:26,666] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:41:26,671] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:41:26,779] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 10:41:57,346] {processor.py:153} INFO - Started process (PID=80203) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:41:57,347] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:41:57,349] {logging_mixin.py:115} INFO - [2022-06-06 10:41:57,349] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:41:57,409] {logging_mixin.py:115} INFO - [2022-06-06 10:41:57,407] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:41:57,410] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:41:57,505] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 10:42:28,134] {processor.py:153} INFO - Started process (PID=80269) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:42:28,137] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:42:28,139] {logging_mixin.py:115} INFO - [2022-06-06 10:42:28,139] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:42:28,243] {logging_mixin.py:115} INFO - [2022-06-06 10:42:28,240] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:42:28,246] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:42:28,358] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-06 10:42:58,504] {processor.py:153} INFO - Started process (PID=80338) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:42:58,506] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:42:58,508] {logging_mixin.py:115} INFO - [2022-06-06 10:42:58,508] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:42:58,599] {logging_mixin.py:115} INFO - [2022-06-06 10:42:58,597] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:42:58,601] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:42:58,745] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-06 10:43:28,834] {processor.py:153} INFO - Started process (PID=80395) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:43:28,840] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:43:28,842] {logging_mixin.py:115} INFO - [2022-06-06 10:43:28,842] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:43:28,942] {logging_mixin.py:115} INFO - [2022-06-06 10:43:28,939] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:43:28,943] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:43:29,048] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-06 10:43:59,713] {processor.py:153} INFO - Started process (PID=80463) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:43:59,714] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:43:59,716] {logging_mixin.py:115} INFO - [2022-06-06 10:43:59,716] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:43:59,821] {logging_mixin.py:115} INFO - [2022-06-06 10:43:59,818] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:43:59,824] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:43:59,946] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.237 seconds
[2022-06-06 10:44:30,821] {processor.py:153} INFO - Started process (PID=80530) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:44:30,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:44:30,826] {logging_mixin.py:115} INFO - [2022-06-06 10:44:30,826] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:44:30,897] {logging_mixin.py:115} INFO - [2022-06-06 10:44:30,895] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:44:30,898] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:44:30,997] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 10:45:01,599] {processor.py:153} INFO - Started process (PID=80597) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:45:01,603] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:45:01,606] {logging_mixin.py:115} INFO - [2022-06-06 10:45:01,606] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:45:01,727] {logging_mixin.py:115} INFO - [2022-06-06 10:45:01,723] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:45:01,736] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:45:01,913] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.325 seconds
[2022-06-06 10:45:32,285] {processor.py:153} INFO - Started process (PID=80667) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:45:32,288] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:45:32,289] {logging_mixin.py:115} INFO - [2022-06-06 10:45:32,289] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:45:32,350] {logging_mixin.py:115} INFO - [2022-06-06 10:45:32,349] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:45:32,351] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:45:32,452] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 10:46:02,959] {processor.py:153} INFO - Started process (PID=80725) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:46:02,961] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:46:02,963] {logging_mixin.py:115} INFO - [2022-06-06 10:46:02,963] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:46:03,037] {logging_mixin.py:115} INFO - [2022-06-06 10:46:03,035] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:46:03,039] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:46:03,148] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-06 10:46:33,755] {processor.py:153} INFO - Started process (PID=80797) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:46:33,760] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:46:33,761] {logging_mixin.py:115} INFO - [2022-06-06 10:46:33,761] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:46:33,840] {logging_mixin.py:115} INFO - [2022-06-06 10:46:33,837] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:46:33,840] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:46:33,940] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 10:47:05,004] {processor.py:153} INFO - Started process (PID=80867) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:47:05,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:47:05,009] {logging_mixin.py:115} INFO - [2022-06-06 10:47:05,009] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:47:05,083] {logging_mixin.py:115} INFO - [2022-06-06 10:47:05,080] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:47:05,085] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:47:05,189] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-06 10:47:36,101] {processor.py:153} INFO - Started process (PID=80934) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:47:36,104] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:47:36,106] {logging_mixin.py:115} INFO - [2022-06-06 10:47:36,106] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:47:36,177] {logging_mixin.py:115} INFO - [2022-06-06 10:47:36,174] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:47:36,179] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:47:36,287] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 10:48:07,105] {processor.py:153} INFO - Started process (PID=81003) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:48:07,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:48:07,112] {logging_mixin.py:115} INFO - [2022-06-06 10:48:07,112] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:48:07,203] {logging_mixin.py:115} INFO - [2022-06-06 10:48:07,199] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:48:07,207] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:48:07,342] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.246 seconds
[2022-06-06 10:48:37,564] {processor.py:153} INFO - Started process (PID=81061) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:48:37,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:48:37,576] {logging_mixin.py:115} INFO - [2022-06-06 10:48:37,576] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:48:37,785] {logging_mixin.py:115} INFO - [2022-06-06 10:48:37,779] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:48:37,788] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:48:38,081] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.537 seconds
[2022-06-06 10:49:08,970] {processor.py:153} INFO - Started process (PID=81130) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:49:08,972] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:49:08,973] {logging_mixin.py:115} INFO - [2022-06-06 10:49:08,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:49:09,069] {logging_mixin.py:115} INFO - [2022-06-06 10:49:09,066] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:49:09,071] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:49:09,178] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-06 10:49:40,096] {processor.py:153} INFO - Started process (PID=81197) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:49:40,098] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:49:40,099] {logging_mixin.py:115} INFO - [2022-06-06 10:49:40,099] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:49:40,187] {logging_mixin.py:115} INFO - [2022-06-06 10:49:40,184] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:49:40,191] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:49:40,325] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-06 10:50:11,224] {processor.py:153} INFO - Started process (PID=81265) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:50:11,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:50:11,239] {logging_mixin.py:115} INFO - [2022-06-06 10:50:11,239] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:50:11,316] {logging_mixin.py:115} INFO - [2022-06-06 10:50:11,314] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:50:11,317] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:50:11,416] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 10:50:42,358] {processor.py:153} INFO - Started process (PID=81332) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:50:42,361] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:50:42,362] {logging_mixin.py:115} INFO - [2022-06-06 10:50:42,362] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:50:42,450] {logging_mixin.py:115} INFO - [2022-06-06 10:50:42,448] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:50:42,451] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:50:42,569] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-06 10:51:12,672] {processor.py:153} INFO - Started process (PID=81388) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:51:12,675] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:51:12,676] {logging_mixin.py:115} INFO - [2022-06-06 10:51:12,676] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:51:12,751] {logging_mixin.py:115} INFO - [2022-06-06 10:51:12,748] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:51:12,752] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:51:12,861] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 10:51:43,227] {processor.py:153} INFO - Started process (PID=81459) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:51:43,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:51:43,234] {logging_mixin.py:115} INFO - [2022-06-06 10:51:43,234] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:51:43,393] {logging_mixin.py:115} INFO - [2022-06-06 10:51:43,389] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:51:43,399] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:51:43,538] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.323 seconds
[2022-06-06 10:52:14,068] {processor.py:153} INFO - Started process (PID=81533) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:52:14,071] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:52:14,073] {logging_mixin.py:115} INFO - [2022-06-06 10:52:14,073] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:52:14,171] {logging_mixin.py:115} INFO - [2022-06-06 10:52:14,168] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:52:14,173] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:52:14,302] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-06 10:52:44,757] {processor.py:153} INFO - Started process (PID=81601) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:52:44,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:52:44,769] {logging_mixin.py:115} INFO - [2022-06-06 10:52:44,769] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:52:44,864] {logging_mixin.py:115} INFO - [2022-06-06 10:52:44,860] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:52:44,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:52:45,000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.250 seconds
[2022-06-06 10:53:15,143] {processor.py:153} INFO - Started process (PID=81669) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:53:15,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:53:15,147] {logging_mixin.py:115} INFO - [2022-06-06 10:53:15,147] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:53:15,260] {logging_mixin.py:115} INFO - [2022-06-06 10:53:15,257] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:53:15,261] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:53:15,366] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.233 seconds
[2022-06-06 10:53:45,445] {processor.py:153} INFO - Started process (PID=81724) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:53:45,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:53:45,448] {logging_mixin.py:115} INFO - [2022-06-06 10:53:45,448] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:53:45,527] {logging_mixin.py:115} INFO - [2022-06-06 10:53:45,523] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:53:45,528] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:53:45,633] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-06 10:54:15,691] {processor.py:153} INFO - Started process (PID=81795) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:54:15,693] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:54:15,695] {logging_mixin.py:115} INFO - [2022-06-06 10:54:15,694] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:54:15,760] {logging_mixin.py:115} INFO - [2022-06-06 10:54:15,756] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:54:15,761] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:54:15,874] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 10:54:45,984] {processor.py:153} INFO - Started process (PID=81864) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:54:45,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:54:45,992] {logging_mixin.py:115} INFO - [2022-06-06 10:54:45,992] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:54:46,057] {logging_mixin.py:115} INFO - [2022-06-06 10:54:46,054] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:54:46,060] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:54:46,163] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 10:55:16,643] {processor.py:153} INFO - Started process (PID=81930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:55:16,645] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:55:16,647] {logging_mixin.py:115} INFO - [2022-06-06 10:55:16,647] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:55:16,716] {logging_mixin.py:115} INFO - [2022-06-06 10:55:16,714] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:55:16,717] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:55:16,828] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 10:55:47,150] {processor.py:153} INFO - Started process (PID=81987) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:55:47,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:55:47,154] {logging_mixin.py:115} INFO - [2022-06-06 10:55:47,153] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:55:47,244] {logging_mixin.py:115} INFO - [2022-06-06 10:55:47,241] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:55:47,247] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:55:47,362] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.221 seconds
[2022-06-06 10:56:17,895] {processor.py:153} INFO - Started process (PID=82056) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:56:17,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:56:17,901] {logging_mixin.py:115} INFO - [2022-06-06 10:56:17,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:56:17,976] {logging_mixin.py:115} INFO - [2022-06-06 10:56:17,972] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:56:17,977] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:56:18,075] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 10:56:48,184] {processor.py:153} INFO - Started process (PID=82122) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:56:48,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:56:48,197] {logging_mixin.py:115} INFO - [2022-06-06 10:56:48,197] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:56:48,299] {logging_mixin.py:115} INFO - [2022-06-06 10:56:48,296] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:56:48,301] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:56:48,437] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.259 seconds
[2022-06-06 10:57:18,674] {processor.py:153} INFO - Started process (PID=82178) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:57:18,677] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:57:18,678] {logging_mixin.py:115} INFO - [2022-06-06 10:57:18,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:57:18,934] {logging_mixin.py:115} INFO - [2022-06-06 10:57:18,886] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:57:18,954] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:57:19,318] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.650 seconds
[2022-06-06 10:57:50,049] {processor.py:153} INFO - Started process (PID=82246) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:57:50,052] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:57:50,054] {logging_mixin.py:115} INFO - [2022-06-06 10:57:50,054] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:57:50,195] {logging_mixin.py:115} INFO - [2022-06-06 10:57:50,190] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:57:50,202] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:57:50,382] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.340 seconds
[2022-06-06 10:58:20,681] {processor.py:153} INFO - Started process (PID=82314) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:58:20,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:58:20,687] {logging_mixin.py:115} INFO - [2022-06-06 10:58:20,687] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:58:20,836] {logging_mixin.py:115} INFO - [2022-06-06 10:58:20,828] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:58:20,844] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:58:20,998] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.327 seconds
[2022-06-06 10:58:51,134] {processor.py:153} INFO - Started process (PID=82382) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:58:51,136] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:58:51,137] {logging_mixin.py:115} INFO - [2022-06-06 10:58:51,137] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:58:51,204] {logging_mixin.py:115} INFO - [2022-06-06 10:58:51,201] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:58:51,205] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:58:51,304] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 10:59:21,545] {processor.py:153} INFO - Started process (PID=82441) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:59:21,547] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:59:21,550] {logging_mixin.py:115} INFO - [2022-06-06 10:59:21,550] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:59:21,654] {logging_mixin.py:115} INFO - [2022-06-06 10:59:21,651] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:59:21,656] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:59:21,777] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.239 seconds
[2022-06-06 10:59:51,890] {processor.py:153} INFO - Started process (PID=82509) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:59:51,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 10:59:51,895] {logging_mixin.py:115} INFO - [2022-06-06 10:59:51,894] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:59:51,963] {logging_mixin.py:115} INFO - [2022-06-06 10:59:51,961] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 10:59:51,964] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 10:59:52,076] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 11:00:22,660] {processor.py:153} INFO - Started process (PID=82579) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:00:22,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:00:22,663] {logging_mixin.py:115} INFO - [2022-06-06 11:00:22,663] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:00:22,728] {logging_mixin.py:115} INFO - [2022-06-06 11:00:22,724] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:00:22,730] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:00:22,827] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 11:00:53,015] {processor.py:153} INFO - Started process (PID=82648) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:00:53,018] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:00:53,019] {logging_mixin.py:115} INFO - [2022-06-06 11:00:53,019] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:00:53,097] {logging_mixin.py:115} INFO - [2022-06-06 11:00:53,092] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:00:53,098] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:00:53,233] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.223 seconds
[2022-06-06 11:01:23,405] {processor.py:153} INFO - Started process (PID=82715) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:01:23,407] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:01:23,408] {logging_mixin.py:115} INFO - [2022-06-06 11:01:23,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:01:23,482] {logging_mixin.py:115} INFO - [2022-06-06 11:01:23,478] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:01:23,484] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:01:23,616] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-06 11:01:53,764] {processor.py:153} INFO - Started process (PID=82773) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:01:53,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:01:53,770] {logging_mixin.py:115} INFO - [2022-06-06 11:01:53,770] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:01:53,850] {logging_mixin.py:115} INFO - [2022-06-06 11:01:53,847] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:01:53,851] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:01:53,954] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-06 11:02:24,159] {processor.py:153} INFO - Started process (PID=82841) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:02:24,163] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:02:24,165] {logging_mixin.py:115} INFO - [2022-06-06 11:02:24,165] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:02:24,250] {logging_mixin.py:115} INFO - [2022-06-06 11:02:24,247] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:02:24,252] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:02:24,351] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 11:02:54,511] {processor.py:153} INFO - Started process (PID=82907) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:02:54,513] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:02:54,515] {logging_mixin.py:115} INFO - [2022-06-06 11:02:54,515] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:02:54,592] {logging_mixin.py:115} INFO - [2022-06-06 11:02:54,590] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:02:54,594] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:02:54,700] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-06 11:03:25,042] {processor.py:153} INFO - Started process (PID=82975) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:03:25,045] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:03:25,046] {logging_mixin.py:115} INFO - [2022-06-06 11:03:25,046] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:03:25,111] {logging_mixin.py:115} INFO - [2022-06-06 11:03:25,109] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:03:25,112] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:03:25,236] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-06 11:03:55,300] {processor.py:153} INFO - Started process (PID=83034) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:03:55,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:03:55,304] {logging_mixin.py:115} INFO - [2022-06-06 11:03:55,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:03:55,363] {logging_mixin.py:115} INFO - [2022-06-06 11:03:55,361] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:03:55,364] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:03:55,479] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 11:04:25,608] {processor.py:153} INFO - Started process (PID=83103) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:04:25,612] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:04:25,618] {logging_mixin.py:115} INFO - [2022-06-06 11:04:25,618] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:04:25,685] {logging_mixin.py:115} INFO - [2022-06-06 11:04:25,683] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:04:25,686] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:04:25,786] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 11:04:56,067] {processor.py:153} INFO - Started process (PID=83169) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:04:56,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:04:56,069] {logging_mixin.py:115} INFO - [2022-06-06 11:04:56,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:04:56,135] {logging_mixin.py:115} INFO - [2022-06-06 11:04:56,132] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:04:56,137] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:04:56,236] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 11:05:26,560] {processor.py:153} INFO - Started process (PID=83236) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:05:26,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:05:26,564] {logging_mixin.py:115} INFO - [2022-06-06 11:05:26,564] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:05:26,627] {logging_mixin.py:115} INFO - [2022-06-06 11:05:26,624] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:05:26,629] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:05:26,775] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-06 11:05:57,625] {processor.py:153} INFO - Started process (PID=83309) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:05:57,627] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:05:57,629] {logging_mixin.py:115} INFO - [2022-06-06 11:05:57,628] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:05:57,698] {logging_mixin.py:115} INFO - [2022-06-06 11:05:57,695] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:05:57,700] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:05:57,831] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-06 11:06:28,792] {processor.py:153} INFO - Started process (PID=83377) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:06:28,794] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:06:28,795] {logging_mixin.py:115} INFO - [2022-06-06 11:06:28,795] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:06:28,879] {logging_mixin.py:115} INFO - [2022-06-06 11:06:28,876] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:06:28,880] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:06:29,014] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-06 11:06:59,135] {processor.py:153} INFO - Started process (PID=83436) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:06:59,137] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:06:59,139] {logging_mixin.py:115} INFO - [2022-06-06 11:06:59,139] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:06:59,227] {logging_mixin.py:115} INFO - [2022-06-06 11:06:59,224] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:06:59,230] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:06:59,332] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 11:07:29,884] {processor.py:153} INFO - Started process (PID=83505) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:07:29,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:07:29,889] {logging_mixin.py:115} INFO - [2022-06-06 11:07:29,889] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:07:29,959] {logging_mixin.py:115} INFO - [2022-06-06 11:07:29,955] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:07:29,960] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:07:30,058] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 11:08:00,790] {processor.py:153} INFO - Started process (PID=83574) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:08:00,791] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:08:00,793] {logging_mixin.py:115} INFO - [2022-06-06 11:08:00,793] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:08:00,894] {logging_mixin.py:115} INFO - [2022-06-06 11:08:00,889] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:08:00,897] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:08:01,020] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.234 seconds
[2022-06-06 11:08:31,630] {processor.py:153} INFO - Started process (PID=83644) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:08:31,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:08:31,636] {logging_mixin.py:115} INFO - [2022-06-06 11:08:31,636] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:08:31,696] {logging_mixin.py:115} INFO - [2022-06-06 11:08:31,693] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:08:31,698] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:08:31,792] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 11:09:02,419] {processor.py:153} INFO - Started process (PID=83713) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:09:02,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:09:02,424] {logging_mixin.py:115} INFO - [2022-06-06 11:09:02,424] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:09:02,492] {logging_mixin.py:115} INFO - [2022-06-06 11:09:02,489] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:09:02,494] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:09:02,590] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 11:09:32,966] {processor.py:153} INFO - Started process (PID=83769) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:09:32,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:09:32,970] {logging_mixin.py:115} INFO - [2022-06-06 11:09:32,970] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:09:33,024] {logging_mixin.py:115} INFO - [2022-06-06 11:09:33,020] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:09:33,025] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:09:33,120] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 11:10:03,327] {processor.py:153} INFO - Started process (PID=83839) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:10:03,329] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:10:03,330] {logging_mixin.py:115} INFO - [2022-06-06 11:10:03,330] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:10:03,378] {logging_mixin.py:115} INFO - [2022-06-06 11:10:03,376] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:10:03,379] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:10:03,473] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-06 11:10:33,973] {processor.py:153} INFO - Started process (PID=83906) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:10:33,976] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:10:33,977] {logging_mixin.py:115} INFO - [2022-06-06 11:10:33,977] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:10:34,033] {logging_mixin.py:115} INFO - [2022-06-06 11:10:34,031] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:10:34,034] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:10:34,132] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 11:11:04,402] {processor.py:153} INFO - Started process (PID=83974) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:11:04,405] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:11:04,406] {logging_mixin.py:115} INFO - [2022-06-06 11:11:04,406] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:11:04,466] {logging_mixin.py:115} INFO - [2022-06-06 11:11:04,463] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:11:04,467] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:11:04,576] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 11:11:35,127] {processor.py:153} INFO - Started process (PID=84041) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:11:35,130] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:11:35,132] {logging_mixin.py:115} INFO - [2022-06-06 11:11:35,132] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:11:35,193] {logging_mixin.py:115} INFO - [2022-06-06 11:11:35,189] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:11:35,195] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:11:35,291] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 11:12:05,845] {processor.py:153} INFO - Started process (PID=84110) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:12:05,846] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:12:05,846] {logging_mixin.py:115} INFO - [2022-06-06 11:12:05,846] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:12:05,897] {logging_mixin.py:115} INFO - [2022-06-06 11:12:05,895] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:12:05,899] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:12:05,993] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 11:12:36,339] {processor.py:153} INFO - Started process (PID=84171) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:12:36,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:12:36,342] {logging_mixin.py:115} INFO - [2022-06-06 11:12:36,342] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:12:36,410] {logging_mixin.py:115} INFO - [2022-06-06 11:12:36,407] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:12:36,413] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:12:36,522] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-06 11:13:06,968] {processor.py:153} INFO - Started process (PID=84239) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:13:06,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:13:06,971] {logging_mixin.py:115} INFO - [2022-06-06 11:13:06,971] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:13:07,025] {logging_mixin.py:115} INFO - [2022-06-06 11:13:07,022] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:13:07,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:13:07,122] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 11:13:37,895] {processor.py:153} INFO - Started process (PID=84305) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:13:37,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:13:37,901] {logging_mixin.py:115} INFO - [2022-06-06 11:13:37,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:13:37,963] {logging_mixin.py:115} INFO - [2022-06-06 11:13:37,961] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:13:37,965] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:13:38,058] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 11:14:08,334] {processor.py:153} INFO - Started process (PID=84374) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:14:08,336] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:14:08,337] {logging_mixin.py:115} INFO - [2022-06-06 11:14:08,336] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:14:08,401] {logging_mixin.py:115} INFO - [2022-06-06 11:14:08,398] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:14:08,403] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:14:08,507] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 11:14:39,016] {processor.py:153} INFO - Started process (PID=84442) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:14:39,019] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:14:39,020] {logging_mixin.py:115} INFO - [2022-06-06 11:14:39,020] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:14:39,078] {logging_mixin.py:115} INFO - [2022-06-06 11:14:39,075] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:14:39,080] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:14:39,174] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 11:15:09,455] {processor.py:153} INFO - Started process (PID=84509) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:15:09,457] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:15:09,457] {logging_mixin.py:115} INFO - [2022-06-06 11:15:09,457] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:15:09,513] {logging_mixin.py:115} INFO - [2022-06-06 11:15:09,510] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:15:09,514] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:15:09,616] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 11:15:40,130] {processor.py:153} INFO - Started process (PID=84566) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:15:40,135] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:15:40,137] {logging_mixin.py:115} INFO - [2022-06-06 11:15:40,137] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:15:40,203] {logging_mixin.py:115} INFO - [2022-06-06 11:15:40,201] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:15:40,205] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:15:40,300] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 11:16:10,730] {processor.py:153} INFO - Started process (PID=84633) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:16:10,733] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:16:10,734] {logging_mixin.py:115} INFO - [2022-06-06 11:16:10,734] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:16:10,795] {logging_mixin.py:115} INFO - [2022-06-06 11:16:10,792] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:16:10,796] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:16:10,892] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 11:16:41,403] {processor.py:153} INFO - Started process (PID=84703) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:16:41,407] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:16:41,408] {logging_mixin.py:115} INFO - [2022-06-06 11:16:41,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:16:41,470] {logging_mixin.py:115} INFO - [2022-06-06 11:16:41,468] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:16:41,472] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:16:41,566] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 11:17:12,074] {processor.py:153} INFO - Started process (PID=84770) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:17:12,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:17:12,077] {logging_mixin.py:115} INFO - [2022-06-06 11:17:12,077] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:17:12,146] {logging_mixin.py:115} INFO - [2022-06-06 11:17:12,144] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:17:12,147] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:17:12,248] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 11:17:42,775] {processor.py:153} INFO - Started process (PID=84837) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:17:42,777] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:17:42,779] {logging_mixin.py:115} INFO - [2022-06-06 11:17:42,779] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:17:42,843] {logging_mixin.py:115} INFO - [2022-06-06 11:17:42,841] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:17:42,845] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:17:42,954] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-06 11:18:13,505] {processor.py:153} INFO - Started process (PID=84894) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:18:13,507] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:18:13,508] {logging_mixin.py:115} INFO - [2022-06-06 11:18:13,508] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:18:13,553] {logging_mixin.py:115} INFO - [2022-06-06 11:18:13,551] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:18:13,554] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:18:13,656] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 11:18:43,975] {processor.py:153} INFO - Started process (PID=84961) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:18:43,978] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:18:43,980] {logging_mixin.py:115} INFO - [2022-06-06 11:18:43,980] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:18:44,049] {logging_mixin.py:115} INFO - [2022-06-06 11:18:44,046] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:18:44,050] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:18:44,150] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 11:19:14,745] {processor.py:153} INFO - Started process (PID=85029) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:19:14,748] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:19:14,749] {logging_mixin.py:115} INFO - [2022-06-06 11:19:14,749] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:19:14,805] {logging_mixin.py:115} INFO - [2022-06-06 11:19:14,803] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:19:14,807] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:19:14,903] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 11:19:45,406] {processor.py:153} INFO - Started process (PID=85096) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:19:45,412] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:19:45,413] {logging_mixin.py:115} INFO - [2022-06-06 11:19:45,413] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:19:45,465] {logging_mixin.py:115} INFO - [2022-06-06 11:19:45,463] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:19:45,466] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:19:45,563] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 11:20:16,110] {processor.py:153} INFO - Started process (PID=85163) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:20:16,112] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:20:16,113] {logging_mixin.py:115} INFO - [2022-06-06 11:20:16,113] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:20:16,166] {logging_mixin.py:115} INFO - [2022-06-06 11:20:16,164] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:20:16,169] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:20:16,268] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 11:20:46,724] {processor.py:153} INFO - Started process (PID=85231) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:20:46,727] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:20:46,728] {logging_mixin.py:115} INFO - [2022-06-06 11:20:46,728] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:20:46,777] {logging_mixin.py:115} INFO - [2022-06-06 11:20:46,775] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:20:46,778] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:20:46,885] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 11:21:17,461] {processor.py:153} INFO - Started process (PID=85289) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:21:17,463] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:21:17,465] {logging_mixin.py:115} INFO - [2022-06-06 11:21:17,465] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:21:17,515] {logging_mixin.py:115} INFO - [2022-06-06 11:21:17,512] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:21:17,517] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:21:17,623] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 11:21:48,260] {processor.py:153} INFO - Started process (PID=85355) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:21:48,263] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:21:48,264] {logging_mixin.py:115} INFO - [2022-06-06 11:21:48,264] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:21:48,333] {logging_mixin.py:115} INFO - [2022-06-06 11:21:48,329] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:21:48,334] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:21:48,431] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 11:22:18,940] {processor.py:153} INFO - Started process (PID=85422) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:22:18,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:22:18,945] {logging_mixin.py:115} INFO - [2022-06-06 11:22:18,944] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:22:19,006] {logging_mixin.py:115} INFO - [2022-06-06 11:22:19,004] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:22:19,008] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:22:19,110] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 11:22:49,669] {processor.py:153} INFO - Started process (PID=85492) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:22:49,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:22:49,672] {logging_mixin.py:115} INFO - [2022-06-06 11:22:49,672] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:22:49,745] {logging_mixin.py:115} INFO - [2022-06-06 11:22:49,742] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:22:49,746] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:22:49,853] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 11:23:20,469] {processor.py:153} INFO - Started process (PID=85561) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:23:20,470] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:23:20,471] {logging_mixin.py:115} INFO - [2022-06-06 11:23:20,471] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:23:20,517] {logging_mixin.py:115} INFO - [2022-06-06 11:23:20,515] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:23:20,519] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:23:20,620] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 11:23:51,291] {processor.py:153} INFO - Started process (PID=85631) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:23:51,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:23:51,296] {logging_mixin.py:115} INFO - [2022-06-06 11:23:51,296] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:23:51,383] {logging_mixin.py:115} INFO - [2022-06-06 11:23:51,380] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:23:51,384] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:23:51,517] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.230 seconds
[2022-06-06 11:24:22,226] {processor.py:153} INFO - Started process (PID=85691) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:24:22,230] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:24:22,232] {logging_mixin.py:115} INFO - [2022-06-06 11:24:22,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:24:22,292] {logging_mixin.py:115} INFO - [2022-06-06 11:24:22,290] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:24:22,293] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:24:22,408] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-06 11:24:53,019] {processor.py:153} INFO - Started process (PID=85760) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:24:53,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:24:53,023] {logging_mixin.py:115} INFO - [2022-06-06 11:24:53,023] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:24:53,112] {logging_mixin.py:115} INFO - [2022-06-06 11:24:53,109] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:24:53,113] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:24:53,228] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-06 11:25:23,852] {processor.py:153} INFO - Started process (PID=85828) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:25:23,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:25:23,857] {logging_mixin.py:115} INFO - [2022-06-06 11:25:23,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:25:23,927] {logging_mixin.py:115} INFO - [2022-06-06 11:25:23,925] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:25:23,928] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:25:24,023] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 11:25:54,719] {processor.py:153} INFO - Started process (PID=85894) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:25:54,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:25:54,721] {logging_mixin.py:115} INFO - [2022-06-06 11:25:54,721] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:25:54,767] {logging_mixin.py:115} INFO - [2022-06-06 11:25:54,765] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:25:54,768] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:25:54,864] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 11:26:25,380] {processor.py:153} INFO - Started process (PID=85962) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:26:25,382] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:26:25,384] {logging_mixin.py:115} INFO - [2022-06-06 11:26:25,384] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:26:25,443] {logging_mixin.py:115} INFO - [2022-06-06 11:26:25,440] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:26:25,444] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:26:25,549] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 11:26:56,155] {processor.py:153} INFO - Started process (PID=86022) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:26:56,157] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:26:56,158] {logging_mixin.py:115} INFO - [2022-06-06 11:26:56,158] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:26:56,221] {logging_mixin.py:115} INFO - [2022-06-06 11:26:56,218] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:26:56,224] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:26:56,323] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 11:27:27,112] {processor.py:153} INFO - Started process (PID=86089) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:27:27,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:27:27,115] {logging_mixin.py:115} INFO - [2022-06-06 11:27:27,115] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:27:27,188] {logging_mixin.py:115} INFO - [2022-06-06 11:27:27,185] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:27:27,189] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:27:27,301] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 11:27:57,732] {processor.py:153} INFO - Started process (PID=86155) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:27:57,734] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:27:57,737] {logging_mixin.py:115} INFO - [2022-06-06 11:27:57,737] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:27:57,823] {logging_mixin.py:115} INFO - [2022-06-06 11:27:57,821] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:27:57,826] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:27:57,931] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.212 seconds
[2022-06-06 11:28:27,983] {processor.py:153} INFO - Started process (PID=86224) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:28:27,985] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:28:27,987] {logging_mixin.py:115} INFO - [2022-06-06 11:28:27,987] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:28:28,048] {logging_mixin.py:115} INFO - [2022-06-06 11:28:28,046] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:28:28,049] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:28:28,144] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 11:28:58,246] {processor.py:153} INFO - Started process (PID=86290) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:28:58,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:28:58,249] {logging_mixin.py:115} INFO - [2022-06-06 11:28:58,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:28:58,295] {logging_mixin.py:115} INFO - [2022-06-06 11:28:58,292] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:28:58,297] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:28:58,400] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 11:29:28,646] {processor.py:153} INFO - Started process (PID=86347) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:29:28,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:29:28,652] {logging_mixin.py:115} INFO - [2022-06-06 11:29:28,652] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:29:28,724] {logging_mixin.py:115} INFO - [2022-06-06 11:29:28,722] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:29:28,727] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:29:28,819] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.178 seconds
[2022-06-06 11:29:59,031] {processor.py:153} INFO - Started process (PID=86415) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:29:59,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:29:59,035] {logging_mixin.py:115} INFO - [2022-06-06 11:29:59,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:29:59,108] {logging_mixin.py:115} INFO - [2022-06-06 11:29:59,105] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:29:59,111] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:29:59,214] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-06 11:30:29,310] {processor.py:153} INFO - Started process (PID=86483) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:30:29,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:30:29,315] {logging_mixin.py:115} INFO - [2022-06-06 11:30:29,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:30:29,367] {logging_mixin.py:115} INFO - [2022-06-06 11:30:29,365] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:30:29,368] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:30:29,470] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 11:31:00,143] {processor.py:153} INFO - Started process (PID=86552) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:31:00,145] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:31:00,148] {logging_mixin.py:115} INFO - [2022-06-06 11:31:00,148] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:31:00,219] {logging_mixin.py:115} INFO - [2022-06-06 11:31:00,214] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:31:00,221] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:31:00,340] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 11:31:31,136] {processor.py:153} INFO - Started process (PID=86621) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:31:31,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:31:31,139] {logging_mixin.py:115} INFO - [2022-06-06 11:31:31,139] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:31:31,200] {logging_mixin.py:115} INFO - [2022-06-06 11:31:31,197] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:31:31,201] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:31:31,324] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 11:32:01,933] {processor.py:153} INFO - Started process (PID=86680) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:32:01,939] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:32:01,942] {logging_mixin.py:115} INFO - [2022-06-06 11:32:01,941] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:32:02,013] {logging_mixin.py:115} INFO - [2022-06-06 11:32:02,010] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:32:02,014] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:32:02,115] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-06 11:32:32,848] {processor.py:153} INFO - Started process (PID=86748) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:32:32,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:32:32,852] {logging_mixin.py:115} INFO - [2022-06-06 11:32:32,852] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:32:32,906] {logging_mixin.py:115} INFO - [2022-06-06 11:32:32,904] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:32:32,907] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:32:33,004] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 11:33:03,087] {processor.py:153} INFO - Started process (PID=86817) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:33:03,089] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:33:03,090] {logging_mixin.py:115} INFO - [2022-06-06 11:33:03,090] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:33:03,155] {logging_mixin.py:115} INFO - [2022-06-06 11:33:03,152] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:33:03,157] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:33:03,254] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 11:33:33,351] {processor.py:153} INFO - Started process (PID=86887) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:33:33,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:33:33,354] {logging_mixin.py:115} INFO - [2022-06-06 11:33:33,354] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:33:33,404] {logging_mixin.py:115} INFO - [2022-06-06 11:33:33,401] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:33:33,433] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:33:33,531] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 11:34:04,238] {processor.py:153} INFO - Started process (PID=86953) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:34:04,241] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:34:04,242] {logging_mixin.py:115} INFO - [2022-06-06 11:34:04,242] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:34:04,313] {logging_mixin.py:115} INFO - [2022-06-06 11:34:04,310] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:34:04,315] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:34:04,449] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-06 11:34:35,220] {processor.py:153} INFO - Started process (PID=87010) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:34:35,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:34:35,223] {logging_mixin.py:115} INFO - [2022-06-06 11:34:35,223] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:34:35,273] {logging_mixin.py:115} INFO - [2022-06-06 11:34:35,271] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:34:35,275] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:34:35,374] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 11:35:05,522] {processor.py:153} INFO - Started process (PID=87077) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:35:05,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:35:05,524] {logging_mixin.py:115} INFO - [2022-06-06 11:35:05,524] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:35:05,580] {logging_mixin.py:115} INFO - [2022-06-06 11:35:05,576] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:35:05,581] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:35:05,680] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 11:35:36,041] {processor.py:153} INFO - Started process (PID=87145) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:35:36,045] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:35:36,048] {logging_mixin.py:115} INFO - [2022-06-06 11:35:36,048] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:35:36,109] {logging_mixin.py:115} INFO - [2022-06-06 11:35:36,107] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:35:36,110] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:35:36,206] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 11:36:06,240] {processor.py:153} INFO - Started process (PID=87215) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:36:06,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:36:06,243] {logging_mixin.py:115} INFO - [2022-06-06 11:36:06,243] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:36:06,295] {logging_mixin.py:115} INFO - [2022-06-06 11:36:06,293] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:36:06,296] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:36:06,393] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 11:36:36,494] {processor.py:153} INFO - Started process (PID=87276) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:36:36,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:36:36,498] {logging_mixin.py:115} INFO - [2022-06-06 11:36:36,498] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:36:36,557] {logging_mixin.py:115} INFO - [2022-06-06 11:36:36,554] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:36:36,559] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:36:36,653] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 11:37:06,766] {processor.py:153} INFO - Started process (PID=87346) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:37:06,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:37:06,771] {logging_mixin.py:115} INFO - [2022-06-06 11:37:06,771] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:37:06,826] {logging_mixin.py:115} INFO - [2022-06-06 11:37:06,824] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:37:06,827] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:37:06,924] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 11:37:37,373] {processor.py:153} INFO - Started process (PID=87413) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:37:37,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:37:37,379] {logging_mixin.py:115} INFO - [2022-06-06 11:37:37,379] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:37:37,452] {logging_mixin.py:115} INFO - [2022-06-06 11:37:37,448] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:37:37,453] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:37:37,548] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-06 11:38:08,479] {processor.py:153} INFO - Started process (PID=87477) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:38:08,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:38:08,482] {logging_mixin.py:115} INFO - [2022-06-06 11:38:08,482] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:38:08,554] {logging_mixin.py:115} INFO - [2022-06-06 11:38:08,550] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:38:08,555] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:38:08,678] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 11:38:39,162] {processor.py:153} INFO - Started process (PID=87545) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:38:39,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:38:39,167] {logging_mixin.py:115} INFO - [2022-06-06 11:38:39,167] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:38:39,285] {logging_mixin.py:115} INFO - [2022-06-06 11:38:39,279] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:38:39,287] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:38:39,500] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.341 seconds
[2022-06-06 11:39:09,679] {processor.py:153} INFO - Started process (PID=87604) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:39:09,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:39:09,681] {logging_mixin.py:115} INFO - [2022-06-06 11:39:09,681] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:39:09,727] {logging_mixin.py:115} INFO - [2022-06-06 11:39:09,725] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:39:09,728] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:39:09,826] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 11:39:39,908] {processor.py:153} INFO - Started process (PID=87671) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:39:39,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:39:39,914] {logging_mixin.py:115} INFO - [2022-06-06 11:39:39,914] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:39:39,977] {logging_mixin.py:115} INFO - [2022-06-06 11:39:39,975] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:39:39,978] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:39:40,074] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 11:40:10,209] {processor.py:153} INFO - Started process (PID=87740) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:40:10,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:40:10,213] {logging_mixin.py:115} INFO - [2022-06-06 11:40:10,213] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:40:10,272] {logging_mixin.py:115} INFO - [2022-06-06 11:40:10,270] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:40:10,273] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:40:10,372] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 11:40:40,481] {processor.py:153} INFO - Started process (PID=87807) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:40:40,483] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:40:40,484] {logging_mixin.py:115} INFO - [2022-06-06 11:40:40,484] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:40:40,545] {logging_mixin.py:115} INFO - [2022-06-06 11:40:40,542] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:40:40,549] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:40:40,655] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 11:41:11,165] {processor.py:153} INFO - Started process (PID=87865) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:41:11,169] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:41:11,172] {logging_mixin.py:115} INFO - [2022-06-06 11:41:11,172] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:41:11,241] {logging_mixin.py:115} INFO - [2022-06-06 11:41:11,239] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:41:11,243] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:41:11,354] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 11:41:41,580] {processor.py:153} INFO - Started process (PID=87935) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:41:41,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:41:41,583] {logging_mixin.py:115} INFO - [2022-06-06 11:41:41,582] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:41:41,652] {logging_mixin.py:115} INFO - [2022-06-06 11:41:41,651] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:41:41,653] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:41:41,765] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 11:42:11,867] {processor.py:153} INFO - Started process (PID=88006) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:42:11,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:42:11,869] {logging_mixin.py:115} INFO - [2022-06-06 11:42:11,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:42:11,917] {logging_mixin.py:115} INFO - [2022-06-06 11:42:11,915] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:42:11,919] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:42:12,014] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 11:42:42,301] {processor.py:153} INFO - Started process (PID=88074) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:42:42,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:42:42,304] {logging_mixin.py:115} INFO - [2022-06-06 11:42:42,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:42:42,377] {logging_mixin.py:115} INFO - [2022-06-06 11:42:42,374] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:42:42,378] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:42:42,478] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-06 11:43:12,783] {processor.py:153} INFO - Started process (PID=88127) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:43:12,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:43:12,788] {logging_mixin.py:115} INFO - [2022-06-06 11:43:12,788] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:43:12,846] {logging_mixin.py:115} INFO - [2022-06-06 11:43:12,844] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:43:12,848] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:43:12,947] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 11:43:43,213] {processor.py:153} INFO - Started process (PID=88198) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:43:43,216] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:43:43,217] {logging_mixin.py:115} INFO - [2022-06-06 11:43:43,217] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:43:43,296] {logging_mixin.py:115} INFO - [2022-06-06 11:43:43,294] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:43:43,297] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:43:43,392] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 11:44:13,647] {processor.py:153} INFO - Started process (PID=88266) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:44:13,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:44:13,651] {logging_mixin.py:115} INFO - [2022-06-06 11:44:13,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:44:13,713] {logging_mixin.py:115} INFO - [2022-06-06 11:44:13,710] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:44:13,714] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:44:13,816] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 11:44:43,995] {processor.py:153} INFO - Started process (PID=88333) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:44:43,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:44:44,000] {logging_mixin.py:115} INFO - [2022-06-06 11:44:43,999] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:44:44,074] {logging_mixin.py:115} INFO - [2022-06-06 11:44:44,071] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:44:44,075] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:44:44,170] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 11:45:14,855] {processor.py:153} INFO - Started process (PID=88393) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:45:14,857] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:45:14,861] {logging_mixin.py:115} INFO - [2022-06-06 11:45:14,861] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:45:14,927] {logging_mixin.py:115} INFO - [2022-06-06 11:45:14,925] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:45:14,928] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:45:15,025] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 11:45:45,095] {processor.py:153} INFO - Started process (PID=88463) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:45:45,097] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:45:45,098] {logging_mixin.py:115} INFO - [2022-06-06 11:45:45,098] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:45:45,163] {logging_mixin.py:115} INFO - [2022-06-06 11:45:45,161] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:45:45,165] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:45:45,266] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 11:46:15,521] {processor.py:153} INFO - Started process (PID=88530) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:46:15,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:46:15,528] {logging_mixin.py:115} INFO - [2022-06-06 11:46:15,528] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:46:15,597] {logging_mixin.py:115} INFO - [2022-06-06 11:46:15,594] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:46:15,598] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:46:15,695] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-06 11:46:46,090] {processor.py:153} INFO - Started process (PID=88598) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:46:46,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:46:46,095] {logging_mixin.py:115} INFO - [2022-06-06 11:46:46,095] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:46:46,167] {logging_mixin.py:115} INFO - [2022-06-06 11:46:46,165] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:46:46,169] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:46:46,272] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 11:47:16,382] {processor.py:153} INFO - Started process (PID=88657) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:47:16,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:47:16,389] {logging_mixin.py:115} INFO - [2022-06-06 11:47:16,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:47:16,445] {logging_mixin.py:115} INFO - [2022-06-06 11:47:16,443] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:47:16,446] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:47:16,545] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 11:47:46,846] {processor.py:153} INFO - Started process (PID=88725) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:47:46,849] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:47:46,851] {logging_mixin.py:115} INFO - [2022-06-06 11:47:46,851] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:47:46,927] {logging_mixin.py:115} INFO - [2022-06-06 11:47:46,924] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:47:46,929] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:47:47,032] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 11:48:17,207] {processor.py:153} INFO - Started process (PID=88793) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:48:17,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:48:17,212] {logging_mixin.py:115} INFO - [2022-06-06 11:48:17,211] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:48:17,271] {logging_mixin.py:115} INFO - [2022-06-06 11:48:17,268] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:48:17,272] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:48:17,372] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 11:48:48,190] {processor.py:153} INFO - Started process (PID=88860) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:48:48,193] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:48:48,194] {logging_mixin.py:115} INFO - [2022-06-06 11:48:48,194] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:48:48,263] {logging_mixin.py:115} INFO - [2022-06-06 11:48:48,261] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:48:48,265] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:48:48,363] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 11:49:19,060] {processor.py:153} INFO - Started process (PID=88927) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:49:19,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:49:19,064] {logging_mixin.py:115} INFO - [2022-06-06 11:49:19,064] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:49:19,141] {logging_mixin.py:115} INFO - [2022-06-06 11:49:19,138] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:49:19,142] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:49:19,256] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-06 11:49:50,020] {processor.py:153} INFO - Started process (PID=88985) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:49:50,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:49:50,023] {logging_mixin.py:115} INFO - [2022-06-06 11:49:50,023] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:49:50,093] {logging_mixin.py:115} INFO - [2022-06-06 11:49:50,089] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:49:50,096] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:49:50,193] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.186 seconds
[2022-06-06 11:50:21,008] {processor.py:153} INFO - Started process (PID=89055) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:50:21,011] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:50:21,012] {logging_mixin.py:115} INFO - [2022-06-06 11:50:21,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:50:21,064] {logging_mixin.py:115} INFO - [2022-06-06 11:50:21,061] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:50:21,064] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:50:21,160] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 11:50:51,953] {processor.py:153} INFO - Started process (PID=89125) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:50:51,956] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:50:51,957] {logging_mixin.py:115} INFO - [2022-06-06 11:50:51,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:50:52,017] {logging_mixin.py:115} INFO - [2022-06-06 11:50:52,015] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:50:52,019] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:50:52,116] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 11:51:22,782] {processor.py:153} INFO - Started process (PID=89191) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:51:22,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:51:22,786] {logging_mixin.py:115} INFO - [2022-06-06 11:51:22,786] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:51:22,853] {logging_mixin.py:115} INFO - [2022-06-06 11:51:22,850] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:51:22,854] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:51:22,951] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 11:51:53,273] {processor.py:153} INFO - Started process (PID=89256) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:51:53,276] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:51:53,277] {logging_mixin.py:115} INFO - [2022-06-06 11:51:53,277] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:51:53,352] {logging_mixin.py:115} INFO - [2022-06-06 11:51:53,349] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:51:53,353] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:51:53,464] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.194 seconds
[2022-06-06 11:52:23,882] {processor.py:153} INFO - Started process (PID=89315) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:52:23,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:52:23,887] {logging_mixin.py:115} INFO - [2022-06-06 11:52:23,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:52:23,954] {logging_mixin.py:115} INFO - [2022-06-06 11:52:23,951] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:52:23,955] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:52:24,055] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 11:52:54,121] {processor.py:153} INFO - Started process (PID=89382) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:52:54,123] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:52:54,126] {logging_mixin.py:115} INFO - [2022-06-06 11:52:54,126] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:52:54,208] {logging_mixin.py:115} INFO - [2022-06-06 11:52:54,204] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:52:54,209] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:52:54,308] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 11:53:24,788] {processor.py:153} INFO - Started process (PID=89449) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:53:24,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:53:24,790] {logging_mixin.py:115} INFO - [2022-06-06 11:53:24,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:53:24,867] {logging_mixin.py:115} INFO - [2022-06-06 11:53:24,862] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:53:24,870] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:53:24,973] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-06 11:53:55,747] {processor.py:153} INFO - Started process (PID=89517) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:53:55,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:53:55,753] {logging_mixin.py:115} INFO - [2022-06-06 11:53:55,753] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:53:55,812] {logging_mixin.py:115} INFO - [2022-06-06 11:53:55,810] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:53:55,814] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:53:55,910] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 11:54:25,980] {processor.py:153} INFO - Started process (PID=89576) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:54:25,982] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:54:25,983] {logging_mixin.py:115} INFO - [2022-06-06 11:54:25,983] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:54:26,041] {logging_mixin.py:115} INFO - [2022-06-06 11:54:26,038] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:54:26,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:54:26,138] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 11:54:56,282] {processor.py:153} INFO - Started process (PID=89648) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:54:56,284] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:54:56,285] {logging_mixin.py:115} INFO - [2022-06-06 11:54:56,285] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:54:56,341] {logging_mixin.py:115} INFO - [2022-06-06 11:54:56,339] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:54:56,343] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:54:56,437] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 11:55:26,468] {processor.py:153} INFO - Started process (PID=89716) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:55:26,470] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:55:26,471] {logging_mixin.py:115} INFO - [2022-06-06 11:55:26,471] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:55:26,534] {logging_mixin.py:115} INFO - [2022-06-06 11:55:26,531] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:55:26,535] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:55:26,634] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 11:55:57,556] {processor.py:153} INFO - Started process (PID=89783) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:55:57,559] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:55:57,560] {logging_mixin.py:115} INFO - [2022-06-06 11:55:57,560] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:55:57,622] {logging_mixin.py:115} INFO - [2022-06-06 11:55:57,619] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:55:57,624] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:55:57,727] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 11:56:27,760] {processor.py:153} INFO - Started process (PID=89841) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:56:27,762] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:56:27,763] {logging_mixin.py:115} INFO - [2022-06-06 11:56:27,763] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:56:27,810] {logging_mixin.py:115} INFO - [2022-06-06 11:56:27,808] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:56:27,812] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:56:27,908] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 11:56:58,087] {processor.py:153} INFO - Started process (PID=89910) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:56:58,090] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:56:58,092] {logging_mixin.py:115} INFO - [2022-06-06 11:56:58,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:56:58,176] {logging_mixin.py:115} INFO - [2022-06-06 11:56:58,174] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:56:58,177] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:56:58,284] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.203 seconds
[2022-06-06 11:57:28,903] {processor.py:153} INFO - Started process (PID=89979) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:57:28,906] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:57:28,909] {logging_mixin.py:115} INFO - [2022-06-06 11:57:28,908] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:57:28,986] {logging_mixin.py:115} INFO - [2022-06-06 11:57:28,984] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:57:28,988] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:57:29,086] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.190 seconds
[2022-06-06 11:57:59,783] {processor.py:153} INFO - Started process (PID=90047) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:57:59,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:57:59,788] {logging_mixin.py:115} INFO - [2022-06-06 11:57:59,788] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:57:59,841] {logging_mixin.py:115} INFO - [2022-06-06 11:57:59,839] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:57:59,842] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:57:59,937] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 11:58:30,439] {processor.py:153} INFO - Started process (PID=90114) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:58:30,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:58:30,445] {logging_mixin.py:115} INFO - [2022-06-06 11:58:30,445] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:58:30,524] {logging_mixin.py:115} INFO - [2022-06-06 11:58:30,518] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:58:30,527] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:58:30,648] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-06 11:59:00,829] {processor.py:153} INFO - Started process (PID=90171) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:59:00,832] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:59:00,833] {logging_mixin.py:115} INFO - [2022-06-06 11:59:00,833] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:59:00,904] {logging_mixin.py:115} INFO - [2022-06-06 11:59:00,902] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:59:00,905] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:59:01,021] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-06 11:59:31,799] {processor.py:153} INFO - Started process (PID=90241) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:59:31,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 11:59:31,802] {logging_mixin.py:115} INFO - [2022-06-06 11:59:31,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:59:31,851] {logging_mixin.py:115} INFO - [2022-06-06 11:59:31,849] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 11:59:31,852] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 11:59:31,949] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 12:00:02,570] {processor.py:153} INFO - Started process (PID=90309) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:00:02,573] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:00:02,575] {logging_mixin.py:115} INFO - [2022-06-06 12:00:02,575] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:00:02,643] {logging_mixin.py:115} INFO - [2022-06-06 12:00:02,639] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:00:02,644] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:00:02,737] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 12:00:33,070] {processor.py:153} INFO - Started process (PID=90380) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:00:33,073] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:00:33,076] {logging_mixin.py:115} INFO - [2022-06-06 12:00:33,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:00:33,149] {logging_mixin.py:115} INFO - [2022-06-06 12:00:33,147] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:00:33,151] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:00:33,253] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 12:01:03,291] {processor.py:153} INFO - Started process (PID=90444) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:01:03,292] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:01:03,294] {logging_mixin.py:115} INFO - [2022-06-06 12:01:03,294] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:01:03,353] {logging_mixin.py:115} INFO - [2022-06-06 12:01:03,349] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:01:03,355] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:01:03,469] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 12:01:33,791] {processor.py:153} INFO - Started process (PID=90503) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:01:33,794] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:01:33,795] {logging_mixin.py:115} INFO - [2022-06-06 12:01:33,795] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:01:33,870] {logging_mixin.py:115} INFO - [2022-06-06 12:01:33,867] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:01:33,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:01:33,980] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.196 seconds
[2022-06-06 12:02:04,158] {processor.py:153} INFO - Started process (PID=90569) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:02:04,164] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:02:04,168] {logging_mixin.py:115} INFO - [2022-06-06 12:02:04,168] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:02:04,246] {logging_mixin.py:115} INFO - [2022-06-06 12:02:04,243] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:02:04,248] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:02:04,349] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.198 seconds
[2022-06-06 12:02:34,410] {processor.py:153} INFO - Started process (PID=90637) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:02:34,413] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:02:34,417] {logging_mixin.py:115} INFO - [2022-06-06 12:02:34,417] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:02:34,479] {logging_mixin.py:115} INFO - [2022-06-06 12:02:34,476] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:02:34,481] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:02:34,586] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 12:03:05,584] {processor.py:153} INFO - Started process (PID=90707) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:03:05,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:03:05,593] {logging_mixin.py:115} INFO - [2022-06-06 12:03:05,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:03:05,653] {logging_mixin.py:115} INFO - [2022-06-06 12:03:05,650] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:03:05,655] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:03:05,747] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 12:03:36,545] {processor.py:153} INFO - Started process (PID=90766) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:03:36,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:03:36,547] {logging_mixin.py:115} INFO - [2022-06-06 12:03:36,547] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:03:36,600] {logging_mixin.py:115} INFO - [2022-06-06 12:03:36,598] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:03:36,601] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:03:36,700] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 12:04:07,652] {processor.py:153} INFO - Started process (PID=90834) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:04:07,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:04:07,659] {logging_mixin.py:115} INFO - [2022-06-06 12:04:07,659] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:04:07,719] {logging_mixin.py:115} INFO - [2022-06-06 12:04:07,717] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:04:07,721] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:04:07,816] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 12:04:37,967] {processor.py:153} INFO - Started process (PID=90900) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:04:37,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:04:37,972] {logging_mixin.py:115} INFO - [2022-06-06 12:04:37,972] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:04:38,036] {logging_mixin.py:115} INFO - [2022-06-06 12:04:38,034] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:04:38,038] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:04:38,141] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 12:05:08,226] {processor.py:153} INFO - Started process (PID=90971) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:05:08,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:05:08,230] {logging_mixin.py:115} INFO - [2022-06-06 12:05:08,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:05:08,285] {logging_mixin.py:115} INFO - [2022-06-06 12:05:08,283] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:05:08,288] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:05:08,381] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 12:05:38,798] {processor.py:153} INFO - Started process (PID=91038) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:05:38,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:05:38,800] {logging_mixin.py:115} INFO - [2022-06-06 12:05:38,800] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:05:38,851] {logging_mixin.py:115} INFO - [2022-06-06 12:05:38,848] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:05:38,852] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:05:38,955] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 12:06:09,234] {processor.py:153} INFO - Started process (PID=91094) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:06:09,237] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:06:09,240] {logging_mixin.py:115} INFO - [2022-06-06 12:06:09,240] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:06:09,310] {logging_mixin.py:115} INFO - [2022-06-06 12:06:09,306] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:06:09,311] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:06:09,412] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 12:06:39,654] {processor.py:153} INFO - Started process (PID=91162) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:06:39,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:06:39,661] {logging_mixin.py:115} INFO - [2022-06-06 12:06:39,661] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:06:39,724] {logging_mixin.py:115} INFO - [2022-06-06 12:06:39,722] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:06:39,726] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:06:39,822] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 12:07:10,800] {processor.py:153} INFO - Started process (PID=91230) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:07:10,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:07:10,802] {logging_mixin.py:115} INFO - [2022-06-06 12:07:10,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:07:10,852] {logging_mixin.py:115} INFO - [2022-06-06 12:07:10,849] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:07:10,853] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:07:10,949] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 12:07:41,702] {processor.py:153} INFO - Started process (PID=91294) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:07:41,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:07:41,707] {logging_mixin.py:115} INFO - [2022-06-06 12:07:41,707] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:07:41,767] {logging_mixin.py:115} INFO - [2022-06-06 12:07:41,765] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:07:41,769] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:07:41,862] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 12:08:12,015] {processor.py:153} INFO - Started process (PID=91355) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:08:12,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:08:12,018] {logging_mixin.py:115} INFO - [2022-06-06 12:08:12,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:08:12,107] {logging_mixin.py:115} INFO - [2022-06-06 12:08:12,104] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:08:12,108] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:08:12,240] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.232 seconds
[2022-06-06 12:08:42,521] {processor.py:153} INFO - Started process (PID=91421) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:08:42,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:08:42,527] {logging_mixin.py:115} INFO - [2022-06-06 12:08:42,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:08:42,584] {logging_mixin.py:115} INFO - [2022-06-06 12:08:42,581] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:08:42,585] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:08:42,698] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-06 12:09:13,505] {processor.py:153} INFO - Started process (PID=91490) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:09:13,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:09:13,510] {logging_mixin.py:115} INFO - [2022-06-06 12:09:13,510] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:09:13,568] {logging_mixin.py:115} INFO - [2022-06-06 12:09:13,567] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:09:13,569] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:09:13,666] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 12:09:43,902] {processor.py:153} INFO - Started process (PID=91557) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:09:43,906] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:09:43,908] {logging_mixin.py:115} INFO - [2022-06-06 12:09:43,908] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:09:43,966] {logging_mixin.py:115} INFO - [2022-06-06 12:09:43,963] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:09:43,968] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:09:44,064] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 12:10:14,429] {processor.py:153} INFO - Started process (PID=91624) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:10:14,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:10:14,439] {logging_mixin.py:115} INFO - [2022-06-06 12:10:14,439] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:10:14,524] {logging_mixin.py:115} INFO - [2022-06-06 12:10:14,517] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:10:14,525] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:10:14,651] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.226 seconds
[2022-06-06 12:10:44,850] {processor.py:153} INFO - Started process (PID=91683) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:10:44,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:10:44,855] {logging_mixin.py:115} INFO - [2022-06-06 12:10:44,854] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:10:44,928] {logging_mixin.py:115} INFO - [2022-06-06 12:10:44,925] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:10:44,938] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:10:45,053] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.210 seconds
[2022-06-06 12:11:16,037] {processor.py:153} INFO - Started process (PID=91750) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:11:16,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:11:16,041] {logging_mixin.py:115} INFO - [2022-06-06 12:11:16,041] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:11:16,085] {logging_mixin.py:115} INFO - [2022-06-06 12:11:16,083] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:11:16,087] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:11:16,180] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.146 seconds
[2022-06-06 12:11:46,266] {processor.py:153} INFO - Started process (PID=91823) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:11:46,268] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:11:46,270] {logging_mixin.py:115} INFO - [2022-06-06 12:11:46,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:11:46,315] {logging_mixin.py:115} INFO - [2022-06-06 12:11:46,313] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:11:46,317] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:11:46,409] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 12:12:17,244] {processor.py:153} INFO - Started process (PID=91892) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:12:17,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:12:17,249] {logging_mixin.py:115} INFO - [2022-06-06 12:12:17,249] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:12:17,309] {logging_mixin.py:115} INFO - [2022-06-06 12:12:17,306] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:12:17,310] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:12:17,407] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 12:12:47,495] {processor.py:153} INFO - Started process (PID=91958) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:12:47,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:12:47,498] {logging_mixin.py:115} INFO - [2022-06-06 12:12:47,498] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:12:47,574] {logging_mixin.py:115} INFO - [2022-06-06 12:12:47,569] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:12:47,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:12:47,692] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.201 seconds
[2022-06-06 12:13:18,450] {processor.py:153} INFO - Started process (PID=92020) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:13:18,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:13:18,452] {logging_mixin.py:115} INFO - [2022-06-06 12:13:18,452] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:13:18,494] {logging_mixin.py:115} INFO - [2022-06-06 12:13:18,491] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:13:18,495] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:13:18,589] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.142 seconds
[2022-06-06 12:13:49,475] {processor.py:153} INFO - Started process (PID=92086) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:13:49,478] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:13:49,481] {logging_mixin.py:115} INFO - [2022-06-06 12:13:49,480] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:13:49,551] {logging_mixin.py:115} INFO - [2022-06-06 12:13:49,548] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:13:49,553] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:13:49,657] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-06 12:14:20,055] {processor.py:153} INFO - Started process (PID=92153) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:14:20,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:14:20,060] {logging_mixin.py:115} INFO - [2022-06-06 12:14:20,059] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:14:20,125] {logging_mixin.py:115} INFO - [2022-06-06 12:14:20,122] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:14:20,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:14:20,225] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 12:14:50,512] {processor.py:153} INFO - Started process (PID=92218) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:14:50,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:14:50,518] {logging_mixin.py:115} INFO - [2022-06-06 12:14:50,518] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:14:50,579] {logging_mixin.py:115} INFO - [2022-06-06 12:14:50,576] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:14:50,580] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:14:50,676] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 12:15:21,526] {processor.py:153} INFO - Started process (PID=92286) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:15:21,530] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:15:21,532] {logging_mixin.py:115} INFO - [2022-06-06 12:15:21,532] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:15:21,631] {logging_mixin.py:115} INFO - [2022-06-06 12:15:21,629] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:15:21,642] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:15:21,867] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.349 seconds
[2022-06-06 12:15:52,145] {processor.py:153} INFO - Started process (PID=92343) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:15:52,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:15:52,150] {logging_mixin.py:115} INFO - [2022-06-06 12:15:52,150] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:15:52,210] {logging_mixin.py:115} INFO - [2022-06-06 12:15:52,208] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:15:52,211] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:15:52,310] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 12:16:22,372] {processor.py:153} INFO - Started process (PID=92412) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:16:22,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:16:22,375] {logging_mixin.py:115} INFO - [2022-06-06 12:16:22,375] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:16:22,422] {logging_mixin.py:115} INFO - [2022-06-06 12:16:22,420] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:16:22,424] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:16:22,533] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 12:16:52,874] {processor.py:153} INFO - Started process (PID=92478) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:16:52,876] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:16:52,878] {logging_mixin.py:115} INFO - [2022-06-06 12:16:52,878] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:16:52,946] {logging_mixin.py:115} INFO - [2022-06-06 12:16:52,944] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:16:52,948] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:16:53,042] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 12:17:23,471] {processor.py:153} INFO - Started process (PID=92546) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:17:23,474] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:17:23,475] {logging_mixin.py:115} INFO - [2022-06-06 12:17:23,475] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:17:23,526] {logging_mixin.py:115} INFO - [2022-06-06 12:17:23,524] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:17:23,528] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:17:23,631] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 12:17:53,792] {processor.py:153} INFO - Started process (PID=92605) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:17:53,795] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:17:53,797] {logging_mixin.py:115} INFO - [2022-06-06 12:17:53,797] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:17:53,853] {logging_mixin.py:115} INFO - [2022-06-06 12:17:53,851] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:17:53,854] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:17:53,955] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 12:18:24,092] {processor.py:153} INFO - Started process (PID=92674) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:18:24,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:18:24,095] {logging_mixin.py:115} INFO - [2022-06-06 12:18:24,095] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:18:24,165] {logging_mixin.py:115} INFO - [2022-06-06 12:18:24,163] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:18:24,168] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:18:24,281] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 12:18:54,390] {processor.py:153} INFO - Started process (PID=92744) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:18:54,393] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:18:54,395] {logging_mixin.py:115} INFO - [2022-06-06 12:18:54,395] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:18:54,448] {logging_mixin.py:115} INFO - [2022-06-06 12:18:54,445] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:18:54,449] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:18:54,543] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 12:19:25,231] {processor.py:153} INFO - Started process (PID=92811) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:19:25,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:19:25,234] {logging_mixin.py:115} INFO - [2022-06-06 12:19:25,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:19:25,287] {logging_mixin.py:115} INFO - [2022-06-06 12:19:25,285] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:19:25,289] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:19:25,392] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 12:19:55,988] {processor.py:153} INFO - Started process (PID=92876) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:19:55,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:19:55,991] {logging_mixin.py:115} INFO - [2022-06-06 12:19:55,991] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:19:56,043] {logging_mixin.py:115} INFO - [2022-06-06 12:19:56,039] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:19:56,045] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:19:56,156] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 12:20:26,651] {processor.py:153} INFO - Started process (PID=92934) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:20:26,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:20:26,659] {logging_mixin.py:115} INFO - [2022-06-06 12:20:26,659] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:20:26,716] {logging_mixin.py:115} INFO - [2022-06-06 12:20:26,715] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:20:26,718] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:20:26,814] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 12:20:57,664] {processor.py:153} INFO - Started process (PID=93006) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:20:57,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:20:57,667] {logging_mixin.py:115} INFO - [2022-06-06 12:20:57,667] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:20:57,712] {logging_mixin.py:115} INFO - [2022-06-06 12:20:57,711] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:20:57,715] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:20:57,809] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 12:21:28,412] {processor.py:153} INFO - Started process (PID=93075) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:21:28,414] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:21:28,416] {logging_mixin.py:115} INFO - [2022-06-06 12:21:28,416] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:21:28,474] {logging_mixin.py:115} INFO - [2022-06-06 12:21:28,472] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:21:28,476] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:21:28,573] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 12:21:58,640] {processor.py:153} INFO - Started process (PID=93142) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:21:58,642] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:21:58,643] {logging_mixin.py:115} INFO - [2022-06-06 12:21:58,643] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:21:58,702] {logging_mixin.py:115} INFO - [2022-06-06 12:21:58,700] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:21:58,704] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:21:58,802] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 12:22:29,677] {processor.py:153} INFO - Started process (PID=93210) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:22:29,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:22:29,682] {logging_mixin.py:115} INFO - [2022-06-06 12:22:29,682] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:22:29,741] {logging_mixin.py:115} INFO - [2022-06-06 12:22:29,739] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:22:29,742] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:22:29,864] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 12:23:00,146] {processor.py:153} INFO - Started process (PID=93268) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:23:00,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:23:00,149] {logging_mixin.py:115} INFO - [2022-06-06 12:23:00,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:23:00,200] {logging_mixin.py:115} INFO - [2022-06-06 12:23:00,197] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:23:00,202] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:23:00,309] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 12:23:30,510] {processor.py:153} INFO - Started process (PID=93338) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:23:30,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:23:30,516] {logging_mixin.py:115} INFO - [2022-06-06 12:23:30,515] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:23:30,573] {logging_mixin.py:115} INFO - [2022-06-06 12:23:30,571] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:23:30,574] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:23:30,669] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 12:24:00,819] {processor.py:153} INFO - Started process (PID=93407) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:24:00,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:24:00,823] {logging_mixin.py:115} INFO - [2022-06-06 12:24:00,823] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:24:00,882] {logging_mixin.py:115} INFO - [2022-06-06 12:24:00,880] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:24:00,884] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:24:00,981] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 12:24:31,117] {processor.py:153} INFO - Started process (PID=93477) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:24:31,120] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:24:31,121] {logging_mixin.py:115} INFO - [2022-06-06 12:24:31,121] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:24:31,180] {logging_mixin.py:115} INFO - [2022-06-06 12:24:31,177] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:24:31,181] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:24:31,275] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 12:25:02,108] {processor.py:153} INFO - Started process (PID=93543) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:25:02,111] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:25:02,113] {logging_mixin.py:115} INFO - [2022-06-06 12:25:02,113] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:25:02,168] {logging_mixin.py:115} INFO - [2022-06-06 12:25:02,166] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:25:02,170] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:25:02,265] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 12:25:33,044] {processor.py:153} INFO - Started process (PID=93612) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:25:33,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:25:33,047] {logging_mixin.py:115} INFO - [2022-06-06 12:25:33,047] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:25:33,099] {logging_mixin.py:115} INFO - [2022-06-06 12:25:33,096] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:25:33,100] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:25:33,201] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 12:26:03,274] {processor.py:153} INFO - Started process (PID=93668) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:26:03,278] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:26:03,280] {logging_mixin.py:115} INFO - [2022-06-06 12:26:03,280] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:26:03,341] {logging_mixin.py:115} INFO - [2022-06-06 12:26:03,339] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:26:03,343] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:26:03,439] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 12:26:33,495] {processor.py:153} INFO - Started process (PID=93736) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:26:33,497] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:26:33,499] {logging_mixin.py:115} INFO - [2022-06-06 12:26:33,499] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:26:33,563] {logging_mixin.py:115} INFO - [2022-06-06 12:26:33,561] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:26:33,565] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:26:33,663] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 12:27:03,872] {processor.py:153} INFO - Started process (PID=93806) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:27:03,877] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:27:03,879] {logging_mixin.py:115} INFO - [2022-06-06 12:27:03,879] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:27:03,947] {logging_mixin.py:115} INFO - [2022-06-06 12:27:03,945] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:27:03,948] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:27:04,045] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 12:27:34,147] {processor.py:153} INFO - Started process (PID=93875) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:27:34,163] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:27:34,180] {logging_mixin.py:115} INFO - [2022-06-06 12:27:34,180] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:27:34,268] {logging_mixin.py:115} INFO - [2022-06-06 12:27:34,265] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:27:34,280] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:27:34,418] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.282 seconds
[2022-06-06 12:28:05,142] {processor.py:153} INFO - Started process (PID=93944) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:28:05,144] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:28:05,145] {logging_mixin.py:115} INFO - [2022-06-06 12:28:05,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:28:05,198] {logging_mixin.py:115} INFO - [2022-06-06 12:28:05,196] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:28:05,200] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:28:05,308] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 12:28:35,334] {processor.py:153} INFO - Started process (PID=94003) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:28:35,336] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:28:35,337] {logging_mixin.py:115} INFO - [2022-06-06 12:28:35,337] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:28:35,406] {logging_mixin.py:115} INFO - [2022-06-06 12:28:35,402] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:28:35,411] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:28:35,539] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.208 seconds
[2022-06-06 12:29:06,459] {processor.py:153} INFO - Started process (PID=94071) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:29:06,462] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:29:06,464] {logging_mixin.py:115} INFO - [2022-06-06 12:29:06,464] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:29:06,539] {logging_mixin.py:115} INFO - [2022-06-06 12:29:06,537] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:29:06,541] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:29:06,641] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.189 seconds
[2022-06-06 12:29:36,710] {processor.py:153} INFO - Started process (PID=94139) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:29:36,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:29:36,714] {logging_mixin.py:115} INFO - [2022-06-06 12:29:36,714] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:29:36,771] {logging_mixin.py:115} INFO - [2022-06-06 12:29:36,769] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:29:36,774] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:29:36,867] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 12:30:07,057] {processor.py:153} INFO - Started process (PID=94206) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:30:07,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:30:07,061] {logging_mixin.py:115} INFO - [2022-06-06 12:30:07,061] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:30:07,120] {logging_mixin.py:115} INFO - [2022-06-06 12:30:07,118] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:30:07,121] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:30:07,215] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 12:30:38,148] {processor.py:153} INFO - Started process (PID=94272) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:30:38,150] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:30:38,151] {logging_mixin.py:115} INFO - [2022-06-06 12:30:38,151] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:30:38,200] {logging_mixin.py:115} INFO - [2022-06-06 12:30:38,197] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:30:38,203] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:30:38,302] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 12:31:08,519] {processor.py:153} INFO - Started process (PID=94331) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:31:08,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:31:08,524] {logging_mixin.py:115} INFO - [2022-06-06 12:31:08,524] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:31:08,577] {logging_mixin.py:115} INFO - [2022-06-06 12:31:08,575] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:31:08,578] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:31:08,674] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 12:31:39,073] {processor.py:153} INFO - Started process (PID=94399) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:31:39,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:31:39,076] {logging_mixin.py:115} INFO - [2022-06-06 12:31:39,076] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:31:39,132] {logging_mixin.py:115} INFO - [2022-06-06 12:31:39,130] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:31:39,133] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:31:39,229] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 12:32:10,227] {processor.py:153} INFO - Started process (PID=94468) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:32:10,229] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:32:10,231] {logging_mixin.py:115} INFO - [2022-06-06 12:32:10,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:32:10,277] {logging_mixin.py:115} INFO - [2022-06-06 12:32:10,275] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:32:10,278] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:32:10,373] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-06 12:32:40,488] {processor.py:153} INFO - Started process (PID=94535) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:32:40,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:32:40,492] {logging_mixin.py:115} INFO - [2022-06-06 12:32:40,492] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:32:40,546] {logging_mixin.py:115} INFO - [2022-06-06 12:32:40,544] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:32:40,548] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:32:40,647] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 12:33:10,779] {processor.py:153} INFO - Started process (PID=94602) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:33:10,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:33:10,787] {logging_mixin.py:115} INFO - [2022-06-06 12:33:10,787] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:33:10,860] {logging_mixin.py:115} INFO - [2022-06-06 12:33:10,857] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:33:10,861] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:33:10,963] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.191 seconds
[2022-06-06 12:33:41,375] {processor.py:153} INFO - Started process (PID=94670) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:33:41,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:33:41,382] {logging_mixin.py:115} INFO - [2022-06-06 12:33:41,381] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:33:41,438] {logging_mixin.py:115} INFO - [2022-06-06 12:33:41,436] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:33:41,440] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:33:41,534] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 12:34:11,785] {processor.py:153} INFO - Started process (PID=94729) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:34:11,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:34:11,788] {logging_mixin.py:115} INFO - [2022-06-06 12:34:11,788] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:34:11,835] {logging_mixin.py:115} INFO - [2022-06-06 12:34:11,833] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:34:11,837] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:34:11,934] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 12:34:42,929] {processor.py:153} INFO - Started process (PID=94796) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:34:42,933] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:34:42,935] {logging_mixin.py:115} INFO - [2022-06-06 12:34:42,935] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:34:42,997] {logging_mixin.py:115} INFO - [2022-06-06 12:34:42,995] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:34:42,998] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:34:43,095] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 12:35:14,013] {processor.py:153} INFO - Started process (PID=94861) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:35:14,015] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:35:14,017] {logging_mixin.py:115} INFO - [2022-06-06 12:35:14,017] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:35:14,073] {logging_mixin.py:115} INFO - [2022-06-06 12:35:14,071] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:35:14,075] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:35:14,172] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 12:35:45,153] {processor.py:153} INFO - Started process (PID=94930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:35:45,156] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:35:45,158] {logging_mixin.py:115} INFO - [2022-06-06 12:35:45,158] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:35:45,216] {logging_mixin.py:115} INFO - [2022-06-06 12:35:45,213] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:35:45,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:35:45,312] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 12:36:15,525] {processor.py:153} INFO - Started process (PID=94998) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:36:15,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:36:15,530] {logging_mixin.py:115} INFO - [2022-06-06 12:36:15,530] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:36:15,597] {logging_mixin.py:115} INFO - [2022-06-06 12:36:15,595] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:36:15,599] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:36:15,692] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 12:36:45,898] {processor.py:153} INFO - Started process (PID=95064) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:36:45,902] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:36:45,904] {logging_mixin.py:115} INFO - [2022-06-06 12:36:45,903] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:36:45,961] {logging_mixin.py:115} INFO - [2022-06-06 12:36:45,959] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:36:45,962] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:36:46,061] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 12:37:16,238] {processor.py:153} INFO - Started process (PID=95121) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:37:16,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:37:16,242] {logging_mixin.py:115} INFO - [2022-06-06 12:37:16,241] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:37:16,297] {logging_mixin.py:115} INFO - [2022-06-06 12:37:16,295] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:37:16,299] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:37:16,392] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 12:37:47,149] {processor.py:153} INFO - Started process (PID=95191) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:37:47,151] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:37:47,153] {logging_mixin.py:115} INFO - [2022-06-06 12:37:47,152] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:37:47,208] {logging_mixin.py:115} INFO - [2022-06-06 12:37:47,206] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:37:47,209] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:37:47,303] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 12:38:18,207] {processor.py:153} INFO - Started process (PID=95261) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:38:18,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:38:18,212] {logging_mixin.py:115} INFO - [2022-06-06 12:38:18,212] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:38:18,280] {logging_mixin.py:115} INFO - [2022-06-06 12:38:18,278] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:38:18,282] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:38:18,377] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 12:38:48,453] {processor.py:153} INFO - Started process (PID=95326) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:38:48,454] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:38:48,456] {logging_mixin.py:115} INFO - [2022-06-06 12:38:48,456] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:38:48,505] {logging_mixin.py:115} INFO - [2022-06-06 12:38:48,503] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:38:48,506] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:38:48,615] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 12:39:19,317] {processor.py:153} INFO - Started process (PID=95396) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:39:19,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:39:19,322] {logging_mixin.py:115} INFO - [2022-06-06 12:39:19,322] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:39:19,378] {logging_mixin.py:115} INFO - [2022-06-06 12:39:19,375] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:39:19,379] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:39:19,472] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 12:39:50,206] {processor.py:153} INFO - Started process (PID=95466) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:39:50,207] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:39:50,208] {logging_mixin.py:115} INFO - [2022-06-06 12:39:50,208] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:39:50,253] {logging_mixin.py:115} INFO - [2022-06-06 12:39:50,250] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:39:50,254] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:39:50,348] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-06 12:40:21,224] {processor.py:153} INFO - Started process (PID=95524) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:40:21,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:40:21,229] {logging_mixin.py:115} INFO - [2022-06-06 12:40:21,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:40:21,305] {logging_mixin.py:115} INFO - [2022-06-06 12:40:21,302] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:40:21,306] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:40:21,417] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 12:40:52,282] {processor.py:153} INFO - Started process (PID=95591) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:40:52,286] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:40:52,287] {logging_mixin.py:115} INFO - [2022-06-06 12:40:52,287] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:40:52,337] {logging_mixin.py:115} INFO - [2022-06-06 12:40:52,334] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:40:52,338] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:40:52,454] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 12:41:23,250] {processor.py:153} INFO - Started process (PID=95660) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:41:23,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:41:23,255] {logging_mixin.py:115} INFO - [2022-06-06 12:41:23,254] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:41:23,316] {logging_mixin.py:115} INFO - [2022-06-06 12:41:23,315] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:41:23,317] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:41:23,415] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 12:41:53,485] {processor.py:153} INFO - Started process (PID=95729) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:41:53,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:41:53,489] {logging_mixin.py:115} INFO - [2022-06-06 12:41:53,489] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:41:53,553] {logging_mixin.py:115} INFO - [2022-06-06 12:41:53,550] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:41:53,555] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:41:53,657] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 12:42:24,077] {processor.py:153} INFO - Started process (PID=95798) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:42:24,079] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:42:24,080] {logging_mixin.py:115} INFO - [2022-06-06 12:42:24,080] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:42:24,154] {logging_mixin.py:115} INFO - [2022-06-06 12:42:24,151] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:42:24,155] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:42:24,250] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 12:58:13,788] {processor.py:153} INFO - Started process (PID=95802) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:58:13,789] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:58:13,790] {logging_mixin.py:115} INFO - [2022-06-06 12:58:13,789] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:58:13,840] {logging_mixin.py:115} INFO - [2022-06-06 12:58:13,838] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:58:13,842] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:58:13,943] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 12:58:44,230] {processor.py:153} INFO - Started process (PID=95868) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:58:44,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:58:44,233] {logging_mixin.py:115} INFO - [2022-06-06 12:58:44,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:58:44,330] {logging_mixin.py:115} INFO - [2022-06-06 12:58:44,328] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:58:44,331] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:58:44,431] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-06 12:59:14,695] {processor.py:153} INFO - Started process (PID=95927) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:59:14,696] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:59:14,698] {logging_mixin.py:115} INFO - [2022-06-06 12:59:14,697] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:59:14,743] {logging_mixin.py:115} INFO - [2022-06-06 12:59:14,741] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:59:14,745] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:59:14,842] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 12:59:45,470] {processor.py:153} INFO - Started process (PID=95997) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:59:45,471] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 12:59:45,474] {logging_mixin.py:115} INFO - [2022-06-06 12:59:45,474] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:59:45,526] {logging_mixin.py:115} INFO - [2022-06-06 12:59:45,524] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 12:59:45,528] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 12:59:45,620] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 13:00:16,464] {processor.py:153} INFO - Started process (PID=96064) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:00:16,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:00:16,467] {logging_mixin.py:115} INFO - [2022-06-06 13:00:16,467] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:00:16,514] {logging_mixin.py:115} INFO - [2022-06-06 13:00:16,512] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:00:16,516] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:00:16,621] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 13:00:47,318] {processor.py:153} INFO - Started process (PID=96132) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:00:47,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:00:47,321] {logging_mixin.py:115} INFO - [2022-06-06 13:00:47,321] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:00:47,377] {logging_mixin.py:115} INFO - [2022-06-06 13:00:47,375] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:00:47,378] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:00:47,472] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 13:01:18,300] {processor.py:153} INFO - Started process (PID=96201) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:01:18,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:01:18,304] {logging_mixin.py:115} INFO - [2022-06-06 13:01:18,304] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:01:18,365] {logging_mixin.py:115} INFO - [2022-06-06 13:01:18,363] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:01:18,368] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:01:18,459] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 13:19:41,227] {processor.py:153} INFO - Started process (PID=96259) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:19:41,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:19:41,233] {logging_mixin.py:115} INFO - [2022-06-06 13:19:41,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:19:41,522] {logging_mixin.py:115} INFO - [2022-06-06 13:19:41,511] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:19:41,525] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:19:41,792] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.569 seconds
[2022-06-06 13:20:12,726] {processor.py:153} INFO - Started process (PID=96327) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:20:12,727] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:20:12,729] {logging_mixin.py:115} INFO - [2022-06-06 13:20:12,728] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:20:12,837] {logging_mixin.py:115} INFO - [2022-06-06 13:20:12,834] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:20:12,839] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:20:12,954] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.231 seconds
[2022-06-06 13:21:32,372] {processor.py:153} INFO - Started process (PID=96394) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:21:32,373] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:21:32,375] {logging_mixin.py:115} INFO - [2022-06-06 13:21:32,375] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:21:32,431] {logging_mixin.py:115} INFO - [2022-06-06 13:21:32,429] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:21:32,433] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:21:32,528] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 13:22:03,375] {processor.py:153} INFO - Started process (PID=96463) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:22:03,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:22:03,380] {logging_mixin.py:115} INFO - [2022-06-06 13:22:03,380] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:22:03,437] {logging_mixin.py:115} INFO - [2022-06-06 13:22:03,434] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:22:03,438] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:22:03,531] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 13:23:19,190] {processor.py:153} INFO - Started process (PID=96521) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:23:19,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:23:19,193] {logging_mixin.py:115} INFO - [2022-06-06 13:23:19,193] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:23:19,259] {logging_mixin.py:115} INFO - [2022-06-06 13:23:19,257] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:23:19,261] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:23:19,363] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 13:24:28,428] {processor.py:153} INFO - Started process (PID=96587) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:24:28,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:24:28,430] {logging_mixin.py:115} INFO - [2022-06-06 13:24:28,430] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:24:28,484] {logging_mixin.py:115} INFO - [2022-06-06 13:24:28,482] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:24:28,485] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:24:28,582] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 13:24:59,281] {processor.py:153} INFO - Started process (PID=96653) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:24:59,284] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:24:59,286] {logging_mixin.py:115} INFO - [2022-06-06 13:24:59,286] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:24:59,343] {logging_mixin.py:115} INFO - [2022-06-06 13:24:59,340] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:24:59,344] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:24:59,435] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 13:26:09,094] {processor.py:153} INFO - Started process (PID=96719) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:26:09,097] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:26:09,098] {logging_mixin.py:115} INFO - [2022-06-06 13:26:09,098] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:26:09,157] {logging_mixin.py:115} INFO - [2022-06-06 13:26:09,155] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:26:09,158] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:26:09,251] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 13:26:43,327] {processor.py:153} INFO - Started process (PID=96776) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:26:43,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:26:43,329] {logging_mixin.py:115} INFO - [2022-06-06 13:26:43,329] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:26:43,431] {logging_mixin.py:115} INFO - [2022-06-06 13:26:43,429] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:26:43,433] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:26:43,566] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.244 seconds
[2022-06-06 13:27:13,723] {processor.py:153} INFO - Started process (PID=96847) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:27:13,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:27:13,728] {logging_mixin.py:115} INFO - [2022-06-06 13:27:13,728] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:27:13,786] {logging_mixin.py:115} INFO - [2022-06-06 13:27:13,784] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:27:13,788] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:27:13,883] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 13:28:27,872] {processor.py:153} INFO - Started process (PID=96915) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:28:27,873] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:28:27,875] {logging_mixin.py:115} INFO - [2022-06-06 13:28:27,874] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:28:27,926] {logging_mixin.py:115} INFO - [2022-06-06 13:28:27,924] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:28:27,928] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:28:28,023] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 13:28:58,683] {processor.py:153} INFO - Started process (PID=96982) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:28:58,686] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:28:58,688] {logging_mixin.py:115} INFO - [2022-06-06 13:28:58,688] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:28:58,758] {logging_mixin.py:115} INFO - [2022-06-06 13:28:58,756] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:28:58,759] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:28:58,854] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 13:30:08,406] {processor.py:153} INFO - Started process (PID=97039) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:30:08,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:30:08,408] {logging_mixin.py:115} INFO - [2022-06-06 13:30:08,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:30:08,451] {logging_mixin.py:115} INFO - [2022-06-06 13:30:08,450] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:30:08,453] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:30:08,546] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.142 seconds
[2022-06-06 13:30:38,697] {processor.py:153} INFO - Started process (PID=97106) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:30:38,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:30:38,702] {logging_mixin.py:115} INFO - [2022-06-06 13:30:38,702] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:30:38,766] {logging_mixin.py:115} INFO - [2022-06-06 13:30:38,764] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:30:38,767] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:30:38,860] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 13:31:59,221] {processor.py:153} INFO - Started process (PID=97174) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:31:59,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:31:59,224] {logging_mixin.py:115} INFO - [2022-06-06 13:31:59,224] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:31:59,352] {logging_mixin.py:115} INFO - [2022-06-06 13:31:59,349] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:31:59,354] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:31:59,470] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.252 seconds
[2022-06-06 13:35:34,791] {processor.py:153} INFO - Started process (PID=97244) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:35:34,795] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:35:34,802] {logging_mixin.py:115} INFO - [2022-06-06 13:35:34,802] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:35:35,172] {logging_mixin.py:115} INFO - [2022-06-06 13:35:35,164] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:35:35,174] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:35:35,540] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.763 seconds
[2022-06-06 13:36:05,932] {processor.py:153} INFO - Started process (PID=97300) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:36:05,936] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:36:05,939] {logging_mixin.py:115} INFO - [2022-06-06 13:36:05,939] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:36:06,055] {logging_mixin.py:115} INFO - [2022-06-06 13:36:06,045] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:36:06,057] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:36:06,193] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.267 seconds
[2022-06-06 13:36:37,001] {processor.py:153} INFO - Started process (PID=97367) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:36:37,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:36:37,006] {logging_mixin.py:115} INFO - [2022-06-06 13:36:37,006] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:36:37,142] {logging_mixin.py:115} INFO - [2022-06-06 13:36:37,139] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:36:37,144] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:36:37,282] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.286 seconds
[2022-06-06 13:37:08,306] {processor.py:153} INFO - Started process (PID=97435) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:37:08,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:37:08,312] {logging_mixin.py:115} INFO - [2022-06-06 13:37:08,312] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:37:08,422] {logging_mixin.py:115} INFO - [2022-06-06 13:37:08,419] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:37:08,424] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:37:08,569] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.267 seconds
[2022-06-06 13:37:39,027] {processor.py:153} INFO - Started process (PID=97502) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:37:39,030] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:37:39,033] {logging_mixin.py:115} INFO - [2022-06-06 13:37:39,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:37:39,191] {logging_mixin.py:115} INFO - [2022-06-06 13:37:39,188] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:37:39,193] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:37:39,334] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.318 seconds
[2022-06-06 13:38:09,923] {processor.py:153} INFO - Started process (PID=97567) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:38:09,925] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:38:09,926] {logging_mixin.py:115} INFO - [2022-06-06 13:38:09,926] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:38:10,021] {logging_mixin.py:115} INFO - [2022-06-06 13:38:10,018] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:38:10,023] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:38:10,155] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.240 seconds
[2022-06-06 13:38:41,038] {processor.py:153} INFO - Started process (PID=97627) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:38:41,041] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:38:41,043] {logging_mixin.py:115} INFO - [2022-06-06 13:38:41,043] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:38:41,139] {logging_mixin.py:115} INFO - [2022-06-06 13:38:41,135] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:38:41,142] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:38:41,253] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-06 13:39:11,665] {processor.py:153} INFO - Started process (PID=97698) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:39:11,667] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:39:11,668] {logging_mixin.py:115} INFO - [2022-06-06 13:39:11,668] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:39:11,753] {logging_mixin.py:115} INFO - [2022-06-06 13:39:11,751] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:39:11,754] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:39:11,860] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.205 seconds
[2022-06-06 13:39:42,701] {processor.py:153} INFO - Started process (PID=97772) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:39:42,704] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:39:42,706] {logging_mixin.py:115} INFO - [2022-06-06 13:39:42,706] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:39:42,801] {logging_mixin.py:115} INFO - [2022-06-06 13:39:42,798] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:39:42,802] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:39:42,952] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.258 seconds
[2022-06-06 13:40:13,462] {processor.py:153} INFO - Started process (PID=97840) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:40:13,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:40:13,466] {logging_mixin.py:115} INFO - [2022-06-06 13:40:13,466] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:40:13,560] {logging_mixin.py:115} INFO - [2022-06-06 13:40:13,557] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:40:13,562] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:40:13,677] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.224 seconds
[2022-06-06 13:40:44,229] {processor.py:153} INFO - Started process (PID=97896) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:40:44,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:40:44,232] {logging_mixin.py:115} INFO - [2022-06-06 13:40:44,232] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:40:44,326] {logging_mixin.py:115} INFO - [2022-06-06 13:40:44,320] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:40:44,328] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:40:44,442] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.216 seconds
[2022-06-06 13:41:14,521] {processor.py:153} INFO - Started process (PID=97965) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:41:14,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:41:14,526] {logging_mixin.py:115} INFO - [2022-06-06 13:41:14,526] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:41:14,615] {logging_mixin.py:115} INFO - [2022-06-06 13:41:14,612] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:41:14,617] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:41:14,723] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-06 13:41:45,221] {processor.py:153} INFO - Started process (PID=98034) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:41:45,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:41:45,233] {logging_mixin.py:115} INFO - [2022-06-06 13:41:45,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:41:45,335] {logging_mixin.py:115} INFO - [2022-06-06 13:41:45,328] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:41:45,339] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:41:45,479] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.267 seconds
[2022-06-06 13:42:15,635] {processor.py:153} INFO - Started process (PID=98106) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:42:15,649] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:42:15,653] {logging_mixin.py:115} INFO - [2022-06-06 13:42:15,653] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:42:15,893] {logging_mixin.py:115} INFO - [2022-06-06 13:42:15,886] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:42:15,896] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:42:16,156] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.533 seconds
[2022-06-06 13:42:47,231] {processor.py:153} INFO - Started process (PID=98161) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:42:47,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:42:47,236] {logging_mixin.py:115} INFO - [2022-06-06 13:42:47,236] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:42:47,377] {logging_mixin.py:115} INFO - [2022-06-06 13:42:47,374] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:42:47,378] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:42:47,522] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.297 seconds
[2022-06-06 13:43:17,766] {processor.py:153} INFO - Started process (PID=98231) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:43:17,770] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:43:17,772] {logging_mixin.py:115} INFO - [2022-06-06 13:43:17,772] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:43:17,907] {logging_mixin.py:115} INFO - [2022-06-06 13:43:17,900] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:43:17,912] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:43:18,063] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.307 seconds
[2022-06-06 13:43:48,865] {processor.py:153} INFO - Started process (PID=98304) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:43:48,867] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:43:48,869] {logging_mixin.py:115} INFO - [2022-06-06 13:43:48,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:43:48,961] {logging_mixin.py:115} INFO - [2022-06-06 13:43:48,959] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:43:48,962] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:43:49,067] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.204 seconds
[2022-06-06 13:44:19,595] {processor.py:153} INFO - Started process (PID=98361) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:44:19,597] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:44:19,598] {logging_mixin.py:115} INFO - [2022-06-06 13:44:19,598] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:44:19,689] {logging_mixin.py:115} INFO - [2022-06-06 13:44:19,686] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:44:19,691] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:44:19,808] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.218 seconds
[2022-06-06 13:44:50,789] {processor.py:153} INFO - Started process (PID=98428) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:44:50,791] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:44:50,793] {logging_mixin.py:115} INFO - [2022-06-06 13:44:50,793] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:44:50,862] {logging_mixin.py:115} INFO - [2022-06-06 13:44:50,859] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:44:50,863] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:44:50,965] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 13:45:21,030] {processor.py:153} INFO - Started process (PID=98494) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:45:21,033] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:45:21,035] {logging_mixin.py:115} INFO - [2022-06-06 13:45:21,035] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:45:21,093] {logging_mixin.py:115} INFO - [2022-06-06 13:45:21,091] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:45:21,095] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:45:21,190] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 13:45:51,925] {processor.py:153} INFO - Started process (PID=98561) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:45:51,928] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:45:51,930] {logging_mixin.py:115} INFO - [2022-06-06 13:45:51,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:45:51,999] {logging_mixin.py:115} INFO - [2022-06-06 13:45:51,997] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:45:52,000] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:45:52,092] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 13:46:22,287] {processor.py:153} INFO - Started process (PID=98630) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:46:22,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:46:22,291] {logging_mixin.py:115} INFO - [2022-06-06 13:46:22,291] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:46:22,387] {logging_mixin.py:115} INFO - [2022-06-06 13:46:22,385] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:46:22,391] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:46:22,503] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.222 seconds
[2022-06-06 13:46:53,241] {processor.py:153} INFO - Started process (PID=98688) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:46:53,244] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:46:53,246] {logging_mixin.py:115} INFO - [2022-06-06 13:46:53,246] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:46:53,323] {logging_mixin.py:115} INFO - [2022-06-06 13:46:53,321] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:46:53,324] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:46:53,440] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-06 13:47:23,499] {processor.py:153} INFO - Started process (PID=98757) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:47:23,501] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:47:23,503] {logging_mixin.py:115} INFO - [2022-06-06 13:47:23,503] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:47:23,562] {logging_mixin.py:115} INFO - [2022-06-06 13:47:23,559] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:47:23,564] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:47:23,678] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 13:47:53,812] {processor.py:153} INFO - Started process (PID=98826) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:47:53,815] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:47:53,816] {logging_mixin.py:115} INFO - [2022-06-06 13:47:53,816] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:47:53,880] {logging_mixin.py:115} INFO - [2022-06-06 13:47:53,877] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:47:53,881] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:47:53,982] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 13:48:24,012] {processor.py:153} INFO - Started process (PID=98894) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:48:24,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:48:24,014] {logging_mixin.py:115} INFO - [2022-06-06 13:48:24,014] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:48:24,075] {logging_mixin.py:115} INFO - [2022-06-06 13:48:24,072] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:48:24,078] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:48:24,234] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-06 13:48:54,975] {processor.py:153} INFO - Started process (PID=98962) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:48:54,977] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:48:54,978] {logging_mixin.py:115} INFO - [2022-06-06 13:48:54,978] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:48:55,057] {logging_mixin.py:115} INFO - [2022-06-06 13:48:55,054] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:48:55,060] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:48:55,196] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-06 13:49:25,334] {processor.py:153} INFO - Started process (PID=99021) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:49:25,337] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:49:25,339] {logging_mixin.py:115} INFO - [2022-06-06 13:49:25,339] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:49:25,442] {logging_mixin.py:115} INFO - [2022-06-06 13:49:25,439] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:49:25,443] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:49:25,581] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.257 seconds
[2022-06-06 13:49:56,274] {processor.py:153} INFO - Started process (PID=99086) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:49:56,276] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:49:56,278] {logging_mixin.py:115} INFO - [2022-06-06 13:49:56,277] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:49:56,345] {logging_mixin.py:115} INFO - [2022-06-06 13:49:56,341] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:49:56,346] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:49:56,446] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 13:50:26,898] {processor.py:153} INFO - Started process (PID=99158) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:50:26,901] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:50:26,902] {logging_mixin.py:115} INFO - [2022-06-06 13:50:26,902] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:50:26,947] {logging_mixin.py:115} INFO - [2022-06-06 13:50:26,945] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:50:26,948] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:50:27,040] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-06 13:50:57,747] {processor.py:153} INFO - Started process (PID=99224) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:50:57,748] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:50:57,749] {logging_mixin.py:115} INFO - [2022-06-06 13:50:57,749] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:50:57,814] {logging_mixin.py:115} INFO - [2022-06-06 13:50:57,812] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:50:57,816] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:50:57,918] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 13:51:28,586] {processor.py:153} INFO - Started process (PID=99281) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:51:28,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:51:28,590] {logging_mixin.py:115} INFO - [2022-06-06 13:51:28,590] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:51:28,685] {logging_mixin.py:115} INFO - [2022-06-06 13:51:28,682] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:51:28,688] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:51:28,794] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-06 13:51:59,771] {processor.py:153} INFO - Started process (PID=99348) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:51:59,774] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:51:59,776] {logging_mixin.py:115} INFO - [2022-06-06 13:51:59,776] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:51:59,837] {logging_mixin.py:115} INFO - [2022-06-06 13:51:59,835] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:51:59,839] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:51:59,935] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 13:52:30,419] {processor.py:153} INFO - Started process (PID=99415) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:52:30,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:52:30,423] {logging_mixin.py:115} INFO - [2022-06-06 13:52:30,423] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:52:30,499] {logging_mixin.py:115} INFO - [2022-06-06 13:52:30,497] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:52:30,501] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:52:30,605] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 13:53:00,785] {processor.py:153} INFO - Started process (PID=99473) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:53:00,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:53:00,790] {logging_mixin.py:115} INFO - [2022-06-06 13:53:00,789] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:53:00,901] {logging_mixin.py:115} INFO - [2022-06-06 13:53:00,897] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:53:00,906] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:53:01,059] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.279 seconds
[2022-06-06 13:53:31,568] {processor.py:153} INFO - Started process (PID=99540) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:53:31,580] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:53:31,581] {logging_mixin.py:115} INFO - [2022-06-06 13:53:31,581] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:53:31,660] {logging_mixin.py:115} INFO - [2022-06-06 13:53:31,658] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:53:31,661] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:53:31,768] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-06 13:54:02,304] {processor.py:153} INFO - Started process (PID=99606) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:54:02,307] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:54:02,309] {logging_mixin.py:115} INFO - [2022-06-06 13:54:02,309] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:54:02,401] {logging_mixin.py:115} INFO - [2022-06-06 13:54:02,399] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:54:02,403] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:54:02,508] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-06 13:54:32,876] {processor.py:153} INFO - Started process (PID=99671) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:54:32,879] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:54:32,881] {logging_mixin.py:115} INFO - [2022-06-06 13:54:32,881] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:54:33,009] {logging_mixin.py:115} INFO - [2022-06-06 13:54:33,006] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:54:33,010] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:54:33,199] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.347 seconds
[2022-06-06 13:55:03,681] {processor.py:153} INFO - Started process (PID=99740) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:55:03,683] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:55:03,684] {logging_mixin.py:115} INFO - [2022-06-06 13:55:03,684] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:55:03,777] {logging_mixin.py:115} INFO - [2022-06-06 13:55:03,775] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:55:03,779] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:55:03,887] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.211 seconds
[2022-06-06 13:55:34,594] {processor.py:153} INFO - Started process (PID=99798) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:55:34,597] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:55:34,599] {logging_mixin.py:115} INFO - [2022-06-06 13:55:34,599] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:55:34,659] {logging_mixin.py:115} INFO - [2022-06-06 13:55:34,657] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:55:34,661] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:55:34,757] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 13:56:05,786] {processor.py:153} INFO - Started process (PID=99863) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:56:05,788] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:56:05,789] {logging_mixin.py:115} INFO - [2022-06-06 13:56:05,789] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:56:05,857] {logging_mixin.py:115} INFO - [2022-06-06 13:56:05,855] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:56:05,858] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:56:05,961] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 13:56:36,432] {processor.py:153} INFO - Started process (PID=99930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:56:36,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:56:36,435] {logging_mixin.py:115} INFO - [2022-06-06 13:56:36,435] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:56:36,526] {logging_mixin.py:115} INFO - [2022-06-06 13:56:36,522] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:56:36,528] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:56:36,650] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.224 seconds
[2022-06-06 13:57:07,069] {processor.py:153} INFO - Started process (PID=99997) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:57:07,073] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:57:07,074] {logging_mixin.py:115} INFO - [2022-06-06 13:57:07,074] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:57:07,148] {logging_mixin.py:115} INFO - [2022-06-06 13:57:07,145] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:57:07,150] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:57:07,248] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 13:57:37,611] {processor.py:153} INFO - Started process (PID=365) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:57:37,613] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:57:37,614] {logging_mixin.py:115} INFO - [2022-06-06 13:57:37,614] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:57:37,729] {logging_mixin.py:115} INFO - [2022-06-06 13:57:37,724] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:57:37,731] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:57:37,897] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.303 seconds
[2022-06-06 13:58:08,094] {processor.py:153} INFO - Started process (PID=427) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:58:08,097] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:58:08,098] {logging_mixin.py:115} INFO - [2022-06-06 13:58:08,098] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:58:08,235] {logging_mixin.py:115} INFO - [2022-06-06 13:58:08,232] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:58:08,236] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:58:08,369] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.284 seconds
[2022-06-06 13:58:39,141] {processor.py:153} INFO - Started process (PID=493) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:58:39,145] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:58:39,147] {logging_mixin.py:115} INFO - [2022-06-06 13:58:39,147] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:58:39,229] {logging_mixin.py:115} INFO - [2022-06-06 13:58:39,227] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:58:39,231] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:58:39,345] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.213 seconds
[2022-06-06 13:59:10,302] {processor.py:153} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:59:10,306] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:59:10,308] {logging_mixin.py:115} INFO - [2022-06-06 13:59:10,307] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:59:10,403] {logging_mixin.py:115} INFO - [2022-06-06 13:59:10,399] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:59:10,405] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:59:10,529] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-06 13:59:40,578] {processor.py:153} INFO - Started process (PID=625) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:59:40,579] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 13:59:40,580] {logging_mixin.py:115} INFO - [2022-06-06 13:59:40,580] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:59:40,649] {logging_mixin.py:115} INFO - [2022-06-06 13:59:40,646] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 13:59:40,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 13:59:40,777] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 14:00:10,898] {processor.py:153} INFO - Started process (PID=690) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:00:10,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:00:10,903] {logging_mixin.py:115} INFO - [2022-06-06 14:00:10,903] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:00:11,000] {logging_mixin.py:115} INFO - [2022-06-06 14:00:10,998] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:00:11,001] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:00:11,115] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.229 seconds
[2022-06-06 14:00:41,386] {processor.py:153} INFO - Started process (PID=759) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:00:41,388] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:00:41,389] {logging_mixin.py:115} INFO - [2022-06-06 14:00:41,389] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:00:41,511] {logging_mixin.py:115} INFO - [2022-06-06 14:00:41,506] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:00:41,513] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:00:41,633] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.251 seconds
[2022-06-06 14:01:11,720] {processor.py:153} INFO - Started process (PID=828) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:01:11,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:01:11,732] {logging_mixin.py:115} INFO - [2022-06-06 14:01:11,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:01:11,848] {logging_mixin.py:115} INFO - [2022-06-06 14:01:11,837] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:01:11,850] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:01:11,962] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.247 seconds
[2022-06-06 14:01:42,680] {processor.py:153} INFO - Started process (PID=886) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:01:42,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:01:42,683] {logging_mixin.py:115} INFO - [2022-06-06 14:01:42,683] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:01:42,773] {logging_mixin.py:115} INFO - [2022-06-06 14:01:42,769] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:01:42,776] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:01:42,895] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.220 seconds
[2022-06-06 14:02:13,108] {processor.py:153} INFO - Started process (PID=954) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:02:13,110] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:02:13,112] {logging_mixin.py:115} INFO - [2022-06-06 14:02:13,112] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:02:13,198] {logging_mixin.py:115} INFO - [2022-06-06 14:02:13,195] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:02:13,199] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:02:13,304] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 14:02:43,764] {processor.py:153} INFO - Started process (PID=1024) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:02:43,768] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:02:43,769] {logging_mixin.py:115} INFO - [2022-06-06 14:02:43,769] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:02:43,852] {logging_mixin.py:115} INFO - [2022-06-06 14:02:43,849] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:02:43,854] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:02:43,963] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.204 seconds
[2022-06-06 14:03:14,154] {processor.py:153} INFO - Started process (PID=1079) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:03:14,156] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:03:14,158] {logging_mixin.py:115} INFO - [2022-06-06 14:03:14,158] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:03:14,245] {logging_mixin.py:115} INFO - [2022-06-06 14:03:14,243] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:03:14,246] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:03:14,363] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-06 14:03:44,612] {processor.py:153} INFO - Started process (PID=1148) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:03:44,616] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:03:44,626] {logging_mixin.py:115} INFO - [2022-06-06 14:03:44,626] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:03:44,768] {logging_mixin.py:115} INFO - [2022-06-06 14:03:44,764] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:03:44,769] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:03:44,969] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.377 seconds
[2022-06-06 14:04:15,143] {processor.py:153} INFO - Started process (PID=1213) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:04:15,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:04:15,148] {logging_mixin.py:115} INFO - [2022-06-06 14:04:15,147] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:04:15,242] {logging_mixin.py:115} INFO - [2022-06-06 14:04:15,240] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:04:15,244] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:04:15,355] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.217 seconds
[2022-06-06 14:04:45,465] {processor.py:153} INFO - Started process (PID=1275) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:04:45,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:04:45,469] {logging_mixin.py:115} INFO - [2022-06-06 14:04:45,469] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:04:45,566] {logging_mixin.py:115} INFO - [2022-06-06 14:04:45,563] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:04:45,568] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:04:45,719] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-06 14:05:16,550] {processor.py:153} INFO - Started process (PID=1345) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:05:16,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:05:16,559] {logging_mixin.py:115} INFO - [2022-06-06 14:05:16,559] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:05:16,687] {logging_mixin.py:115} INFO - [2022-06-06 14:05:16,684] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:05:16,689] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:05:16,801] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-06 14:05:47,140] {processor.py:153} INFO - Started process (PID=1416) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:05:47,142] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:05:47,144] {logging_mixin.py:115} INFO - [2022-06-06 14:05:47,144] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:05:47,284] {logging_mixin.py:115} INFO - [2022-06-06 14:05:47,281] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:05:47,286] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:05:47,395] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.262 seconds
[2022-06-06 14:06:17,608] {processor.py:153} INFO - Started process (PID=1476) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:06:17,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:06:17,611] {logging_mixin.py:115} INFO - [2022-06-06 14:06:17,611] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:06:17,710] {logging_mixin.py:115} INFO - [2022-06-06 14:06:17,704] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:06:17,714] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:06:17,968] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.363 seconds
[2022-06-06 14:06:48,490] {processor.py:153} INFO - Started process (PID=1547) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:06:48,498] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:06:48,508] {logging_mixin.py:115} INFO - [2022-06-06 14:06:48,506] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:06:48,706] {logging_mixin.py:115} INFO - [2022-06-06 14:06:48,703] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:06:48,707] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:06:48,881] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.433 seconds
[2022-06-06 14:07:19,043] {processor.py:153} INFO - Started process (PID=1613) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:07:19,045] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:07:19,046] {logging_mixin.py:115} INFO - [2022-06-06 14:07:19,046] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:07:19,148] {logging_mixin.py:115} INFO - [2022-06-06 14:07:19,144] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:07:19,150] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:07:19,290] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.254 seconds
[2022-06-06 14:07:50,002] {processor.py:153} INFO - Started process (PID=1670) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:07:50,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:07:50,011] {logging_mixin.py:115} INFO - [2022-06-06 14:07:50,011] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:07:50,186] {logging_mixin.py:115} INFO - [2022-06-06 14:07:50,176] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:07:50,189] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:07:50,385] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.387 seconds
[2022-06-06 14:08:20,521] {processor.py:153} INFO - Started process (PID=1741) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:08:20,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:08:20,528] {logging_mixin.py:115} INFO - [2022-06-06 14:08:20,528] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:08:20,653] {logging_mixin.py:115} INFO - [2022-06-06 14:08:20,649] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:08:20,655] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:08:20,775] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.264 seconds
[2022-06-06 14:08:50,859] {processor.py:153} INFO - Started process (PID=1808) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:08:50,861] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:08:50,863] {logging_mixin.py:115} INFO - [2022-06-06 14:08:50,863] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:08:50,938] {logging_mixin.py:115} INFO - [2022-06-06 14:08:50,935] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:08:50,939] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:08:51,037] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 14:09:21,098] {processor.py:153} INFO - Started process (PID=1876) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:09:21,100] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:09:21,104] {logging_mixin.py:115} INFO - [2022-06-06 14:09:21,104] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:09:21,184] {logging_mixin.py:115} INFO - [2022-06-06 14:09:21,182] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:09:21,186] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:09:21,285] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 14:09:51,538] {processor.py:153} INFO - Started process (PID=1934) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:09:51,539] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:09:51,540] {logging_mixin.py:115} INFO - [2022-06-06 14:09:51,540] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:09:51,590] {logging_mixin.py:115} INFO - [2022-06-06 14:09:51,588] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:09:51,591] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:09:51,697] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 14:10:21,895] {processor.py:153} INFO - Started process (PID=1999) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:10:21,898] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:10:21,900] {logging_mixin.py:115} INFO - [2022-06-06 14:10:21,900] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:10:21,949] {logging_mixin.py:115} INFO - [2022-06-06 14:10:21,947] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:10:21,950] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:10:22,048] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 14:10:52,658] {processor.py:153} INFO - Started process (PID=2065) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:10:52,661] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:10:52,662] {logging_mixin.py:115} INFO - [2022-06-06 14:10:52,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:10:52,730] {logging_mixin.py:115} INFO - [2022-06-06 14:10:52,727] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:10:52,731] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:10:52,868] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-06 14:11:23,464] {processor.py:153} INFO - Started process (PID=2131) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:11:23,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:11:23,469] {logging_mixin.py:115} INFO - [2022-06-06 14:11:23,468] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:11:23,577] {logging_mixin.py:115} INFO - [2022-06-06 14:11:23,574] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:11:23,579] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:11:23,690] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.235 seconds
[2022-06-06 14:11:53,848] {processor.py:153} INFO - Started process (PID=2198) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:11:53,851] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:11:53,853] {logging_mixin.py:115} INFO - [2022-06-06 14:11:53,853] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:11:53,927] {logging_mixin.py:115} INFO - [2022-06-06 14:11:53,925] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:11:53,929] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:11:54,040] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.197 seconds
[2022-06-06 14:12:24,315] {processor.py:153} INFO - Started process (PID=2255) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:12:24,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:12:24,319] {logging_mixin.py:115} INFO - [2022-06-06 14:12:24,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:12:24,389] {logging_mixin.py:115} INFO - [2022-06-06 14:12:24,386] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:12:24,390] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:12:24,500] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.193 seconds
[2022-06-06 14:12:54,632] {processor.py:153} INFO - Started process (PID=2322) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:12:54,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:12:54,635] {logging_mixin.py:115} INFO - [2022-06-06 14:12:54,635] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:12:54,693] {logging_mixin.py:115} INFO - [2022-06-06 14:12:54,691] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:12:54,696] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:12:54,791] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 14:13:25,058] {processor.py:153} INFO - Started process (PID=2391) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:13:25,060] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:13:25,063] {logging_mixin.py:115} INFO - [2022-06-06 14:13:25,063] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:13:25,120] {logging_mixin.py:115} INFO - [2022-06-06 14:13:25,118] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:13:25,121] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:13:25,221] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 14:13:55,321] {processor.py:153} INFO - Started process (PID=2460) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:13:55,323] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:13:55,325] {logging_mixin.py:115} INFO - [2022-06-06 14:13:55,325] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:13:55,384] {logging_mixin.py:115} INFO - [2022-06-06 14:13:55,382] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:13:55,387] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:13:55,481] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 14:14:26,010] {processor.py:153} INFO - Started process (PID=2528) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:14:26,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:14:26,018] {logging_mixin.py:115} INFO - [2022-06-06 14:14:26,018] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:14:26,165] {logging_mixin.py:115} INFO - [2022-06-06 14:14:26,160] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:14:26,168] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:14:26,337] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.341 seconds
[2022-06-06 14:14:56,530] {processor.py:153} INFO - Started process (PID=2586) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:14:56,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:14:56,533] {logging_mixin.py:115} INFO - [2022-06-06 14:14:56,533] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:14:56,636] {logging_mixin.py:115} INFO - [2022-06-06 14:14:56,632] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:14:56,640] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:14:56,769] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.243 seconds
[2022-06-06 14:15:27,442] {processor.py:153} INFO - Started process (PID=2651) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:15:27,446] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:15:27,449] {logging_mixin.py:115} INFO - [2022-06-06 14:15:27,449] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:15:27,604] {logging_mixin.py:115} INFO - [2022-06-06 14:15:27,598] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:15:27,606] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:15:27,758] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.332 seconds
[2022-06-06 14:15:57,927] {processor.py:153} INFO - Started process (PID=2716) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:15:57,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:15:57,930] {logging_mixin.py:115} INFO - [2022-06-06 14:15:57,930] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:15:58,040] {logging_mixin.py:115} INFO - [2022-06-06 14:15:58,038] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:15:58,042] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:15:58,160] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.238 seconds
[2022-06-06 14:16:28,593] {processor.py:153} INFO - Started process (PID=2781) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:16:28,598] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:16:28,600] {logging_mixin.py:115} INFO - [2022-06-06 14:16:28,600] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:16:28,700] {logging_mixin.py:115} INFO - [2022-06-06 14:16:28,696] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:16:28,702] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:16:28,846] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.258 seconds
[2022-06-06 14:32:21,625] {processor.py:153} INFO - Started process (PID=2794) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:32:21,626] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:32:21,628] {logging_mixin.py:115} INFO - [2022-06-06 14:32:21,628] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:32:21,739] {logging_mixin.py:115} INFO - [2022-06-06 14:32:21,735] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:32:21,740] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:32:21,886] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.267 seconds
[2022-06-06 14:32:52,668] {processor.py:153} INFO - Started process (PID=2859) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:32:52,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:32:52,672] {logging_mixin.py:115} INFO - [2022-06-06 14:32:52,671] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:32:52,758] {logging_mixin.py:115} INFO - [2022-06-06 14:32:52,755] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:32:52,764] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:32:52,865] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-06 14:34:07,358] {processor.py:153} INFO - Started process (PID=2927) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:34:07,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:34:07,360] {logging_mixin.py:115} INFO - [2022-06-06 14:34:07,360] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:34:07,412] {logging_mixin.py:115} INFO - [2022-06-06 14:34:07,409] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:34:07,413] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:34:07,523] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 14:34:38,298] {processor.py:153} INFO - Started process (PID=2984) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:34:38,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:34:38,300] {logging_mixin.py:115} INFO - [2022-06-06 14:34:38,300] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:34:38,384] {logging_mixin.py:115} INFO - [2022-06-06 14:34:38,381] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:34:38,386] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:34:38,506] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.214 seconds
[2022-06-06 14:35:51,318] {processor.py:153} INFO - Started process (PID=3053) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:35:51,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:35:51,322] {logging_mixin.py:115} INFO - [2022-06-06 14:35:51,322] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:35:51,373] {logging_mixin.py:115} INFO - [2022-06-06 14:35:51,371] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:35:51,374] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:35:51,470] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 14:36:22,138] {processor.py:153} INFO - Started process (PID=3121) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:36:22,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:36:22,141] {logging_mixin.py:115} INFO - [2022-06-06 14:36:22,141] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:36:22,190] {logging_mixin.py:115} INFO - [2022-06-06 14:36:22,188] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:36:22,191] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:36:22,286] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 14:37:35,632] {processor.py:153} INFO - Started process (PID=3186) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:37:35,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:37:35,634] {logging_mixin.py:115} INFO - [2022-06-06 14:37:35,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:37:35,681] {logging_mixin.py:115} INFO - [2022-06-06 14:37:35,678] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:37:35,682] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:37:35,775] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-06 14:38:45,674] {processor.py:153} INFO - Started process (PID=3246) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:38:45,677] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:38:45,678] {logging_mixin.py:115} INFO - [2022-06-06 14:38:45,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:38:45,745] {logging_mixin.py:115} INFO - [2022-06-06 14:38:45,742] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:38:45,746] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:38:45,854] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.185 seconds
[2022-06-06 14:39:16,753] {processor.py:153} INFO - Started process (PID=3316) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:39:16,755] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:39:16,757] {logging_mixin.py:115} INFO - [2022-06-06 14:39:16,757] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:39:16,806] {logging_mixin.py:115} INFO - [2022-06-06 14:39:16,803] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:39:16,807] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:39:16,901] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 14:40:38,262] {processor.py:153} INFO - Started process (PID=3380) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:40:38,264] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:40:38,266] {logging_mixin.py:115} INFO - [2022-06-06 14:40:38,266] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:40:38,319] {logging_mixin.py:115} INFO - [2022-06-06 14:40:38,317] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:40:38,322] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:40:38,414] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 14:41:09,149] {processor.py:153} INFO - Started process (PID=3449) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:41:09,151] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:41:09,152] {logging_mixin.py:115} INFO - [2022-06-06 14:41:09,151] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:41:09,215] {logging_mixin.py:115} INFO - [2022-06-06 14:41:09,212] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:41:09,216] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:41:09,317] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 14:42:27,456] {processor.py:153} INFO - Started process (PID=3505) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:42:27,458] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:42:27,459] {logging_mixin.py:115} INFO - [2022-06-06 14:42:27,459] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:42:27,523] {logging_mixin.py:115} INFO - [2022-06-06 14:42:27,521] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:42:27,525] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:42:27,623] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.172 seconds
[2022-06-06 14:42:58,055] {processor.py:153} INFO - Started process (PID=3572) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:42:58,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:42:58,058] {logging_mixin.py:115} INFO - [2022-06-06 14:42:58,058] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:42:58,123] {logging_mixin.py:115} INFO - [2022-06-06 14:42:58,120] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:42:58,128] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:42:58,228] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 14:43:29,298] {processor.py:153} INFO - Started process (PID=3639) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:43:29,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:43:29,301] {logging_mixin.py:115} INFO - [2022-06-06 14:43:29,301] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:43:29,355] {logging_mixin.py:115} INFO - [2022-06-06 14:43:29,353] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:43:29,357] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:43:29,461] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 14:44:44,726] {processor.py:153} INFO - Started process (PID=3709) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:44:44,727] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:44:44,728] {logging_mixin.py:115} INFO - [2022-06-06 14:44:44,728] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:44:44,774] {logging_mixin.py:115} INFO - [2022-06-06 14:44:44,772] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:44:44,776] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:44:44,868] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-06 14:45:15,772] {processor.py:153} INFO - Started process (PID=3770) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:45:15,774] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:45:15,777] {logging_mixin.py:115} INFO - [2022-06-06 14:45:15,777] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:45:15,844] {logging_mixin.py:115} INFO - [2022-06-06 14:45:15,842] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:45:15,845] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:45:15,943] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 14:46:30,231] {processor.py:153} INFO - Started process (PID=3842) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:46:30,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:46:30,235] {logging_mixin.py:115} INFO - [2022-06-06 14:46:30,234] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:46:30,289] {logging_mixin.py:115} INFO - [2022-06-06 14:46:30,287] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:46:30,291] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:46:30,384] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 14:47:00,424] {processor.py:153} INFO - Started process (PID=3915) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:47:00,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:47:00,427] {logging_mixin.py:115} INFO - [2022-06-06 14:47:00,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:47:00,476] {logging_mixin.py:115} INFO - [2022-06-06 14:47:00,474] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:47:00,477] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:47:00,575] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 14:48:08,549] {processor.py:153} INFO - Started process (PID=3982) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:48:08,550] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:48:08,551] {logging_mixin.py:115} INFO - [2022-06-06 14:48:08,551] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:48:08,610] {logging_mixin.py:115} INFO - [2022-06-06 14:48:08,608] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:48:08,612] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:48:08,714] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 14:49:25,375] {processor.py:153} INFO - Started process (PID=4042) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:49:25,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:49:25,378] {logging_mixin.py:115} INFO - [2022-06-06 14:49:25,378] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:49:25,431] {logging_mixin.py:115} INFO - [2022-06-06 14:49:25,428] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:49:25,432] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:49:25,528] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 14:49:55,667] {processor.py:153} INFO - Started process (PID=4112) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:49:55,672] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:49:55,673] {logging_mixin.py:115} INFO - [2022-06-06 14:49:55,673] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:49:55,739] {logging_mixin.py:115} INFO - [2022-06-06 14:49:55,737] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:49:55,741] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:49:55,835] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 14:51:11,129] {processor.py:153} INFO - Started process (PID=4179) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:51:11,131] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:51:11,132] {logging_mixin.py:115} INFO - [2022-06-06 14:51:11,132] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:51:11,179] {logging_mixin.py:115} INFO - [2022-06-06 14:51:11,176] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:51:11,180] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:51:11,273] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 14:51:42,132] {processor.py:153} INFO - Started process (PID=4250) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:51:42,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:51:42,134] {logging_mixin.py:115} INFO - [2022-06-06 14:51:42,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:51:42,190] {logging_mixin.py:115} INFO - [2022-06-06 14:51:42,188] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:51:42,191] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:51:42,288] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 14:53:05,245] {processor.py:153} INFO - Started process (PID=4307) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:53:05,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:53:05,248] {logging_mixin.py:115} INFO - [2022-06-06 14:53:05,248] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:53:05,299] {logging_mixin.py:115} INFO - [2022-06-06 14:53:05,297] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:53:05,301] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:53:05,393] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 14:54:28,194] {processor.py:153} INFO - Started process (PID=4375) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:54:28,196] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:54:28,197] {logging_mixin.py:115} INFO - [2022-06-06 14:54:28,197] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:54:28,251] {logging_mixin.py:115} INFO - [2022-06-06 14:54:28,249] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:54:28,253] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:54:28,345] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 14:54:59,009] {processor.py:153} INFO - Started process (PID=4446) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:54:59,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:54:59,012] {logging_mixin.py:115} INFO - [2022-06-06 14:54:59,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:54:59,061] {logging_mixin.py:115} INFO - [2022-06-06 14:54:59,059] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:54:59,061] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:54:59,157] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 14:56:23,138] {processor.py:153} INFO - Started process (PID=4516) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:56:23,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:56:23,142] {logging_mixin.py:115} INFO - [2022-06-06 14:56:23,142] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:56:23,306] {logging_mixin.py:115} INFO - [2022-06-06 14:56:23,304] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:56:23,308] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:56:23,597] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.461 seconds
[2022-06-06 14:56:54,484] {processor.py:153} INFO - Started process (PID=4574) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:56:54,487] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:56:54,490] {logging_mixin.py:115} INFO - [2022-06-06 14:56:54,490] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:56:54,554] {logging_mixin.py:115} INFO - [2022-06-06 14:56:54,552] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:56:54,555] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:56:54,650] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.175 seconds
[2022-06-06 14:58:11,377] {processor.py:153} INFO - Started process (PID=4641) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:58:11,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:58:11,380] {logging_mixin.py:115} INFO - [2022-06-06 14:58:11,380] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:58:11,421] {logging_mixin.py:115} INFO - [2022-06-06 14:58:11,419] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:58:11,422] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:58:11,518] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-06 14:59:20,497] {processor.py:153} INFO - Started process (PID=4709) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:59:20,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:59:20,501] {logging_mixin.py:115} INFO - [2022-06-06 14:59:20,501] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:59:20,555] {logging_mixin.py:115} INFO - [2022-06-06 14:59:20,552] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:59:20,556] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:59:20,650] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 14:59:51,369] {processor.py:153} INFO - Started process (PID=4773) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:59:51,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 14:59:51,376] {logging_mixin.py:115} INFO - [2022-06-06 14:59:51,375] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:59:51,437] {logging_mixin.py:115} INFO - [2022-06-06 14:59:51,434] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 14:59:51,439] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 14:59:51,557] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 15:01:13,744] {processor.py:153} INFO - Started process (PID=4834) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:01:13,745] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:01:13,747] {logging_mixin.py:115} INFO - [2022-06-06 15:01:13,746] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:01:13,810] {logging_mixin.py:115} INFO - [2022-06-06 15:01:13,808] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:01:13,812] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:01:13,917] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 15:01:44,631] {processor.py:153} INFO - Started process (PID=4900) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:01:44,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:01:44,634] {logging_mixin.py:115} INFO - [2022-06-06 15:01:44,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:01:44,682] {logging_mixin.py:115} INFO - [2022-06-06 15:01:44,680] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:01:44,683] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:01:44,779] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 15:02:15,404] {processor.py:153} INFO - Started process (PID=4964) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:02:15,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:02:15,408] {logging_mixin.py:115} INFO - [2022-06-06 15:02:15,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:02:15,455] {logging_mixin.py:115} INFO - [2022-06-06 15:02:15,453] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:02:15,457] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:02:15,549] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-06 15:03:27,595] {processor.py:153} INFO - Started process (PID=5022) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:03:27,596] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:03:27,597] {logging_mixin.py:115} INFO - [2022-06-06 15:03:27,597] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:03:27,661] {logging_mixin.py:115} INFO - [2022-06-06 15:03:27,658] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:03:27,662] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:03:27,754] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 15:03:57,985] {processor.py:153} INFO - Started process (PID=5091) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:03:57,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:03:57,991] {logging_mixin.py:115} INFO - [2022-06-06 15:03:57,990] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:03:58,047] {logging_mixin.py:115} INFO - [2022-06-06 15:03:58,045] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:03:58,049] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:03:58,141] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 15:05:06,159] {processor.py:153} INFO - Started process (PID=5162) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:05:06,160] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:05:06,161] {logging_mixin.py:115} INFO - [2022-06-06 15:05:06,161] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:05:06,206] {logging_mixin.py:115} INFO - [2022-06-06 15:05:06,203] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:05:06,207] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:05:06,300] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-06 15:06:27,088] {processor.py:153} INFO - Started process (PID=5226) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:06:27,090] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:06:27,091] {logging_mixin.py:115} INFO - [2022-06-06 15:06:27,091] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:06:27,142] {logging_mixin.py:115} INFO - [2022-06-06 15:06:27,140] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:06:27,144] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:06:27,285] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.200 seconds
[2022-06-06 15:06:57,541] {processor.py:153} INFO - Started process (PID=5285) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:06:57,542] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:06:57,543] {logging_mixin.py:115} INFO - [2022-06-06 15:06:57,543] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:06:57,605] {logging_mixin.py:115} INFO - [2022-06-06 15:06:57,602] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:06:57,606] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:06:57,699] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 15:22:40,888] {processor.py:153} INFO - Started process (PID=5355) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:22:40,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:22:40,895] {logging_mixin.py:115} INFO - [2022-06-06 15:22:40,895] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:22:41,060] {logging_mixin.py:115} INFO - [2022-06-06 15:22:41,050] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:22:41,063] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:22:41,196] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.312 seconds
[2022-06-06 15:23:11,362] {processor.py:153} INFO - Started process (PID=5412) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:23:11,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:23:11,367] {logging_mixin.py:115} INFO - [2022-06-06 15:23:11,367] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:23:11,455] {logging_mixin.py:115} INFO - [2022-06-06 15:23:11,452] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:23:11,457] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:23:11,585] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.227 seconds
[2022-06-06 15:24:24,687] {processor.py:153} INFO - Started process (PID=5478) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:24:24,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:24:24,689] {logging_mixin.py:115} INFO - [2022-06-06 15:24:24,689] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:24:24,740] {logging_mixin.py:115} INFO - [2022-06-06 15:24:24,738] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:24:24,741] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:24:24,836] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 15:24:55,065] {processor.py:153} INFO - Started process (PID=5547) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:24:55,067] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:24:55,069] {logging_mixin.py:115} INFO - [2022-06-06 15:24:55,069] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:24:55,117] {logging_mixin.py:115} INFO - [2022-06-06 15:24:55,114] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:24:55,118] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:24:55,211] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 15:26:08,416] {processor.py:153} INFO - Started process (PID=5616) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:26:08,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:26:08,419] {logging_mixin.py:115} INFO - [2022-06-06 15:26:08,419] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:26:08,461] {logging_mixin.py:115} INFO - [2022-06-06 15:26:08,459] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:26:08,462] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:26:08,553] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.139 seconds
[2022-06-06 15:27:28,785] {processor.py:153} INFO - Started process (PID=5674) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:27:28,787] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:27:28,789] {logging_mixin.py:115} INFO - [2022-06-06 15:27:28,789] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:27:28,851] {logging_mixin.py:115} INFO - [2022-06-06 15:27:28,849] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:27:28,852] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:27:28,974] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-06 15:27:59,593] {processor.py:153} INFO - Started process (PID=5745) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:27:59,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:27:59,596] {logging_mixin.py:115} INFO - [2022-06-06 15:27:59,596] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:27:59,643] {logging_mixin.py:115} INFO - [2022-06-06 15:27:59,641] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:27:59,644] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:27:59,738] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-06 15:44:23,076] {processor.py:153} INFO - Started process (PID=5814) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:44:23,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:44:23,084] {logging_mixin.py:115} INFO - [2022-06-06 15:44:23,084] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:44:23,244] {logging_mixin.py:115} INFO - [2022-06-06 15:44:23,240] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:44:23,247] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:44:23,424] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.351 seconds
[2022-06-06 15:44:53,947] {processor.py:153} INFO - Started process (PID=5883) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:44:53,949] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 15:44:53,950] {logging_mixin.py:115} INFO - [2022-06-06 15:44:53,950] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:44:54,042] {logging_mixin.py:115} INFO - [2022-06-06 15:44:54,040] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 15:44:54,044] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 15:44:54,141] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.204 seconds
[2022-06-06 16:01:39,327] {processor.py:153} INFO - Started process (PID=5943) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:01:39,329] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:01:39,332] {logging_mixin.py:115} INFO - [2022-06-06 16:01:39,332] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:01:39,441] {logging_mixin.py:115} INFO - [2022-06-06 16:01:39,438] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:01:39,442] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:01:39,713] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.389 seconds
[2022-06-06 16:02:10,275] {processor.py:153} INFO - Started process (PID=6009) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:02:10,277] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:02:10,278] {logging_mixin.py:115} INFO - [2022-06-06 16:02:10,278] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:02:10,359] {logging_mixin.py:115} INFO - [2022-06-06 16:02:10,357] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:02:10,360] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:02:10,483] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.215 seconds
[2022-06-06 16:18:10,419] {processor.py:153} INFO - Started process (PID=6073) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:18:10,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:18:10,425] {logging_mixin.py:115} INFO - [2022-06-06 16:18:10,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:18:10,794] {logging_mixin.py:115} INFO - [2022-06-06 16:18:10,782] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:18:10,800] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:18:11,111] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.710 seconds
[2022-06-06 16:35:39,061] {processor.py:153} INFO - Started process (PID=6134) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:35:39,068] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:35:39,070] {logging_mixin.py:115} INFO - [2022-06-06 16:35:39,070] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:35:39,232] {logging_mixin.py:115} INFO - [2022-06-06 16:35:39,229] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:35:39,234] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:35:39,455] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.401 seconds
[2022-06-06 16:36:10,465] {processor.py:153} INFO - Started process (PID=6201) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:36:10,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:36:10,469] {logging_mixin.py:115} INFO - [2022-06-06 16:36:10,469] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:36:10,573] {logging_mixin.py:115} INFO - [2022-06-06 16:36:10,571] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:36:10,575] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:36:10,678] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.219 seconds
[2022-06-06 16:36:41,030] {processor.py:153} INFO - Started process (PID=6266) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:36:41,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:36:41,033] {logging_mixin.py:115} INFO - [2022-06-06 16:36:41,033] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:36:41,097] {logging_mixin.py:115} INFO - [2022-06-06 16:36:41,094] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:36:41,098] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:36:41,199] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 16:37:50,692] {processor.py:153} INFO - Started process (PID=6323) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:37:50,694] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:37:50,696] {logging_mixin.py:115} INFO - [2022-06-06 16:37:50,696] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:37:50,756] {logging_mixin.py:115} INFO - [2022-06-06 16:37:50,753] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:37:50,758] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:37:50,851] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 16:39:11,928] {processor.py:153} INFO - Started process (PID=6391) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:39:11,931] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:39:11,933] {logging_mixin.py:115} INFO - [2022-06-06 16:39:11,932] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:39:11,991] {logging_mixin.py:115} INFO - [2022-06-06 16:39:11,989] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:39:11,992] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:39:12,091] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 16:39:42,877] {processor.py:153} INFO - Started process (PID=6458) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:39:42,879] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:39:42,883] {logging_mixin.py:115} INFO - [2022-06-06 16:39:42,883] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:39:42,943] {logging_mixin.py:115} INFO - [2022-06-06 16:39:42,942] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:39:42,944] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:39:43,041] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 16:40:22,358] {processor.py:153} INFO - Started process (PID=6515) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:40:22,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:40:22,362] {logging_mixin.py:115} INFO - [2022-06-06 16:40:22,362] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:40:22,421] {logging_mixin.py:115} INFO - [2022-06-06 16:40:22,419] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:40:22,422] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:40:22,515] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 16:40:53,090] {processor.py:153} INFO - Started process (PID=6589) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:40:53,091] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:40:53,092] {logging_mixin.py:115} INFO - [2022-06-06 16:40:53,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:40:53,141] {logging_mixin.py:115} INFO - [2022-06-06 16:40:53,138] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:40:53,142] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:40:53,248] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 16:42:09,085] {processor.py:153} INFO - Started process (PID=6656) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:42:09,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:42:09,090] {logging_mixin.py:115} INFO - [2022-06-06 16:42:09,090] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:42:09,152] {logging_mixin.py:115} INFO - [2022-06-06 16:42:09,149] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:42:09,154] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:42:09,247] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 16:42:40,009] {processor.py:153} INFO - Started process (PID=6726) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:42:40,012] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:42:40,013] {logging_mixin.py:115} INFO - [2022-06-06 16:42:40,013] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:42:40,070] {logging_mixin.py:115} INFO - [2022-06-06 16:42:40,067] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:42:40,071] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:42:40,166] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 16:43:47,529] {processor.py:153} INFO - Started process (PID=6785) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:43:47,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:43:47,534] {logging_mixin.py:115} INFO - [2022-06-06 16:43:47,534] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:43:47,585] {logging_mixin.py:115} INFO - [2022-06-06 16:43:47,582] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:43:47,586] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:43:47,680] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 16:45:00,530] {processor.py:153} INFO - Started process (PID=6853) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:45:00,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:45:00,533] {logging_mixin.py:115} INFO - [2022-06-06 16:45:00,533] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:45:00,587] {logging_mixin.py:115} INFO - [2022-06-06 16:45:00,585] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:45:00,588] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:45:00,683] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 16:45:31,466] {processor.py:153} INFO - Started process (PID=6925) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:45:31,468] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 16:45:31,472] {logging_mixin.py:115} INFO - [2022-06-06 16:45:31,470] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:45:31,548] {logging_mixin.py:115} INFO - [2022-06-06 16:45:31,545] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 16:45:31,550] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 16:45:31,655] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.199 seconds
[2022-06-06 17:02:31,196] {processor.py:153} INFO - Started process (PID=6981) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:02:31,197] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:02:31,198] {logging_mixin.py:115} INFO - [2022-06-06 17:02:31,198] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:02:31,290] {logging_mixin.py:115} INFO - [2022-06-06 17:02:31,282] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:02:31,293] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:02:31,569] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.377 seconds
[2022-06-06 17:03:01,648] {processor.py:153} INFO - Started process (PID=7049) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:03:01,650] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:03:01,651] {logging_mixin.py:115} INFO - [2022-06-06 17:03:01,651] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:03:01,732] {logging_mixin.py:115} INFO - [2022-06-06 17:03:01,730] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:03:01,734] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:03:01,826] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 17:03:32,837] {processor.py:153} INFO - Started process (PID=7117) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:03:32,841] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:03:32,842] {logging_mixin.py:115} INFO - [2022-06-06 17:03:32,842] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:03:32,896] {logging_mixin.py:115} INFO - [2022-06-06 17:03:32,895] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:03:32,898] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:03:32,992] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 17:04:03,561] {processor.py:153} INFO - Started process (PID=7186) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:04:03,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:04:03,565] {logging_mixin.py:115} INFO - [2022-06-06 17:04:03,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:04:03,620] {logging_mixin.py:115} INFO - [2022-06-06 17:04:03,619] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:04:03,624] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:04:03,716] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 17:04:34,377] {processor.py:153} INFO - Started process (PID=7253) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:04:34,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:04:34,380] {logging_mixin.py:115} INFO - [2022-06-06 17:04:34,380] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:04:34,440] {logging_mixin.py:115} INFO - [2022-06-06 17:04:34,437] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:04:34,443] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:04:34,554] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 17:05:05,389] {processor.py:153} INFO - Started process (PID=7309) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:05:05,390] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:05:05,391] {logging_mixin.py:115} INFO - [2022-06-06 17:05:05,391] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:05:05,439] {logging_mixin.py:115} INFO - [2022-06-06 17:05:05,437] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:05:05,441] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:05:05,547] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 17:05:35,589] {processor.py:153} INFO - Started process (PID=7374) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:05:35,591] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:05:35,593] {logging_mixin.py:115} INFO - [2022-06-06 17:05:35,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:05:35,649] {logging_mixin.py:115} INFO - [2022-06-06 17:05:35,646] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:05:35,650] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:05:35,742] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 17:06:05,865] {processor.py:153} INFO - Started process (PID=7442) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:06:05,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:06:05,869] {logging_mixin.py:115} INFO - [2022-06-06 17:06:05,869] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:06:05,915] {logging_mixin.py:115} INFO - [2022-06-06 17:06:05,913] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:06:05,916] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:06:06,010] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 17:06:36,183] {processor.py:153} INFO - Started process (PID=7510) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:06:36,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:06:36,188] {logging_mixin.py:115} INFO - [2022-06-06 17:06:36,188] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:06:36,244] {logging_mixin.py:115} INFO - [2022-06-06 17:06:36,242] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:06:36,247] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:06:36,343] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 17:07:06,416] {processor.py:153} INFO - Started process (PID=7576) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:07:06,418] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:07:06,419] {logging_mixin.py:115} INFO - [2022-06-06 17:07:06,419] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:07:06,464] {logging_mixin.py:115} INFO - [2022-06-06 17:07:06,461] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:07:06,465] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:07:06,582] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 17:07:36,826] {processor.py:153} INFO - Started process (PID=7637) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:07:36,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:07:36,829] {logging_mixin.py:115} INFO - [2022-06-06 17:07:36,829] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:07:36,877] {logging_mixin.py:115} INFO - [2022-06-06 17:07:36,875] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:07:36,879] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:07:36,985] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 17:08:07,097] {processor.py:153} INFO - Started process (PID=7708) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:08:07,102] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:08:07,104] {logging_mixin.py:115} INFO - [2022-06-06 17:08:07,103] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:08:07,161] {logging_mixin.py:115} INFO - [2022-06-06 17:08:07,159] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:08:07,162] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:08:07,255] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 17:08:37,422] {processor.py:153} INFO - Started process (PID=7777) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:08:37,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:08:37,427] {logging_mixin.py:115} INFO - [2022-06-06 17:08:37,427] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:08:37,483] {logging_mixin.py:115} INFO - [2022-06-06 17:08:37,480] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:08:37,484] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:08:37,576] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 17:09:07,656] {processor.py:153} INFO - Started process (PID=7846) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:09:07,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:09:07,658] {logging_mixin.py:115} INFO - [2022-06-06 17:09:07,658] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:09:07,709] {logging_mixin.py:115} INFO - [2022-06-06 17:09:07,706] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:09:07,711] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:09:07,806] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 17:09:38,749] {processor.py:153} INFO - Started process (PID=7912) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:09:38,751] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:09:38,755] {logging_mixin.py:115} INFO - [2022-06-06 17:09:38,752] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:09:38,815] {logging_mixin.py:115} INFO - [2022-06-06 17:09:38,812] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:09:38,817] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:09:38,934] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 17:10:09,081] {processor.py:153} INFO - Started process (PID=7973) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:10:09,084] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:10:09,086] {logging_mixin.py:115} INFO - [2022-06-06 17:10:09,086] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:10:09,137] {logging_mixin.py:115} INFO - [2022-06-06 17:10:09,135] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:10:09,138] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:10:09,232] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 17:10:39,329] {processor.py:153} INFO - Started process (PID=8041) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:10:39,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:10:39,335] {logging_mixin.py:115} INFO - [2022-06-06 17:10:39,335] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:10:39,386] {logging_mixin.py:115} INFO - [2022-06-06 17:10:39,384] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:10:39,388] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:10:39,481] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 17:11:09,809] {processor.py:153} INFO - Started process (PID=8109) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:11:09,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:11:09,813] {logging_mixin.py:115} INFO - [2022-06-06 17:11:09,813] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:11:09,861] {logging_mixin.py:115} INFO - [2022-06-06 17:11:09,858] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:11:09,861] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:11:09,954] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 17:11:40,226] {processor.py:153} INFO - Started process (PID=8176) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:11:40,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:11:40,230] {logging_mixin.py:115} INFO - [2022-06-06 17:11:40,230] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:11:40,281] {logging_mixin.py:115} INFO - [2022-06-06 17:11:40,279] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:11:40,282] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:11:40,374] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 17:12:10,482] {processor.py:153} INFO - Started process (PID=8234) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:12:10,484] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:12:10,485] {logging_mixin.py:115} INFO - [2022-06-06 17:12:10,485] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:12:10,529] {logging_mixin.py:115} INFO - [2022-06-06 17:12:10,526] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:12:10,530] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:12:10,630] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 17:12:40,879] {processor.py:153} INFO - Started process (PID=8305) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:12:40,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:12:40,883] {logging_mixin.py:115} INFO - [2022-06-06 17:12:40,883] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:12:40,934] {logging_mixin.py:115} INFO - [2022-06-06 17:12:40,933] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:12:40,936] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:12:41,031] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 17:13:11,086] {processor.py:153} INFO - Started process (PID=8374) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:13:11,090] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:13:11,092] {logging_mixin.py:115} INFO - [2022-06-06 17:13:11,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:13:11,150] {logging_mixin.py:115} INFO - [2022-06-06 17:13:11,148] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:13:11,151] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:13:11,254] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 17:13:41,679] {processor.py:153} INFO - Started process (PID=8442) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:13:41,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:13:41,682] {logging_mixin.py:115} INFO - [2022-06-06 17:13:41,682] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:13:41,732] {logging_mixin.py:115} INFO - [2022-06-06 17:13:41,729] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:13:41,734] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:13:41,828] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 17:14:12,027] {processor.py:153} INFO - Started process (PID=8509) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:14:12,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:14:12,031] {logging_mixin.py:115} INFO - [2022-06-06 17:14:12,031] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:14:12,086] {logging_mixin.py:115} INFO - [2022-06-06 17:14:12,083] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:14:12,087] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:14:12,183] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 17:14:42,394] {processor.py:153} INFO - Started process (PID=8566) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:14:42,396] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:14:42,398] {logging_mixin.py:115} INFO - [2022-06-06 17:14:42,398] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:14:42,448] {logging_mixin.py:115} INFO - [2022-06-06 17:14:42,446] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:14:42,449] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:14:42,546] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 17:15:12,600] {processor.py:153} INFO - Started process (PID=8637) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:15:12,603] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:15:12,605] {logging_mixin.py:115} INFO - [2022-06-06 17:15:12,605] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:15:12,689] {logging_mixin.py:115} INFO - [2022-06-06 17:15:12,687] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:15:12,691] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:15:12,786] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 17:15:43,002] {processor.py:153} INFO - Started process (PID=8703) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:15:43,004] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:15:43,005] {logging_mixin.py:115} INFO - [2022-06-06 17:15:43,005] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:15:43,057] {logging_mixin.py:115} INFO - [2022-06-06 17:15:43,054] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:15:43,058] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:15:43,159] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 17:16:13,297] {processor.py:153} INFO - Started process (PID=8772) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:16:13,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:16:13,301] {logging_mixin.py:115} INFO - [2022-06-06 17:16:13,301] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:16:13,360] {logging_mixin.py:115} INFO - [2022-06-06 17:16:13,357] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:16:13,362] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:16:13,461] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 17:16:44,085] {processor.py:153} INFO - Started process (PID=8841) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:16:44,087] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:16:44,088] {logging_mixin.py:115} INFO - [2022-06-06 17:16:44,088] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:16:44,148] {logging_mixin.py:115} INFO - [2022-06-06 17:16:44,145] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:16:44,149] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:16:44,247] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 17:17:14,308] {processor.py:153} INFO - Started process (PID=8897) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:17:14,311] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:17:14,314] {logging_mixin.py:115} INFO - [2022-06-06 17:17:14,313] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:17:14,374] {logging_mixin.py:115} INFO - [2022-06-06 17:17:14,372] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:17:14,376] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:17:14,477] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 17:32:51,011] {processor.py:153} INFO - Started process (PID=8954) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:32:51,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:32:51,016] {logging_mixin.py:115} INFO - [2022-06-06 17:32:51,015] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:32:51,160] {logging_mixin.py:115} INFO - [2022-06-06 17:32:51,151] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:32:51,161] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:32:51,639] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.631 seconds
[2022-06-06 17:33:21,734] {processor.py:153} INFO - Started process (PID=9023) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:33:21,736] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:33:21,737] {logging_mixin.py:115} INFO - [2022-06-06 17:33:21,737] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:33:21,805] {logging_mixin.py:115} INFO - [2022-06-06 17:33:21,802] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:33:21,806] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:33:21,911] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.182 seconds
[2022-06-06 17:34:35,759] {processor.py:153} INFO - Started process (PID=9081) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:34:35,760] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:34:35,762] {logging_mixin.py:115} INFO - [2022-06-06 17:34:35,762] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:34:35,815] {logging_mixin.py:115} INFO - [2022-06-06 17:34:35,813] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:34:35,816] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:34:35,921] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 17:35:06,758] {processor.py:153} INFO - Started process (PID=9147) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:35:06,761] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:35:06,764] {logging_mixin.py:115} INFO - [2022-06-06 17:35:06,764] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:35:06,821] {logging_mixin.py:115} INFO - [2022-06-06 17:35:06,818] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:35:06,822] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:35:06,923] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 17:36:20,419] {processor.py:153} INFO - Started process (PID=9214) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:36:20,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:36:20,423] {logging_mixin.py:115} INFO - [2022-06-06 17:36:20,423] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:36:20,481] {logging_mixin.py:115} INFO - [2022-06-06 17:36:20,479] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:36:20,482] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:36:20,582] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 17:36:51,262] {processor.py:153} INFO - Started process (PID=9282) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:36:51,264] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:36:51,265] {logging_mixin.py:115} INFO - [2022-06-06 17:36:51,265] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:36:51,344] {logging_mixin.py:115} INFO - [2022-06-06 17:36:51,342] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:36:51,345] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:36:51,439] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.183 seconds
[2022-06-06 17:37:28,428] {processor.py:153} INFO - Started process (PID=9349) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:37:28,430] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:37:28,432] {logging_mixin.py:115} INFO - [2022-06-06 17:37:28,432] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:37:28,497] {logging_mixin.py:115} INFO - [2022-06-06 17:37:28,494] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:37:28,499] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:37:28,602] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 17:38:41,801] {processor.py:153} INFO - Started process (PID=9408) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:38:41,803] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:38:41,805] {logging_mixin.py:115} INFO - [2022-06-06 17:38:41,804] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:38:41,852] {logging_mixin.py:115} INFO - [2022-06-06 17:38:41,849] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:38:41,853] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:38:41,946] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.148 seconds
[2022-06-06 17:39:12,824] {processor.py:153} INFO - Started process (PID=9475) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:39:12,826] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:39:12,827] {logging_mixin.py:115} INFO - [2022-06-06 17:39:12,827] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:39:12,878] {logging_mixin.py:115} INFO - [2022-06-06 17:39:12,876] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:39:12,880] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:39:12,972] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 17:40:26,257] {processor.py:153} INFO - Started process (PID=9541) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:40:26,258] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:40:26,259] {logging_mixin.py:115} INFO - [2022-06-06 17:40:26,259] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:40:26,303] {logging_mixin.py:115} INFO - [2022-06-06 17:40:26,301] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:40:26,304] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:40:26,429] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 17:40:57,054] {processor.py:153} INFO - Started process (PID=9612) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:40:57,056] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:40:57,057] {logging_mixin.py:115} INFO - [2022-06-06 17:40:57,057] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:40:57,104] {logging_mixin.py:115} INFO - [2022-06-06 17:40:57,101] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:40:57,106] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:40:57,206] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 17:42:12,266] {processor.py:153} INFO - Started process (PID=9670) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:42:12,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:42:12,270] {logging_mixin.py:115} INFO - [2022-06-06 17:42:12,270] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:42:12,312] {logging_mixin.py:115} INFO - [2022-06-06 17:42:12,311] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:42:12,313] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:42:12,408] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.145 seconds
[2022-06-06 17:43:38,076] {processor.py:153} INFO - Started process (PID=9736) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:43:38,077] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:43:38,079] {logging_mixin.py:115} INFO - [2022-06-06 17:43:38,079] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:43:38,136] {logging_mixin.py:115} INFO - [2022-06-06 17:43:38,133] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:43:38,138] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:43:38,281] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.207 seconds
[2022-06-06 17:44:08,518] {processor.py:153} INFO - Started process (PID=9805) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:44:08,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:44:08,521] {logging_mixin.py:115} INFO - [2022-06-06 17:44:08,521] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:44:08,574] {logging_mixin.py:115} INFO - [2022-06-06 17:44:08,572] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:44:08,575] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:44:08,678] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 17:45:29,341] {processor.py:153} INFO - Started process (PID=9874) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:45:29,343] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:45:29,344] {logging_mixin.py:115} INFO - [2022-06-06 17:45:29,344] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:45:29,398] {logging_mixin.py:115} INFO - [2022-06-06 17:45:29,396] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:45:29,400] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:45:29,505] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 17:46:00,445] {processor.py:153} INFO - Started process (PID=9945) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:46:00,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:46:00,448] {logging_mixin.py:115} INFO - [2022-06-06 17:46:00,448] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:46:00,526] {logging_mixin.py:115} INFO - [2022-06-06 17:46:00,524] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:46:00,527] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:46:00,663] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.225 seconds
[2022-06-06 17:46:31,270] {processor.py:153} INFO - Started process (PID=10002) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:46:31,273] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 17:46:31,274] {logging_mixin.py:115} INFO - [2022-06-06 17:46:31,274] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:46:31,332] {logging_mixin.py:115} INFO - [2022-06-06 17:46:31,330] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 17:46:31,334] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 17:46:31,426] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.169 seconds
[2022-06-06 18:04:15,762] {processor.py:153} INFO - Started process (PID=10069) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:04:15,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:04:15,772] {logging_mixin.py:115} INFO - [2022-06-06 18:04:15,772] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:04:16,002] {logging_mixin.py:115} INFO - [2022-06-06 18:04:15,994] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:04:16,004] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:04:16,441] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.684 seconds
[2022-06-06 18:04:47,001] {processor.py:153} INFO - Started process (PID=10143) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:04:47,003] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:04:47,005] {logging_mixin.py:115} INFO - [2022-06-06 18:04:47,005] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:04:47,095] {logging_mixin.py:115} INFO - [2022-06-06 18:04:47,093] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:04:47,096] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:04:47,200] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.210 seconds
[2022-06-06 18:05:53,264] {processor.py:153} INFO - Started process (PID=10200) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:05:53,266] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:05:53,268] {logging_mixin.py:115} INFO - [2022-06-06 18:05:53,267] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:05:53,320] {logging_mixin.py:115} INFO - [2022-06-06 18:05:53,319] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:05:53,323] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:05:53,415] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 18:06:23,459] {processor.py:153} INFO - Started process (PID=10269) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:06:23,461] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:06:23,462] {logging_mixin.py:115} INFO - [2022-06-06 18:06:23,462] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:06:23,522] {logging_mixin.py:115} INFO - [2022-06-06 18:06:23,520] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:06:23,523] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:06:23,620] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 18:22:51,561] {processor.py:153} INFO - Started process (PID=10337) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:22:51,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:22:51,565] {logging_mixin.py:115} INFO - [2022-06-06 18:22:51,565] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:22:51,774] {logging_mixin.py:115} INFO - [2022-06-06 18:22:51,766] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:22:51,783] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:22:52,155] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.598 seconds
[2022-06-06 18:23:22,625] {processor.py:153} INFO - Started process (PID=10407) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:23:22,632] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:23:22,634] {logging_mixin.py:115} INFO - [2022-06-06 18:23:22,634] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:23:22,690] {logging_mixin.py:115} INFO - [2022-06-06 18:23:22,688] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:23:22,691] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:23:22,806] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-06 18:23:53,742] {processor.py:153} INFO - Started process (PID=10474) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:23:53,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:23:53,745] {logging_mixin.py:115} INFO - [2022-06-06 18:23:53,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:23:53,798] {logging_mixin.py:115} INFO - [2022-06-06 18:23:53,795] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:23:53,802] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:23:53,893] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 18:24:24,457] {processor.py:153} INFO - Started process (PID=10532) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:24:24,459] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:24:24,460] {logging_mixin.py:115} INFO - [2022-06-06 18:24:24,460] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:24:24,505] {logging_mixin.py:115} INFO - [2022-06-06 18:24:24,501] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:24:24,506] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:24:24,597] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.143 seconds
[2022-06-06 18:24:55,229] {processor.py:153} INFO - Started process (PID=10600) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:24:55,231] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:24:55,233] {logging_mixin.py:115} INFO - [2022-06-06 18:24:55,233] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:24:55,291] {logging_mixin.py:115} INFO - [2022-06-06 18:24:55,290] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:24:55,293] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:24:55,387] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 18:25:25,959] {processor.py:153} INFO - Started process (PID=10666) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:25:25,963] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:25:25,965] {logging_mixin.py:115} INFO - [2022-06-06 18:25:25,964] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:25:26,024] {logging_mixin.py:115} INFO - [2022-06-06 18:25:26,022] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:25:26,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:25:26,118] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 18:25:56,748] {processor.py:153} INFO - Started process (PID=10735) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:25:56,749] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:25:56,751] {logging_mixin.py:115} INFO - [2022-06-06 18:25:56,751] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:25:56,830] {logging_mixin.py:115} INFO - [2022-06-06 18:25:56,828] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:25:56,832] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:25:56,940] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.195 seconds
[2022-06-06 18:26:27,514] {processor.py:153} INFO - Started process (PID=10802) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:26:27,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:26:27,520] {logging_mixin.py:115} INFO - [2022-06-06 18:26:27,519] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:26:27,597] {logging_mixin.py:115} INFO - [2022-06-06 18:26:27,594] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:26:27,598] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:26:27,700] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.192 seconds
[2022-06-06 18:26:58,365] {processor.py:153} INFO - Started process (PID=10868) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:26:58,367] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:26:58,369] {logging_mixin.py:115} INFO - [2022-06-06 18:26:58,369] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:26:58,427] {logging_mixin.py:115} INFO - [2022-06-06 18:26:58,424] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:26:58,428] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:26:58,521] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 18:27:28,890] {processor.py:153} INFO - Started process (PID=10924) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:27:28,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:27:28,893] {logging_mixin.py:115} INFO - [2022-06-06 18:27:28,893] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:27:28,938] {logging_mixin.py:115} INFO - [2022-06-06 18:27:28,936] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:27:28,940] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:27:29,045] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 18:27:59,745] {processor.py:153} INFO - Started process (PID=10994) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:27:59,748] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:27:59,750] {logging_mixin.py:115} INFO - [2022-06-06 18:27:59,750] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:27:59,817] {logging_mixin.py:115} INFO - [2022-06-06 18:27:59,815] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:27:59,818] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:27:59,919] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 18:28:30,430] {processor.py:153} INFO - Started process (PID=11059) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:28:30,432] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:28:30,433] {logging_mixin.py:115} INFO - [2022-06-06 18:28:30,432] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:28:30,482] {logging_mixin.py:115} INFO - [2022-06-06 18:28:30,479] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:28:30,483] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:28:30,580] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 18:29:01,057] {processor.py:153} INFO - Started process (PID=11127) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:29:01,059] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:29:01,061] {logging_mixin.py:115} INFO - [2022-06-06 18:29:01,061] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:29:01,104] {logging_mixin.py:115} INFO - [2022-06-06 18:29:01,102] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:29:01,105] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:29:01,200] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 18:29:31,676] {processor.py:153} INFO - Started process (PID=11196) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:29:31,679] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:29:31,681] {logging_mixin.py:115} INFO - [2022-06-06 18:29:31,681] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:29:31,739] {logging_mixin.py:115} INFO - [2022-06-06 18:29:31,737] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:29:31,741] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:29:31,836] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 18:30:02,447] {processor.py:153} INFO - Started process (PID=11261) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:30:02,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:30:02,451] {logging_mixin.py:115} INFO - [2022-06-06 18:30:02,451] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:30:02,507] {logging_mixin.py:115} INFO - [2022-06-06 18:30:02,505] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:30:02,509] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:30:02,600] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 18:30:33,043] {processor.py:153} INFO - Started process (PID=11331) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:30:33,044] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:30:33,045] {logging_mixin.py:115} INFO - [2022-06-06 18:30:33,045] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:30:33,102] {logging_mixin.py:115} INFO - [2022-06-06 18:30:33,099] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:30:33,104] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:30:33,210] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 18:31:04,067] {processor.py:153} INFO - Started process (PID=11390) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:31:04,070] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:31:04,072] {logging_mixin.py:115} INFO - [2022-06-06 18:31:04,072] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:31:04,134] {logging_mixin.py:115} INFO - [2022-06-06 18:31:04,131] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:31:04,135] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:31:04,228] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 18:31:34,300] {processor.py:153} INFO - Started process (PID=11455) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:31:34,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:31:34,303] {logging_mixin.py:115} INFO - [2022-06-06 18:31:34,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:31:34,371] {logging_mixin.py:115} INFO - [2022-06-06 18:31:34,369] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:31:34,373] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:31:34,467] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 18:32:04,742] {processor.py:153} INFO - Started process (PID=11522) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:32:04,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:32:04,744] {logging_mixin.py:115} INFO - [2022-06-06 18:32:04,744] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:32:04,795] {logging_mixin.py:115} INFO - [2022-06-06 18:32:04,793] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:32:04,796] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:32:04,900] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 18:32:35,078] {processor.py:153} INFO - Started process (PID=11589) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:32:35,081] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:32:35,085] {logging_mixin.py:115} INFO - [2022-06-06 18:32:35,085] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:32:35,142] {logging_mixin.py:115} INFO - [2022-06-06 18:32:35,140] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:32:35,144] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:32:35,238] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 18:33:05,431] {processor.py:153} INFO - Started process (PID=11656) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:33:05,432] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:33:05,433] {logging_mixin.py:115} INFO - [2022-06-06 18:33:05,433] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:33:05,488] {logging_mixin.py:115} INFO - [2022-06-06 18:33:05,485] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:33:05,489] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:33:05,584] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 18:33:36,103] {processor.py:153} INFO - Started process (PID=11715) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:33:36,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:33:36,107] {logging_mixin.py:115} INFO - [2022-06-06 18:33:36,107] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:33:36,163] {logging_mixin.py:115} INFO - [2022-06-06 18:33:36,161] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:33:36,165] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:33:36,258] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 18:34:06,737] {processor.py:153} INFO - Started process (PID=11782) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:34:06,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:34:06,739] {logging_mixin.py:115} INFO - [2022-06-06 18:34:06,739] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:34:06,784] {logging_mixin.py:115} INFO - [2022-06-06 18:34:06,782] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:34:06,785] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:34:06,876] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.141 seconds
[2022-06-06 18:34:37,508] {processor.py:153} INFO - Started process (PID=11848) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:34:37,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:34:37,515] {logging_mixin.py:115} INFO - [2022-06-06 18:34:37,514] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:34:37,575] {logging_mixin.py:115} INFO - [2022-06-06 18:34:37,573] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:34:37,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:34:37,673] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.171 seconds
[2022-06-06 18:35:08,453] {processor.py:153} INFO - Started process (PID=11918) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:35:08,456] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:35:08,458] {logging_mixin.py:115} INFO - [2022-06-06 18:35:08,458] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:35:08,520] {logging_mixin.py:115} INFO - [2022-06-06 18:35:08,517] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:35:08,521] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:35:08,617] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 18:35:39,047] {processor.py:153} INFO - Started process (PID=11988) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:35:39,049] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:35:39,050] {logging_mixin.py:115} INFO - [2022-06-06 18:35:39,050] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:35:39,093] {logging_mixin.py:115} INFO - [2022-06-06 18:35:39,091] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:35:39,094] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:35:39,186] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.142 seconds
[2022-06-06 18:36:09,679] {processor.py:153} INFO - Started process (PID=12056) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:36:09,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:36:09,683] {logging_mixin.py:115} INFO - [2022-06-06 18:36:09,682] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:36:09,725] {logging_mixin.py:115} INFO - [2022-06-06 18:36:09,723] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:36:09,728] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:36:09,823] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 18:36:40,329] {processor.py:153} INFO - Started process (PID=12113) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:36:40,331] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:36:40,333] {logging_mixin.py:115} INFO - [2022-06-06 18:36:40,332] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:36:40,386] {logging_mixin.py:115} INFO - [2022-06-06 18:36:40,384] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:36:40,387] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:36:40,479] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 18:37:11,004] {processor.py:153} INFO - Started process (PID=12181) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:37:11,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:37:11,009] {logging_mixin.py:115} INFO - [2022-06-06 18:37:11,009] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:37:11,053] {logging_mixin.py:115} INFO - [2022-06-06 18:37:11,050] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:37:11,055] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:37:11,156] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.156 seconds
[2022-06-06 18:37:41,709] {processor.py:153} INFO - Started process (PID=12248) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:37:41,712] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:37:41,713] {logging_mixin.py:115} INFO - [2022-06-06 18:37:41,713] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:37:41,763] {logging_mixin.py:115} INFO - [2022-06-06 18:37:41,760] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:37:41,764] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:37:41,855] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.149 seconds
[2022-06-06 18:53:01,953] {processor.py:153} INFO - Started process (PID=12289) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:53:01,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:53:01,957] {logging_mixin.py:115} INFO - [2022-06-06 18:53:01,957] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:53:02,261] {logging_mixin.py:115} INFO - [2022-06-06 18:53:02,252] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:53:02,266] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:53:02,703] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.757 seconds
[2022-06-06 18:53:33,299] {processor.py:153} INFO - Started process (PID=12353) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:53:33,301] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:53:33,303] {logging_mixin.py:115} INFO - [2022-06-06 18:53:33,303] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:53:33,380] {logging_mixin.py:115} INFO - [2022-06-06 18:53:33,377] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:53:33,381] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:53:33,482] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.187 seconds
[2022-06-06 18:54:49,109] {processor.py:153} INFO - Started process (PID=12411) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:54:49,111] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:54:49,113] {logging_mixin.py:115} INFO - [2022-06-06 18:54:49,112] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:54:49,170] {logging_mixin.py:115} INFO - [2022-06-06 18:54:49,168] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:54:49,172] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:54:49,274] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 18:55:20,010] {processor.py:153} INFO - Started process (PID=12482) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:55:20,011] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:55:20,012] {logging_mixin.py:115} INFO - [2022-06-06 18:55:20,012] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:55:20,066] {logging_mixin.py:115} INFO - [2022-06-06 18:55:20,062] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:55:20,067] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:55:20,172] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.164 seconds
[2022-06-06 18:56:28,191] {processor.py:153} INFO - Started process (PID=12550) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:56:28,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:56:28,193] {logging_mixin.py:115} INFO - [2022-06-06 18:56:28,193] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:56:28,243] {logging_mixin.py:115} INFO - [2022-06-06 18:56:28,241] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:56:28,245] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:56:28,336] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 18:56:58,984] {processor.py:153} INFO - Started process (PID=12622) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:56:58,986] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:56:58,988] {logging_mixin.py:115} INFO - [2022-06-06 18:56:58,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:56:59,055] {logging_mixin.py:115} INFO - [2022-06-06 18:56:59,052] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:56:59,056] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:56:59,151] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.176 seconds
[2022-06-06 18:57:29,790] {processor.py:153} INFO - Started process (PID=12689) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:57:29,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:57:29,794] {logging_mixin.py:115} INFO - [2022-06-06 18:57:29,794] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:57:29,868] {logging_mixin.py:115} INFO - [2022-06-06 18:57:29,866] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:57:29,869] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:57:29,971] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.184 seconds
[2022-06-06 18:58:00,583] {processor.py:153} INFO - Started process (PID=12757) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:58:00,585] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:58:00,586] {logging_mixin.py:115} INFO - [2022-06-06 18:58:00,586] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:58:00,639] {logging_mixin.py:115} INFO - [2022-06-06 18:58:00,637] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:58:00,642] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:58:00,753] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 18:59:07,268] {processor.py:153} INFO - Started process (PID=12815) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:59:07,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 18:59:07,272] {logging_mixin.py:115} INFO - [2022-06-06 18:59:07,272] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:59:07,333] {logging_mixin.py:115} INFO - [2022-06-06 18:59:07,331] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 18:59:07,334] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 18:59:07,430] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.167 seconds
[2022-06-06 19:00:30,897] {processor.py:153} INFO - Started process (PID=12882) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:00:30,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:00:30,901] {logging_mixin.py:115} INFO - [2022-06-06 19:00:30,901] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:00:30,947] {logging_mixin.py:115} INFO - [2022-06-06 19:00:30,944] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:00:30,949] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:00:31,044] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 19:01:01,282] {processor.py:153} INFO - Started process (PID=12950) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:01:01,285] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:01:01,286] {logging_mixin.py:115} INFO - [2022-06-06 19:01:01,286] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:01:01,341] {logging_mixin.py:115} INFO - [2022-06-06 19:01:01,339] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:01:01,343] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:01:01,436] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.157 seconds
[2022-06-06 19:02:23,827] {processor.py:153} INFO - Started process (PID=13007) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:02:23,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:02:23,830] {logging_mixin.py:115} INFO - [2022-06-06 19:02:23,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:02:23,885] {logging_mixin.py:115} INFO - [2022-06-06 19:02:23,882] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:02:23,888] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:02:23,983] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.159 seconds
[2022-06-06 19:02:54,176] {processor.py:153} INFO - Started process (PID=13075) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:02:54,178] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:02:54,179] {logging_mixin.py:115} INFO - [2022-06-06 19:02:54,179] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:02:54,224] {logging_mixin.py:115} INFO - [2022-06-06 19:02:54,222] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:02:54,226] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:02:54,319] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 19:04:10,781] {processor.py:153} INFO - Started process (PID=13142) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:04:10,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:04:10,785] {logging_mixin.py:115} INFO - [2022-06-06 19:04:10,784] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:04:10,842] {logging_mixin.py:115} INFO - [2022-06-06 19:04:10,839] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:04:10,844] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:04:10,938] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.162 seconds
[2022-06-06 19:05:28,835] {processor.py:153} INFO - Started process (PID=13210) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:05:28,837] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:05:28,838] {logging_mixin.py:115} INFO - [2022-06-06 19:05:28,838] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:05:28,893] {logging_mixin.py:115} INFO - [2022-06-06 19:05:28,891] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:05:28,894] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:05:28,990] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.158 seconds
[2022-06-06 19:05:59,818] {processor.py:153} INFO - Started process (PID=13276) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:05:59,819] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:05:59,820] {logging_mixin.py:115} INFO - [2022-06-06 19:05:59,820] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:05:59,893] {logging_mixin.py:115} INFO - [2022-06-06 19:05:59,884] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:05:59,895] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:06:00,003] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.188 seconds
[2022-06-06 19:06:33,854] {processor.py:153} INFO - Started process (PID=13335) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:06:33,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:06:33,858] {logging_mixin.py:115} INFO - [2022-06-06 19:06:33,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:06:33,926] {logging_mixin.py:115} INFO - [2022-06-06 19:06:33,923] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:06:33,928] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:06:34,025] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 19:07:04,119] {processor.py:153} INFO - Started process (PID=13402) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:07:04,121] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:07:04,123] {logging_mixin.py:115} INFO - [2022-06-06 19:07:04,123] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:07:04,191] {logging_mixin.py:115} INFO - [2022-06-06 19:07:04,189] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:07:04,193] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:07:04,287] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.174 seconds
[2022-06-06 19:08:15,820] {processor.py:153} INFO - Started process (PID=13472) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:08:15,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:08:15,822] {logging_mixin.py:115} INFO - [2022-06-06 19:08:15,822] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:08:15,876] {logging_mixin.py:115} INFO - [2022-06-06 19:08:15,873] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:08:15,877] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:08:15,970] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.153 seconds
[2022-06-06 19:08:46,650] {processor.py:153} INFO - Started process (PID=13529) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:08:46,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:08:46,655] {logging_mixin.py:115} INFO - [2022-06-06 19:08:46,655] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:08:46,717] {logging_mixin.py:115} INFO - [2022-06-06 19:08:46,714] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:08:46,717] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:08:46,823] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.180 seconds
[2022-06-06 19:09:55,422] {processor.py:153} INFO - Started process (PID=13594) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:09:55,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:09:55,425] {logging_mixin.py:115} INFO - [2022-06-06 19:09:55,425] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:09:55,489] {logging_mixin.py:115} INFO - [2022-06-06 19:09:55,487] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:09:55,490] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:09:55,596] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.177 seconds
[2022-06-06 19:10:26,327] {processor.py:153} INFO - Started process (PID=13667) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:10:26,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:10:26,334] {logging_mixin.py:115} INFO - [2022-06-06 19:10:26,334] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:10:26,390] {logging_mixin.py:115} INFO - [2022-06-06 19:10:26,388] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:10:26,391] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:10:26,486] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 19:11:50,343] {processor.py:153} INFO - Started process (PID=13736) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:11:50,345] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:11:50,346] {logging_mixin.py:115} INFO - [2022-06-06 19:11:50,346] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:11:50,400] {logging_mixin.py:115} INFO - [2022-06-06 19:11:50,398] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:11:50,402] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:11:50,500] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 19:12:21,050] {processor.py:153} INFO - Started process (PID=13800) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:12:21,052] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:12:21,053] {logging_mixin.py:115} INFO - [2022-06-06 19:12:21,053] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:12:21,096] {logging_mixin.py:115} INFO - [2022-06-06 19:12:21,094] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:12:21,097] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:12:21,198] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 19:13:31,248] {processor.py:153} INFO - Started process (PID=13863) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:13:31,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:13:31,250] {logging_mixin.py:115} INFO - [2022-06-06 19:13:31,250] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:13:31,305] {logging_mixin.py:115} INFO - [2022-06-06 19:13:31,303] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:13:31,307] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:13:31,411] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 19:14:42,163] {processor.py:153} INFO - Started process (PID=13930) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:14:42,164] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:14:42,165] {logging_mixin.py:115} INFO - [2022-06-06 19:14:42,165] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:14:42,213] {logging_mixin.py:115} INFO - [2022-06-06 19:14:42,211] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:14:42,214] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:14:42,307] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.147 seconds
[2022-06-06 19:15:13,097] {processor.py:153} INFO - Started process (PID=14000) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:15:13,099] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:15:13,102] {logging_mixin.py:115} INFO - [2022-06-06 19:15:13,102] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:15:13,188] {logging_mixin.py:115} INFO - [2022-06-06 19:15:13,184] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:15:13,190] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:15:13,290] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.202 seconds
[2022-06-06 19:16:38,488] {processor.py:153} INFO - Started process (PID=14058) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:16:38,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:16:38,490] {logging_mixin.py:115} INFO - [2022-06-06 19:16:38,490] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:16:38,564] {logging_mixin.py:115} INFO - [2022-06-06 19:16:38,562] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:16:38,565] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:16:38,659] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.173 seconds
[2022-06-06 19:17:09,527] {processor.py:153} INFO - Started process (PID=14126) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:17:09,530] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:17:09,531] {logging_mixin.py:115} INFO - [2022-06-06 19:17:09,531] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:17:09,581] {logging_mixin.py:115} INFO - [2022-06-06 19:17:09,579] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:17:09,582] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:17:09,675] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.152 seconds
[2022-06-06 19:18:18,809] {processor.py:153} INFO - Started process (PID=14193) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:18:18,811] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:18:18,813] {logging_mixin.py:115} INFO - [2022-06-06 19:18:18,813] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:18:18,870] {logging_mixin.py:115} INFO - [2022-06-06 19:18:18,868] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:18:18,872] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:18:18,967] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 19:19:28,005] {processor.py:153} INFO - Started process (PID=14261) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:19:28,008] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:19:28,009] {logging_mixin.py:115} INFO - [2022-06-06 19:19:28,009] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:19:28,070] {logging_mixin.py:115} INFO - [2022-06-06 19:19:28,067] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:19:28,072] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:19:28,166] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.166 seconds
[2022-06-06 19:19:59,005] {processor.py:153} INFO - Started process (PID=14328) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:19:59,008] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:19:59,009] {logging_mixin.py:115} INFO - [2022-06-06 19:19:59,009] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:19:59,066] {logging_mixin.py:115} INFO - [2022-06-06 19:19:59,062] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:19:59,067] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:19:59,183] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.181 seconds
[2022-06-06 19:21:06,314] {processor.py:153} INFO - Started process (PID=14387) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:21:06,316] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:21:06,317] {logging_mixin.py:115} INFO - [2022-06-06 19:21:06,317] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:21:06,369] {logging_mixin.py:115} INFO - [2022-06-06 19:21:06,367] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:21:06,370] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:21:06,461] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.150 seconds
[2022-06-06 19:21:37,159] {processor.py:153} INFO - Started process (PID=14454) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:21:37,161] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:21:37,162] {logging_mixin.py:115} INFO - [2022-06-06 19:21:37,162] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:21:37,216] {logging_mixin.py:115} INFO - [2022-06-06 19:21:37,215] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:21:37,217] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:21:37,310] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 19:22:17,333] {processor.py:153} INFO - Started process (PID=14521) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:22:17,335] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:22:17,336] {logging_mixin.py:115} INFO - [2022-06-06 19:22:17,336] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:22:17,405] {logging_mixin.py:115} INFO - [2022-06-06 19:22:17,402] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:22:17,406] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:22:17,500] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.170 seconds
[2022-06-06 19:22:47,618] {processor.py:153} INFO - Started process (PID=14589) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:22:47,619] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:22:47,620] {logging_mixin.py:115} INFO - [2022-06-06 19:22:47,620] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:22:47,665] {logging_mixin.py:115} INFO - [2022-06-06 19:22:47,663] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:22:47,666] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:22:47,781] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 19:24:05,528] {processor.py:153} INFO - Started process (PID=14646) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:24:05,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:24:05,530] {logging_mixin.py:115} INFO - [2022-06-06 19:24:05,530] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:24:05,575] {logging_mixin.py:115} INFO - [2022-06-06 19:24:05,573] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:24:05,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:24:05,669] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.144 seconds
[2022-06-06 19:25:16,902] {processor.py:153} INFO - Started process (PID=14714) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:25:16,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:25:16,905] {logging_mixin.py:115} INFO - [2022-06-06 19:25:16,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:25:16,966] {logging_mixin.py:115} INFO - [2022-06-06 19:25:16,964] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:25:16,968] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:25:17,063] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.168 seconds
[2022-06-06 19:25:47,753] {processor.py:153} INFO - Started process (PID=14783) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:25:47,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:25:47,758] {logging_mixin.py:115} INFO - [2022-06-06 19:25:47,758] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:25:47,813] {logging_mixin.py:115} INFO - [2022-06-06 19:25:47,811] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:25:47,814] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:25:47,908] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.161 seconds
[2022-06-06 19:27:04,227] {processor.py:153} INFO - Started process (PID=14851) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:27:04,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:27:04,229] {logging_mixin.py:115} INFO - [2022-06-06 19:27:04,229] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:27:04,275] {logging_mixin.py:115} INFO - [2022-06-06 19:27:04,273] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:27:04,277] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:27:04,375] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.151 seconds
[2022-06-06 19:27:35,212] {processor.py:153} INFO - Started process (PID=14909) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:27:35,215] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:27:35,218] {logging_mixin.py:115} INFO - [2022-06-06 19:27:35,218] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:27:35,270] {logging_mixin.py:115} INFO - [2022-06-06 19:27:35,267] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:27:35,271] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:27:35,362] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 19:28:44,064] {processor.py:153} INFO - Started process (PID=14976) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:28:44,065] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:28:44,067] {logging_mixin.py:115} INFO - [2022-06-06 19:28:44,067] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:28:44,110] {logging_mixin.py:115} INFO - [2022-06-06 19:28:44,108] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:28:44,113] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:28:44,216] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.155 seconds
[2022-06-06 19:29:14,844] {processor.py:153} INFO - Started process (PID=15044) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:29:14,846] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:29:14,847] {logging_mixin.py:115} INFO - [2022-06-06 19:29:14,847] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:29:14,902] {logging_mixin.py:115} INFO - [2022-06-06 19:29:14,899] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:29:14,903] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:29:15,006] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.163 seconds
[2022-06-06 19:30:37,658] {processor.py:153} INFO - Started process (PID=15110) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:30:37,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:30:37,662] {logging_mixin.py:115} INFO - [2022-06-06 19:30:37,662] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:30:37,710] {logging_mixin.py:115} INFO - [2022-06-06 19:30:37,708] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:30:37,712] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:30:37,815] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.160 seconds
[2022-06-06 19:31:52,174] {processor.py:153} INFO - Started process (PID=15167) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:31:52,176] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:31:52,178] {logging_mixin.py:115} INFO - [2022-06-06 19:31:52,178] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:31:52,235] {logging_mixin.py:115} INFO - [2022-06-06 19:31:52,232] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:31:52,236] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:31:52,333] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.165 seconds
[2022-06-06 19:32:22,387] {processor.py:153} INFO - Started process (PID=15236) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:32:22,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:32:22,390] {logging_mixin.py:115} INFO - [2022-06-06 19:32:22,390] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:32:22,436] {logging_mixin.py:115} INFO - [2022-06-06 19:32:22,433] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:32:22,438] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:32:22,536] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.154 seconds
[2022-06-06 19:47:51,794] {processor.py:153} INFO - Started process (PID=15307) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:47:51,796] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:47:51,797] {logging_mixin.py:115} INFO - [2022-06-06 19:47:51,797] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:47:51,987] {logging_mixin.py:115} INFO - [2022-06-06 19:47:51,971] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:47:51,989] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:47:52,281] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.490 seconds
[2022-06-06 19:48:22,740] {processor.py:153} INFO - Started process (PID=15374) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:48:22,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 19:48:22,745] {logging_mixin.py:115} INFO - [2022-06-06 19:48:22,745] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:48:22,809] {logging_mixin.py:115} INFO - [2022-06-06 19:48:22,807] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 19:48:22,810] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 19:48:22,910] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.179 seconds
[2022-06-06 21:23:23,978] {processor.py:153} INFO - Started process (PID=15430) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 21:23:23,986] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 21:23:23,988] {logging_mixin.py:115} INFO - [2022-06-06 21:23:23,988] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 21:23:24,188] {logging_mixin.py:115} INFO - [2022-06-06 21:23:24,176] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 21:23:24,190] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 21:23:24,406] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.434 seconds
[2022-06-06 22:45:26,922] {processor.py:153} INFO - Started process (PID=15495) to work on /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 22:45:26,930] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_consumer_DAG.py for tasks to queue
[2022-06-06 22:45:26,932] {logging_mixin.py:115} INFO - [2022-06-06 22:45:26,932] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 22:45:27,096] {logging_mixin.py:115} INFO - [2022-06-06 22:45:27,093] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_consumer_DAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_consumer_DAG.py", line 51, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 190, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: pyspark_consumer). Invalid arguments were:
**kwargs: {'volumes': ['/usr/local/airflow/dags/src/spark_consume_data:/spark_consume_data']}
[2022-06-06 22:45:27,100] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_consumer_DAG.py
[2022-06-06 22:45:27,373] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_consumer_DAG.py took 0.465 seconds
